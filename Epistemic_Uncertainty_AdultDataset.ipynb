{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-483: Big Data Mining - Progress Report\n",
    "# Interpreting Algorithmic Fairness via Aleatoric and Epistemic Uncertainties\n",
    "##### By Zohair Hashmi | Sajal Chandra | Rayaan Siddiqi | Sean Kudrna\n",
    "\n",
    "### Part 1 : Epistemic Uncertainty & Fairness Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "`load_boston` has been removed from scikit-learn since version 1.2.\n",
      "\n",
      "The Boston housing prices dataset has an ethical problem: as\n",
      "investigated in [1], the authors of this dataset engineered a\n",
      "non-invertible variable \"B\" assuming that racial self-segregation had a\n",
      "positive impact on house prices [2]. Furthermore the goal of the\n",
      "research that led to the creation of this dataset was to study the\n",
      "impact of air quality but it did not give adequate demonstration of the\n",
      "validity of this assumption.\n",
      "\n",
      "The scikit-learn maintainers therefore strongly discourage the use of\n",
      "this dataset unless the purpose of the code is to study and educate\n",
      "about ethical issues in data science and machine learning.\n",
      "\n",
      "In this special case, you can fetch the dataset from the original\n",
      "source::\n",
      "\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "\n",
      "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "    target = raw_df.values[1::2, 2]\n",
      "\n",
      "Alternative datasets include the California housing dataset and the\n",
      "Ames housing dataset. You can load the datasets as follows::\n",
      "\n",
      "    from sklearn.datasets import fetch_california_housing\n",
      "    housing = fetch_california_housing()\n",
      "\n",
      "for the California housing dataset and::\n",
      "\n",
      "    from sklearn.datasets import fetch_openml\n",
      "    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "for the Ames housing dataset.\n",
      "\n",
      "[1] M Carlisle.\n",
      "\"Racist data destruction?\"\n",
      "<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n",
      "\n",
      "[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n",
      "\"Hedonic housing prices and the demand for clean air.\"\n",
      "Journal of environmental economics and management 5.1 (1978): 81-102.\n",
      "<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
      ": LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keras Uncertainty will use standalone Keras backend"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.datasets import StructuredDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_german\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import keras_uncertainty as ku\n",
    "import keras_uncertainty.backend as K\n",
    "\n",
    "from keras_uncertainty.layers import StochasticDropout\n",
    "from keras_uncertainty.layers import DropConnectDense, VariationalDense, FlipoutDense, SamplingSoftmax\n",
    "from keras_uncertainty.utils import numpy_entropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATASET FROM AIF360\n",
    "\n",
    "Currently we are working with \"Adult Dataset\" in this notebook. The following code loads the dataset from AIF360. The dataset is already split into train and test sets. We will use the train set to train our models and the test set to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39073, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Test Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9769, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'race']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Priveleged and unpriveleged groups"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sex': 1}] [{'sex': 0}]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset_orig = load_preproc_data_adult()\n",
    "\n",
    "# split into train and test\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.80], shuffle=True)\n",
    "\n",
    "# priveleged and unpriveleged groups\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Test Dataset shape\"))\n",
    "print(dataset_orig_test.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Priveleged and unpriveleged groups\"))\n",
    "print(privileged_groups, unprivileged_groups)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_frac = np.round(np.linspace(0.1, 1.0, 10), 1)\n",
    "dataset_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_orig_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m train_sets \u001b[39m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m frac \u001b[39min\u001b[39;00m dataset_frac:\n\u001b[1;32m----> 5\u001b[0m     train_sets[frac] \u001b[39m=\u001b[39m dataset_orig_train\u001b[39m.\u001b[39mcopy(deepcopy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m     train_sets[frac] \u001b[39m=\u001b[39m train_sets[frac]\u001b[39m.\u001b[39msplit([frac], shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[39m#print shape of each train set\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_orig_train' is not defined"
     ]
    }
   ],
   "source": [
    "# prepare all possible train sets with different pruning percentages \n",
    "# and store them in a dictionary\n",
    "train_sets = {}\n",
    "for frac in dataset_frac:\n",
    "    train_sets[frac] = dataset_orig_train.copy(deepcopy=True)\n",
    "    train_sets[frac] = train_sets[frac].split([frac], shuffle=True)[0]\n",
    "\n",
    "#print shape of each train set\n",
    "for frac in dataset_frac:\n",
    "    print(\"{}% of the data set: \".format(frac*100), end=\" \")\n",
    "    print(train_sets[frac].features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train group A features & labels shape for pruning percentage 10.0 :\t (3907, 18) (3907, 1)\n",
      "Train group A features & labels shape for pruning percentage 20.0 :\t (7814, 18) (7814, 1)\n",
      "Train group A features & labels shape for pruning percentage 30.0 :\t (11721, 18) (11721, 1)\n",
      "Train group A features & labels shape for pruning percentage 40.0 :\t (15629, 18) (15629, 1)\n",
      "Train group A features & labels shape for pruning percentage 50.0 :\t (19536, 18) (19536, 1)\n",
      "Train group A features & labels shape for pruning percentage 60.0 :\t (23443, 18) (23443, 1)\n",
      "Train group A features & labels shape for pruning percentage 70.0 :\t (27351, 18) (27351, 1)\n",
      "Train group A features & labels shape for pruning percentage 80.0 :\t (31258, 18) (31258, 1)\n",
      "Train group A features & labels shape for pruning percentage 90.0 :\t (35165, 18) (35165, 1)\n",
      "Train group A features & labels shape for pruning percentage 100.0 :\t (39073, 18) (39073, 1)\n"
     ]
    }
   ],
   "source": [
    "#print the shape of each train group A\n",
    "for i in range(10):\n",
    "    print(\"Train group A features & labels shape for pruning percentage\", dataset_frac[i]*100, \":\\t\", train_sets[dataset_frac[i]].features.shape, train_sets[dataset_frac[i]].labels.shape)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above files are now stored as .pkl files in the directory. Use these files directly for running model tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_sets to file\n",
    "import pickle\n",
    "with open('adult_results/adult_train_sets.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_sets, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# save test set to file\n",
    "with open('adult_results/adult_test_set.pickle', 'wb') as handle:\n",
    "    pickle.dump(dataset_orig_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset from the .pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train sets from file\n",
    "import pickle\n",
    "with open('adult_results/adult_train_sets.pickle', 'rb') as handle:\n",
    "    train_sets = pickle.load(handle)\n",
    "\n",
    "# load test set from file\n",
    "with open('adult_results/adult_test_set.pickle', 'rb') as handle:\n",
    "    dataset_orig_test = pickle.load(handle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:84: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:84: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Zohair Hashmi\\AppData\\Local\\Temp\\ipykernel_1144\\1140481961.py:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.variance_type is \"logit\":\n",
      "C:\\Users\\Zohair Hashmi\\AppData\\Local\\Temp\\ipykernel_1144\\1140481961.py:84: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.variance_type is \"linear_variance\":\n"
     ]
    }
   ],
   "source": [
    "class StochasticModel:\n",
    "    \"\"\"\n",
    "        Stochastic model, requiring several forward passes to produce an estimate of the posterior predictive distribution.\n",
    "        This class just wraps a keras model to enable dropout at inference time.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, num_samples=10):\n",
    "        \"\"\"\n",
    "            Builds a stochastic model from a keras model. The model should already be trained.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.num_samples = num_samples\n",
    "    \n",
    "    def predict_samples(self, x, num_samples=None, batch_size=1, multi_output=False, **kwargs):\n",
    "        \"\"\"\n",
    "            Performs num_samples predictions using the model, and returns the produced output samples.\n",
    "        \"\"\"\n",
    "\n",
    "        if num_samples is None:\n",
    "            num_samples = self.num_samples\n",
    "\n",
    "        assert num_samples > 0\n",
    "        samples = [None] * num_samples\n",
    "\n",
    "        if \"verbose\" not in kwargs:\n",
    "            kwargs[\"verbose\"] = 0\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            samples[i] = self.model.predict(x, batch_size=batch_size, **kwargs)\n",
    "\n",
    "        if multi_output:\n",
    "            return samples\n",
    "        else:\n",
    "            return np.array(samples)\n",
    "\n",
    "class StochasticClassifier(StochasticModel):\n",
    "    def __init__(self, model, num_samples=10):\n",
    "        super().__init__(model, num_samples)\n",
    "\n",
    "    def predict(self, inp, num_samples=None, batch_size=32, **kwargs):\n",
    "        \"\"\"\n",
    "            Performs a prediction given input inp using MC Dropout, and returns the averaged probabilities of model output.\n",
    "        \"\"\"\n",
    "        samples = self.predict_samples(inp, num_samples, batch_size=batch_size, **kwargs)\n",
    "        mean_probs = np.mean(samples, axis=0)\n",
    "        mean_probs = mean_probs / np.sum(mean_probs, axis=1, keepdims=True)\n",
    "\n",
    "        return mean_probs\n",
    "\n",
    "class  StochasticRegressor(StochasticModel):\n",
    "    def __init__(self, model, num_samples=10):\n",
    "        super().__init__(model, num_samples)\n",
    "\n",
    "    def predict(self, inp, num_samples=None, batch_size=32, output_scaler=None, **kwargs):\n",
    "        \"\"\"\n",
    "            Performs a prediction  given input inp using MC Dropout, and returns the mean and standard deviation of the model output.\n",
    "        \"\"\"\n",
    "        samples = self.predict_samples(inp, num_samples, batch_size=batch_size, **kwargs)\n",
    "\n",
    "        if output_scaler is not None:\n",
    "            samples = list(map(lambda x: output_scaler.inverse_transform(x), samples))\n",
    "\n",
    "        mean_pred = np.mean(samples, axis=0)\n",
    "        std_pred = np.std(samples, axis=0)\n",
    "\n",
    "        return mean_pred, std_pred    \n",
    "\n",
    "class TwoHeadStochasticRegressor(StochasticModel):\n",
    "    \"\"\"\n",
    "        A stochastic model that has two ouput heads, one for mean and another for variance, useful for aleatoric/epistemic uncertainty estimation.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, num_samples=10, variance_type=\"linear_variance\"):\n",
    "        super().__init__(model, num_samples)\n",
    "\n",
    "        assert variance_type in [\"logit\", \"linear_std\", \"linear_variance\"]\n",
    "        self.variance_type = variance_type\n",
    "\n",
    "    \"\"\"\n",
    "        Preprocesses and interprets the variance output prodcued by the model, producing a standard deviation.\n",
    "    \"\"\"\n",
    "    def preprocess_variance_output(self, var_input):\n",
    "        if self.variance_type is \"logit\":\n",
    "            return np.exp(var_input)\n",
    "\n",
    "        if self.variance_type is \"linear_variance\":\n",
    "            return np.sqrt(var_input)\n",
    "        \n",
    "        return var_input\n",
    "\n",
    "    def predict(self, inp, num_samples=None, batch_size=32, output_scaler=None, disentangle_uncertainty=False, **kwargs):\n",
    "        \"\"\"\n",
    "            Performs a prediction given input inp and returns the mean and standard deviation of the model output.\n",
    "        \"\"\"\n",
    "        samples = self.predict_samples(inp, num_samples, batch_size=batch_size, multi_output=True, **kwargs)\n",
    "        mean_samples, var_samples = [x[0] for x in samples], [x[1] for x in samples]\n",
    "\n",
    "        if output_scaler is not None:\n",
    "            mean_samples = list(map(lambda x: output_scaler.inverse_transform(x), mean_samples))\n",
    "            var_samples = list(map(lambda x: output_scaler.inverse_transform(x), var_samples))\n",
    "\n",
    "        means = np.array(mean_samples)\n",
    "        variances = np.array(var_samples)\n",
    "        stds = self.preprocess_variance_output(variances)\n",
    "        \n",
    "        mixture_mean = np.mean(means, axis=0)\n",
    "        mixture_var  = np.mean(np.square(stds) + np.square(means), axis=0) - np.square(mixture_mean)\n",
    "        mixture_var[mixture_var < 0.0] = 0.0\n",
    "        mixture_std = np.sqrt(mixture_var)\n",
    "                                \n",
    "        if disentangle_uncertainty:            \n",
    "            epi_std = np.std(means, axis=0)\n",
    "            ale_std = np.mean(stds, axis=0)\n",
    "\n",
    "            return mixture_mean, ale_std, epi_std\n",
    "\n",
    "        return mixture_mean, mixture_std\n",
    "\n",
    "class KernelDensityStochasticModel(StochasticModel):\n",
    "    def __init__(self, model, num_samples=10, bandwidth=1.0):\n",
    "        super().__init__(model, num_samples)\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    x = x - np.max(x, axis=axis, keepdims=True)\n",
    "\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=axis, keepdims=True)\n",
    "\n",
    "def sampling_softmax(mean_logit, std_logit, num_samples=10):\n",
    "    logit_shape = (mean_logit.shape[0], num_samples, mean_logit.shape[-1])\n",
    "\n",
    "    logit_mean = np.expand_dims(mean_logit, axis=1)\n",
    "    logit_mean = np.repeat(logit_mean, num_samples, axis=1)\n",
    "\n",
    "    logit_std = np.expand_dims(std_logit, axis=1)\n",
    "    logit_std = np.repeat(logit_std, num_samples, axis=1)\n",
    "\n",
    "    logit_samples = np.random.normal(size=logit_shape, loc=logit_mean, scale=logit_std)\n",
    "\n",
    "    prob_samples = softmax(logit_samples, axis=-1)\n",
    "    probs = np.mean(prob_samples, axis=1)\n",
    "\n",
    "    # This is required due to approximation error, without it probabilities can sum to 1.01 or 0.99\n",
    "    probs = probs / np.sum(probs, axis=-1, keepdims=True) \n",
    "\n",
    "    return probs\n",
    "\n",
    "class DisentangledStochasticClassifier(TwoHeadStochasticRegressor):\n",
    "    def __init__(self, model, epi_num_samples=10, ale_num_samples=100) -> None:\n",
    "        super(DisentangledStochasticClassifier, self).__init__(model, num_samples=epi_num_samples)\n",
    "\n",
    "        self.epi_num_samples = epi_num_samples\n",
    "        self.ale_num_samples = ale_num_samples\n",
    "\n",
    "    def predict(self, inp, num_samples=None, batch_size=32):\n",
    "        y_logits_mean, y_logits_std_ale, y_logits_std_epi = TwoHeadStochasticRegressor.predict(self, inp, num_samples=num_samples, batch_size=batch_size, disentangle_uncertainty=True)\n",
    "\n",
    "        y_probs = sampling_softmax(y_logits_mean, y_logits_std_ale + y_logits_std_epi, num_samples=self.ale_num_samples)\n",
    "        y_probs_epi = sampling_softmax(y_logits_mean, y_logits_std_epi, num_samples=self.ale_num_samples)\n",
    "        y_probs_ale = sampling_softmax(y_logits_mean, y_logits_std_ale, num_samples=self.ale_num_samples)\n",
    "\n",
    "        return y_probs, y_probs_ale, y_probs_epi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty(probs):\n",
    "    return numpy_entropy(probs, axis=-1)\n",
    "\n",
    "def two_head_model(trunk_model, num_classes=2, num_samples=100):\n",
    "    inp = Input(shape=(18,))\n",
    "    x = trunk_model(inp)\n",
    "    logit_mean = Dense(num_classes, activation=\"linear\")(x)\n",
    "    logit_var = Dense(num_classes, activation=\"softplus\")(x)\n",
    "    probs = SamplingSoftmax(num_samples=num_samples, variance_type=\"linear_std\")([logit_mean, logit_var])\n",
    "    \n",
    "    train_model = Model(inp, probs, name=\"train_model\")\n",
    "    pred_model = Model(inp, [logit_mean, logit_var], name=\"pred_model\")\n",
    "\n",
    "    train_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return train_model, pred_model\n",
    "\n",
    "def train_eval_stochastic_model(trunk_model, x_train, y_train, domain, epochs=300):\n",
    "    train_model, pred_model = two_head_model(trunk_model)\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    train_model.fit(x_train, y_train, verbose=2, epochs=epochs, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[es])\n",
    "\n",
    "    fin_model = DisentangledStochasticClassifier(pred_model, epi_num_samples=NUM_SAMPLES)\n",
    "    print(\"predicting...\")\n",
    "    pred_mean, pred_ale_std, pred_epi_std = fin_model.predict(domain, batch_size=BATCH_SIZE)\n",
    "    print(\"prediction completed\")\n",
    "    ale_entropy = uncertainty(pred_ale_std)\n",
    "    epi_entropy = uncertainty(pred_epi_std)\n",
    "\n",
    "    return pred_mean, ale_entropy, epi_entropy\n",
    "\n",
    "def train_dropout_model(x_train, y_train, domain, prob=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation=\"relu\", input_shape=(x_train.shape[1],)))\n",
    "    model.add(StochasticDropout(prob))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(StochasticDropout(prob))\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return train_eval_stochastic_model(model, x_train, y_train, domain, epochs=100)\n",
    "\n",
    "def train_ensemble_model(x_train, y_train, domain, ensemble_size=10):\n",
    "    models = []\n",
    "    for i in range(ensemble_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation=\"relu\", input_shape=(x_train.shape[1],)))\n",
    "        model.add(Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.1)))\n",
    "        model.add(Dense(2, activation=\"linear\"))\n",
    "\n",
    "        model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                      metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                               tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    ale_entropy = 0\n",
    "    epi_entropy = 0\n",
    "    pred = []\n",
    "    i = 0\n",
    "\n",
    "    for model in models:\n",
    "        pred_prob, ale, epi = train_eval_stochastic_model(model, x_train, y_train, domain, epochs=100)\n",
    "        ale_entropy += ale\n",
    "        epi_entropy += epi\n",
    "        pred.append(pred_prob)\n",
    "        print('ensemble model ', i + 1, ' trained')\n",
    "        i += 1\n",
    "\n",
    "    ale_entropy /= ensemble_size\n",
    "    epi_entropy /= ensemble_size\n",
    "    # average the prediction\n",
    "    pred = np.array(pred)\n",
    "    pred = np.mean(pred, axis=0)\n",
    "    return pred, ale_entropy, epi_entropy\n",
    "\n",
    "def train_dropout_ensemble_model(x_train, y_train, domain, prob=0.5, ensemble_size=10):\n",
    "    models = []\n",
    "    for i in range(ensemble_size):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation=\"relu\", input_shape=(x_train.shape[1],)))\n",
    "        model.add(StochasticDropout(prob))\n",
    "        model.add(Dense(32, activation=\"relu\"))\n",
    "        model.add(StochasticDropout(prob))\n",
    "\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    ale_entropy = 0\n",
    "    epi_entropy = 0\n",
    "    pred = []\n",
    "    i = 0\n",
    "\n",
    "    for model in models:\n",
    "        pred_prob, ale, epi = train_eval_stochastic_model(model, x_train, y_train, domain, epochs=100)\n",
    "        ale_entropy += ale\n",
    "        epi_entropy += epi\n",
    "        pred.append(pred_prob)\n",
    "        print('ensemble model ', i + 1, ' trained')\n",
    "        i += 1\n",
    "\n",
    "    ale_entropy /= ensemble_size\n",
    "    epi_entropy /= ensemble_size\n",
    "    pred = np.array(pred)\n",
    "    pred = np.mean(pred, axis=0)\n",
    "\n",
    "    return pred, ale_entropy, epi_entropy\n",
    "        \n",
    "NUM_SAMPLES = 50\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAIRNESS METRICS - EQUALITY OF OPPORTUNITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to assign prediction based on threshold\n",
    "def assign_pred(pred_prob, class_threshold):\n",
    "    predicted_labels = []\n",
    "    for i in range(len(pred_prob)):\n",
    "        predictions = []\n",
    "        for x in pred_prob[i][:,0]:\n",
    "            if x > class_threshold:\n",
    "                predictions.append(0.0)\n",
    "            else:\n",
    "                predictions.append(1.0)\n",
    "        predicted_labels.append(predictions)\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "#function for equal opportunity difference for each threshold\n",
    "def equal_opportunity_difference(dataset_orig_test, pred_prob, class_threshold):\n",
    "    predicted_labels = assign_pred(pred_prob, class_threshold)\n",
    "    df_test = dataset_orig_test.convert_to_dataframe()[0]\n",
    "    equal_opportunity_difference = []\n",
    "    for i in range(0, len(predicted_labels)):\n",
    "        df_test['Income Binary'] = predicted_labels[i]\n",
    "\n",
    "        structured_dataset = StructuredDataset(df_test, dataset_orig_test.label_names, dataset_orig_test.protected_attribute_names)\n",
    "\n",
    "        structured_binary_dataset = BinaryLabelDataset(df=structured_dataset.convert_to_dataframe()[0], \n",
    "                                         label_names=dataset_orig_test.label_names, \n",
    "                                         protected_attribute_names=dataset_orig_test.protected_attribute_names, \n",
    "                                         favorable_label=dataset_orig_test.favorable_label, \n",
    "                                         unfavorable_label=dataset_orig_test.unfavorable_label)\n",
    "        \n",
    "        classified_metric = ClassificationMetric(dataset_orig_test, \n",
    "                                                 structured_binary_dataset,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "        \n",
    "        equal_opportunity_difference.append(abs(classified_metric.equal_opportunity_difference()))\n",
    "        print(\"Equal opportunity difference for dataset of size %.2f = %f\" % (i*0.1+0.1, abs(classified_metric.equal_opportunity_difference())))\n",
    "            #    = %f\" % abs(classified_metric.equal_opportunity_difference()))\n",
    "\n",
    "    return equal_opportunity_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  0.1\n",
      "Epoch 1/100\n",
      "13/13 - 13s - loss: 3.7778 - accuracy: 0.6250 - val_loss: 3.5352 - val_accuracy: 0.7238 - 13s/epoch - 994ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.3568 - accuracy: 0.7552 - val_loss: 3.1430 - val_accuracy: 0.7545 - 283ms/epoch - 22ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 2.9888 - accuracy: 0.7638 - val_loss: 2.8027 - val_accuracy: 0.7558 - 211ms/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 2.6667 - accuracy: 0.7638 - val_loss: 2.5035 - val_accuracy: 0.7558 - 125ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.3842 - accuracy: 0.7638 - val_loss: 2.2435 - val_accuracy: 0.7558 - 148ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 2.1357 - accuracy: 0.7638 - val_loss: 2.0127 - val_accuracy: 0.7558 - 128ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.9161 - accuracy: 0.7638 - val_loss: 1.8084 - val_accuracy: 0.7558 - 186ms/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.7231 - accuracy: 0.7638 - val_loss: 1.6258 - val_accuracy: 0.7558 - 133ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.5519 - accuracy: 0.7638 - val_loss: 1.4703 - val_accuracy: 0.7558 - 136ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.4016 - accuracy: 0.7638 - val_loss: 1.3288 - val_accuracy: 0.7558 - 127ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.2690 - accuracy: 0.7642 - val_loss: 1.2072 - val_accuracy: 0.7583 - 175ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.1520 - accuracy: 0.7648 - val_loss: 1.0997 - val_accuracy: 0.7673 - 124ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.0511 - accuracy: 0.7731 - val_loss: 1.0065 - val_accuracy: 0.7992 - 123ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.9617 - accuracy: 0.7930 - val_loss: 0.9263 - val_accuracy: 0.8056 - 141ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.8850 - accuracy: 0.8006 - val_loss: 0.8555 - val_accuracy: 0.8031 - 119ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.8198 - accuracy: 0.7971 - val_loss: 0.7980 - val_accuracy: 0.8095 - 131ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.7620 - accuracy: 0.8029 - val_loss: 0.7433 - val_accuracy: 0.8146 - 134ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.7120 - accuracy: 0.8061 - val_loss: 0.7009 - val_accuracy: 0.8082 - 144ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6702 - accuracy: 0.8016 - val_loss: 0.6618 - val_accuracy: 0.8043 - 165ms/epoch - 13ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6344 - accuracy: 0.8067 - val_loss: 0.6283 - val_accuracy: 0.8056 - 127ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.6037 - accuracy: 0.8051 - val_loss: 0.5987 - val_accuracy: 0.8082 - 134ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.5770 - accuracy: 0.8016 - val_loss: 0.5760 - val_accuracy: 0.8069 - 137ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.5549 - accuracy: 0.8061 - val_loss: 0.5569 - val_accuracy: 0.8107 - 215ms/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.5353 - accuracy: 0.8048 - val_loss: 0.5405 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.5204 - accuracy: 0.8058 - val_loss: 0.5264 - val_accuracy: 0.8082 - 125ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.5046 - accuracy: 0.8051 - val_loss: 0.5115 - val_accuracy: 0.8107 - 132ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4931 - accuracy: 0.8051 - val_loss: 0.5036 - val_accuracy: 0.8056 - 121ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4841 - accuracy: 0.8054 - val_loss: 0.4947 - val_accuracy: 0.8095 - 133ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4758 - accuracy: 0.8051 - val_loss: 0.4866 - val_accuracy: 0.8082 - 136ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4683 - accuracy: 0.8064 - val_loss: 0.4801 - val_accuracy: 0.8095 - 155ms/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4625 - accuracy: 0.8061 - val_loss: 0.4743 - val_accuracy: 0.8082 - 171ms/epoch - 13ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4579 - accuracy: 0.8051 - val_loss: 0.4701 - val_accuracy: 0.8082 - 131ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4524 - accuracy: 0.8058 - val_loss: 0.4684 - val_accuracy: 0.8107 - 123ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4497 - accuracy: 0.8067 - val_loss: 0.4640 - val_accuracy: 0.8069 - 121ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4497 - accuracy: 0.8064 - val_loss: 0.4654 - val_accuracy: 0.8107 - 117ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4452 - accuracy: 0.8070 - val_loss: 0.4631 - val_accuracy: 0.8095 - 120ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4422 - accuracy: 0.8054 - val_loss: 0.4654 - val_accuracy: 0.8069 - 126ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4424 - accuracy: 0.8064 - val_loss: 0.4629 - val_accuracy: 0.8056 - 123ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4429 - accuracy: 0.8038 - val_loss: 0.4572 - val_accuracy: 0.8095 - 129ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4376 - accuracy: 0.8051 - val_loss: 0.4551 - val_accuracy: 0.8095 - 125ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4380 - accuracy: 0.8054 - val_loss: 0.4540 - val_accuracy: 0.8095 - 138ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4356 - accuracy: 0.8051 - val_loss: 0.4523 - val_accuracy: 0.8082 - 134ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4364 - accuracy: 0.8022 - val_loss: 0.4528 - val_accuracy: 0.8082 - 121ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4343 - accuracy: 0.8054 - val_loss: 0.4526 - val_accuracy: 0.8082 - 128ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4333 - accuracy: 0.8054 - val_loss: 0.4523 - val_accuracy: 0.8095 - 201ms/epoch - 15ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4346 - accuracy: 0.8061 - val_loss: 0.4501 - val_accuracy: 0.8082 - 163ms/epoch - 13ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4332 - accuracy: 0.8054 - val_loss: 0.4513 - val_accuracy: 0.8069 - 148ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4335 - accuracy: 0.8074 - val_loss: 0.4511 - val_accuracy: 0.8082 - 139ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4322 - accuracy: 0.8048 - val_loss: 0.4531 - val_accuracy: 0.8069 - 289ms/epoch - 22ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4328 - accuracy: 0.8054 - val_loss: 0.4493 - val_accuracy: 0.8082 - 171ms/epoch - 13ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4315 - accuracy: 0.8058 - val_loss: 0.4484 - val_accuracy: 0.8082 - 138ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4311 - accuracy: 0.8051 - val_loss: 0.4503 - val_accuracy: 0.8082 - 141ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4317 - accuracy: 0.8048 - val_loss: 0.4502 - val_accuracy: 0.8056 - 135ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4312 - accuracy: 0.8067 - val_loss: 0.4509 - val_accuracy: 0.8120 - 133ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4318 - accuracy: 0.8070 - val_loss: 0.4491 - val_accuracy: 0.8069 - 128ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.4319 - accuracy: 0.8058 - val_loss: 0.4502 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.4312 - accuracy: 0.8064 - val_loss: 0.4542 - val_accuracy: 0.8043 - 133ms/epoch - 10ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.4321 - accuracy: 0.8038 - val_loss: 0.4525 - val_accuracy: 0.8069 - 132ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.4323 - accuracy: 0.8058 - val_loss: 0.4495 - val_accuracy: 0.8107 - 134ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.4311 - accuracy: 0.8045 - val_loss: 0.4519 - val_accuracy: 0.8082 - 138ms/epoch - 11ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.4310 - accuracy: 0.8045 - val_loss: 0.4491 - val_accuracy: 0.8095 - 152ms/epoch - 12ms/step\n",
      "Epoch 61: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "13/13 - 3s - loss: 3.7564 - accuracy: 0.6486 - val_loss: 3.5134 - val_accuracy: 0.7187 - 3s/epoch - 214ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.3456 - accuracy: 0.7427 - val_loss: 3.1297 - val_accuracy: 0.7519 - 253ms/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 2.9828 - accuracy: 0.7622 - val_loss: 2.7926 - val_accuracy: 0.7558 - 133ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 2.6612 - accuracy: 0.7638 - val_loss: 2.4965 - val_accuracy: 0.7558 - 128ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.3795 - accuracy: 0.7638 - val_loss: 2.2346 - val_accuracy: 0.7558 - 151ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 2.1323 - accuracy: 0.7638 - val_loss: 2.0067 - val_accuracy: 0.7558 - 124ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.9141 - accuracy: 0.7638 - val_loss: 1.8020 - val_accuracy: 0.7558 - 131ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.7209 - accuracy: 0.7638 - val_loss: 1.6246 - val_accuracy: 0.7558 - 162ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.5515 - accuracy: 0.7638 - val_loss: 1.4675 - val_accuracy: 0.7558 - 123ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.4022 - accuracy: 0.7638 - val_loss: 1.3285 - val_accuracy: 0.7558 - 126ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.2700 - accuracy: 0.7638 - val_loss: 1.2069 - val_accuracy: 0.7558 - 116ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.1517 - accuracy: 0.7638 - val_loss: 1.0986 - val_accuracy: 0.7558 - 131ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.0472 - accuracy: 0.7645 - val_loss: 1.0020 - val_accuracy: 0.7570 - 143ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.9567 - accuracy: 0.7782 - val_loss: 0.9182 - val_accuracy: 0.7839 - 132ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.8785 - accuracy: 0.7862 - val_loss: 0.8474 - val_accuracy: 0.7967 - 127ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.8127 - accuracy: 0.7888 - val_loss: 0.7884 - val_accuracy: 0.8043 - 137ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.7545 - accuracy: 0.8016 - val_loss: 0.7367 - val_accuracy: 0.8069 - 126ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.7060 - accuracy: 0.8061 - val_loss: 0.6921 - val_accuracy: 0.8069 - 124ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6631 - accuracy: 0.8013 - val_loss: 0.6558 - val_accuracy: 0.8095 - 135ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6286 - accuracy: 0.8067 - val_loss: 0.6225 - val_accuracy: 0.8107 - 131ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.5966 - accuracy: 0.8054 - val_loss: 0.5956 - val_accuracy: 0.8095 - 129ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.5728 - accuracy: 0.8029 - val_loss: 0.5720 - val_accuracy: 0.8107 - 134ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.5513 - accuracy: 0.8067 - val_loss: 0.5559 - val_accuracy: 0.8056 - 132ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.5311 - accuracy: 0.8077 - val_loss: 0.5367 - val_accuracy: 0.8069 - 125ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.5151 - accuracy: 0.8048 - val_loss: 0.5220 - val_accuracy: 0.8107 - 118ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.5021 - accuracy: 0.8067 - val_loss: 0.5103 - val_accuracy: 0.8069 - 188ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4904 - accuracy: 0.8077 - val_loss: 0.4988 - val_accuracy: 0.8107 - 114ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4811 - accuracy: 0.8048 - val_loss: 0.4916 - val_accuracy: 0.8107 - 117ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4734 - accuracy: 0.8067 - val_loss: 0.4859 - val_accuracy: 0.8043 - 111ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4663 - accuracy: 0.8042 - val_loss: 0.4782 - val_accuracy: 0.8120 - 139ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4599 - accuracy: 0.8074 - val_loss: 0.4764 - val_accuracy: 0.8043 - 121ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4558 - accuracy: 0.8054 - val_loss: 0.4702 - val_accuracy: 0.8082 - 119ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4533 - accuracy: 0.8051 - val_loss: 0.4660 - val_accuracy: 0.8095 - 112ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4506 - accuracy: 0.8051 - val_loss: 0.4632 - val_accuracy: 0.8107 - 194ms/epoch - 15ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4461 - accuracy: 0.8045 - val_loss: 0.4619 - val_accuracy: 0.8043 - 127ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4446 - accuracy: 0.8051 - val_loss: 0.4622 - val_accuracy: 0.8095 - 161ms/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4422 - accuracy: 0.8045 - val_loss: 0.4574 - val_accuracy: 0.8082 - 120ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4402 - accuracy: 0.8070 - val_loss: 0.4569 - val_accuracy: 0.8043 - 126ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4393 - accuracy: 0.8061 - val_loss: 0.4552 - val_accuracy: 0.8069 - 122ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4373 - accuracy: 0.8064 - val_loss: 0.4537 - val_accuracy: 0.8082 - 125ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4355 - accuracy: 0.8074 - val_loss: 0.4532 - val_accuracy: 0.8043 - 121ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4349 - accuracy: 0.8061 - val_loss: 0.4525 - val_accuracy: 0.8082 - 140ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4352 - accuracy: 0.8051 - val_loss: 0.4509 - val_accuracy: 0.8056 - 138ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4349 - accuracy: 0.8048 - val_loss: 0.4503 - val_accuracy: 0.8082 - 141ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4346 - accuracy: 0.8061 - val_loss: 0.4510 - val_accuracy: 0.8082 - 150ms/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4334 - accuracy: 0.8070 - val_loss: 0.4527 - val_accuracy: 0.8043 - 133ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4341 - accuracy: 0.8048 - val_loss: 0.4505 - val_accuracy: 0.8095 - 131ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4326 - accuracy: 0.8061 - val_loss: 0.4535 - val_accuracy: 0.8043 - 135ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4327 - accuracy: 0.8058 - val_loss: 0.4532 - val_accuracy: 0.8107 - 137ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4364 - accuracy: 0.8054 - val_loss: 0.4495 - val_accuracy: 0.8069 - 123ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4357 - accuracy: 0.8077 - val_loss: 0.4602 - val_accuracy: 0.7967 - 130ms/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4351 - accuracy: 0.8051 - val_loss: 0.4507 - val_accuracy: 0.8082 - 135ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4320 - accuracy: 0.8061 - val_loss: 0.4492 - val_accuracy: 0.8082 - 132ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4324 - accuracy: 0.8051 - val_loss: 0.4496 - val_accuracy: 0.8043 - 129ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4310 - accuracy: 0.8064 - val_loss: 0.4486 - val_accuracy: 0.8082 - 132ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.4300 - accuracy: 0.8058 - val_loss: 0.4478 - val_accuracy: 0.8043 - 130ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.4329 - accuracy: 0.8086 - val_loss: 0.4606 - val_accuracy: 0.8056 - 131ms/epoch - 10ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.4410 - accuracy: 0.8035 - val_loss: 0.4523 - val_accuracy: 0.8107 - 130ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.4373 - accuracy: 0.7962 - val_loss: 0.4515 - val_accuracy: 0.8005 - 129ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.4304 - accuracy: 0.8048 - val_loss: 0.4493 - val_accuracy: 0.8069 - 135ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.4315 - accuracy: 0.8070 - val_loss: 0.4496 - val_accuracy: 0.8082 - 126ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.4296 - accuracy: 0.8048 - val_loss: 0.4484 - val_accuracy: 0.8056 - 131ms/epoch - 10ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.4309 - accuracy: 0.8061 - val_loss: 0.4496 - val_accuracy: 0.8082 - 128ms/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.4296 - accuracy: 0.8061 - val_loss: 0.4484 - val_accuracy: 0.8082 - 138ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.4292 - accuracy: 0.8054 - val_loss: 0.4482 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.4300 - accuracy: 0.8064 - val_loss: 0.4511 - val_accuracy: 0.8056 - 131ms/epoch - 10ms/step\n",
      "Epoch 66: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 3.7625 - accuracy: 0.5946 - val_loss: 3.5176 - val_accuracy: 0.7161 - 2s/epoch - 118ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.3451 - accuracy: 0.7498 - val_loss: 3.1268 - val_accuracy: 0.7545 - 139ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 2.9754 - accuracy: 0.7635 - val_loss: 2.7853 - val_accuracy: 0.7558 - 141ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 2.6506 - accuracy: 0.7638 - val_loss: 2.4836 - val_accuracy: 0.7558 - 134ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.3654 - accuracy: 0.7638 - val_loss: 2.2228 - val_accuracy: 0.7558 - 149ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 2.1131 - accuracy: 0.7638 - val_loss: 1.9908 - val_accuracy: 0.7558 - 162ms/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.8933 - accuracy: 0.7638 - val_loss: 1.7855 - val_accuracy: 0.7558 - 135ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.6999 - accuracy: 0.7638 - val_loss: 1.6058 - val_accuracy: 0.7558 - 129ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.5289 - accuracy: 0.7638 - val_loss: 1.4492 - val_accuracy: 0.7558 - 127ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.3808 - accuracy: 0.7642 - val_loss: 1.3106 - val_accuracy: 0.7558 - 131ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.2488 - accuracy: 0.7642 - val_loss: 1.1884 - val_accuracy: 0.7583 - 126ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.1335 - accuracy: 0.7699 - val_loss: 1.0814 - val_accuracy: 0.7839 - 132ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.0344 - accuracy: 0.7773 - val_loss: 0.9922 - val_accuracy: 0.7954 - 136ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.9488 - accuracy: 0.7974 - val_loss: 0.9122 - val_accuracy: 0.8018 - 125ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.8733 - accuracy: 0.7971 - val_loss: 0.8460 - val_accuracy: 0.8069 - 128ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.8084 - accuracy: 0.8054 - val_loss: 0.7860 - val_accuracy: 0.8043 - 130ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.7537 - accuracy: 0.7990 - val_loss: 0.7363 - val_accuracy: 0.8056 - 134ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.7054 - accuracy: 0.8054 - val_loss: 0.6934 - val_accuracy: 0.8082 - 126ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6645 - accuracy: 0.8032 - val_loss: 0.6546 - val_accuracy: 0.8120 - 126ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6292 - accuracy: 0.8058 - val_loss: 0.6241 - val_accuracy: 0.8069 - 161ms/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.5996 - accuracy: 0.8054 - val_loss: 0.5964 - val_accuracy: 0.8069 - 134ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.5734 - accuracy: 0.8077 - val_loss: 0.5743 - val_accuracy: 0.8082 - 128ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.5519 - accuracy: 0.8045 - val_loss: 0.5527 - val_accuracy: 0.8069 - 123ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.5329 - accuracy: 0.8061 - val_loss: 0.5367 - val_accuracy: 0.8095 - 116ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.5175 - accuracy: 0.8061 - val_loss: 0.5232 - val_accuracy: 0.8069 - 118ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.5041 - accuracy: 0.8054 - val_loss: 0.5103 - val_accuracy: 0.8069 - 117ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4927 - accuracy: 0.8058 - val_loss: 0.5003 - val_accuracy: 0.8082 - 157ms/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4832 - accuracy: 0.8051 - val_loss: 0.4916 - val_accuracy: 0.8095 - 144ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4747 - accuracy: 0.8054 - val_loss: 0.4853 - val_accuracy: 0.8107 - 110ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4691 - accuracy: 0.8042 - val_loss: 0.4800 - val_accuracy: 0.8069 - 107ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4631 - accuracy: 0.8074 - val_loss: 0.4741 - val_accuracy: 0.8069 - 121ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4570 - accuracy: 0.8058 - val_loss: 0.4701 - val_accuracy: 0.8095 - 131ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4538 - accuracy: 0.8061 - val_loss: 0.4673 - val_accuracy: 0.8082 - 140ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4501 - accuracy: 0.8058 - val_loss: 0.4623 - val_accuracy: 0.8082 - 149ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4481 - accuracy: 0.8048 - val_loss: 0.4606 - val_accuracy: 0.8082 - 135ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4452 - accuracy: 0.8048 - val_loss: 0.4613 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4434 - accuracy: 0.8045 - val_loss: 0.4576 - val_accuracy: 0.8171 - 132ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4420 - accuracy: 0.8083 - val_loss: 0.4631 - val_accuracy: 0.8005 - 123ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4458 - accuracy: 0.8058 - val_loss: 0.4557 - val_accuracy: 0.8095 - 129ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4415 - accuracy: 0.8051 - val_loss: 0.4547 - val_accuracy: 0.8095 - 135ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4389 - accuracy: 0.8058 - val_loss: 0.4545 - val_accuracy: 0.8056 - 138ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4367 - accuracy: 0.8042 - val_loss: 0.4530 - val_accuracy: 0.8133 - 126ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4369 - accuracy: 0.8045 - val_loss: 0.4499 - val_accuracy: 0.8082 - 129ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4343 - accuracy: 0.8058 - val_loss: 0.4500 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4352 - accuracy: 0.8067 - val_loss: 0.4512 - val_accuracy: 0.8082 - 125ms/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4325 - accuracy: 0.8061 - val_loss: 0.4537 - val_accuracy: 0.8146 - 132ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4346 - accuracy: 0.8054 - val_loss: 0.4516 - val_accuracy: 0.8082 - 132ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4347 - accuracy: 0.8074 - val_loss: 0.4491 - val_accuracy: 0.8082 - 137ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4334 - accuracy: 0.8058 - val_loss: 0.4502 - val_accuracy: 0.8082 - 132ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4323 - accuracy: 0.8045 - val_loss: 0.4500 - val_accuracy: 0.8082 - 132ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4328 - accuracy: 0.8064 - val_loss: 0.4504 - val_accuracy: 0.8082 - 122ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4325 - accuracy: 0.8054 - val_loss: 0.4484 - val_accuracy: 0.8069 - 125ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4311 - accuracy: 0.8058 - val_loss: 0.4490 - val_accuracy: 0.8082 - 121ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4303 - accuracy: 0.8058 - val_loss: 0.4501 - val_accuracy: 0.8069 - 173ms/epoch - 13ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4333 - accuracy: 0.8070 - val_loss: 0.4484 - val_accuracy: 0.8082 - 119ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.4325 - accuracy: 0.8067 - val_loss: 0.4488 - val_accuracy: 0.8107 - 125ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.4308 - accuracy: 0.8061 - val_loss: 0.4474 - val_accuracy: 0.8082 - 127ms/epoch - 10ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.4321 - accuracy: 0.8054 - val_loss: 0.4509 - val_accuracy: 0.8069 - 123ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.4336 - accuracy: 0.8061 - val_loss: 0.4504 - val_accuracy: 0.8095 - 122ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.4305 - accuracy: 0.8058 - val_loss: 0.4477 - val_accuracy: 0.8120 - 128ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.4318 - accuracy: 0.8083 - val_loss: 0.4477 - val_accuracy: 0.8082 - 123ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.4303 - accuracy: 0.8070 - val_loss: 0.4474 - val_accuracy: 0.8082 - 130ms/epoch - 10ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.4309 - accuracy: 0.8061 - val_loss: 0.4495 - val_accuracy: 0.8120 - 143ms/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.4319 - accuracy: 0.8048 - val_loss: 0.4475 - val_accuracy: 0.8082 - 139ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.4317 - accuracy: 0.8054 - val_loss: 0.4503 - val_accuracy: 0.8056 - 146ms/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.4319 - accuracy: 0.8045 - val_loss: 0.4480 - val_accuracy: 0.8082 - 121ms/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.4301 - accuracy: 0.8051 - val_loss: 0.4482 - val_accuracy: 0.8082 - 117ms/epoch - 9ms/step\n",
      "Epoch 67: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "13/13 - 1s - loss: 3.6451 - accuracy: 0.5994 - val_loss: 3.4190 - val_accuracy: 0.6905 - 1s/epoch - 100ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.2585 - accuracy: 0.7274 - val_loss: 3.0522 - val_accuracy: 0.7570 - 160ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 2.9064 - accuracy: 0.7603 - val_loss: 2.7226 - val_accuracy: 0.7558 - 147ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 2.5933 - accuracy: 0.7632 - val_loss: 2.4290 - val_accuracy: 0.7558 - 149ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.3136 - accuracy: 0.7638 - val_loss: 2.1704 - val_accuracy: 0.7558 - 250ms/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 2.0680 - accuracy: 0.7638 - val_loss: 1.9451 - val_accuracy: 0.7558 - 150ms/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.8539 - accuracy: 0.7638 - val_loss: 1.7464 - val_accuracy: 0.7558 - 165ms/epoch - 13ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.6670 - accuracy: 0.7638 - val_loss: 1.5750 - val_accuracy: 0.7558 - 127ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.5043 - accuracy: 0.7638 - val_loss: 1.4253 - val_accuracy: 0.7558 - 117ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.3633 - accuracy: 0.7638 - val_loss: 1.2937 - val_accuracy: 0.7558 - 118ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.2393 - accuracy: 0.7638 - val_loss: 1.1787 - val_accuracy: 0.7558 - 130ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.1304 - accuracy: 0.7638 - val_loss: 1.0771 - val_accuracy: 0.7558 - 179ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.0352 - accuracy: 0.7638 - val_loss: 0.9880 - val_accuracy: 0.7558 - 129ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.9498 - accuracy: 0.7638 - val_loss: 0.9092 - val_accuracy: 0.7558 - 125ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.8773 - accuracy: 0.7638 - val_loss: 0.8419 - val_accuracy: 0.7558 - 138ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.8112 - accuracy: 0.7638 - val_loss: 0.7820 - val_accuracy: 0.7558 - 128ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.7536 - accuracy: 0.7664 - val_loss: 0.7324 - val_accuracy: 0.7673 - 129ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.7067 - accuracy: 0.7741 - val_loss: 0.6893 - val_accuracy: 0.7788 - 142ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6641 - accuracy: 0.7942 - val_loss: 0.6512 - val_accuracy: 0.7928 - 107ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6294 - accuracy: 0.7952 - val_loss: 0.6168 - val_accuracy: 0.8018 - 112ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.5988 - accuracy: 0.8010 - val_loss: 0.5913 - val_accuracy: 0.8095 - 113ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.5736 - accuracy: 0.7978 - val_loss: 0.5703 - val_accuracy: 0.8043 - 120ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.5520 - accuracy: 0.8064 - val_loss: 0.5505 - val_accuracy: 0.8095 - 119ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.5324 - accuracy: 0.8038 - val_loss: 0.5352 - val_accuracy: 0.8069 - 127ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.5179 - accuracy: 0.8051 - val_loss: 0.5187 - val_accuracy: 0.8107 - 131ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.5038 - accuracy: 0.8029 - val_loss: 0.5072 - val_accuracy: 0.8120 - 124ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4917 - accuracy: 0.8045 - val_loss: 0.4993 - val_accuracy: 0.8069 - 130ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4826 - accuracy: 0.8061 - val_loss: 0.4910 - val_accuracy: 0.8095 - 114ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4756 - accuracy: 0.8058 - val_loss: 0.4829 - val_accuracy: 0.8107 - 130ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4687 - accuracy: 0.8070 - val_loss: 0.4789 - val_accuracy: 0.8082 - 122ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4634 - accuracy: 0.8064 - val_loss: 0.4774 - val_accuracy: 0.8043 - 158ms/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4580 - accuracy: 0.8054 - val_loss: 0.4701 - val_accuracy: 0.8082 - 151ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4550 - accuracy: 0.8058 - val_loss: 0.4656 - val_accuracy: 0.8082 - 135ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4504 - accuracy: 0.8061 - val_loss: 0.4644 - val_accuracy: 0.8082 - 144ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4488 - accuracy: 0.8051 - val_loss: 0.4602 - val_accuracy: 0.8120 - 125ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4457 - accuracy: 0.8064 - val_loss: 0.4596 - val_accuracy: 0.8082 - 119ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4473 - accuracy: 0.8051 - val_loss: 0.4591 - val_accuracy: 0.8056 - 121ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4418 - accuracy: 0.8058 - val_loss: 0.4546 - val_accuracy: 0.8082 - 121ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4402 - accuracy: 0.8064 - val_loss: 0.4565 - val_accuracy: 0.8107 - 123ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4400 - accuracy: 0.8038 - val_loss: 0.4558 - val_accuracy: 0.8120 - 124ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4401 - accuracy: 0.8070 - val_loss: 0.4540 - val_accuracy: 0.8095 - 136ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4388 - accuracy: 0.8054 - val_loss: 0.4529 - val_accuracy: 0.8095 - 131ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4395 - accuracy: 0.8035 - val_loss: 0.4528 - val_accuracy: 0.8082 - 129ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4359 - accuracy: 0.8051 - val_loss: 0.4544 - val_accuracy: 0.8082 - 127ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4353 - accuracy: 0.8054 - val_loss: 0.4522 - val_accuracy: 0.8082 - 131ms/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4360 - accuracy: 0.8042 - val_loss: 0.4528 - val_accuracy: 0.8043 - 128ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4361 - accuracy: 0.8048 - val_loss: 0.4536 - val_accuracy: 0.8107 - 126ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4333 - accuracy: 0.8064 - val_loss: 0.4508 - val_accuracy: 0.8082 - 129ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4344 - accuracy: 0.8048 - val_loss: 0.4502 - val_accuracy: 0.8082 - 138ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4340 - accuracy: 0.8058 - val_loss: 0.4502 - val_accuracy: 0.8082 - 120ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4329 - accuracy: 0.8058 - val_loss: 0.4505 - val_accuracy: 0.8082 - 125ms/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4331 - accuracy: 0.8061 - val_loss: 0.4544 - val_accuracy: 0.8082 - 122ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4356 - accuracy: 0.8054 - val_loss: 0.4507 - val_accuracy: 0.8107 - 120ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4325 - accuracy: 0.8061 - val_loss: 0.4520 - val_accuracy: 0.8095 - 128ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4338 - accuracy: 0.8058 - val_loss: 0.4517 - val_accuracy: 0.8107 - 128ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.4332 - accuracy: 0.8035 - val_loss: 0.4511 - val_accuracy: 0.8095 - 122ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.4335 - accuracy: 0.8045 - val_loss: 0.4508 - val_accuracy: 0.8056 - 136ms/epoch - 10ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.4327 - accuracy: 0.8042 - val_loss: 0.4523 - val_accuracy: 0.8056 - 120ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.4350 - accuracy: 0.8042 - val_loss: 0.4612 - val_accuracy: 0.8056 - 120ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.4366 - accuracy: 0.8061 - val_loss: 0.4501 - val_accuracy: 0.8082 - 118ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.4379 - accuracy: 0.8035 - val_loss: 0.4521 - val_accuracy: 0.7992 - 140ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.4333 - accuracy: 0.8048 - val_loss: 0.4499 - val_accuracy: 0.8082 - 145ms/epoch - 11ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.4321 - accuracy: 0.8048 - val_loss: 0.4495 - val_accuracy: 0.8043 - 138ms/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.4307 - accuracy: 0.8093 - val_loss: 0.4526 - val_accuracy: 0.8031 - 156ms/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.4335 - accuracy: 0.8019 - val_loss: 0.4520 - val_accuracy: 0.8095 - 142ms/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.4355 - accuracy: 0.8026 - val_loss: 0.4547 - val_accuracy: 0.8120 - 146ms/epoch - 11ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.4313 - accuracy: 0.8035 - val_loss: 0.4547 - val_accuracy: 0.7980 - 133ms/epoch - 10ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 0.4319 - accuracy: 0.8045 - val_loss: 0.4507 - val_accuracy: 0.8082 - 128ms/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 0.4303 - accuracy: 0.8058 - val_loss: 0.4500 - val_accuracy: 0.8095 - 132ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 0.4305 - accuracy: 0.8067 - val_loss: 0.4506 - val_accuracy: 0.8082 - 129ms/epoch - 10ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 0.4305 - accuracy: 0.8058 - val_loss: 0.4474 - val_accuracy: 0.8082 - 135ms/epoch - 10ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 0.4295 - accuracy: 0.8054 - val_loss: 0.4502 - val_accuracy: 0.8056 - 122ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 0.4304 - accuracy: 0.8061 - val_loss: 0.4503 - val_accuracy: 0.8069 - 123ms/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 0.4298 - accuracy: 0.8054 - val_loss: 0.4483 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 0.4291 - accuracy: 0.8054 - val_loss: 0.4489 - val_accuracy: 0.8069 - 129ms/epoch - 10ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 0.4288 - accuracy: 0.8058 - val_loss: 0.4486 - val_accuracy: 0.8082 - 180ms/epoch - 14ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 0.4288 - accuracy: 0.8058 - val_loss: 0.4487 - val_accuracy: 0.8082 - 114ms/epoch - 9ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 0.4284 - accuracy: 0.8058 - val_loss: 0.4489 - val_accuracy: 0.8082 - 119ms/epoch - 9ms/step\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 0.4284 - accuracy: 0.8054 - val_loss: 0.4487 - val_accuracy: 0.8082 - 144ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 0.4285 - accuracy: 0.8064 - val_loss: 0.4498 - val_accuracy: 0.8043 - 133ms/epoch - 10ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 0.4293 - accuracy: 0.8058 - val_loss: 0.4511 - val_accuracy: 0.8107 - 125ms/epoch - 10ms/step\n",
      "Epoch 81: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 3.6820 - accuracy: 0.7309 - val_loss: 3.4252 - val_accuracy: 0.7570 - 2s/epoch - 145ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.2559 - accuracy: 0.7638 - val_loss: 3.0391 - val_accuracy: 0.7558 - 136ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 2.8922 - accuracy: 0.7638 - val_loss: 2.7046 - val_accuracy: 0.7558 - 129ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 2.5763 - accuracy: 0.7638 - val_loss: 2.4103 - val_accuracy: 0.7558 - 125ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.2972 - accuracy: 0.7638 - val_loss: 2.1518 - val_accuracy: 0.7558 - 124ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 2.0524 - accuracy: 0.7638 - val_loss: 1.9270 - val_accuracy: 0.7558 - 136ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.8367 - accuracy: 0.7651 - val_loss: 1.7273 - val_accuracy: 0.7621 - 134ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.6474 - accuracy: 0.7680 - val_loss: 1.5535 - val_accuracy: 0.7749 - 120ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.4808 - accuracy: 0.7821 - val_loss: 1.4007 - val_accuracy: 0.7903 - 127ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.3370 - accuracy: 0.7962 - val_loss: 1.2687 - val_accuracy: 0.8043 - 128ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.2116 - accuracy: 0.7955 - val_loss: 1.1511 - val_accuracy: 0.8043 - 128ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.1002 - accuracy: 0.8003 - val_loss: 1.0512 - val_accuracy: 0.8031 - 126ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.0049 - accuracy: 0.8022 - val_loss: 0.9649 - val_accuracy: 0.8018 - 119ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.9220 - accuracy: 0.8000 - val_loss: 0.8871 - val_accuracy: 0.8031 - 125ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.8498 - accuracy: 0.8045 - val_loss: 0.8234 - val_accuracy: 0.8107 - 124ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.7881 - accuracy: 0.8054 - val_loss: 0.7684 - val_accuracy: 0.8005 - 122ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.7336 - accuracy: 0.8051 - val_loss: 0.7192 - val_accuracy: 0.8082 - 120ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.6904 - accuracy: 0.8010 - val_loss: 0.6790 - val_accuracy: 0.8082 - 121ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6497 - accuracy: 0.8070 - val_loss: 0.6433 - val_accuracy: 0.8095 - 114ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6149 - accuracy: 0.8038 - val_loss: 0.6126 - val_accuracy: 0.8107 - 131ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.5888 - accuracy: 0.8048 - val_loss: 0.5866 - val_accuracy: 0.8095 - 117ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.5637 - accuracy: 0.8070 - val_loss: 0.5648 - val_accuracy: 0.8095 - 120ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.5420 - accuracy: 0.8032 - val_loss: 0.5452 - val_accuracy: 0.8082 - 139ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.5241 - accuracy: 0.8045 - val_loss: 0.5296 - val_accuracy: 0.8069 - 139ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.5087 - accuracy: 0.8061 - val_loss: 0.5168 - val_accuracy: 0.8082 - 137ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4969 - accuracy: 0.8054 - val_loss: 0.5071 - val_accuracy: 0.8031 - 146ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4868 - accuracy: 0.8064 - val_loss: 0.4971 - val_accuracy: 0.8069 - 136ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4768 - accuracy: 0.8058 - val_loss: 0.4900 - val_accuracy: 0.8082 - 126ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4704 - accuracy: 0.8058 - val_loss: 0.4821 - val_accuracy: 0.8082 - 134ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4641 - accuracy: 0.8061 - val_loss: 0.4779 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4580 - accuracy: 0.8067 - val_loss: 0.4710 - val_accuracy: 0.8082 - 125ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4538 - accuracy: 0.8064 - val_loss: 0.4678 - val_accuracy: 0.8082 - 132ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4494 - accuracy: 0.8058 - val_loss: 0.4658 - val_accuracy: 0.8056 - 138ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4495 - accuracy: 0.8038 - val_loss: 0.4666 - val_accuracy: 0.8069 - 129ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4463 - accuracy: 0.8070 - val_loss: 0.4609 - val_accuracy: 0.8107 - 128ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4451 - accuracy: 0.8093 - val_loss: 0.4632 - val_accuracy: 0.8005 - 129ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4456 - accuracy: 0.8042 - val_loss: 0.4588 - val_accuracy: 0.8056 - 129ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4385 - accuracy: 0.8061 - val_loss: 0.4558 - val_accuracy: 0.8082 - 131ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4374 - accuracy: 0.8061 - val_loss: 0.4547 - val_accuracy: 0.8095 - 123ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4359 - accuracy: 0.8061 - val_loss: 0.4543 - val_accuracy: 0.8082 - 177ms/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4353 - accuracy: 0.8054 - val_loss: 0.4549 - val_accuracy: 0.8069 - 136ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4338 - accuracy: 0.8061 - val_loss: 0.4540 - val_accuracy: 0.8082 - 125ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4345 - accuracy: 0.8048 - val_loss: 0.4529 - val_accuracy: 0.8082 - 127ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4331 - accuracy: 0.8058 - val_loss: 0.4537 - val_accuracy: 0.8082 - 126ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4334 - accuracy: 0.8061 - val_loss: 0.4532 - val_accuracy: 0.8069 - 128ms/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4331 - accuracy: 0.8067 - val_loss: 0.4512 - val_accuracy: 0.8082 - 123ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4329 - accuracy: 0.8067 - val_loss: 0.4535 - val_accuracy: 0.8056 - 126ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4333 - accuracy: 0.8061 - val_loss: 0.4518 - val_accuracy: 0.8082 - 126ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4307 - accuracy: 0.8064 - val_loss: 0.4516 - val_accuracy: 0.8082 - 105ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4319 - accuracy: 0.8032 - val_loss: 0.4539 - val_accuracy: 0.8056 - 108ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4312 - accuracy: 0.8048 - val_loss: 0.4524 - val_accuracy: 0.8082 - 123ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4304 - accuracy: 0.8054 - val_loss: 0.4514 - val_accuracy: 0.8082 - 132ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4306 - accuracy: 0.8064 - val_loss: 0.4495 - val_accuracy: 0.8095 - 145ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4292 - accuracy: 0.8061 - val_loss: 0.4501 - val_accuracy: 0.8082 - 137ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4299 - accuracy: 0.8058 - val_loss: 0.4510 - val_accuracy: 0.8082 - 143ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.4291 - accuracy: 0.8067 - val_loss: 0.4485 - val_accuracy: 0.8056 - 139ms/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.4303 - accuracy: 0.8051 - val_loss: 0.4523 - val_accuracy: 0.8082 - 138ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.4289 - accuracy: 0.8067 - val_loss: 0.4486 - val_accuracy: 0.8056 - 136ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.4285 - accuracy: 0.8064 - val_loss: 0.4518 - val_accuracy: 0.8082 - 137ms/epoch - 11ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.4299 - accuracy: 0.8058 - val_loss: 0.4497 - val_accuracy: 0.8056 - 131ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.4302 - accuracy: 0.8045 - val_loss: 0.4529 - val_accuracy: 0.8069 - 135ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.4325 - accuracy: 0.8032 - val_loss: 0.4529 - val_accuracy: 0.8043 - 131ms/epoch - 10ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.4294 - accuracy: 0.8058 - val_loss: 0.4492 - val_accuracy: 0.8082 - 135ms/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.4270 - accuracy: 0.8051 - val_loss: 0.4506 - val_accuracy: 0.8056 - 131ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.4284 - accuracy: 0.8032 - val_loss: 0.4505 - val_accuracy: 0.8082 - 131ms/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.4292 - accuracy: 0.8067 - val_loss: 0.4496 - val_accuracy: 0.8082 - 131ms/epoch - 10ms/step\n",
      "Epoch 66: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "13/13 - 1s - loss: 3.6586 - accuracy: 0.4451 - val_loss: 3.4144 - val_accuracy: 0.6164 - 1s/epoch - 92ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.2416 - accuracy: 0.7053 - val_loss: 3.0286 - val_accuracy: 0.7442 - 134ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 2.8760 - accuracy: 0.7603 - val_loss: 2.6888 - val_accuracy: 0.7519 - 136ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 2.5530 - accuracy: 0.7638 - val_loss: 2.3920 - val_accuracy: 0.7558 - 130ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.2721 - accuracy: 0.7638 - val_loss: 2.1352 - val_accuracy: 0.7558 - 134ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 2.0286 - accuracy: 0.7638 - val_loss: 1.9115 - val_accuracy: 0.7558 - 130ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.8183 - accuracy: 0.7638 - val_loss: 1.7174 - val_accuracy: 0.7558 - 140ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.6335 - accuracy: 0.7638 - val_loss: 1.5459 - val_accuracy: 0.7558 - 127ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.4734 - accuracy: 0.7638 - val_loss: 1.3965 - val_accuracy: 0.7558 - 135ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.3337 - accuracy: 0.7638 - val_loss: 1.2665 - val_accuracy: 0.7558 - 127ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.2098 - accuracy: 0.7638 - val_loss: 1.1533 - val_accuracy: 0.7558 - 125ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.1020 - accuracy: 0.7638 - val_loss: 1.0544 - val_accuracy: 0.7545 - 118ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.0076 - accuracy: 0.7645 - val_loss: 0.9682 - val_accuracy: 0.7609 - 114ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.9255 - accuracy: 0.7731 - val_loss: 0.8949 - val_accuracy: 0.7660 - 133ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.8549 - accuracy: 0.7814 - val_loss: 0.8299 - val_accuracy: 0.7890 - 130ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.7932 - accuracy: 0.7901 - val_loss: 0.7740 - val_accuracy: 0.8018 - 127ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.7405 - accuracy: 0.7987 - val_loss: 0.7243 - val_accuracy: 0.8031 - 125ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.6956 - accuracy: 0.7974 - val_loss: 0.6852 - val_accuracy: 0.8056 - 125ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6562 - accuracy: 0.8035 - val_loss: 0.6471 - val_accuracy: 0.8056 - 177ms/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6221 - accuracy: 0.8035 - val_loss: 0.6178 - val_accuracy: 0.8056 - 114ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.5926 - accuracy: 0.8045 - val_loss: 0.5916 - val_accuracy: 0.8069 - 130ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.5691 - accuracy: 0.8045 - val_loss: 0.5689 - val_accuracy: 0.8107 - 124ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.5482 - accuracy: 0.8064 - val_loss: 0.5499 - val_accuracy: 0.8069 - 118ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.5287 - accuracy: 0.8054 - val_loss: 0.5328 - val_accuracy: 0.8107 - 120ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.5138 - accuracy: 0.8054 - val_loss: 0.5205 - val_accuracy: 0.8082 - 121ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.5011 - accuracy: 0.8048 - val_loss: 0.5074 - val_accuracy: 0.8107 - 136ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4910 - accuracy: 0.8064 - val_loss: 0.5019 - val_accuracy: 0.8095 - 129ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4838 - accuracy: 0.8042 - val_loss: 0.4928 - val_accuracy: 0.8107 - 137ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4731 - accuracy: 0.8058 - val_loss: 0.4850 - val_accuracy: 0.8082 - 120ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4685 - accuracy: 0.8038 - val_loss: 0.4792 - val_accuracy: 0.8146 - 130ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4610 - accuracy: 0.8074 - val_loss: 0.4774 - val_accuracy: 0.8056 - 117ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4573 - accuracy: 0.8054 - val_loss: 0.4699 - val_accuracy: 0.8069 - 127ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4526 - accuracy: 0.8038 - val_loss: 0.4673 - val_accuracy: 0.8095 - 118ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4492 - accuracy: 0.8074 - val_loss: 0.4623 - val_accuracy: 0.8095 - 131ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4474 - accuracy: 0.8038 - val_loss: 0.4627 - val_accuracy: 0.8069 - 139ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4448 - accuracy: 0.8067 - val_loss: 0.4621 - val_accuracy: 0.8120 - 143ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4424 - accuracy: 0.8083 - val_loss: 0.4593 - val_accuracy: 0.8095 - 152ms/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4426 - accuracy: 0.8045 - val_loss: 0.4582 - val_accuracy: 0.8095 - 142ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4401 - accuracy: 0.8061 - val_loss: 0.4573 - val_accuracy: 0.8056 - 136ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4393 - accuracy: 0.8054 - val_loss: 0.4551 - val_accuracy: 0.8095 - 130ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4353 - accuracy: 0.8064 - val_loss: 0.4550 - val_accuracy: 0.8082 - 142ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4357 - accuracy: 0.8058 - val_loss: 0.4545 - val_accuracy: 0.8082 - 136ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4355 - accuracy: 0.8061 - val_loss: 0.4517 - val_accuracy: 0.8095 - 131ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4372 - accuracy: 0.8035 - val_loss: 0.4536 - val_accuracy: 0.8043 - 126ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4350 - accuracy: 0.8042 - val_loss: 0.4527 - val_accuracy: 0.8082 - 122ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4337 - accuracy: 0.8058 - val_loss: 0.4512 - val_accuracy: 0.8069 - 125ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4333 - accuracy: 0.8058 - val_loss: 0.4524 - val_accuracy: 0.8095 - 124ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4358 - accuracy: 0.8032 - val_loss: 0.4550 - val_accuracy: 0.8031 - 132ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4336 - accuracy: 0.8026 - val_loss: 0.4518 - val_accuracy: 0.8069 - 128ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4332 - accuracy: 0.8061 - val_loss: 0.4534 - val_accuracy: 0.8043 - 124ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4325 - accuracy: 0.8058 - val_loss: 0.4506 - val_accuracy: 0.8107 - 126ms/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4321 - accuracy: 0.8058 - val_loss: 0.4510 - val_accuracy: 0.8069 - 136ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4328 - accuracy: 0.8051 - val_loss: 0.4516 - val_accuracy: 0.8095 - 129ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4324 - accuracy: 0.8074 - val_loss: 0.4506 - val_accuracy: 0.8082 - 126ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4311 - accuracy: 0.8048 - val_loss: 0.4496 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.4330 - accuracy: 0.8074 - val_loss: 0.4490 - val_accuracy: 0.8095 - 131ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.4312 - accuracy: 0.8054 - val_loss: 0.4516 - val_accuracy: 0.8120 - 132ms/epoch - 10ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.4328 - accuracy: 0.8064 - val_loss: 0.4508 - val_accuracy: 0.8056 - 119ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.4296 - accuracy: 0.8064 - val_loss: 0.4522 - val_accuracy: 0.8120 - 119ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.4306 - accuracy: 0.8051 - val_loss: 0.4488 - val_accuracy: 0.8082 - 129ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.4301 - accuracy: 0.8058 - val_loss: 0.4472 - val_accuracy: 0.8095 - 117ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.4329 - accuracy: 0.8045 - val_loss: 0.4545 - val_accuracy: 0.8082 - 118ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.4301 - accuracy: 0.8032 - val_loss: 0.4549 - val_accuracy: 0.8031 - 126ms/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.4310 - accuracy: 0.8035 - val_loss: 0.4504 - val_accuracy: 0.8095 - 140ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.4326 - accuracy: 0.8016 - val_loss: 0.4543 - val_accuracy: 0.8082 - 137ms/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.4372 - accuracy: 0.8045 - val_loss: 0.4636 - val_accuracy: 0.7890 - 126ms/epoch - 10ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.4336 - accuracy: 0.8035 - val_loss: 0.4511 - val_accuracy: 0.8082 - 132ms/epoch - 10ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 0.4308 - accuracy: 0.8051 - val_loss: 0.4476 - val_accuracy: 0.8082 - 131ms/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 0.4293 - accuracy: 0.8080 - val_loss: 0.4490 - val_accuracy: 0.8069 - 126ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 0.4285 - accuracy: 0.8054 - val_loss: 0.4503 - val_accuracy: 0.8082 - 122ms/epoch - 9ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 0.4306 - accuracy: 0.8045 - val_loss: 0.4516 - val_accuracy: 0.8146 - 127ms/epoch - 10ms/step\n",
      "Epoch 71: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 3.6035 - accuracy: 0.6374 - val_loss: 3.3599 - val_accuracy: 0.7315 - 2s/epoch - 147ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.1931 - accuracy: 0.7546 - val_loss: 2.9834 - val_accuracy: 0.7545 - 136ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 2.8339 - accuracy: 0.7632 - val_loss: 2.6454 - val_accuracy: 0.7558 - 142ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 2.5174 - accuracy: 0.7638 - val_loss: 2.3599 - val_accuracy: 0.7558 - 119ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.2414 - accuracy: 0.7638 - val_loss: 2.1048 - val_accuracy: 0.7558 - 126ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 2.0022 - accuracy: 0.7638 - val_loss: 1.8833 - val_accuracy: 0.7558 - 137ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.7921 - accuracy: 0.7638 - val_loss: 1.6897 - val_accuracy: 0.7558 - 178ms/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.6105 - accuracy: 0.7638 - val_loss: 1.5212 - val_accuracy: 0.7558 - 118ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.4495 - accuracy: 0.7638 - val_loss: 1.3695 - val_accuracy: 0.7558 - 119ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.3082 - accuracy: 0.7638 - val_loss: 1.2408 - val_accuracy: 0.7558 - 122ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.1856 - accuracy: 0.7638 - val_loss: 1.1256 - val_accuracy: 0.7621 - 124ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.0774 - accuracy: 0.7706 - val_loss: 1.0273 - val_accuracy: 0.7916 - 127ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.9842 - accuracy: 0.7914 - val_loss: 0.9435 - val_accuracy: 0.7992 - 147ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.9031 - accuracy: 0.8010 - val_loss: 0.8679 - val_accuracy: 0.8159 - 133ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.8332 - accuracy: 0.8029 - val_loss: 0.8045 - val_accuracy: 0.8133 - 124ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.7732 - accuracy: 0.8045 - val_loss: 0.7495 - val_accuracy: 0.8146 - 130ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.7210 - accuracy: 0.8048 - val_loss: 0.7066 - val_accuracy: 0.8107 - 128ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.6771 - accuracy: 0.8054 - val_loss: 0.6659 - val_accuracy: 0.8107 - 134ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6391 - accuracy: 0.8045 - val_loss: 0.6310 - val_accuracy: 0.8095 - 127ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6077 - accuracy: 0.8061 - val_loss: 0.6026 - val_accuracy: 0.8107 - 135ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.5810 - accuracy: 0.8048 - val_loss: 0.5781 - val_accuracy: 0.8107 - 125ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.5573 - accuracy: 0.8064 - val_loss: 0.5584 - val_accuracy: 0.8120 - 123ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.5365 - accuracy: 0.8042 - val_loss: 0.5412 - val_accuracy: 0.8082 - 126ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.5199 - accuracy: 0.8054 - val_loss: 0.5249 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.5062 - accuracy: 0.8058 - val_loss: 0.5125 - val_accuracy: 0.8107 - 131ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4936 - accuracy: 0.8042 - val_loss: 0.5028 - val_accuracy: 0.8082 - 126ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4835 - accuracy: 0.8064 - val_loss: 0.4929 - val_accuracy: 0.8095 - 117ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4747 - accuracy: 0.8064 - val_loss: 0.4878 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4691 - accuracy: 0.8035 - val_loss: 0.4796 - val_accuracy: 0.8095 - 130ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4627 - accuracy: 0.8054 - val_loss: 0.4768 - val_accuracy: 0.8095 - 120ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4577 - accuracy: 0.8054 - val_loss: 0.4717 - val_accuracy: 0.8107 - 124ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4538 - accuracy: 0.8054 - val_loss: 0.4673 - val_accuracy: 0.8069 - 124ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4503 - accuracy: 0.8061 - val_loss: 0.4644 - val_accuracy: 0.8082 - 136ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4475 - accuracy: 0.8048 - val_loss: 0.4620 - val_accuracy: 0.8082 - 135ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4445 - accuracy: 0.8038 - val_loss: 0.4597 - val_accuracy: 0.8082 - 140ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4409 - accuracy: 0.8061 - val_loss: 0.4580 - val_accuracy: 0.8095 - 145ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4397 - accuracy: 0.8064 - val_loss: 0.4561 - val_accuracy: 0.8095 - 130ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4375 - accuracy: 0.8048 - val_loss: 0.4558 - val_accuracy: 0.8082 - 127ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4390 - accuracy: 0.8090 - val_loss: 0.4562 - val_accuracy: 0.8107 - 126ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4405 - accuracy: 0.8045 - val_loss: 0.4580 - val_accuracy: 0.8107 - 134ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4405 - accuracy: 0.8038 - val_loss: 0.4553 - val_accuracy: 0.8056 - 127ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4356 - accuracy: 0.8064 - val_loss: 0.4528 - val_accuracy: 0.8095 - 129ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4338 - accuracy: 0.8054 - val_loss: 0.4540 - val_accuracy: 0.8095 - 136ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4334 - accuracy: 0.8045 - val_loss: 0.4518 - val_accuracy: 0.8082 - 129ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4341 - accuracy: 0.8058 - val_loss: 0.4504 - val_accuracy: 0.8082 - 150ms/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4332 - accuracy: 0.8054 - val_loss: 0.4518 - val_accuracy: 0.8095 - 124ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4316 - accuracy: 0.8054 - val_loss: 0.4504 - val_accuracy: 0.8056 - 127ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4309 - accuracy: 0.8074 - val_loss: 0.4514 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4301 - accuracy: 0.8045 - val_loss: 0.4488 - val_accuracy: 0.8069 - 132ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4300 - accuracy: 0.8054 - val_loss: 0.4513 - val_accuracy: 0.8095 - 122ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4311 - accuracy: 0.8048 - val_loss: 0.4505 - val_accuracy: 0.8082 - 131ms/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4315 - accuracy: 0.8070 - val_loss: 0.4477 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4313 - accuracy: 0.8051 - val_loss: 0.4502 - val_accuracy: 0.8056 - 127ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4303 - accuracy: 0.8032 - val_loss: 0.4496 - val_accuracy: 0.8082 - 125ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4292 - accuracy: 0.8067 - val_loss: 0.4531 - val_accuracy: 0.8107 - 130ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.4307 - accuracy: 0.8058 - val_loss: 0.4501 - val_accuracy: 0.8095 - 135ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.4327 - accuracy: 0.8048 - val_loss: 0.4508 - val_accuracy: 0.8043 - 119ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.4300 - accuracy: 0.8061 - val_loss: 0.4499 - val_accuracy: 0.8095 - 132ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.4295 - accuracy: 0.8064 - val_loss: 0.4493 - val_accuracy: 0.8082 - 130ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.4279 - accuracy: 0.8064 - val_loss: 0.4466 - val_accuracy: 0.8095 - 130ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.4281 - accuracy: 0.8054 - val_loss: 0.4506 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.4283 - accuracy: 0.8064 - val_loss: 0.4520 - val_accuracy: 0.8069 - 123ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.4280 - accuracy: 0.8048 - val_loss: 0.4506 - val_accuracy: 0.8107 - 133ms/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.4292 - accuracy: 0.8058 - val_loss: 0.4509 - val_accuracy: 0.8031 - 144ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.4264 - accuracy: 0.8067 - val_loss: 0.4509 - val_accuracy: 0.8069 - 140ms/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.4278 - accuracy: 0.8058 - val_loss: 0.4480 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.4272 - accuracy: 0.8064 - val_loss: 0.4486 - val_accuracy: 0.8095 - 120ms/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 0.4275 - accuracy: 0.8058 - val_loss: 0.4520 - val_accuracy: 0.8031 - 120ms/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 0.4275 - accuracy: 0.8070 - val_loss: 0.4523 - val_accuracy: 0.8095 - 120ms/epoch - 9ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 0.4291 - accuracy: 0.8054 - val_loss: 0.4519 - val_accuracy: 0.8043 - 118ms/epoch - 9ms/step\n",
      "Epoch 70: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "13/13 - 1s - loss: 3.7666 - accuracy: 0.7427 - val_loss: 3.5154 - val_accuracy: 0.7545 - 1s/epoch - 100ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.3418 - accuracy: 0.7638 - val_loss: 3.1309 - val_accuracy: 0.7558 - 123ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 2.9770 - accuracy: 0.7638 - val_loss: 2.7922 - val_accuracy: 0.7558 - 130ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 2.6556 - accuracy: 0.7638 - val_loss: 2.4915 - val_accuracy: 0.7558 - 117ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.3720 - accuracy: 0.7638 - val_loss: 2.2283 - val_accuracy: 0.7558 - 188ms/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 2.1234 - accuracy: 0.7638 - val_loss: 1.9994 - val_accuracy: 0.7532 - 145ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.9030 - accuracy: 0.7670 - val_loss: 1.7936 - val_accuracy: 0.7698 - 131ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.7097 - accuracy: 0.7744 - val_loss: 1.6135 - val_accuracy: 0.7839 - 122ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.5387 - accuracy: 0.7795 - val_loss: 1.4547 - val_accuracy: 0.7980 - 130ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.3885 - accuracy: 0.7872 - val_loss: 1.3167 - val_accuracy: 0.7992 - 151ms/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.2579 - accuracy: 0.7990 - val_loss: 1.1975 - val_accuracy: 0.8056 - 139ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.1434 - accuracy: 0.7958 - val_loss: 1.0942 - val_accuracy: 0.8069 - 147ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.0444 - accuracy: 0.8016 - val_loss: 1.0019 - val_accuracy: 0.8107 - 145ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.9563 - accuracy: 0.8061 - val_loss: 0.9231 - val_accuracy: 0.8095 - 127ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.8810 - accuracy: 0.8074 - val_loss: 0.8587 - val_accuracy: 0.8043 - 123ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.8179 - accuracy: 0.7955 - val_loss: 0.7968 - val_accuracy: 0.8082 - 128ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.7609 - accuracy: 0.8048 - val_loss: 0.7459 - val_accuracy: 0.8107 - 134ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.7117 - accuracy: 0.8051 - val_loss: 0.7000 - val_accuracy: 0.8082 - 141ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6701 - accuracy: 0.8080 - val_loss: 0.6625 - val_accuracy: 0.8107 - 143ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6348 - accuracy: 0.8042 - val_loss: 0.6327 - val_accuracy: 0.8082 - 141ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.6053 - accuracy: 0.8029 - val_loss: 0.6088 - val_accuracy: 0.8069 - 134ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.5792 - accuracy: 0.8054 - val_loss: 0.5823 - val_accuracy: 0.8069 - 179ms/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.5561 - accuracy: 0.8032 - val_loss: 0.5574 - val_accuracy: 0.8107 - 116ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.5342 - accuracy: 0.8064 - val_loss: 0.5392 - val_accuracy: 0.8095 - 118ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.5182 - accuracy: 0.8048 - val_loss: 0.5276 - val_accuracy: 0.8095 - 123ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.5042 - accuracy: 0.8061 - val_loss: 0.5146 - val_accuracy: 0.8082 - 117ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4938 - accuracy: 0.8067 - val_loss: 0.5035 - val_accuracy: 0.8069 - 130ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4852 - accuracy: 0.8051 - val_loss: 0.4971 - val_accuracy: 0.8069 - 115ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4772 - accuracy: 0.8042 - val_loss: 0.4887 - val_accuracy: 0.8082 - 118ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4710 - accuracy: 0.8042 - val_loss: 0.4867 - val_accuracy: 0.8031 - 124ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4624 - accuracy: 0.8077 - val_loss: 0.4821 - val_accuracy: 0.8005 - 122ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4583 - accuracy: 0.8054 - val_loss: 0.4800 - val_accuracy: 0.8069 - 122ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4561 - accuracy: 0.8070 - val_loss: 0.4675 - val_accuracy: 0.8095 - 120ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4499 - accuracy: 0.8032 - val_loss: 0.4668 - val_accuracy: 0.8082 - 122ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4455 - accuracy: 0.8067 - val_loss: 0.4609 - val_accuracy: 0.8095 - 135ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4434 - accuracy: 0.8038 - val_loss: 0.4580 - val_accuracy: 0.8095 - 129ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4406 - accuracy: 0.8074 - val_loss: 0.4587 - val_accuracy: 0.8082 - 115ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4392 - accuracy: 0.8070 - val_loss: 0.4575 - val_accuracy: 0.8069 - 113ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4378 - accuracy: 0.8054 - val_loss: 0.4573 - val_accuracy: 0.8082 - 122ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4377 - accuracy: 0.8045 - val_loss: 0.4543 - val_accuracy: 0.8082 - 140ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4347 - accuracy: 0.8061 - val_loss: 0.4534 - val_accuracy: 0.8069 - 141ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4344 - accuracy: 0.8064 - val_loss: 0.4497 - val_accuracy: 0.8043 - 123ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4342 - accuracy: 0.8067 - val_loss: 0.4508 - val_accuracy: 0.8056 - 134ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4329 - accuracy: 0.8061 - val_loss: 0.4523 - val_accuracy: 0.8082 - 126ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4325 - accuracy: 0.8058 - val_loss: 0.4553 - val_accuracy: 0.8069 - 124ms/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4346 - accuracy: 0.8045 - val_loss: 0.4516 - val_accuracy: 0.8056 - 133ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4331 - accuracy: 0.8051 - val_loss: 0.4559 - val_accuracy: 0.7903 - 133ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4361 - accuracy: 0.8000 - val_loss: 0.4521 - val_accuracy: 0.8107 - 136ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4327 - accuracy: 0.8061 - val_loss: 0.4548 - val_accuracy: 0.8043 - 130ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4309 - accuracy: 0.8074 - val_loss: 0.4524 - val_accuracy: 0.8069 - 137ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4303 - accuracy: 0.8038 - val_loss: 0.4494 - val_accuracy: 0.8069 - 133ms/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4284 - accuracy: 0.8064 - val_loss: 0.4504 - val_accuracy: 0.8095 - 122ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4306 - accuracy: 0.8022 - val_loss: 0.4499 - val_accuracy: 0.8082 - 132ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4303 - accuracy: 0.8010 - val_loss: 0.4524 - val_accuracy: 0.8069 - 122ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4301 - accuracy: 0.8067 - val_loss: 0.4505 - val_accuracy: 0.8082 - 130ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.4544 - val_accuracy: 0.7954 - 134ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.4293 - accuracy: 0.8051 - val_loss: 0.4519 - val_accuracy: 0.8095 - 118ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.4306 - accuracy: 0.8064 - val_loss: 0.4551 - val_accuracy: 0.8095 - 130ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.4283 - accuracy: 0.8048 - val_loss: 0.4553 - val_accuracy: 0.7941 - 120ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.4317 - accuracy: 0.8042 - val_loss: 0.4496 - val_accuracy: 0.8082 - 111ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.4287 - accuracy: 0.8058 - val_loss: 0.4498 - val_accuracy: 0.8069 - 111ms/epoch - 9ms/step\n",
      "Epoch 61: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 3.7381 - accuracy: 0.4189 - val_loss: 3.4993 - val_accuracy: 0.5742 - 2s/epoch - 116ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.3295 - accuracy: 0.6611 - val_loss: 3.1149 - val_accuracy: 0.7340 - 168ms/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 2.9622 - accuracy: 0.7542 - val_loss: 2.7721 - val_accuracy: 0.7519 - 137ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 2.6327 - accuracy: 0.7638 - val_loss: 2.4620 - val_accuracy: 0.7558 - 128ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.3410 - accuracy: 0.7638 - val_loss: 2.1938 - val_accuracy: 0.7558 - 134ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 2.0874 - accuracy: 0.7638 - val_loss: 1.9634 - val_accuracy: 0.7558 - 133ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.8695 - accuracy: 0.7638 - val_loss: 1.7626 - val_accuracy: 0.7558 - 133ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.6794 - accuracy: 0.7638 - val_loss: 1.5874 - val_accuracy: 0.7558 - 127ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.5132 - accuracy: 0.7638 - val_loss: 1.4364 - val_accuracy: 0.7558 - 129ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.3694 - accuracy: 0.7638 - val_loss: 1.3017 - val_accuracy: 0.7558 - 128ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.2417 - accuracy: 0.7638 - val_loss: 1.1845 - val_accuracy: 0.7558 - 131ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.1308 - accuracy: 0.7645 - val_loss: 1.0814 - val_accuracy: 0.7570 - 129ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.0346 - accuracy: 0.7642 - val_loss: 0.9929 - val_accuracy: 0.7570 - 136ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.9490 - accuracy: 0.7661 - val_loss: 0.9153 - val_accuracy: 0.7621 - 129ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.8754 - accuracy: 0.7712 - val_loss: 0.8491 - val_accuracy: 0.7621 - 124ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.8118 - accuracy: 0.7744 - val_loss: 0.7898 - val_accuracy: 0.7839 - 131ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.7567 - accuracy: 0.7830 - val_loss: 0.7406 - val_accuracy: 0.7954 - 124ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.7084 - accuracy: 0.7926 - val_loss: 0.6970 - val_accuracy: 0.8031 - 126ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6679 - accuracy: 0.7994 - val_loss: 0.6612 - val_accuracy: 0.8018 - 132ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6310 - accuracy: 0.8026 - val_loss: 0.6280 - val_accuracy: 0.8005 - 129ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.6012 - accuracy: 0.7997 - val_loss: 0.5990 - val_accuracy: 0.8184 - 241ms/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.5756 - accuracy: 0.8010 - val_loss: 0.5782 - val_accuracy: 0.8133 - 117ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.5519 - accuracy: 0.8054 - val_loss: 0.5579 - val_accuracy: 0.8069 - 131ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.5337 - accuracy: 0.8032 - val_loss: 0.5404 - val_accuracy: 0.8095 - 135ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.5195 - accuracy: 0.8064 - val_loss: 0.5271 - val_accuracy: 0.8107 - 143ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.5055 - accuracy: 0.8058 - val_loss: 0.5136 - val_accuracy: 0.8069 - 193ms/epoch - 15ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4932 - accuracy: 0.8054 - val_loss: 0.5031 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4830 - accuracy: 0.8029 - val_loss: 0.4959 - val_accuracy: 0.8069 - 148ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4747 - accuracy: 0.8061 - val_loss: 0.4907 - val_accuracy: 0.8056 - 131ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4683 - accuracy: 0.8045 - val_loss: 0.4821 - val_accuracy: 0.8107 - 122ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4627 - accuracy: 0.8064 - val_loss: 0.4768 - val_accuracy: 0.8107 - 142ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4566 - accuracy: 0.8051 - val_loss: 0.4734 - val_accuracy: 0.8069 - 139ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4538 - accuracy: 0.8051 - val_loss: 0.4681 - val_accuracy: 0.8069 - 134ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4500 - accuracy: 0.8067 - val_loss: 0.4662 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4479 - accuracy: 0.8058 - val_loss: 0.4654 - val_accuracy: 0.8069 - 132ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4455 - accuracy: 0.8045 - val_loss: 0.4609 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4424 - accuracy: 0.8074 - val_loss: 0.4597 - val_accuracy: 0.8095 - 120ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4416 - accuracy: 0.8048 - val_loss: 0.4598 - val_accuracy: 0.8082 - 221ms/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4412 - accuracy: 0.8042 - val_loss: 0.4599 - val_accuracy: 0.8095 - 112ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4387 - accuracy: 0.8051 - val_loss: 0.4569 - val_accuracy: 0.8082 - 120ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4381 - accuracy: 0.8048 - val_loss: 0.4554 - val_accuracy: 0.8082 - 130ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4358 - accuracy: 0.8064 - val_loss: 0.4558 - val_accuracy: 0.8069 - 132ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4348 - accuracy: 0.8064 - val_loss: 0.4554 - val_accuracy: 0.8069 - 127ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4360 - accuracy: 0.8022 - val_loss: 0.4552 - val_accuracy: 0.8069 - 130ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4334 - accuracy: 0.8061 - val_loss: 0.4534 - val_accuracy: 0.8069 - 138ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4332 - accuracy: 0.8067 - val_loss: 0.4528 - val_accuracy: 0.8069 - 127ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4332 - accuracy: 0.8067 - val_loss: 0.4522 - val_accuracy: 0.8082 - 129ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4325 - accuracy: 0.8042 - val_loss: 0.4557 - val_accuracy: 0.8069 - 131ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4349 - accuracy: 0.8061 - val_loss: 0.4537 - val_accuracy: 0.8082 - 128ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4330 - accuracy: 0.8035 - val_loss: 0.4526 - val_accuracy: 0.8107 - 130ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4329 - accuracy: 0.8054 - val_loss: 0.4565 - val_accuracy: 0.8095 - 121ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4363 - accuracy: 0.8051 - val_loss: 0.4507 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4320 - accuracy: 0.8038 - val_loss: 0.4506 - val_accuracy: 0.8095 - 146ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4303 - accuracy: 0.8058 - val_loss: 0.4526 - val_accuracy: 0.8082 - 138ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4303 - accuracy: 0.8058 - val_loss: 0.4533 - val_accuracy: 0.8043 - 133ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.4311 - accuracy: 0.8064 - val_loss: 0.4526 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.4310 - accuracy: 0.8048 - val_loss: 0.4510 - val_accuracy: 0.8082 - 140ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.4293 - accuracy: 0.8058 - val_loss: 0.4560 - val_accuracy: 0.8005 - 134ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.4322 - accuracy: 0.8045 - val_loss: 0.4515 - val_accuracy: 0.8082 - 130ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.4303 - accuracy: 0.8045 - val_loss: 0.4520 - val_accuracy: 0.8082 - 140ms/epoch - 11ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.4298 - accuracy: 0.8054 - val_loss: 0.4513 - val_accuracy: 0.8082 - 139ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.4305 - accuracy: 0.8054 - val_loss: 0.4536 - val_accuracy: 0.8031 - 133ms/epoch - 10ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.4312 - accuracy: 0.8026 - val_loss: 0.4505 - val_accuracy: 0.8082 - 146ms/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.4297 - accuracy: 0.8058 - val_loss: 0.4537 - val_accuracy: 0.8120 - 136ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.4299 - accuracy: 0.8042 - val_loss: 0.4504 - val_accuracy: 0.8056 - 135ms/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.4289 - accuracy: 0.8061 - val_loss: 0.4521 - val_accuracy: 0.8107 - 139ms/epoch - 11ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.4292 - accuracy: 0.8061 - val_loss: 0.4531 - val_accuracy: 0.8031 - 140ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 0.4289 - accuracy: 0.8048 - val_loss: 0.4492 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 0.4286 - accuracy: 0.8074 - val_loss: 0.4491 - val_accuracy: 0.8069 - 145ms/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 0.4283 - accuracy: 0.8061 - val_loss: 0.4512 - val_accuracy: 0.8056 - 172ms/epoch - 13ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 0.4291 - accuracy: 0.8070 - val_loss: 0.4487 - val_accuracy: 0.8043 - 151ms/epoch - 12ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 0.4278 - accuracy: 0.8067 - val_loss: 0.4506 - val_accuracy: 0.8069 - 149ms/epoch - 11ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 0.4295 - accuracy: 0.8048 - val_loss: 0.4501 - val_accuracy: 0.8069 - 150ms/epoch - 12ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 0.4280 - accuracy: 0.8051 - val_loss: 0.4493 - val_accuracy: 0.8043 - 136ms/epoch - 10ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 0.4281 - accuracy: 0.8058 - val_loss: 0.4528 - val_accuracy: 0.8056 - 146ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 0.4362 - accuracy: 0.7974 - val_loss: 0.4507 - val_accuracy: 0.8069 - 149ms/epoch - 11ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 0.4308 - accuracy: 0.8032 - val_loss: 0.4535 - val_accuracy: 0.8043 - 129ms/epoch - 10ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 0.4285 - accuracy: 0.8070 - val_loss: 0.4506 - val_accuracy: 0.8095 - 126ms/epoch - 10ms/step\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 0.4269 - accuracy: 0.8070 - val_loss: 0.4522 - val_accuracy: 0.8043 - 127ms/epoch - 10ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 0.4290 - accuracy: 0.8048 - val_loss: 0.4506 - val_accuracy: 0.8082 - 146ms/epoch - 11ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 0.4291 - accuracy: 0.8051 - val_loss: 0.4525 - val_accuracy: 0.8069 - 140ms/epoch - 11ms/step\n",
      "Epoch 81: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "13/13 - 1s - loss: 3.5311 - accuracy: 0.7581 - val_loss: 3.2991 - val_accuracy: 0.7558 - 1s/epoch - 109ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 3.1342 - accuracy: 0.7638 - val_loss: 2.9380 - val_accuracy: 0.7558 - 127ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 2.7901 - accuracy: 0.7638 - val_loss: 2.6161 - val_accuracy: 0.7558 - 137ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 2.4857 - accuracy: 0.7638 - val_loss: 2.3322 - val_accuracy: 0.7558 - 123ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 2.2185 - accuracy: 0.7638 - val_loss: 2.0841 - val_accuracy: 0.7558 - 141ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 1.9832 - accuracy: 0.7638 - val_loss: 1.8669 - val_accuracy: 0.7570 - 168ms/epoch - 13ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.7767 - accuracy: 0.7645 - val_loss: 1.6760 - val_accuracy: 0.7621 - 107ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.5956 - accuracy: 0.7661 - val_loss: 1.5083 - val_accuracy: 0.7788 - 114ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.4380 - accuracy: 0.7814 - val_loss: 1.3643 - val_accuracy: 0.7928 - 115ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.2998 - accuracy: 0.7907 - val_loss: 1.2380 - val_accuracy: 0.7941 - 123ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.1802 - accuracy: 0.7901 - val_loss: 1.1272 - val_accuracy: 0.8056 - 130ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.0752 - accuracy: 0.8000 - val_loss: 1.0332 - val_accuracy: 0.8133 - 132ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.9837 - accuracy: 0.8045 - val_loss: 0.9484 - val_accuracy: 0.8082 - 137ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.9057 - accuracy: 0.8032 - val_loss: 0.8779 - val_accuracy: 0.8107 - 144ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.8362 - accuracy: 0.8061 - val_loss: 0.8166 - val_accuracy: 0.8095 - 137ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.7768 - accuracy: 0.8064 - val_loss: 0.7614 - val_accuracy: 0.8120 - 124ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.7260 - accuracy: 0.8045 - val_loss: 0.7149 - val_accuracy: 0.8095 - 127ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.6814 - accuracy: 0.8070 - val_loss: 0.6759 - val_accuracy: 0.8120 - 135ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.6439 - accuracy: 0.8067 - val_loss: 0.6404 - val_accuracy: 0.8095 - 130ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.6121 - accuracy: 0.8064 - val_loss: 0.6109 - val_accuracy: 0.8107 - 283ms/epoch - 22ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.5828 - accuracy: 0.8064 - val_loss: 0.5866 - val_accuracy: 0.8095 - 131ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.5592 - accuracy: 0.8054 - val_loss: 0.5633 - val_accuracy: 0.8120 - 130ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.5391 - accuracy: 0.8054 - val_loss: 0.5463 - val_accuracy: 0.8095 - 125ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.5230 - accuracy: 0.8070 - val_loss: 0.5313 - val_accuracy: 0.8107 - 121ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.5106 - accuracy: 0.8064 - val_loss: 0.5184 - val_accuracy: 0.8107 - 127ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4961 - accuracy: 0.8064 - val_loss: 0.5050 - val_accuracy: 0.8095 - 126ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4848 - accuracy: 0.8058 - val_loss: 0.4979 - val_accuracy: 0.8107 - 130ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4768 - accuracy: 0.8067 - val_loss: 0.4906 - val_accuracy: 0.8107 - 124ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4692 - accuracy: 0.8061 - val_loss: 0.4847 - val_accuracy: 0.8082 - 109ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4622 - accuracy: 0.8061 - val_loss: 0.4789 - val_accuracy: 0.8120 - 116ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4576 - accuracy: 0.8067 - val_loss: 0.4738 - val_accuracy: 0.8056 - 125ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4553 - accuracy: 0.8048 - val_loss: 0.4694 - val_accuracy: 0.8095 - 128ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4495 - accuracy: 0.8058 - val_loss: 0.4669 - val_accuracy: 0.8107 - 122ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4461 - accuracy: 0.8067 - val_loss: 0.4622 - val_accuracy: 0.8107 - 120ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4446 - accuracy: 0.8058 - val_loss: 0.4636 - val_accuracy: 0.8120 - 122ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4417 - accuracy: 0.8064 - val_loss: 0.4588 - val_accuracy: 0.8082 - 121ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4390 - accuracy: 0.8061 - val_loss: 0.4571 - val_accuracy: 0.8107 - 118ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4391 - accuracy: 0.8061 - val_loss: 0.4588 - val_accuracy: 0.8107 - 126ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4387 - accuracy: 0.8064 - val_loss: 0.4590 - val_accuracy: 0.8031 - 131ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4365 - accuracy: 0.8045 - val_loss: 0.4538 - val_accuracy: 0.8095 - 140ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4346 - accuracy: 0.8064 - val_loss: 0.4545 - val_accuracy: 0.8082 - 135ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4341 - accuracy: 0.8064 - val_loss: 0.4535 - val_accuracy: 0.8095 - 139ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4332 - accuracy: 0.8058 - val_loss: 0.4534 - val_accuracy: 0.8107 - 127ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4349 - accuracy: 0.8054 - val_loss: 0.4531 - val_accuracy: 0.8095 - 119ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4315 - accuracy: 0.8061 - val_loss: 0.4530 - val_accuracy: 0.8107 - 135ms/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4340 - accuracy: 0.8058 - val_loss: 0.4522 - val_accuracy: 0.8082 - 134ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4316 - accuracy: 0.8064 - val_loss: 0.4526 - val_accuracy: 0.8082 - 124ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4311 - accuracy: 0.8061 - val_loss: 0.4505 - val_accuracy: 0.8095 - 136ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4307 - accuracy: 0.8064 - val_loss: 0.4503 - val_accuracy: 0.8095 - 141ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4299 - accuracy: 0.8061 - val_loss: 0.4516 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4298 - accuracy: 0.8064 - val_loss: 0.4518 - val_accuracy: 0.8082 - 122ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4308 - accuracy: 0.8058 - val_loss: 0.4503 - val_accuracy: 0.8082 - 128ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4289 - accuracy: 0.8067 - val_loss: 0.4548 - val_accuracy: 0.8107 - 137ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4305 - accuracy: 0.8074 - val_loss: 0.4495 - val_accuracy: 0.8095 - 129ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4286 - accuracy: 0.8067 - val_loss: 0.4512 - val_accuracy: 0.8082 - 123ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 0.4291 - accuracy: 0.8067 - val_loss: 0.4507 - val_accuracy: 0.8107 - 121ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 0.4282 - accuracy: 0.8038 - val_loss: 0.4514 - val_accuracy: 0.8082 - 135ms/epoch - 10ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 0.4289 - accuracy: 0.8061 - val_loss: 0.4522 - val_accuracy: 0.8069 - 127ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 0.4280 - accuracy: 0.8061 - val_loss: 0.4496 - val_accuracy: 0.8095 - 120ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 0.4286 - accuracy: 0.8058 - val_loss: 0.4503 - val_accuracy: 0.8082 - 131ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 0.4285 - accuracy: 0.8064 - val_loss: 0.4499 - val_accuracy: 0.8095 - 136ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 0.4278 - accuracy: 0.8058 - val_loss: 0.4491 - val_accuracy: 0.8082 - 117ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 0.4296 - accuracy: 0.8054 - val_loss: 0.4504 - val_accuracy: 0.8082 - 115ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 0.4308 - accuracy: 0.8051 - val_loss: 0.4508 - val_accuracy: 0.8082 - 125ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 0.4272 - accuracy: 0.8054 - val_loss: 0.4570 - val_accuracy: 0.7967 - 124ms/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 0.4300 - accuracy: 0.8054 - val_loss: 0.4529 - val_accuracy: 0.8082 - 118ms/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 0.4278 - accuracy: 0.8070 - val_loss: 0.4501 - val_accuracy: 0.8095 - 125ms/epoch - 10ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 0.4271 - accuracy: 0.8064 - val_loss: 0.4486 - val_accuracy: 0.8095 - 121ms/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 0.4267 - accuracy: 0.8074 - val_loss: 0.4547 - val_accuracy: 0.7992 - 133ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 0.4294 - accuracy: 0.8058 - val_loss: 0.4508 - val_accuracy: 0.8082 - 143ms/epoch - 11ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 0.4294 - accuracy: 0.8051 - val_loss: 0.4550 - val_accuracy: 0.8031 - 134ms/epoch - 10ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 0.4268 - accuracy: 0.8083 - val_loss: 0.4492 - val_accuracy: 0.8095 - 142ms/epoch - 11ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 0.4253 - accuracy: 0.8061 - val_loss: 0.4488 - val_accuracy: 0.8082 - 134ms/epoch - 10ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 0.4251 - accuracy: 0.8064 - val_loss: 0.4507 - val_accuracy: 0.8095 - 128ms/epoch - 10ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 0.4253 - accuracy: 0.8054 - val_loss: 0.4498 - val_accuracy: 0.8107 - 131ms/epoch - 10ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 0.4258 - accuracy: 0.8064 - val_loss: 0.4519 - val_accuracy: 0.8107 - 136ms/epoch - 10ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 0.4253 - accuracy: 0.8061 - val_loss: 0.4510 - val_accuracy: 0.8082 - 138ms/epoch - 11ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 0.4260 - accuracy: 0.8061 - val_loss: 0.4516 - val_accuracy: 0.8082 - 133ms/epoch - 10ms/step\n",
      "Epoch 78: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.4406959585333589\n",
      "epi entropy:  0.412198451034542\n",
      "\n",
      "dataset size:  0.2\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 3.4814 - accuracy: 0.4852 - val_loss: 3.0895 - val_accuracy: 0.7076 - 2s/epoch - 61ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 2.7895 - accuracy: 0.7468 - val_loss: 2.4761 - val_accuracy: 0.7633 - 258ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 2.2429 - accuracy: 0.7549 - val_loss: 1.9964 - val_accuracy: 0.7620 - 248ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 1.8175 - accuracy: 0.7541 - val_loss: 1.6241 - val_accuracy: 0.7620 - 206ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 1.4894 - accuracy: 0.7541 - val_loss: 1.3382 - val_accuracy: 0.7620 - 213ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 1.2339 - accuracy: 0.7541 - val_loss: 1.1166 - val_accuracy: 0.7620 - 219ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 1.0371 - accuracy: 0.7544 - val_loss: 0.9464 - val_accuracy: 0.7646 - 235ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.8845 - accuracy: 0.7647 - val_loss: 0.8160 - val_accuracy: 0.7799 - 234ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.7665 - accuracy: 0.7877 - val_loss: 0.7140 - val_accuracy: 0.7946 - 216ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.6768 - accuracy: 0.7936 - val_loss: 0.6386 - val_accuracy: 0.7985 - 218ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.6091 - accuracy: 0.7965 - val_loss: 0.5863 - val_accuracy: 0.8004 - 215ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.5612 - accuracy: 0.8004 - val_loss: 0.5432 - val_accuracy: 0.8017 - 188ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.5248 - accuracy: 0.8010 - val_loss: 0.5185 - val_accuracy: 0.7997 - 214ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.5008 - accuracy: 0.8016 - val_loss: 0.4974 - val_accuracy: 0.7978 - 214ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4819 - accuracy: 0.8013 - val_loss: 0.4786 - val_accuracy: 0.8029 - 204ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4682 - accuracy: 0.8028 - val_loss: 0.4672 - val_accuracy: 0.7991 - 200ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4583 - accuracy: 0.8034 - val_loss: 0.4599 - val_accuracy: 0.8004 - 174ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4513 - accuracy: 0.8020 - val_loss: 0.4545 - val_accuracy: 0.8029 - 214ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4459 - accuracy: 0.8039 - val_loss: 0.4497 - val_accuracy: 0.7991 - 238ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4442 - accuracy: 0.8004 - val_loss: 0.4491 - val_accuracy: 0.7972 - 232ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4409 - accuracy: 0.8042 - val_loss: 0.4474 - val_accuracy: 0.8004 - 236ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4377 - accuracy: 0.8042 - val_loss: 0.4458 - val_accuracy: 0.8004 - 231ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4391 - accuracy: 0.8024 - val_loss: 0.4412 - val_accuracy: 0.7991 - 225ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4372 - accuracy: 0.8024 - val_loss: 0.4426 - val_accuracy: 0.8023 - 217ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4358 - accuracy: 0.8016 - val_loss: 0.4426 - val_accuracy: 0.7991 - 218ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4358 - accuracy: 0.8034 - val_loss: 0.4414 - val_accuracy: 0.7991 - 192ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4345 - accuracy: 0.8037 - val_loss: 0.4396 - val_accuracy: 0.8010 - 229ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4333 - accuracy: 0.8026 - val_loss: 0.4438 - val_accuracy: 0.7965 - 202ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4335 - accuracy: 0.8013 - val_loss: 0.4387 - val_accuracy: 0.8017 - 230ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4343 - accuracy: 0.8015 - val_loss: 0.4441 - val_accuracy: 0.7997 - 221ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4338 - accuracy: 0.8012 - val_loss: 0.4417 - val_accuracy: 0.7985 - 209ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4331 - accuracy: 0.8021 - val_loss: 0.4412 - val_accuracy: 0.8010 - 217ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4336 - accuracy: 0.8036 - val_loss: 0.4410 - val_accuracy: 0.7985 - 196ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4317 - accuracy: 0.8024 - val_loss: 0.4400 - val_accuracy: 0.8017 - 198ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4328 - accuracy: 0.8010 - val_loss: 0.4571 - val_accuracy: 0.7831 - 207ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4376 - accuracy: 0.8002 - val_loss: 0.4452 - val_accuracy: 0.8010 - 199ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4352 - accuracy: 0.8037 - val_loss: 0.4393 - val_accuracy: 0.8017 - 249ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4321 - accuracy: 0.8036 - val_loss: 0.4400 - val_accuracy: 0.8023 - 229ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4314 - accuracy: 0.8024 - val_loss: 0.4403 - val_accuracy: 0.8017 - 212ms/epoch - 8ms/step\n",
      "Epoch 39: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 3.3473 - accuracy: 0.7410 - val_loss: 2.9587 - val_accuracy: 0.7620 - 2s/epoch - 76ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 2.6729 - accuracy: 0.7541 - val_loss: 2.3665 - val_accuracy: 0.7620 - 231ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 2.1446 - accuracy: 0.7562 - val_loss: 1.9026 - val_accuracy: 0.7684 - 209ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 1.7275 - accuracy: 0.7727 - val_loss: 1.5422 - val_accuracy: 0.7914 - 253ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 1.4065 - accuracy: 0.7919 - val_loss: 1.2647 - val_accuracy: 0.7940 - 198ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 1.1582 - accuracy: 0.7981 - val_loss: 1.0545 - val_accuracy: 0.8004 - 225ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.9736 - accuracy: 0.8013 - val_loss: 0.8935 - val_accuracy: 0.7997 - 240ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.8325 - accuracy: 0.8007 - val_loss: 0.7748 - val_accuracy: 0.8010 - 215ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.7267 - accuracy: 0.8028 - val_loss: 0.6865 - val_accuracy: 0.8004 - 204ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.6473 - accuracy: 0.8004 - val_loss: 0.6178 - val_accuracy: 0.8010 - 197ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.5890 - accuracy: 0.8010 - val_loss: 0.5706 - val_accuracy: 0.8010 - 213ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.5453 - accuracy: 0.8013 - val_loss: 0.5345 - val_accuracy: 0.8004 - 217ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.5127 - accuracy: 0.8026 - val_loss: 0.5042 - val_accuracy: 0.8017 - 194ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4901 - accuracy: 0.8016 - val_loss: 0.4858 - val_accuracy: 0.8004 - 199ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4730 - accuracy: 0.8036 - val_loss: 0.4715 - val_accuracy: 0.8023 - 203ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4620 - accuracy: 0.8026 - val_loss: 0.4615 - val_accuracy: 0.8010 - 195ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4526 - accuracy: 0.8023 - val_loss: 0.4554 - val_accuracy: 0.8010 - 232ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4467 - accuracy: 0.8013 - val_loss: 0.4498 - val_accuracy: 0.7997 - 199ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4433 - accuracy: 0.8004 - val_loss: 0.4489 - val_accuracy: 0.7997 - 208ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4398 - accuracy: 0.8021 - val_loss: 0.4445 - val_accuracy: 0.7991 - 204ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4394 - accuracy: 0.8007 - val_loss: 0.4437 - val_accuracy: 0.8017 - 231ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4374 - accuracy: 0.8018 - val_loss: 0.4424 - val_accuracy: 0.8023 - 223ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4345 - accuracy: 0.8026 - val_loss: 0.4408 - val_accuracy: 0.8010 - 220ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4335 - accuracy: 0.8036 - val_loss: 0.4398 - val_accuracy: 0.8004 - 327ms/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4335 - accuracy: 0.8020 - val_loss: 0.4409 - val_accuracy: 0.7978 - 332ms/epoch - 13ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4326 - accuracy: 0.8032 - val_loss: 0.4409 - val_accuracy: 0.7972 - 263ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4329 - accuracy: 0.8010 - val_loss: 0.4390 - val_accuracy: 0.8004 - 282ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4336 - accuracy: 0.8015 - val_loss: 0.4398 - val_accuracy: 0.7978 - 234ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4327 - accuracy: 0.8008 - val_loss: 0.4379 - val_accuracy: 0.8017 - 258ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4307 - accuracy: 0.8012 - val_loss: 0.4371 - val_accuracy: 0.8010 - 250ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4308 - accuracy: 0.8016 - val_loss: 0.4374 - val_accuracy: 0.7991 - 257ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4302 - accuracy: 0.8023 - val_loss: 0.4376 - val_accuracy: 0.7997 - 314ms/epoch - 13ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4301 - accuracy: 0.8032 - val_loss: 0.4404 - val_accuracy: 0.7965 - 256ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4300 - accuracy: 0.8000 - val_loss: 0.4370 - val_accuracy: 0.7991 - 239ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4301 - accuracy: 0.8031 - val_loss: 0.4423 - val_accuracy: 0.7940 - 242ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4331 - accuracy: 0.8005 - val_loss: 0.4387 - val_accuracy: 0.8004 - 253ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4293 - accuracy: 0.8015 - val_loss: 0.4380 - val_accuracy: 0.8010 - 233ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4316 - accuracy: 0.8021 - val_loss: 0.4377 - val_accuracy: 0.8023 - 253ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4304 - accuracy: 0.8036 - val_loss: 0.4360 - val_accuracy: 0.8004 - 260ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4294 - accuracy: 0.8016 - val_loss: 0.4381 - val_accuracy: 0.7972 - 286ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4293 - accuracy: 0.8020 - val_loss: 0.4367 - val_accuracy: 0.7991 - 294ms/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4285 - accuracy: 0.8031 - val_loss: 0.4362 - val_accuracy: 0.8023 - 221ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4292 - accuracy: 0.8008 - val_loss: 0.4360 - val_accuracy: 0.8010 - 209ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4290 - accuracy: 0.8032 - val_loss: 0.4374 - val_accuracy: 0.7985 - 219ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4285 - accuracy: 0.8023 - val_loss: 0.4388 - val_accuracy: 0.7997 - 191ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4281 - accuracy: 0.8040 - val_loss: 0.4360 - val_accuracy: 0.7997 - 214ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4283 - accuracy: 0.8024 - val_loss: 0.4372 - val_accuracy: 0.7997 - 198ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4287 - accuracy: 0.8031 - val_loss: 0.4360 - val_accuracy: 0.7991 - 227ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4284 - accuracy: 0.8040 - val_loss: 0.4365 - val_accuracy: 0.8010 - 206ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4305 - accuracy: 0.8005 - val_loss: 0.4349 - val_accuracy: 0.7997 - 256ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 0s - loss: 0.4291 - accuracy: 0.8036 - val_loss: 0.4363 - val_accuracy: 0.7997 - 264ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 0s - loss: 0.4280 - accuracy: 0.8008 - val_loss: 0.4360 - val_accuracy: 0.8010 - 281ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 0s - loss: 0.4286 - accuracy: 0.8024 - val_loss: 0.4385 - val_accuracy: 0.7965 - 342ms/epoch - 14ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 0s - loss: 0.4300 - accuracy: 0.8013 - val_loss: 0.4381 - val_accuracy: 0.7965 - 283ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 0s - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.4365 - val_accuracy: 0.7972 - 318ms/epoch - 13ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 0s - loss: 0.4288 - accuracy: 0.8042 - val_loss: 0.4374 - val_accuracy: 0.7997 - 309ms/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 0s - loss: 0.4282 - accuracy: 0.8028 - val_loss: 0.4374 - val_accuracy: 0.7940 - 283ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 0s - loss: 0.4280 - accuracy: 0.8023 - val_loss: 0.4374 - val_accuracy: 0.7946 - 267ms/epoch - 11ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 0s - loss: 0.4286 - accuracy: 0.8032 - val_loss: 0.4343 - val_accuracy: 0.7997 - 256ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 0s - loss: 0.4272 - accuracy: 0.8012 - val_loss: 0.4383 - val_accuracy: 0.8004 - 320ms/epoch - 13ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 0s - loss: 0.4283 - accuracy: 0.8026 - val_loss: 0.4367 - val_accuracy: 0.7965 - 299ms/epoch - 12ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 0s - loss: 0.4278 - accuracy: 0.8036 - val_loss: 0.4377 - val_accuracy: 0.7991 - 288ms/epoch - 12ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 0s - loss: 0.4285 - accuracy: 0.8013 - val_loss: 0.4362 - val_accuracy: 0.7946 - 312ms/epoch - 12ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 0s - loss: 0.4271 - accuracy: 0.8013 - val_loss: 0.4374 - val_accuracy: 0.7997 - 282ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 0s - loss: 0.4265 - accuracy: 0.8034 - val_loss: 0.4361 - val_accuracy: 0.7991 - 292ms/epoch - 12ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 0s - loss: 0.4270 - accuracy: 0.8039 - val_loss: 0.4376 - val_accuracy: 0.7953 - 288ms/epoch - 12ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 0s - loss: 0.4261 - accuracy: 0.8020 - val_loss: 0.4385 - val_accuracy: 0.7927 - 273ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 0s - loss: 0.4259 - accuracy: 0.8024 - val_loss: 0.4363 - val_accuracy: 0.7959 - 289ms/epoch - 12ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 0s - loss: 0.4278 - accuracy: 0.8029 - val_loss: 0.4384 - val_accuracy: 0.7978 - 275ms/epoch - 11ms/step\n",
      "Epoch 69: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "25/25 - 1s - loss: 3.4709 - accuracy: 0.7024 - val_loss: 3.0548 - val_accuracy: 0.7614 - 1s/epoch - 52ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 2.7655 - accuracy: 0.7541 - val_loss: 2.4502 - val_accuracy: 0.7620 - 211ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 2.2270 - accuracy: 0.7540 - val_loss: 1.9844 - val_accuracy: 0.7620 - 212ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 1.8095 - accuracy: 0.7541 - val_loss: 1.6200 - val_accuracy: 0.7620 - 205ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 1.4814 - accuracy: 0.7543 - val_loss: 1.3334 - val_accuracy: 0.7620 - 199ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 1.2256 - accuracy: 0.7652 - val_loss: 1.1119 - val_accuracy: 0.7825 - 210ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 1.0264 - accuracy: 0.7882 - val_loss: 0.9416 - val_accuracy: 0.8004 - 184ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.8743 - accuracy: 0.7994 - val_loss: 0.8097 - val_accuracy: 0.8010 - 211ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.7593 - accuracy: 0.8012 - val_loss: 0.7127 - val_accuracy: 0.8010 - 204ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.6724 - accuracy: 0.8026 - val_loss: 0.6394 - val_accuracy: 0.7991 - 200ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.6079 - accuracy: 0.8016 - val_loss: 0.5837 - val_accuracy: 0.8017 - 191ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.5593 - accuracy: 0.8010 - val_loss: 0.5434 - val_accuracy: 0.7997 - 198ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.5241 - accuracy: 0.8016 - val_loss: 0.5144 - val_accuracy: 0.7997 - 179ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4993 - accuracy: 0.8020 - val_loss: 0.4970 - val_accuracy: 0.7991 - 181ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4837 - accuracy: 0.8015 - val_loss: 0.4784 - val_accuracy: 0.7991 - 185ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4675 - accuracy: 0.8023 - val_loss: 0.4667 - val_accuracy: 0.7997 - 195ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4585 - accuracy: 0.8012 - val_loss: 0.4594 - val_accuracy: 0.8010 - 192ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4528 - accuracy: 0.8005 - val_loss: 0.4535 - val_accuracy: 0.8004 - 243ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4467 - accuracy: 0.8028 - val_loss: 0.4521 - val_accuracy: 0.7978 - 186ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4436 - accuracy: 0.8031 - val_loss: 0.4482 - val_accuracy: 0.8004 - 203ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4403 - accuracy: 0.8028 - val_loss: 0.4447 - val_accuracy: 0.7997 - 200ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4384 - accuracy: 0.8012 - val_loss: 0.4429 - val_accuracy: 0.8010 - 192ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4377 - accuracy: 0.8013 - val_loss: 0.4454 - val_accuracy: 0.8010 - 187ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4381 - accuracy: 0.8007 - val_loss: 0.4410 - val_accuracy: 0.7997 - 198ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4382 - accuracy: 0.8023 - val_loss: 0.4419 - val_accuracy: 0.7991 - 210ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4347 - accuracy: 0.8021 - val_loss: 0.4397 - val_accuracy: 0.8004 - 197ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4344 - accuracy: 0.8004 - val_loss: 0.4390 - val_accuracy: 0.7997 - 176ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4331 - accuracy: 0.8028 - val_loss: 0.4382 - val_accuracy: 0.8010 - 199ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4325 - accuracy: 0.8012 - val_loss: 0.4389 - val_accuracy: 0.8004 - 191ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4347 - accuracy: 0.8032 - val_loss: 0.4384 - val_accuracy: 0.7997 - 185ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4321 - accuracy: 0.8020 - val_loss: 0.4379 - val_accuracy: 0.8010 - 201ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4330 - accuracy: 0.8021 - val_loss: 0.4399 - val_accuracy: 0.7997 - 204ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.4362 - val_accuracy: 0.8023 - 204ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4314 - accuracy: 0.8018 - val_loss: 0.4379 - val_accuracy: 0.8004 - 182ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4309 - accuracy: 0.8026 - val_loss: 0.4377 - val_accuracy: 0.8010 - 189ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4314 - accuracy: 0.8031 - val_loss: 0.4376 - val_accuracy: 0.7997 - 231ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4304 - accuracy: 0.8036 - val_loss: 0.4364 - val_accuracy: 0.8023 - 190ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4309 - accuracy: 0.8005 - val_loss: 0.4368 - val_accuracy: 0.7991 - 188ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4296 - accuracy: 0.8018 - val_loss: 0.4371 - val_accuracy: 0.8017 - 185ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4298 - accuracy: 0.8015 - val_loss: 0.4359 - val_accuracy: 0.8010 - 248ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4305 - accuracy: 0.8021 - val_loss: 0.4356 - val_accuracy: 0.8017 - 194ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4301 - accuracy: 0.8039 - val_loss: 0.4363 - val_accuracy: 0.7997 - 206ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4299 - accuracy: 0.8020 - val_loss: 0.4378 - val_accuracy: 0.8004 - 208ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4306 - accuracy: 0.8020 - val_loss: 0.4399 - val_accuracy: 0.7965 - 210ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4290 - accuracy: 0.8021 - val_loss: 0.4370 - val_accuracy: 0.8017 - 205ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4325 - accuracy: 0.8050 - val_loss: 0.4356 - val_accuracy: 0.8017 - 196ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4296 - accuracy: 0.8034 - val_loss: 0.4360 - val_accuracy: 0.8010 - 186ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4297 - accuracy: 0.8031 - val_loss: 0.4354 - val_accuracy: 0.8023 - 191ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4293 - accuracy: 0.8016 - val_loss: 0.4375 - val_accuracy: 0.7985 - 181ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4284 - accuracy: 0.8021 - val_loss: 0.4356 - val_accuracy: 0.8023 - 207ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 0s - loss: 0.4291 - accuracy: 0.8023 - val_loss: 0.4397 - val_accuracy: 0.7946 - 194ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 0s - loss: 0.4291 - accuracy: 0.7999 - val_loss: 0.4361 - val_accuracy: 0.8010 - 197ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 0s - loss: 0.4292 - accuracy: 0.8020 - val_loss: 0.4346 - val_accuracy: 0.8023 - 176ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 0s - loss: 0.4283 - accuracy: 0.8012 - val_loss: 0.4361 - val_accuracy: 0.7997 - 196ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 0s - loss: 0.4286 - accuracy: 0.8039 - val_loss: 0.4377 - val_accuracy: 0.8010 - 197ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 0s - loss: 0.4298 - accuracy: 0.8045 - val_loss: 0.4396 - val_accuracy: 0.7953 - 193ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 0s - loss: 0.4284 - accuracy: 0.8042 - val_loss: 0.4365 - val_accuracy: 0.7965 - 184ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 0s - loss: 0.4299 - accuracy: 0.8016 - val_loss: 0.4346 - val_accuracy: 0.8023 - 207ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 0s - loss: 0.4290 - accuracy: 0.8045 - val_loss: 0.4362 - val_accuracy: 0.7978 - 206ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 0s - loss: 0.4285 - accuracy: 0.8020 - val_loss: 0.4354 - val_accuracy: 0.8017 - 212ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 0s - loss: 0.4276 - accuracy: 0.8005 - val_loss: 0.4376 - val_accuracy: 0.7965 - 204ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 0s - loss: 0.4275 - accuracy: 0.8048 - val_loss: 0.4363 - val_accuracy: 0.7978 - 191ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 0s - loss: 0.4275 - accuracy: 0.8029 - val_loss: 0.4367 - val_accuracy: 0.7965 - 217ms/epoch - 9ms/step\n",
      "Epoch 63: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "25/25 - 1s - loss: 3.5827 - accuracy: 0.6689 - val_loss: 3.1368 - val_accuracy: 0.7639 - 1s/epoch - 47ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 2.8359 - accuracy: 0.7546 - val_loss: 2.5084 - val_accuracy: 0.7620 - 188ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 2.2811 - accuracy: 0.7543 - val_loss: 2.0274 - val_accuracy: 0.7626 - 180ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 1.8501 - accuracy: 0.7624 - val_loss: 1.6524 - val_accuracy: 0.7837 - 189ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 1.5128 - accuracy: 0.7823 - val_loss: 1.3614 - val_accuracy: 0.7978 - 208ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 1.2489 - accuracy: 0.7962 - val_loss: 1.1312 - val_accuracy: 0.8010 - 201ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 1.0460 - accuracy: 0.7981 - val_loss: 0.9582 - val_accuracy: 0.8029 - 219ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.8894 - accuracy: 0.8016 - val_loss: 0.8225 - val_accuracy: 0.8036 - 195ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.7712 - accuracy: 0.8018 - val_loss: 0.7217 - val_accuracy: 0.8004 - 206ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.6814 - accuracy: 0.8015 - val_loss: 0.6444 - val_accuracy: 0.8036 - 210ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.6148 - accuracy: 0.8020 - val_loss: 0.5882 - val_accuracy: 0.8036 - 201ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.5656 - accuracy: 0.8008 - val_loss: 0.5466 - val_accuracy: 0.7997 - 218ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.5279 - accuracy: 0.8034 - val_loss: 0.5154 - val_accuracy: 0.8010 - 188ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.5009 - accuracy: 0.8020 - val_loss: 0.4963 - val_accuracy: 0.8004 - 237ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4817 - accuracy: 0.8023 - val_loss: 0.4777 - val_accuracy: 0.8023 - 197ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4677 - accuracy: 0.8024 - val_loss: 0.4652 - val_accuracy: 0.8010 - 199ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4586 - accuracy: 0.8021 - val_loss: 0.4572 - val_accuracy: 0.8017 - 191ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4511 - accuracy: 0.8023 - val_loss: 0.4537 - val_accuracy: 0.8023 - 189ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4450 - accuracy: 0.8020 - val_loss: 0.4489 - val_accuracy: 0.8010 - 204ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4420 - accuracy: 0.8018 - val_loss: 0.4494 - val_accuracy: 0.7965 - 196ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4405 - accuracy: 0.8008 - val_loss: 0.4437 - val_accuracy: 0.8042 - 179ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4378 - accuracy: 0.8007 - val_loss: 0.4439 - val_accuracy: 0.8017 - 226ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4367 - accuracy: 0.8016 - val_loss: 0.4417 - val_accuracy: 0.7978 - 192ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4367 - accuracy: 0.8002 - val_loss: 0.4405 - val_accuracy: 0.8017 - 184ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4348 - accuracy: 0.8023 - val_loss: 0.4393 - val_accuracy: 0.8023 - 208ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4334 - accuracy: 0.8015 - val_loss: 0.4406 - val_accuracy: 0.7978 - 185ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4351 - accuracy: 0.8018 - val_loss: 0.4388 - val_accuracy: 0.8017 - 192ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4322 - accuracy: 0.8040 - val_loss: 0.4376 - val_accuracy: 0.8023 - 180ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4329 - accuracy: 0.8020 - val_loss: 0.4374 - val_accuracy: 0.8017 - 176ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4333 - accuracy: 0.8015 - val_loss: 0.4439 - val_accuracy: 0.7940 - 208ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4341 - accuracy: 0.8026 - val_loss: 0.4372 - val_accuracy: 0.8023 - 211ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4310 - accuracy: 0.8032 - val_loss: 0.4367 - val_accuracy: 0.8017 - 244ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4313 - accuracy: 0.8005 - val_loss: 0.4371 - val_accuracy: 0.8029 - 187ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4304 - accuracy: 0.8028 - val_loss: 0.4364 - val_accuracy: 0.7997 - 214ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4304 - accuracy: 0.8056 - val_loss: 0.4452 - val_accuracy: 0.7953 - 204ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4329 - accuracy: 0.8026 - val_loss: 0.4372 - val_accuracy: 0.8023 - 207ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4340 - accuracy: 0.8004 - val_loss: 0.4397 - val_accuracy: 0.7985 - 209ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4293 - accuracy: 0.8010 - val_loss: 0.4351 - val_accuracy: 0.7997 - 201ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4300 - accuracy: 0.8028 - val_loss: 0.4381 - val_accuracy: 0.7927 - 219ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4294 - accuracy: 0.8023 - val_loss: 0.4356 - val_accuracy: 0.8017 - 211ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4286 - accuracy: 0.8031 - val_loss: 0.4364 - val_accuracy: 0.8023 - 213ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4288 - accuracy: 0.8053 - val_loss: 0.4367 - val_accuracy: 0.7991 - 205ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4300 - accuracy: 0.8021 - val_loss: 0.4357 - val_accuracy: 0.7997 - 206ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4296 - accuracy: 0.8021 - val_loss: 0.4388 - val_accuracy: 0.7946 - 194ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4300 - accuracy: 0.8036 - val_loss: 0.4360 - val_accuracy: 0.8017 - 215ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4306 - accuracy: 0.8012 - val_loss: 0.4360 - val_accuracy: 0.8010 - 205ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4304 - accuracy: 0.8024 - val_loss: 0.4357 - val_accuracy: 0.8004 - 215ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4279 - accuracy: 0.8044 - val_loss: 0.4433 - val_accuracy: 0.7914 - 214ms/epoch - 9ms/step\n",
      "Epoch 48: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "25/25 - 1s - loss: 3.5165 - accuracy: 0.7303 - val_loss: 3.1169 - val_accuracy: 0.7626 - 1s/epoch - 50ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 2.8190 - accuracy: 0.7541 - val_loss: 2.5001 - val_accuracy: 0.7620 - 184ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 2.2715 - accuracy: 0.7541 - val_loss: 2.0206 - val_accuracy: 0.7620 - 211ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 1.8438 - accuracy: 0.7541 - val_loss: 1.6457 - val_accuracy: 0.7620 - 178ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 1.5080 - accuracy: 0.7543 - val_loss: 1.3535 - val_accuracy: 0.7626 - 206ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 1.2446 - accuracy: 0.7620 - val_loss: 1.1243 - val_accuracy: 0.7786 - 185ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 1.0396 - accuracy: 0.7840 - val_loss: 0.9482 - val_accuracy: 0.7940 - 201ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.8829 - accuracy: 0.7919 - val_loss: 0.8159 - val_accuracy: 0.8023 - 204ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.7652 - accuracy: 0.7975 - val_loss: 0.7142 - val_accuracy: 0.8017 - 212ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.6757 - accuracy: 0.8016 - val_loss: 0.6392 - val_accuracy: 0.8049 - 203ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.6109 - accuracy: 0.8002 - val_loss: 0.5852 - val_accuracy: 0.8029 - 203ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.5621 - accuracy: 0.8013 - val_loss: 0.5457 - val_accuracy: 0.8017 - 210ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.5258 - accuracy: 0.8024 - val_loss: 0.5145 - val_accuracy: 0.8017 - 242ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.5007 - accuracy: 0.8015 - val_loss: 0.4927 - val_accuracy: 0.8004 - 194ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4814 - accuracy: 0.8021 - val_loss: 0.4802 - val_accuracy: 0.7997 - 171ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4685 - accuracy: 0.8032 - val_loss: 0.4679 - val_accuracy: 0.8017 - 191ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4602 - accuracy: 0.7997 - val_loss: 0.4598 - val_accuracy: 0.8010 - 190ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4547 - accuracy: 0.8000 - val_loss: 0.4560 - val_accuracy: 0.7972 - 186ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4487 - accuracy: 0.8004 - val_loss: 0.4506 - val_accuracy: 0.8023 - 212ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4432 - accuracy: 0.8013 - val_loss: 0.4462 - val_accuracy: 0.8017 - 210ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4413 - accuracy: 0.8020 - val_loss: 0.4446 - val_accuracy: 0.8042 - 216ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4394 - accuracy: 0.8005 - val_loss: 0.4426 - val_accuracy: 0.8023 - 196ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4371 - accuracy: 0.8021 - val_loss: 0.4427 - val_accuracy: 0.8023 - 226ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4384 - accuracy: 0.8000 - val_loss: 0.4447 - val_accuracy: 0.7997 - 222ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4363 - accuracy: 0.8018 - val_loss: 0.4403 - val_accuracy: 0.8017 - 207ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4357 - accuracy: 0.8020 - val_loss: 0.4401 - val_accuracy: 0.8010 - 212ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4361 - accuracy: 0.8026 - val_loss: 0.4376 - val_accuracy: 0.8010 - 210ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4348 - accuracy: 0.8015 - val_loss: 0.4388 - val_accuracy: 0.8017 - 203ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4332 - accuracy: 0.8016 - val_loss: 0.4384 - val_accuracy: 0.8023 - 188ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4322 - accuracy: 0.8029 - val_loss: 0.4403 - val_accuracy: 0.8010 - 213ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4335 - accuracy: 0.8007 - val_loss: 0.4375 - val_accuracy: 0.8036 - 190ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4323 - accuracy: 0.8021 - val_loss: 0.4388 - val_accuracy: 0.8017 - 200ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4318 - accuracy: 0.8016 - val_loss: 0.4381 - val_accuracy: 0.8010 - 200ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4339 - accuracy: 0.8023 - val_loss: 0.4372 - val_accuracy: 0.8010 - 245ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4320 - accuracy: 0.8034 - val_loss: 0.4411 - val_accuracy: 0.7959 - 197ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4314 - accuracy: 0.8024 - val_loss: 0.4396 - val_accuracy: 0.7933 - 209ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4319 - accuracy: 0.8018 - val_loss: 0.4379 - val_accuracy: 0.7991 - 206ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4321 - accuracy: 0.8018 - val_loss: 0.4363 - val_accuracy: 0.8023 - 224ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4308 - accuracy: 0.8015 - val_loss: 0.4367 - val_accuracy: 0.8042 - 222ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4325 - accuracy: 0.8015 - val_loss: 0.4391 - val_accuracy: 0.7972 - 194ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4319 - accuracy: 0.8034 - val_loss: 0.4367 - val_accuracy: 0.7985 - 211ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4309 - accuracy: 0.8013 - val_loss: 0.4369 - val_accuracy: 0.7991 - 221ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4311 - accuracy: 0.8026 - val_loss: 0.4353 - val_accuracy: 0.8004 - 216ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4323 - accuracy: 0.8028 - val_loss: 0.4383 - val_accuracy: 0.7991 - 216ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4320 - accuracy: 0.8023 - val_loss: 0.4365 - val_accuracy: 0.8004 - 216ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4303 - accuracy: 0.8047 - val_loss: 0.4430 - val_accuracy: 0.7876 - 237ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4301 - accuracy: 0.8015 - val_loss: 0.4351 - val_accuracy: 0.8004 - 240ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4295 - accuracy: 0.8032 - val_loss: 0.4369 - val_accuracy: 0.7985 - 240ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4299 - accuracy: 0.8042 - val_loss: 0.4346 - val_accuracy: 0.7991 - 223ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4296 - accuracy: 0.8028 - val_loss: 0.4377 - val_accuracy: 0.7978 - 223ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 0s - loss: 0.4289 - accuracy: 0.8012 - val_loss: 0.4413 - val_accuracy: 0.7946 - 232ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 0s - loss: 0.4310 - accuracy: 0.8015 - val_loss: 0.4369 - val_accuracy: 0.8029 - 216ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 0s - loss: 0.4289 - accuracy: 0.8026 - val_loss: 0.4391 - val_accuracy: 0.7933 - 204ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 0s - loss: 0.4294 - accuracy: 0.8040 - val_loss: 0.4362 - val_accuracy: 0.7991 - 194ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 0s - loss: 0.4291 - accuracy: 0.8031 - val_loss: 0.4332 - val_accuracy: 0.8010 - 210ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 0s - loss: 0.4295 - accuracy: 0.8031 - val_loss: 0.4348 - val_accuracy: 0.7985 - 212ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 0s - loss: 0.4296 - accuracy: 0.8024 - val_loss: 0.4394 - val_accuracy: 0.7959 - 218ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 0s - loss: 0.4291 - accuracy: 0.8010 - val_loss: 0.4365 - val_accuracy: 0.8004 - 215ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 0s - loss: 0.4285 - accuracy: 0.8032 - val_loss: 0.4345 - val_accuracy: 0.8010 - 216ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 0s - loss: 0.4282 - accuracy: 0.8031 - val_loss: 0.4373 - val_accuracy: 0.8010 - 220ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 0s - loss: 0.4288 - accuracy: 0.8008 - val_loss: 0.4347 - val_accuracy: 0.8004 - 201ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 0s - loss: 0.4280 - accuracy: 0.8029 - val_loss: 0.4355 - val_accuracy: 0.7997 - 204ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 0s - loss: 0.4280 - accuracy: 0.8026 - val_loss: 0.4346 - val_accuracy: 0.8004 - 210ms/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 0s - loss: 0.4270 - accuracy: 0.8026 - val_loss: 0.4358 - val_accuracy: 0.8004 - 215ms/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 0s - loss: 0.4290 - accuracy: 0.8037 - val_loss: 0.4352 - val_accuracy: 0.8010 - 209ms/epoch - 8ms/step\n",
      "Epoch 65: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "25/25 - 1s - loss: 3.4557 - accuracy: 0.7173 - val_loss: 3.0703 - val_accuracy: 0.7582 - 1s/epoch - 53ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 2.7757 - accuracy: 0.7535 - val_loss: 2.4586 - val_accuracy: 0.7620 - 189ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 2.2274 - accuracy: 0.7541 - val_loss: 1.9767 - val_accuracy: 0.7620 - 200ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 1.8028 - accuracy: 0.7541 - val_loss: 1.6066 - val_accuracy: 0.7620 - 192ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 1.4750 - accuracy: 0.7541 - val_loss: 1.3215 - val_accuracy: 0.7620 - 208ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 1.2200 - accuracy: 0.7554 - val_loss: 1.1007 - val_accuracy: 0.7639 - 230ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 1.0223 - accuracy: 0.7608 - val_loss: 0.9306 - val_accuracy: 0.7780 - 210ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.8705 - accuracy: 0.7781 - val_loss: 0.8023 - val_accuracy: 0.7933 - 200ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.7557 - accuracy: 0.7898 - val_loss: 0.7063 - val_accuracy: 0.7933 - 223ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.6699 - accuracy: 0.7981 - val_loss: 0.6338 - val_accuracy: 0.7927 - 210ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.6065 - accuracy: 0.7983 - val_loss: 0.5829 - val_accuracy: 0.8029 - 194ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.5589 - accuracy: 0.8005 - val_loss: 0.5418 - val_accuracy: 0.8023 - 221ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.5248 - accuracy: 0.8023 - val_loss: 0.5129 - val_accuracy: 0.8010 - 202ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4995 - accuracy: 0.8018 - val_loss: 0.4926 - val_accuracy: 0.8029 - 220ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4820 - accuracy: 0.8023 - val_loss: 0.4794 - val_accuracy: 0.7978 - 202ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4683 - accuracy: 0.8013 - val_loss: 0.4670 - val_accuracy: 0.8029 - 253ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4586 - accuracy: 0.8020 - val_loss: 0.4607 - val_accuracy: 0.7978 - 285ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4532 - accuracy: 0.8012 - val_loss: 0.4511 - val_accuracy: 0.8017 - 287ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4477 - accuracy: 0.8015 - val_loss: 0.4492 - val_accuracy: 0.8023 - 263ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4435 - accuracy: 0.8028 - val_loss: 0.4469 - val_accuracy: 0.8023 - 280ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4404 - accuracy: 0.8031 - val_loss: 0.4431 - val_accuracy: 0.8017 - 295ms/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4393 - accuracy: 0.8023 - val_loss: 0.4431 - val_accuracy: 0.8010 - 284ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4383 - accuracy: 0.8029 - val_loss: 0.4415 - val_accuracy: 0.8010 - 286ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4369 - accuracy: 0.8023 - val_loss: 0.4418 - val_accuracy: 0.7997 - 267ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4351 - accuracy: 0.8016 - val_loss: 0.4392 - val_accuracy: 0.8004 - 196ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4352 - accuracy: 0.8004 - val_loss: 0.4385 - val_accuracy: 0.8023 - 185ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4346 - accuracy: 0.8032 - val_loss: 0.4394 - val_accuracy: 0.8010 - 223ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4343 - accuracy: 0.8013 - val_loss: 0.4389 - val_accuracy: 0.7991 - 258ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4335 - accuracy: 0.8012 - val_loss: 0.4410 - val_accuracy: 0.7953 - 212ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4356 - accuracy: 0.8013 - val_loss: 0.4388 - val_accuracy: 0.8004 - 269ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4337 - accuracy: 0.8020 - val_loss: 0.4389 - val_accuracy: 0.8029 - 324ms/epoch - 13ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4334 - accuracy: 0.8012 - val_loss: 0.4368 - val_accuracy: 0.8010 - 336ms/epoch - 13ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4319 - accuracy: 0.7999 - val_loss: 0.4377 - val_accuracy: 0.8010 - 267ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4314 - accuracy: 0.8004 - val_loss: 0.4404 - val_accuracy: 0.7997 - 308ms/epoch - 12ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4319 - accuracy: 0.8013 - val_loss: 0.4386 - val_accuracy: 0.7997 - 304ms/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4315 - accuracy: 0.8018 - val_loss: 0.4376 - val_accuracy: 0.8029 - 281ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4312 - accuracy: 0.8023 - val_loss: 0.4393 - val_accuracy: 0.8004 - 284ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4303 - accuracy: 0.8036 - val_loss: 0.4362 - val_accuracy: 0.8004 - 278ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4309 - accuracy: 0.8028 - val_loss: 0.4392 - val_accuracy: 0.7959 - 251ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4309 - accuracy: 0.8036 - val_loss: 0.4373 - val_accuracy: 0.8004 - 252ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4308 - accuracy: 0.8036 - val_loss: 0.4397 - val_accuracy: 0.7946 - 308ms/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4325 - accuracy: 0.8000 - val_loss: 0.4360 - val_accuracy: 0.7985 - 227ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4342 - accuracy: 0.8045 - val_loss: 0.4386 - val_accuracy: 0.7953 - 244ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4318 - accuracy: 0.8024 - val_loss: 0.4371 - val_accuracy: 0.7991 - 233ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4299 - accuracy: 0.8045 - val_loss: 0.4354 - val_accuracy: 0.7978 - 288ms/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4294 - accuracy: 0.8021 - val_loss: 0.4356 - val_accuracy: 0.8004 - 274ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4295 - accuracy: 0.8029 - val_loss: 0.4343 - val_accuracy: 0.8010 - 263ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4300 - accuracy: 0.8016 - val_loss: 0.4383 - val_accuracy: 0.8023 - 244ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4299 - accuracy: 0.8008 - val_loss: 0.4351 - val_accuracy: 0.8017 - 219ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4290 - accuracy: 0.8018 - val_loss: 0.4379 - val_accuracy: 0.7965 - 227ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 0s - loss: 0.4283 - accuracy: 0.8026 - val_loss: 0.4361 - val_accuracy: 0.8017 - 348ms/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 0s - loss: 0.4284 - accuracy: 0.8031 - val_loss: 0.4355 - val_accuracy: 0.8023 - 262ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 0s - loss: 0.4307 - accuracy: 0.8016 - val_loss: 0.4385 - val_accuracy: 0.7972 - 230ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 0s - loss: 0.4301 - accuracy: 0.8052 - val_loss: 0.4364 - val_accuracy: 0.7991 - 442ms/epoch - 18ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 0s - loss: 0.4294 - accuracy: 0.8023 - val_loss: 0.4362 - val_accuracy: 0.8017 - 290ms/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 0s - loss: 0.4290 - accuracy: 0.8026 - val_loss: 0.4376 - val_accuracy: 0.7921 - 362ms/epoch - 14ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 0s - loss: 0.4314 - accuracy: 0.8034 - val_loss: 0.4365 - val_accuracy: 0.8023 - 302ms/epoch - 12ms/step\n",
      "Epoch 57: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 3.4565 - accuracy: 0.6748 - val_loss: 3.0734 - val_accuracy: 0.7537 - 2s/epoch - 71ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 2.7813 - accuracy: 0.7525 - val_loss: 2.4655 - val_accuracy: 0.7620 - 240ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 2.2381 - accuracy: 0.7541 - val_loss: 1.9876 - val_accuracy: 0.7620 - 245ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 1.8166 - accuracy: 0.7541 - val_loss: 1.6231 - val_accuracy: 0.7620 - 221ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 1.4936 - accuracy: 0.7541 - val_loss: 1.3394 - val_accuracy: 0.7620 - 233ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 1.2408 - accuracy: 0.7541 - val_loss: 1.1195 - val_accuracy: 0.7620 - 250ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 1.0432 - accuracy: 0.7541 - val_loss: 0.9489 - val_accuracy: 0.7620 - 236ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.8888 - accuracy: 0.7602 - val_loss: 0.8168 - val_accuracy: 0.7882 - 237ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.7708 - accuracy: 0.7821 - val_loss: 0.7184 - val_accuracy: 0.7869 - 236ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.6818 - accuracy: 0.7903 - val_loss: 0.6432 - val_accuracy: 0.7940 - 251ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.6149 - accuracy: 0.7986 - val_loss: 0.5883 - val_accuracy: 0.8029 - 269ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.5669 - accuracy: 0.8004 - val_loss: 0.5465 - val_accuracy: 0.7997 - 238ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.5298 - accuracy: 0.8013 - val_loss: 0.5171 - val_accuracy: 0.8017 - 234ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.5037 - accuracy: 0.8015 - val_loss: 0.4946 - val_accuracy: 0.8036 - 283ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4849 - accuracy: 0.8010 - val_loss: 0.4810 - val_accuracy: 0.8029 - 413ms/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4716 - accuracy: 0.8015 - val_loss: 0.4720 - val_accuracy: 0.7978 - 402ms/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4620 - accuracy: 0.8023 - val_loss: 0.4570 - val_accuracy: 0.8029 - 402ms/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4546 - accuracy: 0.8026 - val_loss: 0.4537 - val_accuracy: 0.8029 - 409ms/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4493 - accuracy: 0.8021 - val_loss: 0.4507 - val_accuracy: 0.8023 - 464ms/epoch - 19ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4454 - accuracy: 0.8010 - val_loss: 0.4458 - val_accuracy: 0.8029 - 411ms/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4419 - accuracy: 0.8032 - val_loss: 0.4447 - val_accuracy: 0.8010 - 380ms/epoch - 15ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4400 - accuracy: 0.8021 - val_loss: 0.4430 - val_accuracy: 0.8017 - 430ms/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4384 - accuracy: 0.8015 - val_loss: 0.4427 - val_accuracy: 0.7991 - 395ms/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4387 - accuracy: 0.8028 - val_loss: 0.4404 - val_accuracy: 0.8010 - 389ms/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.4367 - accuracy: 0.8018 - val_loss: 0.4404 - val_accuracy: 0.8029 - 501ms/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4363 - accuracy: 0.8013 - val_loss: 0.4392 - val_accuracy: 0.8017 - 340ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4344 - accuracy: 0.8012 - val_loss: 0.4395 - val_accuracy: 0.8017 - 232ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4342 - accuracy: 0.8047 - val_loss: 0.4374 - val_accuracy: 0.8023 - 230ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4344 - accuracy: 0.8031 - val_loss: 0.4378 - val_accuracy: 0.8023 - 231ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4349 - accuracy: 0.8005 - val_loss: 0.4420 - val_accuracy: 0.7946 - 244ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4342 - accuracy: 0.8016 - val_loss: 0.4419 - val_accuracy: 0.7965 - 218ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4348 - accuracy: 0.8016 - val_loss: 0.4377 - val_accuracy: 0.8023 - 243ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4356 - accuracy: 0.8016 - val_loss: 0.4437 - val_accuracy: 0.7946 - 231ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4333 - accuracy: 0.8013 - val_loss: 0.4358 - val_accuracy: 0.8029 - 233ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4332 - accuracy: 0.8015 - val_loss: 0.4385 - val_accuracy: 0.8004 - 230ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4333 - accuracy: 0.8023 - val_loss: 0.4431 - val_accuracy: 0.7940 - 241ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4347 - accuracy: 0.7988 - val_loss: 0.4373 - val_accuracy: 0.7985 - 239ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4315 - accuracy: 0.8004 - val_loss: 0.4378 - val_accuracy: 0.8023 - 243ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4324 - accuracy: 0.8008 - val_loss: 0.4360 - val_accuracy: 0.8010 - 226ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4322 - accuracy: 0.8013 - val_loss: 0.4401 - val_accuracy: 0.7965 - 235ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4327 - accuracy: 0.8012 - val_loss: 0.4367 - val_accuracy: 0.7997 - 245ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4310 - accuracy: 0.8023 - val_loss: 0.4448 - val_accuracy: 0.7927 - 310ms/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4351 - accuracy: 0.7973 - val_loss: 0.4356 - val_accuracy: 0.8010 - 230ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4323 - accuracy: 0.8023 - val_loss: 0.4371 - val_accuracy: 0.7978 - 242ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4308 - accuracy: 0.8023 - val_loss: 0.4363 - val_accuracy: 0.8023 - 233ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4317 - accuracy: 0.8020 - val_loss: 0.4358 - val_accuracy: 0.8010 - 272ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4306 - accuracy: 0.8024 - val_loss: 0.4385 - val_accuracy: 0.7978 - 291ms/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4296 - accuracy: 0.8028 - val_loss: 0.4371 - val_accuracy: 0.8004 - 415ms/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4305 - accuracy: 0.8010 - val_loss: 0.4365 - val_accuracy: 0.8029 - 451ms/epoch - 18ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4346 - accuracy: 0.7973 - val_loss: 0.4358 - val_accuracy: 0.8017 - 403ms/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 0s - loss: 0.4329 - accuracy: 0.8021 - val_loss: 0.4436 - val_accuracy: 0.7959 - 404ms/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 0s - loss: 0.4322 - accuracy: 0.8050 - val_loss: 0.4421 - val_accuracy: 0.7997 - 411ms/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 0s - loss: 0.4321 - accuracy: 0.8032 - val_loss: 0.4365 - val_accuracy: 0.8017 - 416ms/epoch - 17ms/step\n",
      "Epoch 53: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 3.3306 - accuracy: 0.7287 - val_loss: 2.9387 - val_accuracy: 0.7620 - 2s/epoch - 79ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 2.6643 - accuracy: 0.7541 - val_loss: 2.3646 - val_accuracy: 0.7620 - 269ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 2.1549 - accuracy: 0.7541 - val_loss: 1.9208 - val_accuracy: 0.7620 - 212ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 1.7588 - accuracy: 0.7541 - val_loss: 1.5756 - val_accuracy: 0.7620 - 217ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 1.4469 - accuracy: 0.7541 - val_loss: 1.3037 - val_accuracy: 0.7620 - 221ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 1.2035 - accuracy: 0.7541 - val_loss: 1.0919 - val_accuracy: 0.7614 - 224ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 1.0099 - accuracy: 0.7612 - val_loss: 0.9248 - val_accuracy: 0.7748 - 304ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.8593 - accuracy: 0.7834 - val_loss: 0.7948 - val_accuracy: 0.7959 - 276ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.7442 - accuracy: 0.7978 - val_loss: 0.6991 - val_accuracy: 0.8029 - 219ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.6592 - accuracy: 0.8004 - val_loss: 0.6276 - val_accuracy: 0.8010 - 283ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.5972 - accuracy: 0.8016 - val_loss: 0.5749 - val_accuracy: 0.8004 - 362ms/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.5518 - accuracy: 0.8026 - val_loss: 0.5404 - val_accuracy: 0.7985 - 212ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.5185 - accuracy: 0.8023 - val_loss: 0.5088 - val_accuracy: 0.8010 - 257ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4945 - accuracy: 0.8026 - val_loss: 0.4895 - val_accuracy: 0.7997 - 261ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4781 - accuracy: 0.8008 - val_loss: 0.4742 - val_accuracy: 0.8023 - 253ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4655 - accuracy: 0.8018 - val_loss: 0.4654 - val_accuracy: 0.8010 - 210ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4553 - accuracy: 0.8021 - val_loss: 0.4558 - val_accuracy: 0.8017 - 244ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4482 - accuracy: 0.8026 - val_loss: 0.4521 - val_accuracy: 0.7991 - 241ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4443 - accuracy: 0.8023 - val_loss: 0.4499 - val_accuracy: 0.8004 - 256ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4402 - accuracy: 0.8040 - val_loss: 0.4441 - val_accuracy: 0.8010 - 245ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4373 - accuracy: 0.8000 - val_loss: 0.4438 - val_accuracy: 0.8004 - 249ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4366 - accuracy: 0.8020 - val_loss: 0.4420 - val_accuracy: 0.8017 - 239ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4349 - accuracy: 0.8007 - val_loss: 0.4409 - val_accuracy: 0.7985 - 282ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4345 - accuracy: 0.8018 - val_loss: 0.4405 - val_accuracy: 0.8017 - 255ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4343 - accuracy: 0.8018 - val_loss: 0.4413 - val_accuracy: 0.7991 - 307ms/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4332 - accuracy: 0.8028 - val_loss: 0.4451 - val_accuracy: 0.7933 - 346ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4333 - accuracy: 0.8010 - val_loss: 0.4379 - val_accuracy: 0.8010 - 281ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4323 - accuracy: 0.8024 - val_loss: 0.4405 - val_accuracy: 0.7997 - 326ms/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4336 - accuracy: 0.8013 - val_loss: 0.4370 - val_accuracy: 0.8010 - 353ms/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4307 - accuracy: 0.8048 - val_loss: 0.4405 - val_accuracy: 0.7946 - 296ms/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4309 - accuracy: 0.8015 - val_loss: 0.4400 - val_accuracy: 0.7991 - 340ms/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4303 - accuracy: 0.8021 - val_loss: 0.4374 - val_accuracy: 0.8023 - 260ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4331 - accuracy: 0.8002 - val_loss: 0.4379 - val_accuracy: 0.8017 - 258ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4317 - accuracy: 0.8023 - val_loss: 0.4395 - val_accuracy: 0.7978 - 261ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4290 - accuracy: 0.8021 - val_loss: 0.4382 - val_accuracy: 0.8017 - 252ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4334 - accuracy: 0.7994 - val_loss: 0.4526 - val_accuracy: 0.7857 - 279ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4328 - accuracy: 0.8040 - val_loss: 0.4368 - val_accuracy: 0.8010 - 446ms/epoch - 18ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4308 - accuracy: 0.8012 - val_loss: 0.4389 - val_accuracy: 0.7997 - 477ms/epoch - 19ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.4313 - accuracy: 0.8026 - val_loss: 0.4389 - val_accuracy: 0.7972 - 616ms/epoch - 25ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4307 - accuracy: 0.8024 - val_loss: 0.4354 - val_accuracy: 0.8023 - 488ms/epoch - 20ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.4291 - accuracy: 0.8032 - val_loss: 0.4367 - val_accuracy: 0.8004 - 513ms/epoch - 21ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.4299 - accuracy: 0.8015 - val_loss: 0.4379 - val_accuracy: 0.7978 - 640ms/epoch - 26ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4292 - accuracy: 0.8026 - val_loss: 0.4360 - val_accuracy: 0.8010 - 418ms/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4283 - accuracy: 0.8002 - val_loss: 0.4434 - val_accuracy: 0.7959 - 263ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4298 - accuracy: 0.8026 - val_loss: 0.4378 - val_accuracy: 0.8017 - 271ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4286 - accuracy: 0.8034 - val_loss: 0.4349 - val_accuracy: 0.7985 - 230ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4284 - accuracy: 0.8029 - val_loss: 0.4370 - val_accuracy: 0.7991 - 237ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4288 - accuracy: 0.8060 - val_loss: 0.4372 - val_accuracy: 0.8017 - 267ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4282 - accuracy: 0.8036 - val_loss: 0.4360 - val_accuracy: 0.8010 - 265ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4278 - accuracy: 0.8029 - val_loss: 0.4352 - val_accuracy: 0.8017 - 264ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 0s - loss: 0.4308 - accuracy: 0.8032 - val_loss: 0.4420 - val_accuracy: 0.7940 - 284ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 0s - loss: 0.4273 - accuracy: 0.8024 - val_loss: 0.4366 - val_accuracy: 0.8029 - 260ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 0s - loss: 0.4277 - accuracy: 0.8023 - val_loss: 0.4351 - val_accuracy: 0.8029 - 233ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 0s - loss: 0.4278 - accuracy: 0.8029 - val_loss: 0.4355 - val_accuracy: 0.7997 - 256ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 0s - loss: 0.4275 - accuracy: 0.8007 - val_loss: 0.4351 - val_accuracy: 0.8023 - 257ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 0s - loss: 0.4303 - accuracy: 0.8016 - val_loss: 0.4347 - val_accuracy: 0.8023 - 280ms/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 0s - loss: 0.4280 - accuracy: 0.8028 - val_loss: 0.4357 - val_accuracy: 0.8023 - 321ms/epoch - 13ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 0s - loss: 0.4271 - accuracy: 0.8032 - val_loss: 0.4374 - val_accuracy: 0.7985 - 286ms/epoch - 11ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 0s - loss: 0.4292 - accuracy: 0.8026 - val_loss: 0.4386 - val_accuracy: 0.8023 - 345ms/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 0s - loss: 0.4275 - accuracy: 0.8032 - val_loss: 0.4344 - val_accuracy: 0.8004 - 334ms/epoch - 13ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 0s - loss: 0.4269 - accuracy: 0.8047 - val_loss: 0.4349 - val_accuracy: 0.8029 - 238ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 0s - loss: 0.4282 - accuracy: 0.8031 - val_loss: 0.4341 - val_accuracy: 0.7991 - 233ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 0s - loss: 0.4275 - accuracy: 0.8002 - val_loss: 0.4348 - val_accuracy: 0.8004 - 229ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 0s - loss: 0.4271 - accuracy: 0.8042 - val_loss: 0.4360 - val_accuracy: 0.8004 - 235ms/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 0s - loss: 0.4260 - accuracy: 0.8023 - val_loss: 0.4350 - val_accuracy: 0.7991 - 247ms/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 0s - loss: 0.4268 - accuracy: 0.8023 - val_loss: 0.4466 - val_accuracy: 0.7895 - 250ms/epoch - 10ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 0s - loss: 0.4271 - accuracy: 0.8023 - val_loss: 0.4421 - val_accuracy: 0.7953 - 241ms/epoch - 10ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 0s - loss: 0.4309 - accuracy: 0.8020 - val_loss: 0.4361 - val_accuracy: 0.8023 - 231ms/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 0s - loss: 0.4271 - accuracy: 0.8020 - val_loss: 0.4351 - val_accuracy: 0.8017 - 226ms/epoch - 9ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 0s - loss: 0.4265 - accuracy: 0.8024 - val_loss: 0.4344 - val_accuracy: 0.8017 - 248ms/epoch - 10ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 0s - loss: 0.4289 - accuracy: 0.8036 - val_loss: 0.4361 - val_accuracy: 0.8029 - 346ms/epoch - 14ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 0s - loss: 0.4256 - accuracy: 0.8029 - val_loss: 0.4346 - val_accuracy: 0.7997 - 329ms/epoch - 13ms/step\n",
      "Epoch 72: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "25/25 - 1s - loss: 3.5936 - accuracy: 0.6973 - val_loss: 3.1721 - val_accuracy: 0.7614 - 1s/epoch - 55ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 2.8709 - accuracy: 0.7541 - val_loss: 2.5440 - val_accuracy: 0.7620 - 220ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 2.3119 - accuracy: 0.7541 - val_loss: 2.0501 - val_accuracy: 0.7620 - 215ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 1.8705 - accuracy: 0.7541 - val_loss: 1.6669 - val_accuracy: 0.7620 - 199ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 1.5246 - accuracy: 0.7544 - val_loss: 1.3660 - val_accuracy: 0.7626 - 263ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 1.2545 - accuracy: 0.7682 - val_loss: 1.1326 - val_accuracy: 0.7901 - 205ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 1.0473 - accuracy: 0.7909 - val_loss: 0.9550 - val_accuracy: 0.7946 - 235ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.8897 - accuracy: 0.7954 - val_loss: 0.8212 - val_accuracy: 0.8036 - 232ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.7693 - accuracy: 0.7981 - val_loss: 0.7217 - val_accuracy: 0.8017 - 229ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.6810 - accuracy: 0.7997 - val_loss: 0.6476 - val_accuracy: 0.8004 - 257ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.6139 - accuracy: 0.8015 - val_loss: 0.5868 - val_accuracy: 0.8042 - 226ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.5637 - accuracy: 0.8021 - val_loss: 0.5447 - val_accuracy: 0.8004 - 221ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.5268 - accuracy: 0.8016 - val_loss: 0.5165 - val_accuracy: 0.7997 - 283ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.5006 - accuracy: 0.8040 - val_loss: 0.4932 - val_accuracy: 0.8010 - 348ms/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4834 - accuracy: 0.8018 - val_loss: 0.4783 - val_accuracy: 0.8029 - 291ms/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4693 - accuracy: 0.8037 - val_loss: 0.4672 - val_accuracy: 0.7997 - 285ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4603 - accuracy: 0.8021 - val_loss: 0.4585 - val_accuracy: 0.7972 - 283ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4519 - accuracy: 0.8034 - val_loss: 0.4541 - val_accuracy: 0.7997 - 256ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4463 - accuracy: 0.8031 - val_loss: 0.4497 - val_accuracy: 0.8017 - 294ms/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4432 - accuracy: 0.8028 - val_loss: 0.4460 - val_accuracy: 0.8036 - 280ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4408 - accuracy: 0.8018 - val_loss: 0.4436 - val_accuracy: 0.8023 - 310ms/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4387 - accuracy: 0.8023 - val_loss: 0.4426 - val_accuracy: 0.7997 - 254ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4368 - accuracy: 0.8018 - val_loss: 0.4427 - val_accuracy: 0.7965 - 259ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4360 - accuracy: 0.8023 - val_loss: 0.4394 - val_accuracy: 0.8017 - 268ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4346 - accuracy: 0.8032 - val_loss: 0.4492 - val_accuracy: 0.7940 - 252ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4349 - accuracy: 0.8004 - val_loss: 0.4388 - val_accuracy: 0.8010 - 250ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4336 - accuracy: 0.8020 - val_loss: 0.4412 - val_accuracy: 0.7991 - 285ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4326 - accuracy: 0.8026 - val_loss: 0.4381 - val_accuracy: 0.8004 - 297ms/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4337 - accuracy: 0.8020 - val_loss: 0.4389 - val_accuracy: 0.7991 - 227ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4327 - accuracy: 0.8020 - val_loss: 0.4373 - val_accuracy: 0.8004 - 223ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4341 - accuracy: 0.8026 - val_loss: 0.4411 - val_accuracy: 0.7985 - 233ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4310 - accuracy: 0.8026 - val_loss: 0.4391 - val_accuracy: 0.7997 - 242ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4320 - accuracy: 0.8037 - val_loss: 0.4398 - val_accuracy: 0.7985 - 309ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4322 - accuracy: 0.8016 - val_loss: 0.4364 - val_accuracy: 0.8017 - 232ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4313 - accuracy: 0.8007 - val_loss: 0.4359 - val_accuracy: 0.8017 - 327ms/epoch - 13ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4313 - accuracy: 0.8034 - val_loss: 0.4373 - val_accuracy: 0.7997 - 250ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4303 - accuracy: 0.8020 - val_loss: 0.4377 - val_accuracy: 0.8004 - 245ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4306 - accuracy: 0.8018 - val_loss: 0.4359 - val_accuracy: 0.8017 - 212ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.4359 - val_accuracy: 0.8017 - 218ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4302 - accuracy: 0.8031 - val_loss: 0.4382 - val_accuracy: 0.7953 - 225ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4310 - accuracy: 0.8012 - val_loss: 0.4369 - val_accuracy: 0.7978 - 214ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4307 - accuracy: 0.8008 - val_loss: 0.4362 - val_accuracy: 0.8017 - 224ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4306 - accuracy: 0.8023 - val_loss: 0.4369 - val_accuracy: 0.7978 - 215ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4290 - accuracy: 0.8032 - val_loss: 0.4352 - val_accuracy: 0.8029 - 225ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4299 - accuracy: 0.8044 - val_loss: 0.4407 - val_accuracy: 0.7965 - 237ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4304 - accuracy: 0.8031 - val_loss: 0.4354 - val_accuracy: 0.7997 - 211ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4305 - accuracy: 0.8031 - val_loss: 0.4428 - val_accuracy: 0.7953 - 213ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4290 - accuracy: 0.8005 - val_loss: 0.4356 - val_accuracy: 0.8017 - 215ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4312 - accuracy: 0.8021 - val_loss: 0.4458 - val_accuracy: 0.7901 - 235ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4305 - accuracy: 0.8007 - val_loss: 0.4371 - val_accuracy: 0.8004 - 228ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 0s - loss: 0.4299 - accuracy: 0.8029 - val_loss: 0.4361 - val_accuracy: 0.7991 - 219ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 0s - loss: 0.4284 - accuracy: 0.8018 - val_loss: 0.4412 - val_accuracy: 0.7933 - 217ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 0s - loss: 0.4302 - accuracy: 0.7992 - val_loss: 0.4336 - val_accuracy: 0.8029 - 224ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 0s - loss: 0.4294 - accuracy: 0.8023 - val_loss: 0.4345 - val_accuracy: 0.8017 - 221ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 0s - loss: 0.4295 - accuracy: 0.8037 - val_loss: 0.4367 - val_accuracy: 0.7991 - 222ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 0s - loss: 0.4283 - accuracy: 0.8023 - val_loss: 0.4353 - val_accuracy: 0.8004 - 229ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 0s - loss: 0.4278 - accuracy: 0.8024 - val_loss: 0.4358 - val_accuracy: 0.7965 - 209ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 0s - loss: 0.4297 - accuracy: 0.8028 - val_loss: 0.4363 - val_accuracy: 0.7991 - 227ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 0s - loss: 0.4295 - accuracy: 0.8029 - val_loss: 0.4333 - val_accuracy: 0.7985 - 205ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 0s - loss: 0.4289 - accuracy: 0.8034 - val_loss: 0.4345 - val_accuracy: 0.8010 - 221ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 0s - loss: 0.4274 - accuracy: 0.8036 - val_loss: 0.4352 - val_accuracy: 0.7997 - 208ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 0s - loss: 0.4291 - accuracy: 0.8031 - val_loss: 0.4390 - val_accuracy: 0.7953 - 268ms/epoch - 11ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 0s - loss: 0.4313 - accuracy: 0.7994 - val_loss: 0.4344 - val_accuracy: 0.8017 - 248ms/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 0s - loss: 0.4280 - accuracy: 0.8029 - val_loss: 0.4372 - val_accuracy: 0.7959 - 213ms/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 0s - loss: 0.4273 - accuracy: 0.8039 - val_loss: 0.4343 - val_accuracy: 0.7997 - 224ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 0s - loss: 0.4284 - accuracy: 0.8015 - val_loss: 0.4378 - val_accuracy: 0.7965 - 233ms/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 0s - loss: 0.4273 - accuracy: 0.8050 - val_loss: 0.4349 - val_accuracy: 0.7972 - 217ms/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 0s - loss: 0.4292 - accuracy: 0.8020 - val_loss: 0.4331 - val_accuracy: 0.7991 - 211ms/epoch - 8ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 0s - loss: 0.4266 - accuracy: 0.8024 - val_loss: 0.4331 - val_accuracy: 0.7985 - 223ms/epoch - 9ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 0s - loss: 0.4266 - accuracy: 0.8039 - val_loss: 0.4358 - val_accuracy: 0.7978 - 228ms/epoch - 9ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 0s - loss: 0.4276 - accuracy: 0.8042 - val_loss: 0.4337 - val_accuracy: 0.8023 - 237ms/epoch - 9ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 0s - loss: 0.4259 - accuracy: 0.8036 - val_loss: 0.4357 - val_accuracy: 0.8023 - 248ms/epoch - 10ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 0s - loss: 0.4289 - accuracy: 0.8010 - val_loss: 0.4434 - val_accuracy: 0.7901 - 262ms/epoch - 10ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 0s - loss: 0.4302 - accuracy: 0.8021 - val_loss: 0.4348 - val_accuracy: 0.7997 - 217ms/epoch - 9ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 0s - loss: 0.4276 - accuracy: 0.8026 - val_loss: 0.4370 - val_accuracy: 0.7972 - 244ms/epoch - 10ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 0s - loss: 0.4273 - accuracy: 0.8031 - val_loss: 0.4365 - val_accuracy: 0.7965 - 238ms/epoch - 10ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 0s - loss: 0.4266 - accuracy: 0.8029 - val_loss: 0.4375 - val_accuracy: 0.7985 - 238ms/epoch - 10ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 0s - loss: 0.4271 - accuracy: 0.8034 - val_loss: 0.4362 - val_accuracy: 0.7978 - 207ms/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 0s - loss: 0.4272 - accuracy: 0.8040 - val_loss: 0.4348 - val_accuracy: 0.8010 - 216ms/epoch - 9ms/step\n",
      "Epoch 79: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "25/25 - 1s - loss: 3.5354 - accuracy: 0.5791 - val_loss: 3.1143 - val_accuracy: 0.7614 - 1s/epoch - 50ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 2.8081 - accuracy: 0.7541 - val_loss: 2.4833 - val_accuracy: 0.7620 - 280ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 2.2530 - accuracy: 0.7541 - val_loss: 2.0016 - val_accuracy: 0.7620 - 216ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 1.8253 - accuracy: 0.7541 - val_loss: 1.6289 - val_accuracy: 0.7620 - 212ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 1.4920 - accuracy: 0.7541 - val_loss: 1.3404 - val_accuracy: 0.7620 - 223ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 1.2343 - accuracy: 0.7543 - val_loss: 1.1190 - val_accuracy: 0.7620 - 209ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 1.0352 - accuracy: 0.7565 - val_loss: 0.9464 - val_accuracy: 0.7665 - 244ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.8828 - accuracy: 0.7634 - val_loss: 0.8159 - val_accuracy: 0.7793 - 225ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.7672 - accuracy: 0.7754 - val_loss: 0.7196 - val_accuracy: 0.7831 - 246ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.6785 - accuracy: 0.7927 - val_loss: 0.6437 - val_accuracy: 0.7991 - 222ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.6118 - accuracy: 0.8020 - val_loss: 0.5869 - val_accuracy: 0.7965 - 324ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.5628 - accuracy: 0.7992 - val_loss: 0.5466 - val_accuracy: 0.8004 - 353ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.5272 - accuracy: 0.8023 - val_loss: 0.5163 - val_accuracy: 0.7965 - 324ms/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.5009 - accuracy: 0.8013 - val_loss: 0.4955 - val_accuracy: 0.8004 - 304ms/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4827 - accuracy: 0.8004 - val_loss: 0.4799 - val_accuracy: 0.7991 - 248ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4683 - accuracy: 0.8010 - val_loss: 0.4692 - val_accuracy: 0.7985 - 278ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4582 - accuracy: 0.8028 - val_loss: 0.4598 - val_accuracy: 0.8029 - 322ms/epoch - 13ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4513 - accuracy: 0.8013 - val_loss: 0.4530 - val_accuracy: 0.7997 - 312ms/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4464 - accuracy: 0.8031 - val_loss: 0.4489 - val_accuracy: 0.8010 - 266ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4426 - accuracy: 0.8029 - val_loss: 0.4487 - val_accuracy: 0.7965 - 373ms/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4403 - accuracy: 0.8024 - val_loss: 0.4437 - val_accuracy: 0.8023 - 484ms/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4379 - accuracy: 0.8010 - val_loss: 0.4431 - val_accuracy: 0.8010 - 488ms/epoch - 20ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4360 - accuracy: 0.8023 - val_loss: 0.4445 - val_accuracy: 0.7965 - 329ms/epoch - 13ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4345 - accuracy: 0.8024 - val_loss: 0.4465 - val_accuracy: 0.7946 - 266ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4350 - accuracy: 0.8016 - val_loss: 0.4405 - val_accuracy: 0.8004 - 250ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4341 - accuracy: 0.8024 - val_loss: 0.4412 - val_accuracy: 0.8010 - 250ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4337 - accuracy: 0.8031 - val_loss: 0.4396 - val_accuracy: 0.8023 - 231ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4329 - accuracy: 0.8015 - val_loss: 0.4401 - val_accuracy: 0.8004 - 268ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4325 - accuracy: 0.8018 - val_loss: 0.4393 - val_accuracy: 0.7978 - 241ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4322 - accuracy: 0.8031 - val_loss: 0.4395 - val_accuracy: 0.7997 - 253ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4324 - accuracy: 0.8028 - val_loss: 0.4402 - val_accuracy: 0.7997 - 249ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4316 - accuracy: 0.8021 - val_loss: 0.4379 - val_accuracy: 0.8010 - 305ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4314 - accuracy: 0.8016 - val_loss: 0.4439 - val_accuracy: 0.7946 - 257ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4340 - accuracy: 0.8010 - val_loss: 0.4388 - val_accuracy: 0.8004 - 261ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4311 - accuracy: 0.8024 - val_loss: 0.4377 - val_accuracy: 0.7997 - 250ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4298 - accuracy: 0.8042 - val_loss: 0.4388 - val_accuracy: 0.7985 - 329ms/epoch - 13ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4310 - accuracy: 0.8013 - val_loss: 0.4371 - val_accuracy: 0.8017 - 250ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4299 - accuracy: 0.8023 - val_loss: 0.4385 - val_accuracy: 0.7997 - 242ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4318 - accuracy: 0.7999 - val_loss: 0.4392 - val_accuracy: 0.7978 - 276ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4332 - accuracy: 0.8007 - val_loss: 0.4431 - val_accuracy: 0.8010 - 267ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4314 - accuracy: 0.8050 - val_loss: 0.4378 - val_accuracy: 0.7946 - 259ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4284 - accuracy: 0.8034 - val_loss: 0.4365 - val_accuracy: 0.7997 - 248ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4291 - accuracy: 0.8023 - val_loss: 0.4369 - val_accuracy: 0.8017 - 246ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4293 - accuracy: 0.8023 - val_loss: 0.4390 - val_accuracy: 0.7972 - 235ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4291 - accuracy: 0.7996 - val_loss: 0.4364 - val_accuracy: 0.8004 - 228ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4301 - accuracy: 0.8026 - val_loss: 0.4380 - val_accuracy: 0.7978 - 234ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4311 - accuracy: 0.7984 - val_loss: 0.4372 - val_accuracy: 0.7997 - 282ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4292 - accuracy: 0.8012 - val_loss: 0.4417 - val_accuracy: 0.7940 - 266ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4291 - accuracy: 0.8012 - val_loss: 0.4401 - val_accuracy: 0.8004 - 256ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4298 - accuracy: 0.8034 - val_loss: 0.4441 - val_accuracy: 0.7908 - 257ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 0s - loss: 0.4281 - accuracy: 0.8032 - val_loss: 0.4357 - val_accuracy: 0.7978 - 260ms/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 0s - loss: 0.4289 - accuracy: 0.8044 - val_loss: 0.4356 - val_accuracy: 0.7991 - 236ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 0s - loss: 0.4286 - accuracy: 0.8010 - val_loss: 0.4382 - val_accuracy: 0.7959 - 248ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 0s - loss: 0.4278 - accuracy: 0.8031 - val_loss: 0.4348 - val_accuracy: 0.7997 - 244ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 0s - loss: 0.4273 - accuracy: 0.8029 - val_loss: 0.4371 - val_accuracy: 0.7997 - 233ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 0s - loss: 0.4280 - accuracy: 0.8029 - val_loss: 0.4392 - val_accuracy: 0.7940 - 313ms/epoch - 13ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 0s - loss: 0.4282 - accuracy: 0.8037 - val_loss: 0.4362 - val_accuracy: 0.8010 - 265ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 0s - loss: 0.4270 - accuracy: 0.8029 - val_loss: 0.4363 - val_accuracy: 0.7985 - 231ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 0s - loss: 0.4272 - accuracy: 0.8036 - val_loss: 0.4346 - val_accuracy: 0.8017 - 259ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 0s - loss: 0.4299 - accuracy: 0.8008 - val_loss: 0.4424 - val_accuracy: 0.7927 - 262ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 0s - loss: 0.4295 - accuracy: 0.8039 - val_loss: 0.4386 - val_accuracy: 0.7978 - 248ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 0s - loss: 0.4273 - accuracy: 0.8026 - val_loss: 0.4380 - val_accuracy: 0.7985 - 233ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 0s - loss: 0.4273 - accuracy: 0.8007 - val_loss: 0.4363 - val_accuracy: 0.8004 - 243ms/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 0s - loss: 0.4273 - accuracy: 0.8028 - val_loss: 0.4389 - val_accuracy: 0.7972 - 264ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 0s - loss: 0.4278 - accuracy: 0.8039 - val_loss: 0.4357 - val_accuracy: 0.7997 - 270ms/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 0s - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.4353 - val_accuracy: 0.7997 - 354ms/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 0s - loss: 0.4267 - accuracy: 0.8031 - val_loss: 0.4402 - val_accuracy: 0.7965 - 252ms/epoch - 10ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 0s - loss: 0.4284 - accuracy: 0.8005 - val_loss: 0.4371 - val_accuracy: 0.8004 - 249ms/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 0s - loss: 0.4278 - accuracy: 0.8032 - val_loss: 0.4360 - val_accuracy: 0.7978 - 251ms/epoch - 10ms/step\n",
      "Epoch 69: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.4410759826015914\n",
      "epi entropy:  0.4158793373031786\n",
      "\n",
      "dataset size:  0.3\n",
      "Epoch 1/100\n",
      "37/37 - 4s - loss: 3.1979 - accuracy: 0.5938 - val_loss: 2.6821 - val_accuracy: 0.7505 - 4s/epoch - 99ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 1s - loss: 2.2963 - accuracy: 0.7664 - val_loss: 1.9472 - val_accuracy: 0.7510 - 546ms/epoch - 15ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 1s - loss: 1.6737 - accuracy: 0.7664 - val_loss: 1.4456 - val_accuracy: 0.7510 - 530ms/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 1.2477 - accuracy: 0.7664 - val_loss: 1.1025 - val_accuracy: 0.7510 - 373ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.9581 - accuracy: 0.7689 - val_loss: 0.8700 - val_accuracy: 0.7620 - 338ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.7652 - accuracy: 0.7870 - val_loss: 0.7158 - val_accuracy: 0.7791 - 329ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.6397 - accuracy: 0.7983 - val_loss: 0.6166 - val_accuracy: 0.7898 - 323ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.5585 - accuracy: 0.8033 - val_loss: 0.5589 - val_accuracy: 0.7872 - 319ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.5092 - accuracy: 0.8044 - val_loss: 0.5196 - val_accuracy: 0.7885 - 439ms/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4773 - accuracy: 0.8054 - val_loss: 0.4903 - val_accuracy: 0.7949 - 317ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4574 - accuracy: 0.8055 - val_loss: 0.4760 - val_accuracy: 0.7957 - 298ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4465 - accuracy: 0.8051 - val_loss: 0.4655 - val_accuracy: 0.7962 - 307ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4408 - accuracy: 0.8050 - val_loss: 0.4684 - val_accuracy: 0.7915 - 297ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4362 - accuracy: 0.8047 - val_loss: 0.4601 - val_accuracy: 0.7949 - 297ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4331 - accuracy: 0.8055 - val_loss: 0.4555 - val_accuracy: 0.7957 - 330ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4309 - accuracy: 0.8059 - val_loss: 0.4539 - val_accuracy: 0.7949 - 302ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4297 - accuracy: 0.8059 - val_loss: 0.4532 - val_accuracy: 0.7962 - 329ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4287 - accuracy: 0.8058 - val_loss: 0.4532 - val_accuracy: 0.7962 - 332ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4279 - accuracy: 0.8062 - val_loss: 0.4532 - val_accuracy: 0.7949 - 415ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4287 - accuracy: 0.8046 - val_loss: 0.4632 - val_accuracy: 0.7829 - 497ms/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4300 - accuracy: 0.8035 - val_loss: 0.4545 - val_accuracy: 0.7957 - 487ms/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4265 - accuracy: 0.8065 - val_loss: 0.4501 - val_accuracy: 0.7953 - 470ms/epoch - 13ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 1s - loss: 0.4260 - accuracy: 0.8063 - val_loss: 0.4506 - val_accuracy: 0.7936 - 557ms/epoch - 15ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8057 - val_loss: 0.4513 - val_accuracy: 0.7979 - 463ms/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4255 - accuracy: 0.8056 - val_loss: 0.4510 - val_accuracy: 0.7949 - 483ms/epoch - 13ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 1s - loss: 0.4276 - accuracy: 0.8060 - val_loss: 0.4505 - val_accuracy: 0.7966 - 541ms/epoch - 15ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 1s - loss: 0.4251 - accuracy: 0.8046 - val_loss: 0.4504 - val_accuracy: 0.7936 - 659ms/epoch - 18ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 1s - loss: 0.4261 - accuracy: 0.8056 - val_loss: 0.4492 - val_accuracy: 0.7962 - 565ms/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8054 - val_loss: 0.4510 - val_accuracy: 0.7940 - 299ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4265 - accuracy: 0.8046 - val_loss: 0.4498 - val_accuracy: 0.7945 - 311ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4250 - accuracy: 0.8048 - val_loss: 0.4485 - val_accuracy: 0.7957 - 323ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4248 - accuracy: 0.8087 - val_loss: 0.4481 - val_accuracy: 0.7957 - 310ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4249 - accuracy: 0.8063 - val_loss: 0.4494 - val_accuracy: 0.7983 - 314ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4252 - accuracy: 0.8071 - val_loss: 0.4493 - val_accuracy: 0.7945 - 328ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4248 - accuracy: 0.8067 - val_loss: 0.4492 - val_accuracy: 0.7957 - 322ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4245 - accuracy: 0.8049 - val_loss: 0.4483 - val_accuracy: 0.7945 - 327ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4240 - accuracy: 0.8048 - val_loss: 0.4487 - val_accuracy: 0.7940 - 381ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4250 - accuracy: 0.8065 - val_loss: 0.4591 - val_accuracy: 0.7906 - 460ms/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4264 - accuracy: 0.8041 - val_loss: 0.4551 - val_accuracy: 0.7957 - 481ms/epoch - 13ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4248 - accuracy: 0.8051 - val_loss: 0.4495 - val_accuracy: 0.7949 - 410ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4241 - accuracy: 0.8064 - val_loss: 0.4483 - val_accuracy: 0.7957 - 327ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4251 - accuracy: 0.8060 - val_loss: 0.4487 - val_accuracy: 0.7966 - 320ms/epoch - 9ms/step\n",
      "Epoch 42: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "37/37 - 3s - loss: 3.1815 - accuracy: 0.6681 - val_loss: 2.6645 - val_accuracy: 0.7505 - 3s/epoch - 76ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 2.2707 - accuracy: 0.7664 - val_loss: 1.9264 - val_accuracy: 0.7510 - 435ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 1.6547 - accuracy: 0.7664 - val_loss: 1.4306 - val_accuracy: 0.7510 - 314ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 1.2383 - accuracy: 0.7664 - val_loss: 1.0930 - val_accuracy: 0.7510 - 351ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.9553 - accuracy: 0.7672 - val_loss: 0.8645 - val_accuracy: 0.7544 - 378ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.7650 - accuracy: 0.7804 - val_loss: 0.7146 - val_accuracy: 0.7761 - 360ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 1s - loss: 0.6410 - accuracy: 0.7940 - val_loss: 0.6189 - val_accuracy: 0.7795 - 553ms/epoch - 15ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 1s - loss: 0.5611 - accuracy: 0.8017 - val_loss: 0.5546 - val_accuracy: 0.7893 - 524ms/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.5107 - accuracy: 0.8041 - val_loss: 0.5156 - val_accuracy: 0.7957 - 358ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4794 - accuracy: 0.8046 - val_loss: 0.4914 - val_accuracy: 0.7940 - 367ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4600 - accuracy: 0.8061 - val_loss: 0.4760 - val_accuracy: 0.7953 - 332ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4485 - accuracy: 0.8050 - val_loss: 0.4688 - val_accuracy: 0.7940 - 332ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4412 - accuracy: 0.8044 - val_loss: 0.4612 - val_accuracy: 0.7953 - 276ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4378 - accuracy: 0.8058 - val_loss: 0.4610 - val_accuracy: 0.7957 - 279ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4333 - accuracy: 0.8051 - val_loss: 0.4560 - val_accuracy: 0.7962 - 313ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4317 - accuracy: 0.8051 - val_loss: 0.4542 - val_accuracy: 0.7962 - 426ms/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 1s - loss: 0.4297 - accuracy: 0.8060 - val_loss: 0.4628 - val_accuracy: 0.7915 - 595ms/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 1s - loss: 0.4317 - accuracy: 0.8052 - val_loss: 0.4600 - val_accuracy: 0.7936 - 601ms/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 1s - loss: 0.4296 - accuracy: 0.8058 - val_loss: 0.4553 - val_accuracy: 0.7949 - 569ms/epoch - 15ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 1s - loss: 0.4279 - accuracy: 0.8065 - val_loss: 0.4517 - val_accuracy: 0.7962 - 510ms/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 1s - loss: 0.4277 - accuracy: 0.8062 - val_loss: 0.4517 - val_accuracy: 0.7953 - 624ms/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 1s - loss: 0.4269 - accuracy: 0.8058 - val_loss: 0.4504 - val_accuracy: 0.7953 - 546ms/epoch - 15ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4270 - accuracy: 0.8059 - val_loss: 0.4529 - val_accuracy: 0.7953 - 496ms/epoch - 13ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4264 - accuracy: 0.8064 - val_loss: 0.4566 - val_accuracy: 0.7893 - 499ms/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8054 - val_loss: 0.4504 - val_accuracy: 0.7979 - 450ms/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4278 - accuracy: 0.8034 - val_loss: 0.4502 - val_accuracy: 0.7979 - 449ms/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4251 - accuracy: 0.8059 - val_loss: 0.4491 - val_accuracy: 0.7966 - 481ms/epoch - 13ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4256 - accuracy: 0.8063 - val_loss: 0.4542 - val_accuracy: 0.7936 - 477ms/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4283 - accuracy: 0.8046 - val_loss: 0.4559 - val_accuracy: 0.7945 - 401ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4249 - accuracy: 0.8052 - val_loss: 0.4488 - val_accuracy: 0.7962 - 346ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4245 - accuracy: 0.8061 - val_loss: 0.4475 - val_accuracy: 0.7970 - 338ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4243 - accuracy: 0.8065 - val_loss: 0.4505 - val_accuracy: 0.7957 - 327ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4251 - accuracy: 0.8044 - val_loss: 0.4489 - val_accuracy: 0.7945 - 356ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4245 - accuracy: 0.8058 - val_loss: 0.4498 - val_accuracy: 0.7966 - 478ms/epoch - 13ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4248 - accuracy: 0.8056 - val_loss: 0.4477 - val_accuracy: 0.7957 - 370ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 1s - loss: 0.4241 - accuracy: 0.8062 - val_loss: 0.4475 - val_accuracy: 0.7966 - 560ms/epoch - 15ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4233 - accuracy: 0.8047 - val_loss: 0.4477 - val_accuracy: 0.7953 - 448ms/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 1s - loss: 0.4236 - accuracy: 0.8065 - val_loss: 0.4491 - val_accuracy: 0.7953 - 725ms/epoch - 20ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 1s - loss: 0.4226 - accuracy: 0.8064 - val_loss: 0.4488 - val_accuracy: 0.7987 - 665ms/epoch - 18ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 1s - loss: 0.4239 - accuracy: 0.8058 - val_loss: 0.4473 - val_accuracy: 0.7970 - 581ms/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 1s - loss: 0.4235 - accuracy: 0.8064 - val_loss: 0.4475 - val_accuracy: 0.7962 - 555ms/epoch - 15ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 1s - loss: 0.4258 - accuracy: 0.8022 - val_loss: 0.4477 - val_accuracy: 0.7962 - 623ms/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 1s - loss: 0.4238 - accuracy: 0.8067 - val_loss: 0.4466 - val_accuracy: 0.7996 - 584ms/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 1s - loss: 0.4232 - accuracy: 0.8054 - val_loss: 0.4484 - val_accuracy: 0.7940 - 577ms/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 1s - loss: 0.4237 - accuracy: 0.8039 - val_loss: 0.4483 - val_accuracy: 0.7970 - 520ms/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 0s - loss: 0.4233 - accuracy: 0.8057 - val_loss: 0.4472 - val_accuracy: 0.7928 - 342ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 0s - loss: 0.4227 - accuracy: 0.8064 - val_loss: 0.4461 - val_accuracy: 0.7966 - 310ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "37/37 - 0s - loss: 0.4231 - accuracy: 0.8040 - val_loss: 0.4461 - val_accuracy: 0.7979 - 316ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "37/37 - 0s - loss: 0.4228 - accuracy: 0.8061 - val_loss: 0.4474 - val_accuracy: 0.7962 - 370ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "37/37 - 0s - loss: 0.4218 - accuracy: 0.8060 - val_loss: 0.4477 - val_accuracy: 0.7957 - 315ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "37/37 - 0s - loss: 0.4228 - accuracy: 0.8056 - val_loss: 0.4486 - val_accuracy: 0.7945 - 337ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "37/37 - 0s - loss: 0.4225 - accuracy: 0.8071 - val_loss: 0.4474 - val_accuracy: 0.7966 - 327ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "37/37 - 0s - loss: 0.4226 - accuracy: 0.8061 - val_loss: 0.4501 - val_accuracy: 0.7957 - 336ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "37/37 - 0s - loss: 0.4225 - accuracy: 0.8046 - val_loss: 0.4468 - val_accuracy: 0.7945 - 360ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "37/37 - 0s - loss: 0.4254 - accuracy: 0.8026 - val_loss: 0.4507 - val_accuracy: 0.7953 - 333ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "37/37 - 0s - loss: 0.4220 - accuracy: 0.8066 - val_loss: 0.4490 - val_accuracy: 0.7962 - 320ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "37/37 - 0s - loss: 0.4216 - accuracy: 0.8056 - val_loss: 0.4473 - val_accuracy: 0.7979 - 327ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "37/37 - 0s - loss: 0.4227 - accuracy: 0.8048 - val_loss: 0.4501 - val_accuracy: 0.7962 - 338ms/epoch - 9ms/step\n",
      "Epoch 58: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 3.3809 - accuracy: 0.5888 - val_loss: 2.8601 - val_accuracy: 0.7309 - 2s/epoch - 67ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 1s - loss: 2.4565 - accuracy: 0.7629 - val_loss: 2.0737 - val_accuracy: 0.7510 - 645ms/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 1s - loss: 1.7792 - accuracy: 0.7664 - val_loss: 1.5319 - val_accuracy: 0.7510 - 517ms/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 1.3257 - accuracy: 0.7664 - val_loss: 1.1663 - val_accuracy: 0.7510 - 468ms/epoch - 13ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 1.0187 - accuracy: 0.7664 - val_loss: 0.9175 - val_accuracy: 0.7510 - 317ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.8090 - accuracy: 0.7670 - val_loss: 0.7496 - val_accuracy: 0.7544 - 305ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.6702 - accuracy: 0.7736 - val_loss: 0.6397 - val_accuracy: 0.7736 - 325ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.5790 - accuracy: 0.7943 - val_loss: 0.5670 - val_accuracy: 0.7966 - 324ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.5211 - accuracy: 0.8030 - val_loss: 0.5236 - val_accuracy: 0.7928 - 365ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4855 - accuracy: 0.8050 - val_loss: 0.4982 - val_accuracy: 0.7940 - 400ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4650 - accuracy: 0.8044 - val_loss: 0.4790 - val_accuracy: 0.7962 - 476ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 1s - loss: 0.4501 - accuracy: 0.8040 - val_loss: 0.4736 - val_accuracy: 0.7936 - 500ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4423 - accuracy: 0.8047 - val_loss: 0.4629 - val_accuracy: 0.7957 - 472ms/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4377 - accuracy: 0.8050 - val_loss: 0.4604 - val_accuracy: 0.7966 - 345ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4337 - accuracy: 0.8054 - val_loss: 0.4565 - val_accuracy: 0.7979 - 481ms/epoch - 13ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4315 - accuracy: 0.8054 - val_loss: 0.4548 - val_accuracy: 0.7962 - 304ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4307 - accuracy: 0.8047 - val_loss: 0.4663 - val_accuracy: 0.7825 - 337ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4297 - accuracy: 0.8058 - val_loss: 0.4523 - val_accuracy: 0.7979 - 318ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 1s - loss: 0.4287 - accuracy: 0.8057 - val_loss: 0.4525 - val_accuracy: 0.7945 - 608ms/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 1s - loss: 0.4291 - accuracy: 0.8058 - val_loss: 0.4516 - val_accuracy: 0.7979 - 657ms/epoch - 18ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 1s - loss: 0.4280 - accuracy: 0.8059 - val_loss: 0.4536 - val_accuracy: 0.7936 - 686ms/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4271 - accuracy: 0.8074 - val_loss: 0.4518 - val_accuracy: 0.7953 - 436ms/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 1s - loss: 0.4274 - accuracy: 0.8058 - val_loss: 0.4511 - val_accuracy: 0.7991 - 678ms/epoch - 18ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 1s - loss: 0.4274 - accuracy: 0.8063 - val_loss: 0.4497 - val_accuracy: 0.7979 - 581ms/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 1s - loss: 0.4263 - accuracy: 0.8055 - val_loss: 0.4494 - val_accuracy: 0.7957 - 530ms/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4256 - accuracy: 0.8054 - val_loss: 0.4501 - val_accuracy: 0.7974 - 416ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4262 - accuracy: 0.8054 - val_loss: 0.4496 - val_accuracy: 0.7962 - 355ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8050 - val_loss: 0.4492 - val_accuracy: 0.7983 - 403ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4256 - accuracy: 0.8065 - val_loss: 0.4486 - val_accuracy: 0.7970 - 327ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4251 - accuracy: 0.8049 - val_loss: 0.4520 - val_accuracy: 0.7945 - 341ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8059 - val_loss: 0.4477 - val_accuracy: 0.7945 - 363ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4247 - accuracy: 0.8063 - val_loss: 0.4475 - val_accuracy: 0.7987 - 333ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4242 - accuracy: 0.8057 - val_loss: 0.4487 - val_accuracy: 0.7979 - 328ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4243 - accuracy: 0.8064 - val_loss: 0.4483 - val_accuracy: 0.7940 - 301ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4256 - accuracy: 0.8048 - val_loss: 0.4486 - val_accuracy: 0.7945 - 391ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4263 - accuracy: 0.8040 - val_loss: 0.4554 - val_accuracy: 0.7945 - 370ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4245 - accuracy: 0.8054 - val_loss: 0.4486 - val_accuracy: 0.7940 - 367ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4242 - accuracy: 0.8054 - val_loss: 0.4469 - val_accuracy: 0.7987 - 377ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4240 - accuracy: 0.8055 - val_loss: 0.4474 - val_accuracy: 0.7953 - 346ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 1s - loss: 0.4246 - accuracy: 0.8059 - val_loss: 0.4484 - val_accuracy: 0.7949 - 586ms/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4234 - accuracy: 0.8062 - val_loss: 0.4478 - val_accuracy: 0.7966 - 439ms/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4239 - accuracy: 0.8052 - val_loss: 0.4475 - val_accuracy: 0.7957 - 465ms/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 0s - loss: 0.4230 - accuracy: 0.8064 - val_loss: 0.4471 - val_accuracy: 0.7987 - 460ms/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 0s - loss: 0.4242 - accuracy: 0.8073 - val_loss: 0.4489 - val_accuracy: 0.7962 - 389ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 0s - loss: 0.4232 - accuracy: 0.8059 - val_loss: 0.4462 - val_accuracy: 0.8000 - 430ms/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 0s - loss: 0.4226 - accuracy: 0.8064 - val_loss: 0.4476 - val_accuracy: 0.7949 - 408ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 0s - loss: 0.4247 - accuracy: 0.8058 - val_loss: 0.4488 - val_accuracy: 0.7923 - 410ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "37/37 - 0s - loss: 0.4264 - accuracy: 0.8029 - val_loss: 0.4479 - val_accuracy: 0.7957 - 396ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "37/37 - 0s - loss: 0.4238 - accuracy: 0.8056 - val_loss: 0.4539 - val_accuracy: 0.7936 - 413ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "37/37 - 0s - loss: 0.4234 - accuracy: 0.8068 - val_loss: 0.4497 - val_accuracy: 0.7945 - 437ms/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "37/37 - 0s - loss: 0.4231 - accuracy: 0.8058 - val_loss: 0.4476 - val_accuracy: 0.7966 - 402ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "37/37 - 0s - loss: 0.4234 - accuracy: 0.8060 - val_loss: 0.4473 - val_accuracy: 0.7932 - 363ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "37/37 - 0s - loss: 0.4244 - accuracy: 0.8090 - val_loss: 0.4483 - val_accuracy: 0.7949 - 325ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "37/37 - 0s - loss: 0.4240 - accuracy: 0.8039 - val_loss: 0.4476 - val_accuracy: 0.7940 - 427ms/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "37/37 - 0s - loss: 0.4231 - accuracy: 0.8058 - val_loss: 0.4474 - val_accuracy: 0.7936 - 340ms/epoch - 9ms/step\n",
      "Epoch 55: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 3.3348 - accuracy: 0.7646 - val_loss: 2.8241 - val_accuracy: 0.7510 - 2s/epoch - 51ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 2.4132 - accuracy: 0.7667 - val_loss: 2.0661 - val_accuracy: 0.7518 - 342ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 1.7685 - accuracy: 0.7724 - val_loss: 1.5338 - val_accuracy: 0.7719 - 342ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 1.3213 - accuracy: 0.7921 - val_loss: 1.1661 - val_accuracy: 0.7919 - 393ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 1.0142 - accuracy: 0.8032 - val_loss: 0.9165 - val_accuracy: 0.7949 - 433ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.8059 - accuracy: 0.8056 - val_loss: 0.7489 - val_accuracy: 0.7970 - 355ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.6678 - accuracy: 0.8056 - val_loss: 0.6406 - val_accuracy: 0.7945 - 329ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.5779 - accuracy: 0.8050 - val_loss: 0.5689 - val_accuracy: 0.7957 - 384ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.5196 - accuracy: 0.8059 - val_loss: 0.5228 - val_accuracy: 0.7928 - 342ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4840 - accuracy: 0.8056 - val_loss: 0.4957 - val_accuracy: 0.7957 - 408ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4615 - accuracy: 0.8056 - val_loss: 0.4804 - val_accuracy: 0.7945 - 337ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4488 - accuracy: 0.8052 - val_loss: 0.4692 - val_accuracy: 0.7966 - 368ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4410 - accuracy: 0.8052 - val_loss: 0.4630 - val_accuracy: 0.7949 - 302ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4345 - accuracy: 0.8057 - val_loss: 0.4609 - val_accuracy: 0.7936 - 321ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4325 - accuracy: 0.8063 - val_loss: 0.4560 - val_accuracy: 0.7945 - 347ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4305 - accuracy: 0.8051 - val_loss: 0.4560 - val_accuracy: 0.7936 - 314ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4287 - accuracy: 0.8054 - val_loss: 0.4545 - val_accuracy: 0.7936 - 314ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4296 - accuracy: 0.8064 - val_loss: 0.4523 - val_accuracy: 0.7962 - 334ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4276 - accuracy: 0.8057 - val_loss: 0.4513 - val_accuracy: 0.7991 - 327ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4275 - accuracy: 0.8047 - val_loss: 0.4517 - val_accuracy: 0.7983 - 341ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4267 - accuracy: 0.8062 - val_loss: 0.4507 - val_accuracy: 0.7936 - 310ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8062 - val_loss: 0.4543 - val_accuracy: 0.7945 - 357ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4267 - accuracy: 0.8051 - val_loss: 0.4538 - val_accuracy: 0.7945 - 363ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4261 - accuracy: 0.8072 - val_loss: 0.4575 - val_accuracy: 0.7953 - 349ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4263 - accuracy: 0.8056 - val_loss: 0.4496 - val_accuracy: 0.7987 - 351ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4244 - accuracy: 0.8060 - val_loss: 0.4491 - val_accuracy: 0.7979 - 347ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4248 - accuracy: 0.8074 - val_loss: 0.4493 - val_accuracy: 0.7923 - 330ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4255 - accuracy: 0.8059 - val_loss: 0.4532 - val_accuracy: 0.7928 - 337ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4254 - accuracy: 0.8057 - val_loss: 0.4491 - val_accuracy: 0.7962 - 444ms/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4232 - accuracy: 0.8066 - val_loss: 0.4523 - val_accuracy: 0.7932 - 409ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4256 - accuracy: 0.8058 - val_loss: 0.4488 - val_accuracy: 0.7949 - 356ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4241 - accuracy: 0.8071 - val_loss: 0.4509 - val_accuracy: 0.7949 - 365ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4266 - accuracy: 0.8039 - val_loss: 0.4498 - val_accuracy: 0.7957 - 443ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4241 - accuracy: 0.8064 - val_loss: 0.4501 - val_accuracy: 0.7945 - 339ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4244 - accuracy: 0.8071 - val_loss: 0.4494 - val_accuracy: 0.7949 - 343ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4238 - accuracy: 0.8058 - val_loss: 0.4485 - val_accuracy: 0.7962 - 322ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4233 - accuracy: 0.8064 - val_loss: 0.4490 - val_accuracy: 0.7970 - 328ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4230 - accuracy: 0.8052 - val_loss: 0.4529 - val_accuracy: 0.7953 - 328ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4226 - accuracy: 0.8063 - val_loss: 0.4479 - val_accuracy: 0.7996 - 306ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4256 - accuracy: 0.8076 - val_loss: 0.4506 - val_accuracy: 0.7928 - 308ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4234 - accuracy: 0.8062 - val_loss: 0.4480 - val_accuracy: 0.7953 - 306ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4246 - accuracy: 0.8044 - val_loss: 0.4479 - val_accuracy: 0.7953 - 302ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 0s - loss: 0.4219 - accuracy: 0.8073 - val_loss: 0.4499 - val_accuracy: 0.7949 - 317ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 0s - loss: 0.4217 - accuracy: 0.8073 - val_loss: 0.4502 - val_accuracy: 0.7945 - 327ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 0s - loss: 0.4223 - accuracy: 0.8068 - val_loss: 0.4488 - val_accuracy: 0.7940 - 328ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 0s - loss: 0.4220 - accuracy: 0.8061 - val_loss: 0.4508 - val_accuracy: 0.7953 - 386ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 0s - loss: 0.4219 - accuracy: 0.8061 - val_loss: 0.4487 - val_accuracy: 0.7936 - 332ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "37/37 - 0s - loss: 0.4238 - accuracy: 0.8026 - val_loss: 0.4470 - val_accuracy: 0.7962 - 308ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "37/37 - 0s - loss: 0.4239 - accuracy: 0.8063 - val_loss: 0.4526 - val_accuracy: 0.7945 - 343ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "37/37 - 0s - loss: 0.4216 - accuracy: 0.8070 - val_loss: 0.4466 - val_accuracy: 0.7987 - 364ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "37/37 - 0s - loss: 0.4222 - accuracy: 0.8045 - val_loss: 0.4458 - val_accuracy: 0.7987 - 322ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "37/37 - 0s - loss: 0.4247 - accuracy: 0.8052 - val_loss: 0.4558 - val_accuracy: 0.7945 - 319ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8027 - val_loss: 0.4477 - val_accuracy: 0.7945 - 316ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "37/37 - 0s - loss: 0.4236 - accuracy: 0.8050 - val_loss: 0.4473 - val_accuracy: 0.7970 - 301ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "37/37 - 0s - loss: 0.4211 - accuracy: 0.8067 - val_loss: 0.4462 - val_accuracy: 0.7932 - 311ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "37/37 - 0s - loss: 0.4220 - accuracy: 0.8049 - val_loss: 0.4479 - val_accuracy: 0.7945 - 308ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "37/37 - 0s - loss: 0.4216 - accuracy: 0.8059 - val_loss: 0.4488 - val_accuracy: 0.7957 - 320ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "37/37 - 0s - loss: 0.4207 - accuracy: 0.8064 - val_loss: 0.4470 - val_accuracy: 0.7966 - 337ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "37/37 - 0s - loss: 0.4221 - accuracy: 0.8055 - val_loss: 0.4486 - val_accuracy: 0.7949 - 329ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "37/37 - 0s - loss: 0.4217 - accuracy: 0.8056 - val_loss: 0.4479 - val_accuracy: 0.7945 - 324ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "37/37 - 0s - loss: 0.4230 - accuracy: 0.8057 - val_loss: 0.4478 - val_accuracy: 0.7936 - 342ms/epoch - 9ms/step\n",
      "Epoch 61: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 3.2799 - accuracy: 0.7101 - val_loss: 2.7592 - val_accuracy: 0.7484 - 2s/epoch - 44ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 2.3626 - accuracy: 0.7662 - val_loss: 2.0063 - val_accuracy: 0.7510 - 483ms/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 1.7258 - accuracy: 0.7664 - val_loss: 1.4936 - val_accuracy: 0.7510 - 418ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 1.2912 - accuracy: 0.7680 - val_loss: 1.1395 - val_accuracy: 0.7544 - 352ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.9924 - accuracy: 0.7840 - val_loss: 0.8975 - val_accuracy: 0.7753 - 393ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.7892 - accuracy: 0.7972 - val_loss: 0.7320 - val_accuracy: 0.7923 - 400ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 1s - loss: 0.6548 - accuracy: 0.8051 - val_loss: 0.6268 - val_accuracy: 0.7957 - 515ms/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.5697 - accuracy: 0.8042 - val_loss: 0.5599 - val_accuracy: 0.7966 - 461ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.5152 - accuracy: 0.8057 - val_loss: 0.5192 - val_accuracy: 0.7953 - 393ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4820 - accuracy: 0.8061 - val_loss: 0.4923 - val_accuracy: 0.7966 - 422ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4614 - accuracy: 0.8061 - val_loss: 0.4784 - val_accuracy: 0.7957 - 488ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4492 - accuracy: 0.8048 - val_loss: 0.4680 - val_accuracy: 0.7966 - 466ms/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4411 - accuracy: 0.8046 - val_loss: 0.4601 - val_accuracy: 0.7970 - 494ms/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4364 - accuracy: 0.8060 - val_loss: 0.4596 - val_accuracy: 0.7957 - 375ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4336 - accuracy: 0.8044 - val_loss: 0.4562 - val_accuracy: 0.7957 - 430ms/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4314 - accuracy: 0.8056 - val_loss: 0.4537 - val_accuracy: 0.7974 - 372ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4302 - accuracy: 0.8054 - val_loss: 0.4521 - val_accuracy: 0.7953 - 436ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4290 - accuracy: 0.8049 - val_loss: 0.4519 - val_accuracy: 0.7953 - 381ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4286 - accuracy: 0.8051 - val_loss: 0.4510 - val_accuracy: 0.7953 - 367ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4293 - accuracy: 0.8050 - val_loss: 0.4516 - val_accuracy: 0.7962 - 353ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4277 - accuracy: 0.8050 - val_loss: 0.4515 - val_accuracy: 0.7962 - 335ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4267 - accuracy: 0.8054 - val_loss: 0.4511 - val_accuracy: 0.7957 - 334ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4262 - accuracy: 0.8075 - val_loss: 0.4502 - val_accuracy: 0.7962 - 365ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4265 - accuracy: 0.8058 - val_loss: 0.4490 - val_accuracy: 0.7940 - 432ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4256 - accuracy: 0.8064 - val_loss: 0.4481 - val_accuracy: 0.7949 - 362ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4270 - accuracy: 0.8066 - val_loss: 0.4497 - val_accuracy: 0.7932 - 354ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4260 - accuracy: 0.8059 - val_loss: 0.4543 - val_accuracy: 0.7962 - 430ms/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4246 - accuracy: 0.8062 - val_loss: 0.4480 - val_accuracy: 0.7991 - 360ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4260 - accuracy: 0.8062 - val_loss: 0.4480 - val_accuracy: 0.7945 - 352ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4252 - accuracy: 0.8058 - val_loss: 0.4482 - val_accuracy: 0.7966 - 335ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4262 - accuracy: 0.8052 - val_loss: 0.4480 - val_accuracy: 0.7957 - 384ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 1s - loss: 0.4248 - accuracy: 0.8056 - val_loss: 0.4493 - val_accuracy: 0.7953 - 561ms/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4245 - accuracy: 0.8060 - val_loss: 0.4485 - val_accuracy: 0.7932 - 386ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4253 - accuracy: 0.8051 - val_loss: 0.4476 - val_accuracy: 0.7983 - 392ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4247 - accuracy: 0.8063 - val_loss: 0.4476 - val_accuracy: 0.7936 - 338ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8054 - val_loss: 0.4480 - val_accuracy: 0.7949 - 404ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4253 - accuracy: 0.8057 - val_loss: 0.4500 - val_accuracy: 0.7940 - 395ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4245 - accuracy: 0.8065 - val_loss: 0.4514 - val_accuracy: 0.7940 - 315ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4233 - accuracy: 0.8057 - val_loss: 0.4486 - val_accuracy: 0.7957 - 299ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4235 - accuracy: 0.8062 - val_loss: 0.4477 - val_accuracy: 0.7945 - 301ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4232 - accuracy: 0.8074 - val_loss: 0.4501 - val_accuracy: 0.7957 - 467ms/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4232 - accuracy: 0.8061 - val_loss: 0.4479 - val_accuracy: 0.7991 - 397ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 0s - loss: 0.4232 - accuracy: 0.8068 - val_loss: 0.4489 - val_accuracy: 0.7945 - 371ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 0s - loss: 0.4229 - accuracy: 0.8070 - val_loss: 0.4470 - val_accuracy: 0.7957 - 346ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 0s - loss: 0.4230 - accuracy: 0.8050 - val_loss: 0.4544 - val_accuracy: 0.7940 - 373ms/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 0s - loss: 0.4238 - accuracy: 0.8067 - val_loss: 0.4488 - val_accuracy: 0.7949 - 394ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 0s - loss: 0.4258 - accuracy: 0.8055 - val_loss: 0.4542 - val_accuracy: 0.7932 - 447ms/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "37/37 - 0s - loss: 0.4247 - accuracy: 0.8070 - val_loss: 0.4492 - val_accuracy: 0.7962 - 346ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "37/37 - 0s - loss: 0.4234 - accuracy: 0.8068 - val_loss: 0.4488 - val_accuracy: 0.7940 - 417ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "37/37 - 1s - loss: 0.4240 - accuracy: 0.8057 - val_loss: 0.4475 - val_accuracy: 0.7936 - 647ms/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "37/37 - 1s - loss: 0.4226 - accuracy: 0.8078 - val_loss: 0.4482 - val_accuracy: 0.7940 - 531ms/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "37/37 - 0s - loss: 0.4222 - accuracy: 0.8065 - val_loss: 0.4470 - val_accuracy: 0.7966 - 378ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "37/37 - 1s - loss: 0.4228 - accuracy: 0.8057 - val_loss: 0.4468 - val_accuracy: 0.7928 - 510ms/epoch - 14ms/step\n",
      "Epoch 54/100\n",
      "37/37 - 1s - loss: 0.4219 - accuracy: 0.8054 - val_loss: 0.4493 - val_accuracy: 0.7949 - 573ms/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "37/37 - 1s - loss: 0.4221 - accuracy: 0.8067 - val_loss: 0.4507 - val_accuracy: 0.7945 - 571ms/epoch - 15ms/step\n",
      "Epoch 56/100\n",
      "37/37 - 0s - loss: 0.4217 - accuracy: 0.8055 - val_loss: 0.4461 - val_accuracy: 0.7987 - 422ms/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "37/37 - 0s - loss: 0.4226 - accuracy: 0.8070 - val_loss: 0.4475 - val_accuracy: 0.7966 - 410ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "37/37 - 0s - loss: 0.4249 - accuracy: 0.8042 - val_loss: 0.4517 - val_accuracy: 0.7936 - 405ms/epoch - 11ms/step\n",
      "Epoch 59/100\n",
      "37/37 - 1s - loss: 0.4237 - accuracy: 0.8051 - val_loss: 0.4473 - val_accuracy: 0.7945 - 514ms/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "37/37 - 1s - loss: 0.4219 - accuracy: 0.8066 - val_loss: 0.4452 - val_accuracy: 0.7974 - 535ms/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "37/37 - 0s - loss: 0.4221 - accuracy: 0.8061 - val_loss: 0.4529 - val_accuracy: 0.7940 - 422ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "37/37 - 0s - loss: 0.4225 - accuracy: 0.8057 - val_loss: 0.4490 - val_accuracy: 0.7949 - 420ms/epoch - 11ms/step\n",
      "Epoch 63/100\n",
      "37/37 - 0s - loss: 0.4217 - accuracy: 0.8062 - val_loss: 0.4472 - val_accuracy: 0.7949 - 341ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "37/37 - 0s - loss: 0.4210 - accuracy: 0.8091 - val_loss: 0.4486 - val_accuracy: 0.7923 - 451ms/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "37/37 - 0s - loss: 0.4218 - accuracy: 0.8049 - val_loss: 0.4469 - val_accuracy: 0.7974 - 323ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "37/37 - 0s - loss: 0.4221 - accuracy: 0.8074 - val_loss: 0.4504 - val_accuracy: 0.7940 - 418ms/epoch - 11ms/step\n",
      "Epoch 67/100\n",
      "37/37 - 0s - loss: 0.4212 - accuracy: 0.8063 - val_loss: 0.4470 - val_accuracy: 0.7928 - 389ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "37/37 - 0s - loss: 0.4213 - accuracy: 0.8059 - val_loss: 0.4459 - val_accuracy: 0.7928 - 479ms/epoch - 13ms/step\n",
      "Epoch 69/100\n",
      "37/37 - 1s - loss: 0.4211 - accuracy: 0.8079 - val_loss: 0.4454 - val_accuracy: 0.7949 - 619ms/epoch - 17ms/step\n",
      "Epoch 70/100\n",
      "37/37 - 0s - loss: 0.4225 - accuracy: 0.8052 - val_loss: 0.4471 - val_accuracy: 0.7970 - 406ms/epoch - 11ms/step\n",
      "Epoch 70: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 3.2348 - accuracy: 0.7669 - val_loss: 2.7223 - val_accuracy: 0.7510 - 2s/epoch - 48ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 2.3206 - accuracy: 0.7673 - val_loss: 1.9709 - val_accuracy: 0.7684 - 307ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 1.6884 - accuracy: 0.7905 - val_loss: 1.4585 - val_accuracy: 0.7817 - 353ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 1.2582 - accuracy: 0.7939 - val_loss: 1.1120 - val_accuracy: 0.7804 - 330ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.9667 - accuracy: 0.7985 - val_loss: 0.8754 - val_accuracy: 0.7949 - 344ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.7732 - accuracy: 0.8043 - val_loss: 0.7214 - val_accuracy: 0.7940 - 413ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.6458 - accuracy: 0.8039 - val_loss: 0.6216 - val_accuracy: 0.7906 - 334ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.5632 - accuracy: 0.8054 - val_loss: 0.5531 - val_accuracy: 0.7949 - 321ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.5111 - accuracy: 0.8046 - val_loss: 0.5177 - val_accuracy: 0.7953 - 317ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4783 - accuracy: 0.8051 - val_loss: 0.4889 - val_accuracy: 0.7949 - 328ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4588 - accuracy: 0.8046 - val_loss: 0.4736 - val_accuracy: 0.7949 - 332ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4459 - accuracy: 0.8059 - val_loss: 0.4633 - val_accuracy: 0.7957 - 316ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4390 - accuracy: 0.8066 - val_loss: 0.4601 - val_accuracy: 0.7945 - 325ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4350 - accuracy: 0.8048 - val_loss: 0.4559 - val_accuracy: 0.7970 - 302ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4333 - accuracy: 0.8050 - val_loss: 0.4529 - val_accuracy: 0.7953 - 327ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4303 - accuracy: 0.8056 - val_loss: 0.4534 - val_accuracy: 0.7945 - 363ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 1s - loss: 0.4297 - accuracy: 0.8074 - val_loss: 0.4535 - val_accuracy: 0.7940 - 557ms/epoch - 15ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4275 - accuracy: 0.8055 - val_loss: 0.4503 - val_accuracy: 0.7949 - 346ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4281 - accuracy: 0.8066 - val_loss: 0.4533 - val_accuracy: 0.7949 - 431ms/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4273 - accuracy: 0.8066 - val_loss: 0.4517 - val_accuracy: 0.7949 - 433ms/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4264 - accuracy: 0.8062 - val_loss: 0.4559 - val_accuracy: 0.7949 - 350ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4275 - accuracy: 0.8049 - val_loss: 0.4498 - val_accuracy: 0.7949 - 354ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4255 - accuracy: 0.8063 - val_loss: 0.4504 - val_accuracy: 0.7940 - 348ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4256 - accuracy: 0.8080 - val_loss: 0.4513 - val_accuracy: 0.7953 - 342ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4260 - accuracy: 0.8055 - val_loss: 0.4491 - val_accuracy: 0.7945 - 325ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4248 - accuracy: 0.8049 - val_loss: 0.4489 - val_accuracy: 0.7945 - 373ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4249 - accuracy: 0.8064 - val_loss: 0.4503 - val_accuracy: 0.7945 - 410ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 1s - loss: 0.4254 - accuracy: 0.8047 - val_loss: 0.4467 - val_accuracy: 0.7962 - 548ms/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4252 - accuracy: 0.8066 - val_loss: 0.4477 - val_accuracy: 0.7940 - 414ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4246 - accuracy: 0.8061 - val_loss: 0.4475 - val_accuracy: 0.7953 - 362ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4258 - accuracy: 0.8046 - val_loss: 0.4562 - val_accuracy: 0.7928 - 445ms/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4250 - accuracy: 0.8072 - val_loss: 0.4476 - val_accuracy: 0.7966 - 436ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4241 - accuracy: 0.8070 - val_loss: 0.4464 - val_accuracy: 0.7945 - 325ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4238 - accuracy: 0.8082 - val_loss: 0.4573 - val_accuracy: 0.7919 - 326ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4255 - accuracy: 0.8045 - val_loss: 0.4488 - val_accuracy: 0.7949 - 342ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4240 - accuracy: 0.8060 - val_loss: 0.4484 - val_accuracy: 0.7945 - 321ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4242 - accuracy: 0.8068 - val_loss: 0.4466 - val_accuracy: 0.7928 - 381ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4241 - accuracy: 0.8064 - val_loss: 0.4460 - val_accuracy: 0.7940 - 340ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4242 - accuracy: 0.8080 - val_loss: 0.4473 - val_accuracy: 0.7957 - 332ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4240 - accuracy: 0.8066 - val_loss: 0.4477 - val_accuracy: 0.7962 - 330ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4247 - accuracy: 0.8060 - val_loss: 0.4492 - val_accuracy: 0.7932 - 379ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4232 - accuracy: 0.8075 - val_loss: 0.4480 - val_accuracy: 0.7945 - 380ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 1s - loss: 0.4229 - accuracy: 0.8066 - val_loss: 0.4471 - val_accuracy: 0.7945 - 514ms/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 1s - loss: 0.4235 - accuracy: 0.8063 - val_loss: 0.4481 - val_accuracy: 0.7949 - 878ms/epoch - 24ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 1s - loss: 0.4245 - accuracy: 0.8032 - val_loss: 0.4491 - val_accuracy: 0.7949 - 553ms/epoch - 15ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 1s - loss: 0.4221 - accuracy: 0.8064 - val_loss: 0.4466 - val_accuracy: 0.7928 - 652ms/epoch - 18ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 1s - loss: 0.4223 - accuracy: 0.8073 - val_loss: 0.4487 - val_accuracy: 0.7932 - 710ms/epoch - 19ms/step\n",
      "Epoch 48/100\n",
      "37/37 - 1s - loss: 0.4234 - accuracy: 0.8062 - val_loss: 0.4515 - val_accuracy: 0.7893 - 854ms/epoch - 23ms/step\n",
      "Epoch 48: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 3.2609 - accuracy: 0.7658 - val_loss: 2.7380 - val_accuracy: 0.7510 - 2s/epoch - 49ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 2.3407 - accuracy: 0.7664 - val_loss: 1.9936 - val_accuracy: 0.7510 - 353ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 1.7106 - accuracy: 0.7664 - val_loss: 1.4792 - val_accuracy: 0.7510 - 387ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 1.2778 - accuracy: 0.7664 - val_loss: 1.1274 - val_accuracy: 0.7510 - 337ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.9810 - accuracy: 0.7674 - val_loss: 0.8854 - val_accuracy: 0.7574 - 341ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.7808 - accuracy: 0.7799 - val_loss: 0.7267 - val_accuracy: 0.7765 - 329ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.6503 - accuracy: 0.7947 - val_loss: 0.6227 - val_accuracy: 0.7940 - 322ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.5658 - accuracy: 0.8009 - val_loss: 0.5577 - val_accuracy: 0.7949 - 384ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.5116 - accuracy: 0.8048 - val_loss: 0.5149 - val_accuracy: 0.7957 - 338ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4791 - accuracy: 0.8044 - val_loss: 0.4907 - val_accuracy: 0.7966 - 317ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4596 - accuracy: 0.8059 - val_loss: 0.4740 - val_accuracy: 0.7962 - 318ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4465 - accuracy: 0.8059 - val_loss: 0.4683 - val_accuracy: 0.7953 - 340ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4408 - accuracy: 0.8045 - val_loss: 0.4606 - val_accuracy: 0.7957 - 325ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4343 - accuracy: 0.8057 - val_loss: 0.4559 - val_accuracy: 0.7962 - 311ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4326 - accuracy: 0.8051 - val_loss: 0.4555 - val_accuracy: 0.7966 - 381ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4306 - accuracy: 0.8055 - val_loss: 0.4560 - val_accuracy: 0.7970 - 414ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4292 - accuracy: 0.8057 - val_loss: 0.4527 - val_accuracy: 0.7970 - 351ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4284 - accuracy: 0.8060 - val_loss: 0.4523 - val_accuracy: 0.8004 - 366ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4278 - accuracy: 0.8060 - val_loss: 0.4518 - val_accuracy: 0.7983 - 333ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4275 - accuracy: 0.8045 - val_loss: 0.4503 - val_accuracy: 0.7974 - 381ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4269 - accuracy: 0.8059 - val_loss: 0.4496 - val_accuracy: 0.7923 - 387ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4262 - accuracy: 0.8060 - val_loss: 0.4500 - val_accuracy: 0.7966 - 328ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4256 - accuracy: 0.8055 - val_loss: 0.4503 - val_accuracy: 0.7957 - 403ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4275 - accuracy: 0.8063 - val_loss: 0.4608 - val_accuracy: 0.7945 - 336ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4264 - accuracy: 0.8041 - val_loss: 0.4504 - val_accuracy: 0.7953 - 394ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4254 - accuracy: 0.8051 - val_loss: 0.4482 - val_accuracy: 0.7983 - 367ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4258 - accuracy: 0.8063 - val_loss: 0.4487 - val_accuracy: 0.7953 - 387ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4255 - accuracy: 0.8062 - val_loss: 0.4508 - val_accuracy: 0.7940 - 323ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8055 - val_loss: 0.4486 - val_accuracy: 0.7991 - 373ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4243 - accuracy: 0.8052 - val_loss: 0.4478 - val_accuracy: 0.7953 - 435ms/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4239 - accuracy: 0.8070 - val_loss: 0.4512 - val_accuracy: 0.7957 - 340ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4254 - accuracy: 0.8073 - val_loss: 0.4467 - val_accuracy: 0.7945 - 385ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4250 - accuracy: 0.8058 - val_loss: 0.4514 - val_accuracy: 0.7953 - 372ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4235 - accuracy: 0.8064 - val_loss: 0.4458 - val_accuracy: 0.7974 - 338ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4237 - accuracy: 0.8068 - val_loss: 0.4470 - val_accuracy: 0.7987 - 456ms/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4245 - accuracy: 0.8077 - val_loss: 0.4513 - val_accuracy: 0.7949 - 408ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4237 - accuracy: 0.8054 - val_loss: 0.4496 - val_accuracy: 0.7953 - 386ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4229 - accuracy: 0.8082 - val_loss: 0.4497 - val_accuracy: 0.7940 - 459ms/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4232 - accuracy: 0.8065 - val_loss: 0.4489 - val_accuracy: 0.7953 - 430ms/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4235 - accuracy: 0.8060 - val_loss: 0.4469 - val_accuracy: 0.7966 - 344ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4227 - accuracy: 0.8063 - val_loss: 0.4499 - val_accuracy: 0.7940 - 432ms/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4236 - accuracy: 0.8057 - val_loss: 0.4487 - val_accuracy: 0.7974 - 377ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 0s - loss: 0.4228 - accuracy: 0.8055 - val_loss: 0.4492 - val_accuracy: 0.7953 - 409ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 0s - loss: 0.4224 - accuracy: 0.8077 - val_loss: 0.4497 - val_accuracy: 0.7945 - 436ms/epoch - 12ms/step\n",
      "Epoch 44: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "37/37 - 3s - loss: 3.4564 - accuracy: 0.6570 - val_loss: 2.8957 - val_accuracy: 0.7497 - 3s/epoch - 92ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 2.4720 - accuracy: 0.7658 - val_loss: 2.1005 - val_accuracy: 0.7510 - 466ms/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 1.8053 - accuracy: 0.7664 - val_loss: 1.5636 - val_accuracy: 0.7510 - 471ms/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 1.3500 - accuracy: 0.7680 - val_loss: 1.1919 - val_accuracy: 0.7625 - 381ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 1.0350 - accuracy: 0.7891 - val_loss: 0.9353 - val_accuracy: 0.7795 - 292ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.8218 - accuracy: 0.7967 - val_loss: 0.7662 - val_accuracy: 0.7846 - 309ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.6792 - accuracy: 0.8031 - val_loss: 0.6515 - val_accuracy: 0.7889 - 417ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.5864 - accuracy: 0.8026 - val_loss: 0.5756 - val_accuracy: 0.7928 - 354ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.5268 - accuracy: 0.8052 - val_loss: 0.5314 - val_accuracy: 0.7910 - 449ms/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4887 - accuracy: 0.8059 - val_loss: 0.4994 - val_accuracy: 0.7945 - 328ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4660 - accuracy: 0.8049 - val_loss: 0.4805 - val_accuracy: 0.7945 - 321ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4509 - accuracy: 0.8061 - val_loss: 0.4688 - val_accuracy: 0.7940 - 403ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4427 - accuracy: 0.8048 - val_loss: 0.4647 - val_accuracy: 0.7949 - 378ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4370 - accuracy: 0.8060 - val_loss: 0.4608 - val_accuracy: 0.7957 - 317ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4335 - accuracy: 0.8058 - val_loss: 0.4598 - val_accuracy: 0.7949 - 336ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4317 - accuracy: 0.8051 - val_loss: 0.4540 - val_accuracy: 0.7940 - 318ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4307 - accuracy: 0.8061 - val_loss: 0.4534 - val_accuracy: 0.7957 - 304ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4298 - accuracy: 0.8054 - val_loss: 0.4584 - val_accuracy: 0.7932 - 429ms/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4291 - accuracy: 0.8051 - val_loss: 0.4521 - val_accuracy: 0.7945 - 437ms/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 1s - loss: 0.4289 - accuracy: 0.8054 - val_loss: 0.4509 - val_accuracy: 0.7953 - 605ms/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4273 - accuracy: 0.8045 - val_loss: 0.4516 - val_accuracy: 0.7945 - 437ms/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4275 - accuracy: 0.8066 - val_loss: 0.4507 - val_accuracy: 0.7949 - 396ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4272 - accuracy: 0.8060 - val_loss: 0.4495 - val_accuracy: 0.7949 - 361ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4277 - accuracy: 0.8056 - val_loss: 0.4506 - val_accuracy: 0.7923 - 331ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4313 - accuracy: 0.8027 - val_loss: 0.4520 - val_accuracy: 0.7889 - 413ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4261 - accuracy: 0.8050 - val_loss: 0.4514 - val_accuracy: 0.7957 - 350ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4261 - accuracy: 0.8052 - val_loss: 0.4518 - val_accuracy: 0.7940 - 317ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4264 - accuracy: 0.8056 - val_loss: 0.4510 - val_accuracy: 0.7923 - 375ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4279 - accuracy: 0.8051 - val_loss: 0.4499 - val_accuracy: 0.7957 - 480ms/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4259 - accuracy: 0.8056 - val_loss: 0.4481 - val_accuracy: 0.7949 - 362ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4246 - accuracy: 0.8064 - val_loss: 0.4480 - val_accuracy: 0.7940 - 329ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4260 - accuracy: 0.8061 - val_loss: 0.4486 - val_accuracy: 0.7953 - 330ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4240 - accuracy: 0.8057 - val_loss: 0.4488 - val_accuracy: 0.7940 - 351ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4241 - accuracy: 0.8079 - val_loss: 0.4509 - val_accuracy: 0.7949 - 359ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4244 - accuracy: 0.8052 - val_loss: 0.4489 - val_accuracy: 0.7957 - 329ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4240 - accuracy: 0.8065 - val_loss: 0.4496 - val_accuracy: 0.7966 - 350ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4263 - accuracy: 0.8056 - val_loss: 0.4506 - val_accuracy: 0.7949 - 331ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4249 - accuracy: 0.8048 - val_loss: 0.4495 - val_accuracy: 0.7983 - 326ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4235 - accuracy: 0.8054 - val_loss: 0.4492 - val_accuracy: 0.7932 - 304ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4244 - accuracy: 0.8055 - val_loss: 0.4502 - val_accuracy: 0.7949 - 331ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4241 - accuracy: 0.8049 - val_loss: 0.4571 - val_accuracy: 0.7846 - 350ms/epoch - 9ms/step\n",
      "Epoch 41: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "37/37 - 3s - loss: 3.3375 - accuracy: 0.6382 - val_loss: 2.7803 - val_accuracy: 0.7510 - 3s/epoch - 79ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 1s - loss: 2.3746 - accuracy: 0.7664 - val_loss: 2.0194 - val_accuracy: 0.7510 - 527ms/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 1s - loss: 1.7296 - accuracy: 0.7667 - val_loss: 1.4927 - val_accuracy: 0.7535 - 608ms/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 1s - loss: 1.2844 - accuracy: 0.7818 - val_loss: 1.1310 - val_accuracy: 0.7778 - 566ms/epoch - 15ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 1s - loss: 0.9832 - accuracy: 0.7979 - val_loss: 0.8889 - val_accuracy: 0.7902 - 593ms/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 1s - loss: 0.7833 - accuracy: 0.8026 - val_loss: 0.7276 - val_accuracy: 0.7945 - 570ms/epoch - 15ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 1s - loss: 0.6531 - accuracy: 0.8049 - val_loss: 0.6318 - val_accuracy: 0.7906 - 542ms/epoch - 15ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.5686 - accuracy: 0.8044 - val_loss: 0.5621 - val_accuracy: 0.7932 - 427ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.5154 - accuracy: 0.8052 - val_loss: 0.5215 - val_accuracy: 0.7923 - 423ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4809 - accuracy: 0.8050 - val_loss: 0.4909 - val_accuracy: 0.7945 - 316ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4598 - accuracy: 0.8057 - val_loss: 0.4756 - val_accuracy: 0.7936 - 366ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4479 - accuracy: 0.8060 - val_loss: 0.4681 - val_accuracy: 0.7953 - 317ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4401 - accuracy: 0.8055 - val_loss: 0.4602 - val_accuracy: 0.7949 - 383ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4360 - accuracy: 0.8049 - val_loss: 0.4569 - val_accuracy: 0.7949 - 368ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4329 - accuracy: 0.8055 - val_loss: 0.4550 - val_accuracy: 0.7953 - 402ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4313 - accuracy: 0.8058 - val_loss: 0.4611 - val_accuracy: 0.7949 - 383ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4303 - accuracy: 0.8050 - val_loss: 0.4547 - val_accuracy: 0.7945 - 444ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4305 - accuracy: 0.8041 - val_loss: 0.4516 - val_accuracy: 0.7949 - 473ms/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4279 - accuracy: 0.8045 - val_loss: 0.4498 - val_accuracy: 0.7945 - 335ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4282 - accuracy: 0.8051 - val_loss: 0.4540 - val_accuracy: 0.7953 - 388ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4267 - accuracy: 0.8061 - val_loss: 0.4498 - val_accuracy: 0.7957 - 342ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4270 - accuracy: 0.8059 - val_loss: 0.4496 - val_accuracy: 0.7957 - 391ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4267 - accuracy: 0.8057 - val_loss: 0.4492 - val_accuracy: 0.7970 - 322ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4271 - accuracy: 0.8066 - val_loss: 0.4562 - val_accuracy: 0.7953 - 438ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4270 - accuracy: 0.8047 - val_loss: 0.4518 - val_accuracy: 0.7949 - 287ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4270 - accuracy: 0.8041 - val_loss: 0.4531 - val_accuracy: 0.7940 - 271ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4268 - accuracy: 0.8047 - val_loss: 0.4482 - val_accuracy: 0.7983 - 270ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4253 - accuracy: 0.8057 - val_loss: 0.4531 - val_accuracy: 0.7940 - 428ms/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8078 - val_loss: 0.4584 - val_accuracy: 0.7923 - 431ms/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4246 - accuracy: 0.8074 - val_loss: 0.4471 - val_accuracy: 0.7932 - 362ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4246 - accuracy: 0.8055 - val_loss: 0.4483 - val_accuracy: 0.7953 - 412ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4254 - accuracy: 0.8057 - val_loss: 0.4474 - val_accuracy: 0.8004 - 419ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4248 - accuracy: 0.8047 - val_loss: 0.4491 - val_accuracy: 0.7962 - 436ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4250 - accuracy: 0.8059 - val_loss: 0.4497 - val_accuracy: 0.7966 - 402ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4240 - accuracy: 0.8065 - val_loss: 0.4478 - val_accuracy: 0.7932 - 426ms/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4244 - accuracy: 0.8061 - val_loss: 0.4484 - val_accuracy: 0.7953 - 403ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4241 - accuracy: 0.8065 - val_loss: 0.4471 - val_accuracy: 0.7957 - 391ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4235 - accuracy: 0.8064 - val_loss: 0.4469 - val_accuracy: 0.7949 - 345ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4233 - accuracy: 0.8050 - val_loss: 0.4467 - val_accuracy: 0.7966 - 365ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4246 - accuracy: 0.8052 - val_loss: 0.4475 - val_accuracy: 0.7957 - 408ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 1s - loss: 0.4234 - accuracy: 0.8055 - val_loss: 0.4523 - val_accuracy: 0.7932 - 547ms/epoch - 15ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4234 - accuracy: 0.8072 - val_loss: 0.4455 - val_accuracy: 0.7957 - 430ms/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 0s - loss: 0.4247 - accuracy: 0.8056 - val_loss: 0.4465 - val_accuracy: 0.7970 - 340ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 0s - loss: 0.4240 - accuracy: 0.8065 - val_loss: 0.4510 - val_accuracy: 0.7936 - 353ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 0s - loss: 0.4232 - accuracy: 0.8067 - val_loss: 0.4470 - val_accuracy: 0.7949 - 368ms/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 0s - loss: 0.4248 - accuracy: 0.8059 - val_loss: 0.4490 - val_accuracy: 0.7949 - 425ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 0s - loss: 0.4241 - accuracy: 0.8062 - val_loss: 0.4464 - val_accuracy: 0.7966 - 438ms/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "37/37 - 1s - loss: 0.4225 - accuracy: 0.8064 - val_loss: 0.4463 - val_accuracy: 0.7979 - 501ms/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "37/37 - 0s - loss: 0.4226 - accuracy: 0.8066 - val_loss: 0.4510 - val_accuracy: 0.7945 - 412ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "37/37 - 0s - loss: 0.4227 - accuracy: 0.8057 - val_loss: 0.4486 - val_accuracy: 0.7945 - 446ms/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "37/37 - 0s - loss: 0.4243 - accuracy: 0.8042 - val_loss: 0.4487 - val_accuracy: 0.7953 - 341ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "37/37 - 0s - loss: 0.4228 - accuracy: 0.8060 - val_loss: 0.4489 - val_accuracy: 0.7962 - 389ms/epoch - 11ms/step\n",
      "Epoch 52: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "37/37 - 1s - loss: 3.4019 - accuracy: 0.7654 - val_loss: 2.8770 - val_accuracy: 0.7510 - 1s/epoch - 37ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 2.4581 - accuracy: 0.7664 - val_loss: 2.0968 - val_accuracy: 0.7510 - 366ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 1.7953 - accuracy: 0.7662 - val_loss: 1.5483 - val_accuracy: 0.7522 - 392ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 1s - loss: 1.3310 - accuracy: 0.7842 - val_loss: 1.1679 - val_accuracy: 0.7817 - 583ms/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 1.0145 - accuracy: 0.7987 - val_loss: 0.9153 - val_accuracy: 0.7919 - 426ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.8043 - accuracy: 0.8047 - val_loss: 0.7462 - val_accuracy: 0.7945 - 411ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.6669 - accuracy: 0.8048 - val_loss: 0.6347 - val_accuracy: 0.7932 - 351ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.5755 - accuracy: 0.8054 - val_loss: 0.5654 - val_accuracy: 0.7949 - 285ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.5176 - accuracy: 0.8049 - val_loss: 0.5262 - val_accuracy: 0.7919 - 309ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4820 - accuracy: 0.8059 - val_loss: 0.4941 - val_accuracy: 0.7962 - 296ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4595 - accuracy: 0.8059 - val_loss: 0.4745 - val_accuracy: 0.7953 - 324ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4460 - accuracy: 0.8063 - val_loss: 0.4671 - val_accuracy: 0.7953 - 444ms/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4395 - accuracy: 0.8056 - val_loss: 0.4625 - val_accuracy: 0.7949 - 362ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4347 - accuracy: 0.8066 - val_loss: 0.4569 - val_accuracy: 0.7966 - 311ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4311 - accuracy: 0.8059 - val_loss: 0.4548 - val_accuracy: 0.7945 - 310ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4294 - accuracy: 0.8052 - val_loss: 0.4573 - val_accuracy: 0.7945 - 348ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4290 - accuracy: 0.8079 - val_loss: 0.4519 - val_accuracy: 0.7953 - 352ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4279 - accuracy: 0.8065 - val_loss: 0.4500 - val_accuracy: 0.7936 - 344ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4317 - accuracy: 0.8015 - val_loss: 0.4537 - val_accuracy: 0.7906 - 312ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4281 - accuracy: 0.8055 - val_loss: 0.4494 - val_accuracy: 0.7936 - 343ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4266 - accuracy: 0.8074 - val_loss: 0.4484 - val_accuracy: 0.7923 - 330ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4256 - accuracy: 0.8066 - val_loss: 0.4490 - val_accuracy: 0.7953 - 321ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4265 - accuracy: 0.8062 - val_loss: 0.4507 - val_accuracy: 0.7953 - 327ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4258 - accuracy: 0.8063 - val_loss: 0.4544 - val_accuracy: 0.7902 - 324ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4272 - accuracy: 0.8048 - val_loss: 0.4496 - val_accuracy: 0.7949 - 363ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4257 - accuracy: 0.8056 - val_loss: 0.4532 - val_accuracy: 0.7906 - 359ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4278 - accuracy: 0.8076 - val_loss: 0.4480 - val_accuracy: 0.7940 - 441ms/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4250 - accuracy: 0.8052 - val_loss: 0.4530 - val_accuracy: 0.7949 - 424ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4247 - accuracy: 0.8067 - val_loss: 0.4505 - val_accuracy: 0.7945 - 414ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4258 - accuracy: 0.8061 - val_loss: 0.4495 - val_accuracy: 0.7940 - 318ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4241 - accuracy: 0.8056 - val_loss: 0.4481 - val_accuracy: 0.7979 - 406ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4242 - accuracy: 0.8060 - val_loss: 0.4482 - val_accuracy: 0.7945 - 403ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4245 - accuracy: 0.8065 - val_loss: 0.4519 - val_accuracy: 0.7898 - 387ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4265 - accuracy: 0.8067 - val_loss: 0.4482 - val_accuracy: 0.7923 - 384ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4250 - accuracy: 0.8044 - val_loss: 0.4487 - val_accuracy: 0.7936 - 425ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4260 - accuracy: 0.8034 - val_loss: 0.4502 - val_accuracy: 0.7957 - 463ms/epoch - 13ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4247 - accuracy: 0.8041 - val_loss: 0.4492 - val_accuracy: 0.7940 - 320ms/epoch - 9ms/step\n",
      "Epoch 37: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.4365954841937596\n",
      "epi entropy:  0.41067587444711534\n",
      "\n",
      "dataset size:  0.4\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 3.1605 - accuracy: 0.7543 - val_loss: 2.5119 - val_accuracy: 0.7514 - 2s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 2.0615 - accuracy: 0.7605 - val_loss: 1.6623 - val_accuracy: 0.7700 - 391ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 1.3837 - accuracy: 0.7852 - val_loss: 1.1371 - val_accuracy: 0.7911 - 406ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.9729 - accuracy: 0.7934 - val_loss: 0.8254 - val_accuracy: 0.7965 - 391ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.7311 - accuracy: 0.8011 - val_loss: 0.6478 - val_accuracy: 0.8017 - 418ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.5935 - accuracy: 0.8022 - val_loss: 0.5454 - val_accuracy: 0.8042 - 426ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 1s - loss: 0.5172 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.8042 - 611ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4766 - accuracy: 0.8022 - val_loss: 0.4601 - val_accuracy: 0.8045 - 500ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 1s - loss: 0.4544 - accuracy: 0.8025 - val_loss: 0.4457 - val_accuracy: 0.8036 - 550ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4447 - accuracy: 0.8016 - val_loss: 0.4377 - val_accuracy: 0.8029 - 467ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4397 - accuracy: 0.8028 - val_loss: 0.4352 - val_accuracy: 0.8061 - 466ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4352 - accuracy: 0.8028 - val_loss: 0.4319 - val_accuracy: 0.8036 - 483ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 1s - loss: 0.4358 - accuracy: 0.8020 - val_loss: 0.4336 - val_accuracy: 0.8058 - 752ms/epoch - 15ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4328 - accuracy: 0.8030 - val_loss: 0.4298 - val_accuracy: 0.8049 - 452ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4318 - accuracy: 0.8010 - val_loss: 0.4313 - val_accuracy: 0.8039 - 459ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4320 - accuracy: 0.8020 - val_loss: 0.4317 - val_accuracy: 0.8039 - 475ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 1s - loss: 0.4320 - accuracy: 0.8011 - val_loss: 0.4337 - val_accuracy: 0.8033 - 512ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4303 - accuracy: 0.8026 - val_loss: 0.4309 - val_accuracy: 0.8033 - 497ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 1s - loss: 0.4293 - accuracy: 0.8020 - val_loss: 0.4280 - val_accuracy: 0.7988 - 502ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4295 - accuracy: 0.8016 - val_loss: 0.4277 - val_accuracy: 0.8036 - 404ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 1s - loss: 0.4308 - accuracy: 0.8035 - val_loss: 0.4260 - val_accuracy: 0.8045 - 529ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4290 - accuracy: 0.8031 - val_loss: 0.4260 - val_accuracy: 0.8026 - 453ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 1s - loss: 0.4297 - accuracy: 0.8032 - val_loss: 0.4265 - val_accuracy: 0.8042 - 554ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4286 - accuracy: 0.8033 - val_loss: 0.4342 - val_accuracy: 0.8055 - 449ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 1s - loss: 0.4287 - accuracy: 0.8024 - val_loss: 0.4285 - val_accuracy: 0.8049 - 522ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4293 - accuracy: 0.8008 - val_loss: 0.4284 - val_accuracy: 0.8045 - 465ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 1s - loss: 0.4293 - accuracy: 0.8024 - val_loss: 0.4267 - val_accuracy: 0.7991 - 539ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 1s - loss: 0.4293 - accuracy: 0.8012 - val_loss: 0.4257 - val_accuracy: 0.8045 - 641ms/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 1s - loss: 0.4281 - accuracy: 0.8014 - val_loss: 0.4266 - val_accuracy: 0.8045 - 656ms/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 1s - loss: 0.4285 - accuracy: 0.8016 - val_loss: 0.4254 - val_accuracy: 0.8058 - 750ms/epoch - 15ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 1s - loss: 0.4284 - accuracy: 0.8012 - val_loss: 0.4255 - val_accuracy: 0.8029 - 862ms/epoch - 18ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 1s - loss: 0.4278 - accuracy: 0.8025 - val_loss: 0.4284 - val_accuracy: 0.8042 - 744ms/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 1s - loss: 0.4284 - accuracy: 0.8029 - val_loss: 0.4256 - val_accuracy: 0.8017 - 674ms/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 1s - loss: 0.4288 - accuracy: 0.8004 - val_loss: 0.4343 - val_accuracy: 0.7978 - 599ms/epoch - 12ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4286 - accuracy: 0.8020 - val_loss: 0.4253 - val_accuracy: 0.8001 - 434ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4275 - accuracy: 0.8030 - val_loss: 0.4246 - val_accuracy: 0.8010 - 475ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4272 - accuracy: 0.8028 - val_loss: 0.4249 - val_accuracy: 0.8052 - 480ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4275 - accuracy: 0.8028 - val_loss: 0.4288 - val_accuracy: 0.8049 - 442ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4274 - accuracy: 0.8031 - val_loss: 0.4258 - val_accuracy: 0.8010 - 424ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4275 - accuracy: 0.8013 - val_loss: 0.4254 - val_accuracy: 0.8052 - 442ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4282 - accuracy: 0.8038 - val_loss: 0.4254 - val_accuracy: 0.8042 - 435ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4273 - accuracy: 0.8016 - val_loss: 0.4253 - val_accuracy: 0.8039 - 446ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4265 - accuracy: 0.8024 - val_loss: 0.4246 - val_accuracy: 0.8039 - 491ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4265 - accuracy: 0.8029 - val_loss: 0.4258 - val_accuracy: 0.8020 - 470ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 1s - loss: 0.4274 - accuracy: 0.8013 - val_loss: 0.4247 - val_accuracy: 0.7994 - 511ms/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 1s - loss: 0.4279 - accuracy: 0.8006 - val_loss: 0.4259 - val_accuracy: 0.8042 - 715ms/epoch - 15ms/step\n",
      "Epoch 46: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 3.2063 - accuracy: 0.6457 - val_loss: 2.5342 - val_accuracy: 0.7518 - 2s/epoch - 50ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 1s - loss: 2.0833 - accuracy: 0.7601 - val_loss: 1.6843 - val_accuracy: 0.7527 - 568ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 1s - loss: 1.4052 - accuracy: 0.7783 - val_loss: 1.1537 - val_accuracy: 0.7943 - 515ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.9890 - accuracy: 0.7979 - val_loss: 0.8424 - val_accuracy: 0.7889 - 429ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.7448 - accuracy: 0.7988 - val_loss: 0.6561 - val_accuracy: 0.8033 - 442ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.6022 - accuracy: 0.8017 - val_loss: 0.5533 - val_accuracy: 0.8026 - 432ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.5233 - accuracy: 0.8028 - val_loss: 0.4951 - val_accuracy: 0.8061 - 434ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4811 - accuracy: 0.8013 - val_loss: 0.4634 - val_accuracy: 0.8071 - 413ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4579 - accuracy: 0.8017 - val_loss: 0.4479 - val_accuracy: 0.8055 - 487ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 1s - loss: 0.4470 - accuracy: 0.8017 - val_loss: 0.4392 - val_accuracy: 0.8052 - 569ms/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 1s - loss: 0.4406 - accuracy: 0.8022 - val_loss: 0.4350 - val_accuracy: 0.8052 - 674ms/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 1s - loss: 0.4379 - accuracy: 0.8012 - val_loss: 0.4326 - val_accuracy: 0.8020 - 732ms/epoch - 15ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 1s - loss: 0.4356 - accuracy: 0.8017 - val_loss: 0.4333 - val_accuracy: 0.8058 - 704ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 1s - loss: 0.4338 - accuracy: 0.8018 - val_loss: 0.4312 - val_accuracy: 0.8017 - 783ms/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 1s - loss: 0.4333 - accuracy: 0.8020 - val_loss: 0.4311 - val_accuracy: 0.8045 - 727ms/epoch - 15ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 1s - loss: 0.4322 - accuracy: 0.8030 - val_loss: 0.4290 - val_accuracy: 0.8036 - 681ms/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 1s - loss: 0.4316 - accuracy: 0.8016 - val_loss: 0.4293 - val_accuracy: 0.8007 - 588ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4326 - accuracy: 0.8021 - val_loss: 0.4276 - val_accuracy: 0.8039 - 426ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4317 - accuracy: 0.8024 - val_loss: 0.4279 - val_accuracy: 0.8061 - 452ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4308 - accuracy: 0.8020 - val_loss: 0.4281 - val_accuracy: 0.8061 - 442ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4320 - accuracy: 0.8025 - val_loss: 0.4275 - val_accuracy: 0.8061 - 423ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4298 - accuracy: 0.8027 - val_loss: 0.4273 - val_accuracy: 0.8039 - 441ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4310 - accuracy: 0.8020 - val_loss: 0.4273 - val_accuracy: 0.8023 - 462ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4304 - accuracy: 0.8027 - val_loss: 0.4288 - val_accuracy: 0.7994 - 468ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4303 - accuracy: 0.8025 - val_loss: 0.4274 - val_accuracy: 0.8045 - 443ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4284 - accuracy: 0.8027 - val_loss: 0.4256 - val_accuracy: 0.8049 - 438ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4288 - accuracy: 0.8005 - val_loss: 0.4270 - val_accuracy: 0.8052 - 469ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4294 - accuracy: 0.8016 - val_loss: 0.4269 - val_accuracy: 0.8055 - 453ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 1s - loss: 0.4290 - accuracy: 0.8024 - val_loss: 0.4252 - val_accuracy: 0.8004 - 621ms/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 1s - loss: 0.4294 - accuracy: 0.8008 - val_loss: 0.4268 - val_accuracy: 0.8061 - 661ms/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 1s - loss: 0.4295 - accuracy: 0.8015 - val_loss: 0.4264 - val_accuracy: 0.8004 - 669ms/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 1s - loss: 0.4296 - accuracy: 0.8015 - val_loss: 0.4253 - val_accuracy: 0.8052 - 676ms/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 1s - loss: 0.4299 - accuracy: 0.8004 - val_loss: 0.4265 - val_accuracy: 0.8045 - 654ms/epoch - 13ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 1s - loss: 0.4302 - accuracy: 0.8011 - val_loss: 0.4302 - val_accuracy: 0.8023 - 657ms/epoch - 13ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 1s - loss: 0.4294 - accuracy: 0.8008 - val_loss: 0.4276 - val_accuracy: 0.8049 - 621ms/epoch - 13ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 1s - loss: 0.4291 - accuracy: 0.8022 - val_loss: 0.4303 - val_accuracy: 0.8033 - 559ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 1s - loss: 0.4279 - accuracy: 0.8028 - val_loss: 0.4248 - val_accuracy: 0.8029 - 510ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4284 - accuracy: 0.8018 - val_loss: 0.4278 - val_accuracy: 0.8055 - 454ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4286 - accuracy: 0.8001 - val_loss: 0.4259 - val_accuracy: 0.8045 - 453ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4283 - accuracy: 0.8024 - val_loss: 0.4292 - val_accuracy: 0.8039 - 435ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.4255 - val_accuracy: 0.8055 - 423ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4278 - accuracy: 0.8018 - val_loss: 0.4270 - val_accuracy: 0.8045 - 425ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4279 - accuracy: 0.8020 - val_loss: 0.4242 - val_accuracy: 0.8045 - 437ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 1s - loss: 0.4284 - accuracy: 0.8021 - val_loss: 0.4261 - val_accuracy: 0.7991 - 507ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 0s - loss: 0.4283 - accuracy: 0.8036 - val_loss: 0.4273 - val_accuracy: 0.8052 - 442ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 0s - loss: 0.4276 - accuracy: 0.8020 - val_loss: 0.4260 - val_accuracy: 0.8049 - 464ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "49/49 - 1s - loss: 0.4269 - accuracy: 0.8016 - val_loss: 0.4243 - val_accuracy: 0.8055 - 543ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "49/49 - 1s - loss: 0.4263 - accuracy: 0.8015 - val_loss: 0.4248 - val_accuracy: 0.8026 - 667ms/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "49/49 - 1s - loss: 0.4271 - accuracy: 0.8029 - val_loss: 0.4244 - val_accuracy: 0.8049 - 778ms/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "49/49 - 1s - loss: 0.4273 - accuracy: 0.8015 - val_loss: 0.4243 - val_accuracy: 0.7994 - 798ms/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "49/49 - 1s - loss: 0.4277 - accuracy: 0.8025 - val_loss: 0.4252 - val_accuracy: 0.8052 - 683ms/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "49/49 - 1s - loss: 0.4288 - accuracy: 0.8014 - val_loss: 0.4245 - val_accuracy: 0.8049 - 706ms/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "49/49 - 1s - loss: 0.4288 - accuracy: 0.8014 - val_loss: 0.4240 - val_accuracy: 0.8055 - 722ms/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "49/49 - 1s - loss: 0.4268 - accuracy: 0.8025 - val_loss: 0.4241 - val_accuracy: 0.8039 - 584ms/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "49/49 - 0s - loss: 0.4270 - accuracy: 0.8031 - val_loss: 0.4265 - val_accuracy: 0.8045 - 449ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "49/49 - 1s - loss: 0.4280 - accuracy: 0.8023 - val_loss: 0.4233 - val_accuracy: 0.8026 - 502ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "49/49 - 0s - loss: 0.4266 - accuracy: 0.8033 - val_loss: 0.4248 - val_accuracy: 0.8052 - 427ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "49/49 - 0s - loss: 0.4273 - accuracy: 0.8028 - val_loss: 0.4251 - val_accuracy: 0.8061 - 419ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "49/49 - 0s - loss: 0.4274 - accuracy: 0.8012 - val_loss: 0.4234 - val_accuracy: 0.8052 - 466ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "49/49 - 0s - loss: 0.4270 - accuracy: 0.8027 - val_loss: 0.4295 - val_accuracy: 0.8049 - 427ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "49/49 - 0s - loss: 0.4260 - accuracy: 0.8026 - val_loss: 0.4239 - val_accuracy: 0.8045 - 451ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "49/49 - 1s - loss: 0.4263 - accuracy: 0.8018 - val_loss: 0.4238 - val_accuracy: 0.8049 - 513ms/epoch - 10ms/step\n",
      "Epoch 63/100\n",
      "49/49 - 0s - loss: 0.4268 - accuracy: 0.8011 - val_loss: 0.4235 - val_accuracy: 0.8049 - 452ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "49/49 - 1s - loss: 0.4277 - accuracy: 0.8018 - val_loss: 0.4250 - val_accuracy: 0.8039 - 561ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "49/49 - 1s - loss: 0.4263 - accuracy: 0.8033 - val_loss: 0.4262 - val_accuracy: 0.8001 - 570ms/epoch - 12ms/step\n",
      "Epoch 66/100\n",
      "49/49 - 1s - loss: 0.4261 - accuracy: 0.8019 - val_loss: 0.4236 - val_accuracy: 0.8004 - 595ms/epoch - 12ms/step\n",
      "Epoch 66: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "49/49 - 3s - loss: 3.2002 - accuracy: 0.7344 - val_loss: 2.5352 - val_accuracy: 0.7514 - 3s/epoch - 60ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 2.0757 - accuracy: 0.7599 - val_loss: 1.6714 - val_accuracy: 0.7514 - 451ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 1.3924 - accuracy: 0.7631 - val_loss: 1.1461 - val_accuracy: 0.7668 - 447ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 1s - loss: 0.9786 - accuracy: 0.7867 - val_loss: 0.8295 - val_accuracy: 0.7933 - 566ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.7352 - accuracy: 0.7965 - val_loss: 0.6493 - val_accuracy: 0.7962 - 466ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.5968 - accuracy: 0.8000 - val_loss: 0.5464 - val_accuracy: 0.8055 - 448ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.5210 - accuracy: 0.8004 - val_loss: 0.4912 - val_accuracy: 0.8045 - 497ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4780 - accuracy: 0.8016 - val_loss: 0.4617 - val_accuracy: 0.8052 - 497ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 1s - loss: 0.4569 - accuracy: 0.8009 - val_loss: 0.4469 - val_accuracy: 0.8026 - 668ms/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 1s - loss: 0.4453 - accuracy: 0.8021 - val_loss: 0.4416 - val_accuracy: 0.8017 - 876ms/epoch - 18ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 1s - loss: 0.4400 - accuracy: 0.8020 - val_loss: 0.4350 - val_accuracy: 0.8052 - 947ms/epoch - 19ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 1s - loss: 0.4361 - accuracy: 0.8027 - val_loss: 0.4321 - val_accuracy: 0.8026 - 805ms/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 1s - loss: 0.4355 - accuracy: 0.8002 - val_loss: 0.4314 - val_accuracy: 0.8039 - 809ms/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 1s - loss: 0.4343 - accuracy: 0.8010 - val_loss: 0.4310 - val_accuracy: 0.8020 - 756ms/epoch - 15ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 1s - loss: 0.4330 - accuracy: 0.8028 - val_loss: 0.4295 - val_accuracy: 0.8033 - 546ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4323 - accuracy: 0.8016 - val_loss: 0.4299 - val_accuracy: 0.8055 - 499ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4330 - accuracy: 0.8032 - val_loss: 0.4286 - val_accuracy: 0.8001 - 461ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4318 - accuracy: 0.8022 - val_loss: 0.4354 - val_accuracy: 0.7997 - 491ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4315 - accuracy: 0.8016 - val_loss: 0.4277 - val_accuracy: 0.8033 - 456ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4312 - accuracy: 0.8000 - val_loss: 0.4275 - val_accuracy: 0.8033 - 426ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4305 - accuracy: 0.8021 - val_loss: 0.4292 - val_accuracy: 0.8055 - 484ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4306 - accuracy: 0.8024 - val_loss: 0.4274 - val_accuracy: 0.7988 - 456ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 1s - loss: 0.4299 - accuracy: 0.8016 - val_loss: 0.4276 - val_accuracy: 0.8042 - 549ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4300 - accuracy: 0.8015 - val_loss: 0.4268 - val_accuracy: 0.8033 - 481ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 1s - loss: 0.4313 - accuracy: 0.7987 - val_loss: 0.4275 - val_accuracy: 0.8045 - 621ms/epoch - 13ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 1s - loss: 0.4291 - accuracy: 0.8024 - val_loss: 0.4271 - val_accuracy: 0.7988 - 721ms/epoch - 15ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 1s - loss: 0.4290 - accuracy: 0.8025 - val_loss: 0.4270 - val_accuracy: 0.8045 - 728ms/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 1s - loss: 0.4293 - accuracy: 0.8024 - val_loss: 0.4276 - val_accuracy: 0.8045 - 715ms/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 1s - loss: 0.4287 - accuracy: 0.8020 - val_loss: 0.4262 - val_accuracy: 0.8036 - 756ms/epoch - 15ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 1s - loss: 0.4298 - accuracy: 0.8013 - val_loss: 0.4292 - val_accuracy: 0.8013 - 779ms/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 1s - loss: 0.4296 - accuracy: 0.8009 - val_loss: 0.4259 - val_accuracy: 0.8026 - 713ms/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 1s - loss: 0.4290 - accuracy: 0.8018 - val_loss: 0.4256 - val_accuracy: 0.8052 - 582ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4281 - accuracy: 0.8010 - val_loss: 0.4272 - val_accuracy: 0.8049 - 447ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4286 - accuracy: 0.8016 - val_loss: 0.4286 - val_accuracy: 0.8049 - 433ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4286 - accuracy: 0.8020 - val_loss: 0.4259 - val_accuracy: 0.8023 - 415ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4293 - accuracy: 0.8008 - val_loss: 0.4311 - val_accuracy: 0.8049 - 444ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4295 - accuracy: 0.8008 - val_loss: 0.4276 - val_accuracy: 0.8049 - 454ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4300 - accuracy: 0.8015 - val_loss: 0.4308 - val_accuracy: 0.8049 - 480ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4279 - accuracy: 0.8013 - val_loss: 0.4253 - val_accuracy: 0.7985 - 498ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4274 - accuracy: 0.8032 - val_loss: 0.4252 - val_accuracy: 0.8001 - 448ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4277 - accuracy: 0.8011 - val_loss: 0.4259 - val_accuracy: 0.8049 - 461ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4289 - accuracy: 0.8006 - val_loss: 0.4284 - val_accuracy: 0.8049 - 428ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 1s - loss: 0.4270 - accuracy: 0.8025 - val_loss: 0.4276 - val_accuracy: 0.8039 - 538ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 1s - loss: 0.4276 - accuracy: 0.8024 - val_loss: 0.4261 - val_accuracy: 0.8039 - 674ms/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 1s - loss: 0.4282 - accuracy: 0.8021 - val_loss: 0.4247 - val_accuracy: 0.7994 - 675ms/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 1s - loss: 0.4269 - accuracy: 0.8016 - val_loss: 0.4243 - val_accuracy: 0.8004 - 676ms/epoch - 14ms/step\n",
      "Epoch 47/100\n",
      "49/49 - 1s - loss: 0.4267 - accuracy: 0.8015 - val_loss: 0.4268 - val_accuracy: 0.7981 - 679ms/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "49/49 - 1s - loss: 0.4288 - accuracy: 0.8021 - val_loss: 0.4248 - val_accuracy: 0.8039 - 704ms/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "49/49 - 1s - loss: 0.4269 - accuracy: 0.8036 - val_loss: 0.4256 - val_accuracy: 0.8036 - 647ms/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "49/49 - 1s - loss: 0.4278 - accuracy: 0.8015 - val_loss: 0.4321 - val_accuracy: 0.8036 - 662ms/epoch - 14ms/step\n",
      "Epoch 51/100\n",
      "49/49 - 1s - loss: 0.4275 - accuracy: 0.8011 - val_loss: 0.4255 - val_accuracy: 0.8052 - 523ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "49/49 - 0s - loss: 0.4265 - accuracy: 0.8024 - val_loss: 0.4256 - val_accuracy: 0.8004 - 450ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "49/49 - 0s - loss: 0.4273 - accuracy: 0.8019 - val_loss: 0.4241 - val_accuracy: 0.7985 - 462ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "49/49 - 0s - loss: 0.4274 - accuracy: 0.8020 - val_loss: 0.4290 - val_accuracy: 0.8039 - 446ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "49/49 - 0s - loss: 0.4295 - accuracy: 0.7995 - val_loss: 0.4254 - val_accuracy: 0.7988 - 430ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "49/49 - 0s - loss: 0.4269 - accuracy: 0.8016 - val_loss: 0.4252 - val_accuracy: 0.8049 - 419ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "49/49 - 0s - loss: 0.4264 - accuracy: 0.8013 - val_loss: 0.4249 - val_accuracy: 0.7985 - 438ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "49/49 - 0s - loss: 0.4271 - accuracy: 0.8020 - val_loss: 0.4264 - val_accuracy: 0.8045 - 466ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "49/49 - 1s - loss: 0.4265 - accuracy: 0.8009 - val_loss: 0.4243 - val_accuracy: 0.8042 - 554ms/epoch - 11ms/step\n",
      "Epoch 60/100\n",
      "49/49 - 0s - loss: 0.4272 - accuracy: 0.8012 - val_loss: 0.4271 - val_accuracy: 0.8049 - 443ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "49/49 - 0s - loss: 0.4269 - accuracy: 0.8012 - val_loss: 0.4362 - val_accuracy: 0.7972 - 492ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "49/49 - 1s - loss: 0.4271 - accuracy: 0.8025 - val_loss: 0.4241 - val_accuracy: 0.7994 - 634ms/epoch - 13ms/step\n",
      "Epoch 63/100\n",
      "49/49 - 1s - loss: 0.4279 - accuracy: 0.8016 - val_loss: 0.4274 - val_accuracy: 0.8055 - 688ms/epoch - 14ms/step\n",
      "Epoch 63: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 2.9694 - accuracy: 0.7537 - val_loss: 2.3626 - val_accuracy: 0.7543 - 2s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 1.9497 - accuracy: 0.7708 - val_loss: 1.5708 - val_accuracy: 0.7754 - 433ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 1.3192 - accuracy: 0.7895 - val_loss: 1.0855 - val_accuracy: 0.7985 - 444ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.9352 - accuracy: 0.8000 - val_loss: 0.7948 - val_accuracy: 0.8061 - 428ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.7097 - accuracy: 0.8009 - val_loss: 0.6293 - val_accuracy: 0.8061 - 405ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.5824 - accuracy: 0.8004 - val_loss: 0.5348 - val_accuracy: 0.8045 - 449ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.5117 - accuracy: 0.8015 - val_loss: 0.4857 - val_accuracy: 0.8055 - 469ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4740 - accuracy: 0.8007 - val_loss: 0.4575 - val_accuracy: 0.8061 - 455ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4554 - accuracy: 0.8019 - val_loss: 0.4484 - val_accuracy: 0.8061 - 443ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 1s - loss: 0.4436 - accuracy: 0.8012 - val_loss: 0.4391 - val_accuracy: 0.8017 - 607ms/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 1s - loss: 0.4388 - accuracy: 0.8020 - val_loss: 0.4337 - val_accuracy: 0.8049 - 667ms/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 1s - loss: 0.4356 - accuracy: 0.8017 - val_loss: 0.4311 - val_accuracy: 0.8036 - 652ms/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 1s - loss: 0.4348 - accuracy: 0.8020 - val_loss: 0.4306 - val_accuracy: 0.8010 - 677ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 1s - loss: 0.4332 - accuracy: 0.8024 - val_loss: 0.4298 - val_accuracy: 0.8039 - 833ms/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 1s - loss: 0.4323 - accuracy: 0.8022 - val_loss: 0.4285 - val_accuracy: 0.8033 - 702ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 1s - loss: 0.4308 - accuracy: 0.8023 - val_loss: 0.4288 - val_accuracy: 0.8049 - 667ms/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 1s - loss: 0.4309 - accuracy: 0.8021 - val_loss: 0.4295 - val_accuracy: 0.8039 - 529ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4310 - accuracy: 0.8020 - val_loss: 0.4281 - val_accuracy: 0.8049 - 448ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4307 - accuracy: 0.8017 - val_loss: 0.4406 - val_accuracy: 0.7969 - 435ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4339 - accuracy: 0.7992 - val_loss: 0.4271 - val_accuracy: 0.8036 - 455ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4299 - accuracy: 0.8005 - val_loss: 0.4282 - val_accuracy: 0.8023 - 472ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4295 - accuracy: 0.8007 - val_loss: 0.4259 - val_accuracy: 0.8068 - 471ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4296 - accuracy: 0.8033 - val_loss: 0.4320 - val_accuracy: 0.8013 - 455ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4302 - accuracy: 0.8010 - val_loss: 0.4276 - val_accuracy: 0.8045 - 462ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4287 - accuracy: 0.8017 - val_loss: 0.4261 - val_accuracy: 0.8049 - 446ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4298 - accuracy: 0.8023 - val_loss: 0.4259 - val_accuracy: 0.8052 - 441ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4288 - accuracy: 0.8007 - val_loss: 0.4254 - val_accuracy: 0.8007 - 489ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 1s - loss: 0.4302 - accuracy: 0.8012 - val_loss: 0.4260 - val_accuracy: 0.8010 - 665ms/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 1s - loss: 0.4279 - accuracy: 0.8027 - val_loss: 0.4252 - val_accuracy: 0.8033 - 726ms/epoch - 15ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 1s - loss: 0.4311 - accuracy: 0.8010 - val_loss: 0.4326 - val_accuracy: 0.7972 - 740ms/epoch - 15ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 1s - loss: 0.4307 - accuracy: 0.8027 - val_loss: 0.4269 - val_accuracy: 0.8045 - 660ms/epoch - 13ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 1s - loss: 0.4281 - accuracy: 0.8030 - val_loss: 0.4273 - val_accuracy: 0.8052 - 750ms/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 1s - loss: 0.4280 - accuracy: 0.8022 - val_loss: 0.4269 - val_accuracy: 0.8001 - 658ms/epoch - 13ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 1s - loss: 0.4293 - accuracy: 0.8005 - val_loss: 0.4307 - val_accuracy: 0.7988 - 735ms/epoch - 15ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 1s - loss: 0.4300 - accuracy: 0.8007 - val_loss: 0.4331 - val_accuracy: 0.8033 - 543ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4294 - accuracy: 0.8014 - val_loss: 0.4269 - val_accuracy: 0.8055 - 450ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4280 - accuracy: 0.8013 - val_loss: 0.4254 - val_accuracy: 0.8049 - 428ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4316 - accuracy: 0.8022 - val_loss: 0.4324 - val_accuracy: 0.8010 - 432ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4270 - accuracy: 0.8026 - val_loss: 0.4257 - val_accuracy: 0.8049 - 436ms/epoch - 9ms/step\n",
      "Epoch 39: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 3.1586 - accuracy: 0.7385 - val_loss: 2.5112 - val_accuracy: 0.7514 - 2s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 2.0644 - accuracy: 0.7599 - val_loss: 1.6711 - val_accuracy: 0.7514 - 451ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 1.3959 - accuracy: 0.7631 - val_loss: 1.1498 - val_accuracy: 0.7594 - 397ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.9822 - accuracy: 0.7777 - val_loss: 0.8306 - val_accuracy: 0.7940 - 407ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.7364 - accuracy: 0.7971 - val_loss: 0.6488 - val_accuracy: 0.8058 - 387ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.5957 - accuracy: 0.8015 - val_loss: 0.5513 - val_accuracy: 0.7962 - 394ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.5199 - accuracy: 0.7975 - val_loss: 0.4915 - val_accuracy: 0.8049 - 396ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4791 - accuracy: 0.8004 - val_loss: 0.4620 - val_accuracy: 0.8055 - 418ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4565 - accuracy: 0.8012 - val_loss: 0.4468 - val_accuracy: 0.8049 - 428ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4457 - accuracy: 0.8018 - val_loss: 0.4382 - val_accuracy: 0.8052 - 400ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4402 - accuracy: 0.8005 - val_loss: 0.4354 - val_accuracy: 0.8055 - 496ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4373 - accuracy: 0.8034 - val_loss: 0.4340 - val_accuracy: 0.8042 - 423ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4348 - accuracy: 0.8010 - val_loss: 0.4304 - val_accuracy: 0.8068 - 421ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4334 - accuracy: 0.8032 - val_loss: 0.4329 - val_accuracy: 0.8042 - 425ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4325 - accuracy: 0.8012 - val_loss: 0.4294 - val_accuracy: 0.8045 - 403ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4321 - accuracy: 0.8008 - val_loss: 0.4293 - val_accuracy: 0.8061 - 440ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4312 - accuracy: 0.8036 - val_loss: 0.4324 - val_accuracy: 0.8049 - 496ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4312 - accuracy: 0.8017 - val_loss: 0.4314 - val_accuracy: 0.8055 - 430ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4306 - accuracy: 0.8031 - val_loss: 0.4275 - val_accuracy: 0.8042 - 466ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4311 - accuracy: 0.8012 - val_loss: 0.4278 - val_accuracy: 0.8042 - 408ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4312 - accuracy: 0.8028 - val_loss: 0.4300 - val_accuracy: 0.7978 - 397ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4311 - accuracy: 0.8028 - val_loss: 0.4275 - val_accuracy: 0.8058 - 405ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4298 - accuracy: 0.8022 - val_loss: 0.4260 - val_accuracy: 0.8061 - 397ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4298 - accuracy: 0.8020 - val_loss: 0.4284 - val_accuracy: 0.8052 - 416ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4288 - accuracy: 0.8024 - val_loss: 0.4257 - val_accuracy: 0.8049 - 424ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4292 - accuracy: 0.8025 - val_loss: 0.4265 - val_accuracy: 0.8013 - 420ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4294 - accuracy: 0.8016 - val_loss: 0.4268 - val_accuracy: 0.8004 - 426ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4294 - accuracy: 0.8033 - val_loss: 0.4266 - val_accuracy: 0.8049 - 438ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4295 - accuracy: 0.8024 - val_loss: 0.4271 - val_accuracy: 0.7985 - 427ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4309 - accuracy: 0.8013 - val_loss: 0.4255 - val_accuracy: 0.8061 - 405ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4287 - accuracy: 0.8027 - val_loss: 0.4257 - val_accuracy: 0.8049 - 461ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4288 - accuracy: 0.8027 - val_loss: 0.4253 - val_accuracy: 0.8033 - 415ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4278 - accuracy: 0.8018 - val_loss: 0.4331 - val_accuracy: 0.8007 - 408ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4306 - accuracy: 0.8000 - val_loss: 0.4261 - val_accuracy: 0.8004 - 425ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4286 - accuracy: 0.8025 - val_loss: 0.4266 - val_accuracy: 0.8052 - 478ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4276 - accuracy: 0.8041 - val_loss: 0.4255 - val_accuracy: 0.8023 - 421ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4290 - accuracy: 0.8028 - val_loss: 0.4257 - val_accuracy: 0.8036 - 418ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4279 - accuracy: 0.8021 - val_loss: 0.4290 - val_accuracy: 0.8023 - 435ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4282 - accuracy: 0.8023 - val_loss: 0.4252 - val_accuracy: 0.8055 - 417ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4303 - accuracy: 0.8019 - val_loss: 0.4260 - val_accuracy: 0.8049 - 406ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4284 - accuracy: 0.8014 - val_loss: 0.4248 - val_accuracy: 0.8058 - 402ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4276 - accuracy: 0.8023 - val_loss: 0.4283 - val_accuracy: 0.8049 - 406ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4299 - accuracy: 0.8023 - val_loss: 0.4301 - val_accuracy: 0.8049 - 415ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4296 - accuracy: 0.7994 - val_loss: 0.4292 - val_accuracy: 0.8055 - 441ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 0s - loss: 0.4286 - accuracy: 0.8023 - val_loss: 0.4298 - val_accuracy: 0.8058 - 406ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 0s - loss: 0.4274 - accuracy: 0.8022 - val_loss: 0.4263 - val_accuracy: 0.7988 - 422ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "49/49 - 0s - loss: 0.4279 - accuracy: 0.8035 - val_loss: 0.4250 - val_accuracy: 0.8039 - 406ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "49/49 - 0s - loss: 0.4275 - accuracy: 0.8033 - val_loss: 0.4255 - val_accuracy: 0.8007 - 424ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "49/49 - 0s - loss: 0.4276 - accuracy: 0.8011 - val_loss: 0.4278 - val_accuracy: 0.8052 - 404ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "49/49 - 0s - loss: 0.4281 - accuracy: 0.8014 - val_loss: 0.4292 - val_accuracy: 0.8045 - 408ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "49/49 - 0s - loss: 0.4273 - accuracy: 0.8026 - val_loss: 0.4242 - val_accuracy: 0.8026 - 402ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "49/49 - 0s - loss: 0.4267 - accuracy: 0.8043 - val_loss: 0.4260 - val_accuracy: 0.7978 - 401ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "49/49 - 0s - loss: 0.4273 - accuracy: 0.8033 - val_loss: 0.4250 - val_accuracy: 0.8020 - 496ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "49/49 - 0s - loss: 0.4275 - accuracy: 0.8024 - val_loss: 0.4250 - val_accuracy: 0.8042 - 448ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "49/49 - 0s - loss: 0.4268 - accuracy: 0.8020 - val_loss: 0.4247 - val_accuracy: 0.8001 - 431ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "49/49 - 0s - loss: 0.4279 - accuracy: 0.8016 - val_loss: 0.4248 - val_accuracy: 0.8004 - 412ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "49/49 - 0s - loss: 0.4272 - accuracy: 0.8018 - val_loss: 0.4248 - val_accuracy: 0.8049 - 421ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "49/49 - 0s - loss: 0.4263 - accuracy: 0.8016 - val_loss: 0.4261 - val_accuracy: 0.8055 - 443ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "49/49 - 0s - loss: 0.4273 - accuracy: 0.8036 - val_loss: 0.4269 - val_accuracy: 0.8052 - 479ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "49/49 - 0s - loss: 0.4271 - accuracy: 0.8009 - val_loss: 0.4270 - val_accuracy: 0.8049 - 402ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "49/49 - 0s - loss: 0.4284 - accuracy: 0.8034 - val_loss: 0.4242 - val_accuracy: 0.7994 - 401ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "49/49 - 0s - loss: 0.4269 - accuracy: 0.8023 - val_loss: 0.4275 - val_accuracy: 0.8052 - 462ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "49/49 - 0s - loss: 0.4283 - accuracy: 0.8009 - val_loss: 0.4244 - val_accuracy: 0.8004 - 427ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "49/49 - 0s - loss: 0.4262 - accuracy: 0.8036 - val_loss: 0.4264 - val_accuracy: 0.8036 - 411ms/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "49/49 - 0s - loss: 0.4268 - accuracy: 0.8016 - val_loss: 0.4257 - val_accuracy: 0.8049 - 419ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "49/49 - 0s - loss: 0.4289 - accuracy: 0.8012 - val_loss: 0.4242 - val_accuracy: 0.8013 - 408ms/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "49/49 - 0s - loss: 0.4251 - accuracy: 0.8022 - val_loss: 0.4283 - val_accuracy: 0.8036 - 410ms/epoch - 8ms/step\n",
      "Epoch 68/100\n",
      "49/49 - 0s - loss: 0.4268 - accuracy: 0.8016 - val_loss: 0.4288 - val_accuracy: 0.8061 - 439ms/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "49/49 - 0s - loss: 0.4263 - accuracy: 0.8009 - val_loss: 0.4242 - val_accuracy: 0.8023 - 409ms/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "49/49 - 0s - loss: 0.4262 - accuracy: 0.8031 - val_loss: 0.4269 - val_accuracy: 0.8045 - 413ms/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "49/49 - 0s - loss: 0.4270 - accuracy: 0.8011 - val_loss: 0.4239 - val_accuracy: 0.8010 - 393ms/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "49/49 - 0s - loss: 0.4272 - accuracy: 0.8004 - val_loss: 0.4271 - val_accuracy: 0.8045 - 441ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "49/49 - 1s - loss: 0.4265 - accuracy: 0.8038 - val_loss: 0.4243 - val_accuracy: 0.8010 - 501ms/epoch - 10ms/step\n",
      "Epoch 74/100\n",
      "49/49 - 0s - loss: 0.4257 - accuracy: 0.8024 - val_loss: 0.4250 - val_accuracy: 0.8049 - 418ms/epoch - 9ms/step\n",
      "Epoch 75/100\n",
      "49/49 - 0s - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.4252 - val_accuracy: 0.8007 - 419ms/epoch - 9ms/step\n",
      "Epoch 76/100\n",
      "49/49 - 0s - loss: 0.4261 - accuracy: 0.8024 - val_loss: 0.4243 - val_accuracy: 0.8049 - 405ms/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "49/49 - 0s - loss: 0.4256 - accuracy: 0.8031 - val_loss: 0.4247 - val_accuracy: 0.8023 - 414ms/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "49/49 - 0s - loss: 0.4254 - accuracy: 0.8036 - val_loss: 0.4256 - val_accuracy: 0.7994 - 481ms/epoch - 10ms/step\n",
      "Epoch 79/100\n",
      "49/49 - 0s - loss: 0.4259 - accuracy: 0.8015 - val_loss: 0.4246 - val_accuracy: 0.8049 - 403ms/epoch - 8ms/step\n",
      "Epoch 80/100\n",
      "49/49 - 0s - loss: 0.4266 - accuracy: 0.8001 - val_loss: 0.4249 - val_accuracy: 0.8020 - 390ms/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "49/49 - 0s - loss: 0.4267 - accuracy: 0.8015 - val_loss: 0.4240 - val_accuracy: 0.8017 - 408ms/epoch - 8ms/step\n",
      "Epoch 81: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 3.2004 - accuracy: 0.6181 - val_loss: 2.5217 - val_accuracy: 0.7518 - 2s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 2.0700 - accuracy: 0.7600 - val_loss: 1.6737 - val_accuracy: 0.7521 - 402ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 1.4001 - accuracy: 0.7649 - val_loss: 1.1545 - val_accuracy: 0.7758 - 453ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.9888 - accuracy: 0.7893 - val_loss: 0.8373 - val_accuracy: 0.7917 - 419ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.7409 - accuracy: 0.7968 - val_loss: 0.6515 - val_accuracy: 0.8052 - 438ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.6006 - accuracy: 0.7973 - val_loss: 0.5490 - val_accuracy: 0.8052 - 440ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.5225 - accuracy: 0.8014 - val_loss: 0.4929 - val_accuracy: 0.8052 - 415ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4804 - accuracy: 0.8003 - val_loss: 0.4633 - val_accuracy: 0.8052 - 433ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4580 - accuracy: 0.8015 - val_loss: 0.4480 - val_accuracy: 0.8042 - 430ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4461 - accuracy: 0.8024 - val_loss: 0.4436 - val_accuracy: 0.7994 - 428ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4428 - accuracy: 0.8018 - val_loss: 0.4398 - val_accuracy: 0.8052 - 420ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4385 - accuracy: 0.7997 - val_loss: 0.4327 - val_accuracy: 0.8052 - 415ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4350 - accuracy: 0.8023 - val_loss: 0.4348 - val_accuracy: 0.8039 - 461ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4342 - accuracy: 0.8008 - val_loss: 0.4302 - val_accuracy: 0.8045 - 443ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4326 - accuracy: 0.8030 - val_loss: 0.4328 - val_accuracy: 0.8001 - 434ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4335 - accuracy: 0.8008 - val_loss: 0.4300 - val_accuracy: 0.8010 - 431ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4324 - accuracy: 0.8008 - val_loss: 0.4281 - val_accuracy: 0.8023 - 442ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4308 - accuracy: 0.8020 - val_loss: 0.4311 - val_accuracy: 0.8033 - 423ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4315 - accuracy: 0.8029 - val_loss: 0.4285 - val_accuracy: 0.8036 - 425ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4308 - accuracy: 0.8028 - val_loss: 0.4270 - val_accuracy: 0.8045 - 454ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4301 - accuracy: 0.8019 - val_loss: 0.4273 - val_accuracy: 0.8017 - 418ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4337 - accuracy: 0.7998 - val_loss: 0.4275 - val_accuracy: 0.8013 - 471ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4300 - accuracy: 0.8031 - val_loss: 0.4285 - val_accuracy: 0.8039 - 429ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4305 - accuracy: 0.8028 - val_loss: 0.4298 - val_accuracy: 0.8042 - 433ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4293 - accuracy: 0.8023 - val_loss: 0.4258 - val_accuracy: 0.8042 - 447ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4299 - accuracy: 0.8020 - val_loss: 0.4264 - val_accuracy: 0.8052 - 431ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4298 - accuracy: 0.8028 - val_loss: 0.4267 - val_accuracy: 0.7991 - 432ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4290 - accuracy: 0.8028 - val_loss: 0.4259 - val_accuracy: 0.8001 - 413ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4300 - accuracy: 0.8016 - val_loss: 0.4256 - val_accuracy: 0.8039 - 418ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4289 - accuracy: 0.8024 - val_loss: 0.4260 - val_accuracy: 0.8001 - 436ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4284 - accuracy: 0.8028 - val_loss: 0.4266 - val_accuracy: 0.8020 - 418ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4293 - accuracy: 0.8021 - val_loss: 0.4268 - val_accuracy: 0.8004 - 443ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4294 - accuracy: 0.8027 - val_loss: 0.4275 - val_accuracy: 0.8033 - 428ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4290 - accuracy: 0.8024 - val_loss: 0.4248 - val_accuracy: 0.8039 - 429ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4277 - accuracy: 0.8020 - val_loss: 0.4251 - val_accuracy: 0.8036 - 441ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4285 - accuracy: 0.8007 - val_loss: 0.4276 - val_accuracy: 0.8049 - 435ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4280 - accuracy: 0.8011 - val_loss: 0.4281 - val_accuracy: 0.8033 - 430ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4281 - accuracy: 0.8016 - val_loss: 0.4247 - val_accuracy: 0.8029 - 419ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4290 - accuracy: 0.8020 - val_loss: 0.4248 - val_accuracy: 0.8033 - 446ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4270 - accuracy: 0.8028 - val_loss: 0.4246 - val_accuracy: 0.8039 - 494ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4274 - accuracy: 0.8026 - val_loss: 0.4269 - val_accuracy: 0.8026 - 426ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4281 - accuracy: 0.8016 - val_loss: 0.4257 - val_accuracy: 0.8052 - 429ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4275 - accuracy: 0.8011 - val_loss: 0.4264 - val_accuracy: 0.8045 - 447ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4279 - accuracy: 0.8008 - val_loss: 0.4269 - val_accuracy: 0.8045 - 405ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 0s - loss: 0.4269 - accuracy: 0.8032 - val_loss: 0.4271 - val_accuracy: 0.8058 - 454ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 0s - loss: 0.4270 - accuracy: 0.8010 - val_loss: 0.4247 - val_accuracy: 0.8017 - 432ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "49/49 - 0s - loss: 0.4267 - accuracy: 0.8023 - val_loss: 0.4252 - val_accuracy: 0.8029 - 421ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "49/49 - 0s - loss: 0.4263 - accuracy: 0.8040 - val_loss: 0.4258 - val_accuracy: 0.8023 - 422ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "49/49 - 0s - loss: 0.4307 - accuracy: 0.8006 - val_loss: 0.4252 - val_accuracy: 0.7997 - 396ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "49/49 - 0s - loss: 0.4277 - accuracy: 0.8009 - val_loss: 0.4257 - val_accuracy: 0.8017 - 442ms/epoch - 9ms/step\n",
      "Epoch 50: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 3.1600 - accuracy: 0.7097 - val_loss: 2.5126 - val_accuracy: 0.7514 - 2s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 2.0552 - accuracy: 0.7599 - val_loss: 1.6607 - val_accuracy: 0.7514 - 468ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 1.3853 - accuracy: 0.7599 - val_loss: 1.1460 - val_accuracy: 0.7514 - 408ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.9792 - accuracy: 0.7648 - val_loss: 0.8312 - val_accuracy: 0.7697 - 410ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.7341 - accuracy: 0.7908 - val_loss: 0.6494 - val_accuracy: 0.7889 - 416ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.5939 - accuracy: 0.7994 - val_loss: 0.5450 - val_accuracy: 0.8029 - 442ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.5171 - accuracy: 0.8021 - val_loss: 0.4898 - val_accuracy: 0.8058 - 395ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4770 - accuracy: 0.8021 - val_loss: 0.4609 - val_accuracy: 0.8052 - 414ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4554 - accuracy: 0.8008 - val_loss: 0.4461 - val_accuracy: 0.8052 - 437ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4443 - accuracy: 0.8017 - val_loss: 0.4393 - val_accuracy: 0.8055 - 407ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4389 - accuracy: 0.8016 - val_loss: 0.4366 - val_accuracy: 0.8013 - 394ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4368 - accuracy: 0.8014 - val_loss: 0.4320 - val_accuracy: 0.8052 - 420ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4350 - accuracy: 0.8024 - val_loss: 0.4330 - val_accuracy: 0.8052 - 417ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4336 - accuracy: 0.8028 - val_loss: 0.4409 - val_accuracy: 0.8010 - 420ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4342 - accuracy: 0.8024 - val_loss: 0.4296 - val_accuracy: 0.8049 - 440ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4319 - accuracy: 0.8016 - val_loss: 0.4297 - val_accuracy: 0.8039 - 476ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4309 - accuracy: 0.8027 - val_loss: 0.4295 - val_accuracy: 0.8039 - 437ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4315 - accuracy: 0.8021 - val_loss: 0.4273 - val_accuracy: 0.8045 - 437ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4313 - accuracy: 0.8033 - val_loss: 0.4327 - val_accuracy: 0.8039 - 441ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4309 - accuracy: 0.8020 - val_loss: 0.4312 - val_accuracy: 0.8004 - 424ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4310 - accuracy: 0.8011 - val_loss: 0.4275 - val_accuracy: 0.8017 - 431ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4306 - accuracy: 0.8018 - val_loss: 0.4266 - val_accuracy: 0.8036 - 418ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4295 - accuracy: 0.8020 - val_loss: 0.4272 - val_accuracy: 0.8023 - 420ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4296 - accuracy: 0.8028 - val_loss: 0.4284 - val_accuracy: 0.8039 - 475ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4307 - accuracy: 0.8004 - val_loss: 0.4270 - val_accuracy: 0.8049 - 429ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4287 - accuracy: 0.8026 - val_loss: 0.4263 - val_accuracy: 0.8026 - 428ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4284 - accuracy: 0.8011 - val_loss: 0.4261 - val_accuracy: 0.8020 - 442ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4310 - accuracy: 0.8016 - val_loss: 0.4303 - val_accuracy: 0.7985 - 431ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4302 - accuracy: 0.8020 - val_loss: 0.4249 - val_accuracy: 0.8061 - 418ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4289 - accuracy: 0.8020 - val_loss: 0.4256 - val_accuracy: 0.8039 - 420ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4296 - accuracy: 0.8009 - val_loss: 0.4251 - val_accuracy: 0.8023 - 409ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.4269 - val_accuracy: 0.8052 - 403ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4292 - accuracy: 0.8020 - val_loss: 0.4314 - val_accuracy: 0.8042 - 444ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4286 - accuracy: 0.8015 - val_loss: 0.4295 - val_accuracy: 0.8058 - 432ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4279 - accuracy: 0.8021 - val_loss: 0.4250 - val_accuracy: 0.8017 - 442ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4275 - accuracy: 0.8012 - val_loss: 0.4254 - val_accuracy: 0.8052 - 431ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4273 - accuracy: 0.8028 - val_loss: 0.4272 - val_accuracy: 0.8036 - 432ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4284 - accuracy: 0.8030 - val_loss: 0.4247 - val_accuracy: 0.7994 - 440ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4278 - accuracy: 0.8031 - val_loss: 0.4240 - val_accuracy: 0.8020 - 430ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4293 - accuracy: 0.8009 - val_loss: 0.4276 - val_accuracy: 0.7985 - 485ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4304 - accuracy: 0.8010 - val_loss: 0.4251 - val_accuracy: 0.8045 - 408ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4269 - accuracy: 0.8025 - val_loss: 0.4258 - val_accuracy: 0.8049 - 497ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4271 - accuracy: 0.8035 - val_loss: 0.4248 - val_accuracy: 0.7991 - 469ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4272 - accuracy: 0.8016 - val_loss: 0.4240 - val_accuracy: 0.8010 - 434ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 0s - loss: 0.4272 - accuracy: 0.8029 - val_loss: 0.4264 - val_accuracy: 0.8052 - 435ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 0s - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.4247 - val_accuracy: 0.8042 - 442ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "49/49 - 0s - loss: 0.4266 - accuracy: 0.8024 - val_loss: 0.4282 - val_accuracy: 0.8055 - 454ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "49/49 - 0s - loss: 0.4268 - accuracy: 0.8031 - val_loss: 0.4241 - val_accuracy: 0.8013 - 426ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "49/49 - 0s - loss: 0.4273 - accuracy: 0.8024 - val_loss: 0.4310 - val_accuracy: 0.8061 - 416ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "49/49 - 0s - loss: 0.4303 - accuracy: 0.8001 - val_loss: 0.4237 - val_accuracy: 0.8042 - 422ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "49/49 - 0s - loss: 0.4267 - accuracy: 0.8023 - val_loss: 0.4259 - val_accuracy: 0.8052 - 455ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "49/49 - 0s - loss: 0.4263 - accuracy: 0.8023 - val_loss: 0.4244 - val_accuracy: 0.8017 - 447ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "49/49 - 0s - loss: 0.4271 - accuracy: 0.8012 - val_loss: 0.4282 - val_accuracy: 0.8026 - 428ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "49/49 - 0s - loss: 0.4273 - accuracy: 0.8023 - val_loss: 0.4250 - val_accuracy: 0.7997 - 428ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "49/49 - 1s - loss: 0.4267 - accuracy: 0.8024 - val_loss: 0.4245 - val_accuracy: 0.7997 - 511ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "49/49 - 0s - loss: 0.4269 - accuracy: 0.8016 - val_loss: 0.4304 - val_accuracy: 0.8049 - 424ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "49/49 - 0s - loss: 0.4274 - accuracy: 0.8024 - val_loss: 0.4272 - val_accuracy: 0.8052 - 426ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "49/49 - 0s - loss: 0.4281 - accuracy: 0.7996 - val_loss: 0.4262 - val_accuracy: 0.8049 - 426ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "49/49 - 0s - loss: 0.4268 - accuracy: 0.8036 - val_loss: 0.4230 - val_accuracy: 0.8029 - 432ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "49/49 - 0s - loss: 0.4264 - accuracy: 0.8020 - val_loss: 0.4238 - val_accuracy: 0.7991 - 428ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "49/49 - 0s - loss: 0.4262 - accuracy: 0.8024 - val_loss: 0.4242 - val_accuracy: 0.8045 - 452ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "49/49 - 0s - loss: 0.4259 - accuracy: 0.8023 - val_loss: 0.4276 - val_accuracy: 0.8042 - 433ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "49/49 - 1s - loss: 0.4257 - accuracy: 0.8024 - val_loss: 0.4246 - val_accuracy: 0.8045 - 562ms/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "49/49 - 1s - loss: 0.4262 - accuracy: 0.8035 - val_loss: 0.4254 - val_accuracy: 0.8049 - 732ms/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "49/49 - 1s - loss: 0.4264 - accuracy: 0.8011 - val_loss: 0.4253 - val_accuracy: 0.8058 - 1s/epoch - 22ms/step\n",
      "Epoch 66/100\n",
      "49/49 - 1s - loss: 0.4274 - accuracy: 0.8014 - val_loss: 0.4233 - val_accuracy: 0.7997 - 1s/epoch - 23ms/step\n",
      "Epoch 67/100\n",
      "49/49 - 1s - loss: 0.4272 - accuracy: 0.8009 - val_loss: 0.4244 - val_accuracy: 0.8052 - 633ms/epoch - 13ms/step\n",
      "Epoch 68/100\n",
      "49/49 - 1s - loss: 0.4256 - accuracy: 0.8012 - val_loss: 0.4249 - val_accuracy: 0.8049 - 564ms/epoch - 12ms/step\n",
      "Epoch 69/100\n",
      "49/49 - 0s - loss: 0.4260 - accuracy: 0.8027 - val_loss: 0.4260 - val_accuracy: 0.8045 - 489ms/epoch - 10ms/step\n",
      "Epoch 69: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 3.2835 - accuracy: 0.7120 - val_loss: 2.6128 - val_accuracy: 0.7514 - 2s/epoch - 43ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 2.1421 - accuracy: 0.7599 - val_loss: 1.7322 - val_accuracy: 0.7514 - 457ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 1.4407 - accuracy: 0.7599 - val_loss: 1.1861 - val_accuracy: 0.7514 - 404ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 1s - loss: 1.0071 - accuracy: 0.7613 - val_loss: 0.8488 - val_accuracy: 0.7639 - 640ms/epoch - 13ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 1s - loss: 0.7464 - accuracy: 0.7869 - val_loss: 0.6566 - val_accuracy: 0.7927 - 738ms/epoch - 15ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 1s - loss: 0.6002 - accuracy: 0.7980 - val_loss: 0.5510 - val_accuracy: 0.7991 - 940ms/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 1s - loss: 0.5204 - accuracy: 0.8012 - val_loss: 0.4920 - val_accuracy: 0.8049 - 749ms/epoch - 15ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 1s - loss: 0.4787 - accuracy: 0.8016 - val_loss: 0.4642 - val_accuracy: 0.8058 - 713ms/epoch - 15ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 1s - loss: 0.4556 - accuracy: 0.8012 - val_loss: 0.4472 - val_accuracy: 0.8049 - 780ms/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 1s - loss: 0.4447 - accuracy: 0.8007 - val_loss: 0.4410 - val_accuracy: 0.8020 - 678ms/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4390 - accuracy: 0.8019 - val_loss: 0.4341 - val_accuracy: 0.8061 - 475ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4357 - accuracy: 0.8024 - val_loss: 0.4324 - val_accuracy: 0.8036 - 415ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4328 - accuracy: 0.8012 - val_loss: 0.4376 - val_accuracy: 0.7927 - 411ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4331 - accuracy: 0.8002 - val_loss: 0.4310 - val_accuracy: 0.7991 - 438ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4319 - accuracy: 0.8020 - val_loss: 0.4286 - val_accuracy: 0.8036 - 455ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4315 - accuracy: 0.8018 - val_loss: 0.4285 - val_accuracy: 0.7991 - 433ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4308 - accuracy: 0.8036 - val_loss: 0.4286 - val_accuracy: 0.8004 - 410ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4329 - accuracy: 0.8008 - val_loss: 0.4343 - val_accuracy: 0.7991 - 415ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4320 - accuracy: 0.8002 - val_loss: 0.4291 - val_accuracy: 0.7997 - 383ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4298 - accuracy: 0.8034 - val_loss: 0.4282 - val_accuracy: 0.8036 - 419ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4309 - accuracy: 0.8019 - val_loss: 0.4283 - val_accuracy: 0.8007 - 485ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4288 - accuracy: 0.8029 - val_loss: 0.4287 - val_accuracy: 0.8058 - 451ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 1s - loss: 0.4301 - accuracy: 0.8016 - val_loss: 0.4270 - val_accuracy: 0.8033 - 705ms/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 1s - loss: 0.4288 - accuracy: 0.8020 - val_loss: 0.4273 - val_accuracy: 0.8052 - 645ms/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 1s - loss: 0.4291 - accuracy: 0.8031 - val_loss: 0.4292 - val_accuracy: 0.8049 - 633ms/epoch - 13ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 1s - loss: 0.4290 - accuracy: 0.8015 - val_loss: 0.4265 - val_accuracy: 0.8010 - 659ms/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 1s - loss: 0.4298 - accuracy: 0.8021 - val_loss: 0.4268 - val_accuracy: 0.8052 - 748ms/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 1s - loss: 0.4281 - accuracy: 0.8019 - val_loss: 0.4268 - val_accuracy: 0.8049 - 683ms/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 1s - loss: 0.4286 - accuracy: 0.8020 - val_loss: 0.4284 - val_accuracy: 0.8058 - 680ms/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4278 - accuracy: 0.8028 - val_loss: 0.4269 - val_accuracy: 0.8045 - 448ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4340 - accuracy: 0.7967 - val_loss: 0.4265 - val_accuracy: 0.8007 - 384ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4287 - accuracy: 0.8008 - val_loss: 0.4264 - val_accuracy: 0.8055 - 398ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4293 - accuracy: 0.8019 - val_loss: 0.4261 - val_accuracy: 0.8052 - 395ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4277 - accuracy: 0.8021 - val_loss: 0.4256 - val_accuracy: 0.8039 - 407ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4271 - accuracy: 0.8022 - val_loss: 0.4250 - val_accuracy: 0.8045 - 409ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4274 - accuracy: 0.8032 - val_loss: 0.4263 - val_accuracy: 0.7994 - 400ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4282 - accuracy: 0.8005 - val_loss: 0.4252 - val_accuracy: 0.8017 - 416ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4265 - accuracy: 0.8025 - val_loss: 0.4275 - val_accuracy: 0.8049 - 415ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4289 - accuracy: 0.8011 - val_loss: 0.4254 - val_accuracy: 0.8007 - 421ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4269 - accuracy: 0.8016 - val_loss: 0.4258 - val_accuracy: 0.8061 - 400ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4275 - accuracy: 0.8019 - val_loss: 0.4258 - val_accuracy: 0.8036 - 397ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 1s - loss: 0.4266 - accuracy: 0.8025 - val_loss: 0.4270 - val_accuracy: 0.8045 - 524ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 1s - loss: 0.4283 - accuracy: 0.8020 - val_loss: 0.4260 - val_accuracy: 0.8001 - 673ms/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 1s - loss: 0.4270 - accuracy: 0.8029 - val_loss: 0.4251 - val_accuracy: 0.8045 - 816ms/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 1s - loss: 0.4267 - accuracy: 0.8022 - val_loss: 0.4303 - val_accuracy: 0.8045 - 709ms/epoch - 14ms/step\n",
      "Epoch 45: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 3.0847 - accuracy: 0.7361 - val_loss: 2.4354 - val_accuracy: 0.7514 - 2s/epoch - 34ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 1.9970 - accuracy: 0.7600 - val_loss: 1.6086 - val_accuracy: 0.7511 - 455ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 1.3408 - accuracy: 0.7745 - val_loss: 1.1011 - val_accuracy: 0.7937 - 440ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.9444 - accuracy: 0.7982 - val_loss: 0.8023 - val_accuracy: 0.8033 - 484ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.7141 - accuracy: 0.8015 - val_loss: 0.6311 - val_accuracy: 0.8036 - 468ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.5824 - accuracy: 0.8022 - val_loss: 0.5351 - val_accuracy: 0.8065 - 454ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.5106 - accuracy: 0.8012 - val_loss: 0.4844 - val_accuracy: 0.8042 - 428ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4724 - accuracy: 0.8032 - val_loss: 0.4573 - val_accuracy: 0.8055 - 408ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 1s - loss: 0.4527 - accuracy: 0.8017 - val_loss: 0.4459 - val_accuracy: 0.8042 - 570ms/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 1s - loss: 0.4436 - accuracy: 0.8007 - val_loss: 0.4363 - val_accuracy: 0.8052 - 675ms/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 1s - loss: 0.4387 - accuracy: 0.8014 - val_loss: 0.4362 - val_accuracy: 0.8007 - 659ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 1s - loss: 0.4359 - accuracy: 0.8015 - val_loss: 0.4311 - val_accuracy: 0.8058 - 831ms/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 1s - loss: 0.4332 - accuracy: 0.8020 - val_loss: 0.4303 - val_accuracy: 0.8042 - 912ms/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 1s - loss: 0.4331 - accuracy: 0.8020 - val_loss: 0.4318 - val_accuracy: 0.8049 - 677ms/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 1s - loss: 0.4344 - accuracy: 0.8018 - val_loss: 0.4294 - val_accuracy: 0.8029 - 759ms/epoch - 15ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4317 - accuracy: 0.8013 - val_loss: 0.4282 - val_accuracy: 0.8042 - 460ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4312 - accuracy: 0.8029 - val_loss: 0.4352 - val_accuracy: 0.8052 - 455ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4313 - accuracy: 0.8024 - val_loss: 0.4281 - val_accuracy: 0.8023 - 448ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4297 - accuracy: 0.8018 - val_loss: 0.4301 - val_accuracy: 0.8039 - 431ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4298 - accuracy: 0.8028 - val_loss: 0.4275 - val_accuracy: 0.8010 - 446ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4291 - accuracy: 0.8021 - val_loss: 0.4296 - val_accuracy: 0.8045 - 429ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4303 - accuracy: 0.8024 - val_loss: 0.4333 - val_accuracy: 0.8004 - 412ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4293 - accuracy: 0.8032 - val_loss: 0.4270 - val_accuracy: 0.8010 - 447ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4290 - accuracy: 0.8019 - val_loss: 0.4263 - val_accuracy: 0.8036 - 451ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4297 - accuracy: 0.8017 - val_loss: 0.4257 - val_accuracy: 0.8049 - 447ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4312 - accuracy: 0.8004 - val_loss: 0.4282 - val_accuracy: 0.8052 - 463ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 1s - loss: 0.4292 - accuracy: 0.8010 - val_loss: 0.4266 - val_accuracy: 0.8039 - 596ms/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 1s - loss: 0.4272 - accuracy: 0.8026 - val_loss: 0.4273 - val_accuracy: 0.8058 - 696ms/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 1s - loss: 0.4278 - accuracy: 0.8016 - val_loss: 0.4302 - val_accuracy: 0.7997 - 685ms/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 1s - loss: 0.4296 - accuracy: 0.8025 - val_loss: 0.4279 - val_accuracy: 0.8039 - 757ms/epoch - 15ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 1s - loss: 0.4283 - accuracy: 0.8031 - val_loss: 0.4280 - val_accuracy: 0.8061 - 767ms/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 1s - loss: 0.4286 - accuracy: 0.8012 - val_loss: 0.4282 - val_accuracy: 0.7991 - 744ms/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 1s - loss: 0.4286 - accuracy: 0.8020 - val_loss: 0.4297 - val_accuracy: 0.8052 - 706ms/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4272 - accuracy: 0.8026 - val_loss: 0.4250 - val_accuracy: 0.8010 - 498ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4284 - accuracy: 0.8018 - val_loss: 0.4262 - val_accuracy: 0.8052 - 451ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4270 - accuracy: 0.8028 - val_loss: 0.4282 - val_accuracy: 0.8049 - 434ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4280 - accuracy: 0.8020 - val_loss: 0.4255 - val_accuracy: 0.8020 - 453ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 1s - loss: 0.4279 - accuracy: 0.8020 - val_loss: 0.4263 - val_accuracy: 0.8058 - 514ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4279 - accuracy: 0.8018 - val_loss: 0.4270 - val_accuracy: 0.8049 - 445ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4276 - accuracy: 0.8028 - val_loss: 0.4255 - val_accuracy: 0.8052 - 461ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4267 - accuracy: 0.8035 - val_loss: 0.4301 - val_accuracy: 0.8052 - 444ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4280 - accuracy: 0.8009 - val_loss: 0.4254 - val_accuracy: 0.8020 - 434ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4276 - accuracy: 0.8016 - val_loss: 0.4262 - val_accuracy: 0.8052 - 422ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4270 - accuracy: 0.8031 - val_loss: 0.4256 - val_accuracy: 0.8001 - 447ms/epoch - 9ms/step\n",
      "Epoch 44: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 3.1575 - accuracy: 0.7580 - val_loss: 2.5143 - val_accuracy: 0.7514 - 2s/epoch - 51ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 2.0614 - accuracy: 0.7599 - val_loss: 1.6675 - val_accuracy: 0.7514 - 439ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 1.3880 - accuracy: 0.7599 - val_loss: 1.1449 - val_accuracy: 0.7514 - 481ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.9753 - accuracy: 0.7629 - val_loss: 0.8271 - val_accuracy: 0.7770 - 430ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.7307 - accuracy: 0.7895 - val_loss: 0.6453 - val_accuracy: 0.8026 - 439ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.5929 - accuracy: 0.8008 - val_loss: 0.5437 - val_accuracy: 0.8049 - 457ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.5173 - accuracy: 0.8019 - val_loss: 0.4902 - val_accuracy: 0.8042 - 437ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4770 - accuracy: 0.8008 - val_loss: 0.4622 - val_accuracy: 0.8039 - 449ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4555 - accuracy: 0.8009 - val_loss: 0.4476 - val_accuracy: 0.8020 - 425ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4445 - accuracy: 0.8024 - val_loss: 0.4392 - val_accuracy: 0.8052 - 416ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 1s - loss: 0.4384 - accuracy: 0.8031 - val_loss: 0.4348 - val_accuracy: 0.8049 - 732ms/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 1s - loss: 0.4358 - accuracy: 0.8031 - val_loss: 0.4325 - val_accuracy: 0.8039 - 781ms/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 1s - loss: 0.4336 - accuracy: 0.8017 - val_loss: 0.4304 - val_accuracy: 0.8033 - 941ms/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 1s - loss: 0.4329 - accuracy: 0.8023 - val_loss: 0.4331 - val_accuracy: 0.8013 - 834ms/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 1s - loss: 0.4319 - accuracy: 0.8021 - val_loss: 0.4317 - val_accuracy: 0.8036 - 701ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 1s - loss: 0.4313 - accuracy: 0.8024 - val_loss: 0.4291 - val_accuracy: 0.8036 - 799ms/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 1s - loss: 0.4312 - accuracy: 0.8026 - val_loss: 0.4287 - val_accuracy: 0.8023 - 642ms/epoch - 13ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4308 - accuracy: 0.8024 - val_loss: 0.4282 - val_accuracy: 0.8036 - 442ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4304 - accuracy: 0.8012 - val_loss: 0.4275 - val_accuracy: 0.8052 - 432ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4315 - accuracy: 0.7992 - val_loss: 0.4278 - val_accuracy: 0.8045 - 452ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4302 - accuracy: 0.8031 - val_loss: 0.4282 - val_accuracy: 0.8001 - 442ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4317 - accuracy: 0.7992 - val_loss: 0.4269 - val_accuracy: 0.8007 - 434ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4296 - accuracy: 0.8013 - val_loss: 0.4305 - val_accuracy: 0.8029 - 418ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4315 - accuracy: 0.8000 - val_loss: 0.4317 - val_accuracy: 0.8023 - 468ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4304 - accuracy: 0.8020 - val_loss: 0.4281 - val_accuracy: 0.8045 - 465ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4280 - accuracy: 0.8024 - val_loss: 0.4266 - val_accuracy: 0.8001 - 493ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4285 - accuracy: 0.8020 - val_loss: 0.4297 - val_accuracy: 0.7994 - 453ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 1s - loss: 0.4329 - accuracy: 0.8017 - val_loss: 0.4293 - val_accuracy: 0.8004 - 534ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 1s - loss: 0.4284 - accuracy: 0.8021 - val_loss: 0.4275 - val_accuracy: 0.8049 - 660ms/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 1s - loss: 0.4280 - accuracy: 0.8031 - val_loss: 0.4265 - val_accuracy: 0.7991 - 597ms/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 1s - loss: 0.4280 - accuracy: 0.8030 - val_loss: 0.4274 - val_accuracy: 0.8039 - 634ms/epoch - 13ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 1s - loss: 0.4276 - accuracy: 0.8016 - val_loss: 0.4262 - val_accuracy: 0.8007 - 813ms/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 1s - loss: 0.4267 - accuracy: 0.8026 - val_loss: 0.4270 - val_accuracy: 0.8001 - 714ms/epoch - 15ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 1s - loss: 0.4291 - accuracy: 0.8024 - val_loss: 0.4270 - val_accuracy: 0.8049 - 701ms/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 1s - loss: 0.4267 - accuracy: 0.8022 - val_loss: 0.4260 - val_accuracy: 0.7994 - 673ms/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4301 - accuracy: 0.7992 - val_loss: 0.4272 - val_accuracy: 0.7988 - 399ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4280 - accuracy: 0.8025 - val_loss: 0.4284 - val_accuracy: 0.8001 - 434ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4271 - accuracy: 0.8015 - val_loss: 0.4265 - val_accuracy: 0.8049 - 442ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4266 - accuracy: 0.8029 - val_loss: 0.4253 - val_accuracy: 0.7981 - 449ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4263 - accuracy: 0.8036 - val_loss: 0.4257 - val_accuracy: 0.7994 - 452ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4267 - accuracy: 0.8023 - val_loss: 0.4286 - val_accuracy: 0.8052 - 452ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4276 - accuracy: 0.8024 - val_loss: 0.4253 - val_accuracy: 0.8001 - 452ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4267 - accuracy: 0.8027 - val_loss: 0.4258 - val_accuracy: 0.7988 - 427ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4278 - accuracy: 0.8009 - val_loss: 0.4255 - val_accuracy: 0.8045 - 431ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 0s - loss: 0.4268 - accuracy: 0.8032 - val_loss: 0.4344 - val_accuracy: 0.7937 - 417ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 0s - loss: 0.4296 - accuracy: 0.7998 - val_loss: 0.4252 - val_accuracy: 0.7997 - 466ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "49/49 - 1s - loss: 0.4267 - accuracy: 0.8013 - val_loss: 0.4260 - val_accuracy: 0.8045 - 694ms/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "49/49 - 1s - loss: 0.4260 - accuracy: 0.8020 - val_loss: 0.4247 - val_accuracy: 0.8023 - 841ms/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "49/49 - 1s - loss: 0.4280 - accuracy: 0.8004 - val_loss: 0.4264 - val_accuracy: 0.7991 - 750ms/epoch - 15ms/step\n",
      "Epoch 50/100\n",
      "49/49 - 1s - loss: 0.4281 - accuracy: 0.8001 - val_loss: 0.4243 - val_accuracy: 0.7997 - 811ms/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "49/49 - 1s - loss: 0.4273 - accuracy: 0.8009 - val_loss: 0.4253 - val_accuracy: 0.8010 - 851ms/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "49/49 - 1s - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.4269 - val_accuracy: 0.8045 - 803ms/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "49/49 - 1s - loss: 0.4278 - accuracy: 0.8016 - val_loss: 0.4253 - val_accuracy: 0.8049 - 610ms/epoch - 12ms/step\n",
      "Epoch 54/100\n",
      "49/49 - 0s - loss: 0.4273 - accuracy: 0.8011 - val_loss: 0.4320 - val_accuracy: 0.8013 - 434ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "49/49 - 0s - loss: 0.4278 - accuracy: 0.8013 - val_loss: 0.4303 - val_accuracy: 0.8042 - 439ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "49/49 - 0s - loss: 0.4295 - accuracy: 0.8004 - val_loss: 0.4263 - val_accuracy: 0.8039 - 435ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "49/49 - 0s - loss: 0.4264 - accuracy: 0.8016 - val_loss: 0.4265 - val_accuracy: 0.8045 - 423ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "49/49 - 0s - loss: 0.4260 - accuracy: 0.8026 - val_loss: 0.4255 - val_accuracy: 0.8017 - 417ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "49/49 - 0s - loss: 0.4254 - accuracy: 0.8020 - val_loss: 0.4251 - val_accuracy: 0.8033 - 462ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "49/49 - 0s - loss: 0.4269 - accuracy: 0.8023 - val_loss: 0.4258 - val_accuracy: 0.8026 - 455ms/epoch - 9ms/step\n",
      "Epoch 60: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.43761980942708745\n",
      "epi entropy:  0.41189464333236436\n",
      "\n",
      "dataset size:  0.5\n",
      "Epoch 1/100\n",
      "62/62 - 4s - loss: 2.9913 - accuracy: 0.7313 - val_loss: 2.2192 - val_accuracy: 0.7656 - 4s/epoch - 58ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 1.7487 - accuracy: 0.7597 - val_loss: 1.3253 - val_accuracy: 0.7753 - 518ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 1.0809 - accuracy: 0.7871 - val_loss: 0.8544 - val_accuracy: 0.8048 - 541ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 1s - loss: 0.7381 - accuracy: 0.8011 - val_loss: 0.6193 - val_accuracy: 0.8101 - 529ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 1s - loss: 0.5711 - accuracy: 0.8032 - val_loss: 0.5085 - val_accuracy: 0.8101 - 518ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.4942 - accuracy: 0.8018 - val_loss: 0.4584 - val_accuracy: 0.8091 - 695ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 1s - loss: 0.4582 - accuracy: 0.8026 - val_loss: 0.4407 - val_accuracy: 0.8089 - 599ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 1s - loss: 0.4430 - accuracy: 0.8029 - val_loss: 0.4255 - val_accuracy: 0.8089 - 606ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4360 - accuracy: 0.8032 - val_loss: 0.4254 - val_accuracy: 0.8101 - 636ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4347 - accuracy: 0.8032 - val_loss: 0.4192 - val_accuracy: 0.8101 - 800ms/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4326 - accuracy: 0.8025 - val_loss: 0.4205 - val_accuracy: 0.8109 - 882ms/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4321 - accuracy: 0.8027 - val_loss: 0.4268 - val_accuracy: 0.8053 - 995ms/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4318 - accuracy: 0.8021 - val_loss: 0.4148 - val_accuracy: 0.8104 - 928ms/epoch - 15ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4298 - accuracy: 0.8023 - val_loss: 0.4150 - val_accuracy: 0.8094 - 929ms/epoch - 15ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4283 - accuracy: 0.8021 - val_loss: 0.4145 - val_accuracy: 0.8109 - 818ms/epoch - 13ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4293 - accuracy: 0.8024 - val_loss: 0.4141 - val_accuracy: 0.8109 - 529ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4283 - accuracy: 0.8021 - val_loss: 0.4153 - val_accuracy: 0.8089 - 549ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4287 - accuracy: 0.8022 - val_loss: 0.4179 - val_accuracy: 0.8112 - 582ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4301 - accuracy: 0.8001 - val_loss: 0.4151 - val_accuracy: 0.8109 - 557ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4279 - accuracy: 0.8027 - val_loss: 0.4135 - val_accuracy: 0.8112 - 546ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4281 - accuracy: 0.8019 - val_loss: 0.4138 - val_accuracy: 0.8109 - 530ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4284 - accuracy: 0.8033 - val_loss: 0.4147 - val_accuracy: 0.8099 - 599ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4275 - accuracy: 0.8017 - val_loss: 0.4136 - val_accuracy: 0.8094 - 569ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4279 - accuracy: 0.8022 - val_loss: 0.4137 - val_accuracy: 0.8094 - 615ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.4125 - val_accuracy: 0.8109 - 891ms/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4272 - accuracy: 0.8036 - val_loss: 0.4126 - val_accuracy: 0.8101 - 804ms/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4261 - accuracy: 0.8034 - val_loss: 0.4198 - val_accuracy: 0.8027 - 897ms/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4277 - accuracy: 0.8007 - val_loss: 0.4127 - val_accuracy: 0.8089 - 930ms/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4255 - accuracy: 0.8029 - val_loss: 0.4122 - val_accuracy: 0.8094 - 946ms/epoch - 15ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4271 - accuracy: 0.8027 - val_loss: 0.4148 - val_accuracy: 0.8096 - 686ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8027 - val_loss: 0.4139 - val_accuracy: 0.8099 - 515ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4257 - accuracy: 0.8023 - val_loss: 0.4122 - val_accuracy: 0.8089 - 595ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8012 - val_loss: 0.4123 - val_accuracy: 0.8104 - 540ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 1s - loss: 0.4285 - accuracy: 0.8024 - val_loss: 0.4156 - val_accuracy: 0.8089 - 532ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4275 - accuracy: 0.8014 - val_loss: 0.4120 - val_accuracy: 0.8089 - 561ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 1s - loss: 0.4271 - accuracy: 0.8032 - val_loss: 0.4148 - val_accuracy: 0.8089 - 520ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 1s - loss: 0.4258 - accuracy: 0.8010 - val_loss: 0.4165 - val_accuracy: 0.8089 - 570ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8018 - val_loss: 0.4117 - val_accuracy: 0.8104 - 529ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 1s - loss: 0.4253 - accuracy: 0.8027 - val_loss: 0.4141 - val_accuracy: 0.8089 - 645ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 1s - loss: 0.4254 - accuracy: 0.8025 - val_loss: 0.4117 - val_accuracy: 0.8094 - 896ms/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 1s - loss: 0.4257 - accuracy: 0.8048 - val_loss: 0.4128 - val_accuracy: 0.8083 - 948ms/epoch - 15ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8014 - val_loss: 0.4117 - val_accuracy: 0.8091 - 1s/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "62/62 - 1s - loss: 0.4266 - accuracy: 0.8028 - val_loss: 0.4125 - val_accuracy: 0.8109 - 870ms/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "62/62 - 1s - loss: 0.4245 - accuracy: 0.8020 - val_loss: 0.4123 - val_accuracy: 0.8081 - 883ms/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "62/62 - 1s - loss: 0.4250 - accuracy: 0.8032 - val_loss: 0.4145 - val_accuracy: 0.8081 - 662ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "62/62 - 1s - loss: 0.4262 - accuracy: 0.8023 - val_loss: 0.4138 - val_accuracy: 0.8109 - 550ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "62/62 - 1s - loss: 0.4281 - accuracy: 0.8005 - val_loss: 0.4126 - val_accuracy: 0.8096 - 557ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "62/62 - 1s - loss: 0.4249 - accuracy: 0.8026 - val_loss: 0.4118 - val_accuracy: 0.8089 - 541ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "62/62 - 1s - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.4135 - val_accuracy: 0.8104 - 533ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "62/62 - 1s - loss: 0.4247 - accuracy: 0.8023 - val_loss: 0.4119 - val_accuracy: 0.8106 - 595ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "62/62 - 1s - loss: 0.4248 - accuracy: 0.8019 - val_loss: 0.4126 - val_accuracy: 0.8071 - 532ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "62/62 - 1s - loss: 0.4254 - accuracy: 0.8013 - val_loss: 0.4138 - val_accuracy: 0.8114 - 545ms/epoch - 9ms/step\n",
      "Epoch 52: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "62/62 - 3s - loss: 2.9105 - accuracy: 0.7241 - val_loss: 2.1512 - val_accuracy: 0.7656 - 3s/epoch - 55ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 1.6972 - accuracy: 0.7611 - val_loss: 1.2900 - val_accuracy: 0.7735 - 735ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 1.0593 - accuracy: 0.7851 - val_loss: 0.8412 - val_accuracy: 0.8078 - 544ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 1s - loss: 0.7311 - accuracy: 0.8013 - val_loss: 0.6175 - val_accuracy: 0.8091 - 582ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 1s - loss: 0.5694 - accuracy: 0.8018 - val_loss: 0.5091 - val_accuracy: 0.8091 - 548ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.4926 - accuracy: 0.8020 - val_loss: 0.4581 - val_accuracy: 0.8114 - 608ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 1s - loss: 0.4588 - accuracy: 0.8020 - val_loss: 0.4346 - val_accuracy: 0.8117 - 521ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 1s - loss: 0.4431 - accuracy: 0.8011 - val_loss: 0.4246 - val_accuracy: 0.8106 - 545ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4375 - accuracy: 0.8006 - val_loss: 0.4194 - val_accuracy: 0.8106 - 613ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4343 - accuracy: 0.8021 - val_loss: 0.4188 - val_accuracy: 0.8106 - 608ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4327 - accuracy: 0.8015 - val_loss: 0.4184 - val_accuracy: 0.8094 - 782ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4310 - accuracy: 0.8025 - val_loss: 0.4163 - val_accuracy: 0.8114 - 882ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4310 - accuracy: 0.8016 - val_loss: 0.4166 - val_accuracy: 0.8086 - 888ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4309 - accuracy: 0.8021 - val_loss: 0.4145 - val_accuracy: 0.8117 - 895ms/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4293 - accuracy: 0.8029 - val_loss: 0.4143 - val_accuracy: 0.8114 - 942ms/epoch - 15ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4294 - accuracy: 0.8022 - val_loss: 0.4142 - val_accuracy: 0.8117 - 879ms/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4281 - accuracy: 0.8028 - val_loss: 0.4156 - val_accuracy: 0.8109 - 543ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4314 - accuracy: 0.8004 - val_loss: 0.4171 - val_accuracy: 0.8106 - 533ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4288 - accuracy: 0.8020 - val_loss: 0.4252 - val_accuracy: 0.8017 - 522ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4286 - accuracy: 0.8012 - val_loss: 0.4169 - val_accuracy: 0.8101 - 553ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4270 - accuracy: 0.8029 - val_loss: 0.4132 - val_accuracy: 0.8091 - 532ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4276 - accuracy: 0.8027 - val_loss: 0.4133 - val_accuracy: 0.8106 - 533ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4271 - accuracy: 0.8021 - val_loss: 0.4170 - val_accuracy: 0.8119 - 549ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8016 - val_loss: 0.4131 - val_accuracy: 0.8109 - 518ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4275 - accuracy: 0.8032 - val_loss: 0.4123 - val_accuracy: 0.8114 - 536ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8023 - val_loss: 0.4138 - val_accuracy: 0.8114 - 741ms/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4273 - accuracy: 0.8014 - val_loss: 0.4146 - val_accuracy: 0.8124 - 934ms/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8025 - val_loss: 0.4128 - val_accuracy: 0.8119 - 1s/epoch - 18ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4270 - accuracy: 0.8018 - val_loss: 0.4117 - val_accuracy: 0.8099 - 1s/epoch - 19ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4270 - accuracy: 0.8018 - val_loss: 0.4168 - val_accuracy: 0.8119 - 1s/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 1s - loss: 0.4266 - accuracy: 0.8026 - val_loss: 0.4117 - val_accuracy: 0.8104 - 712ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4277 - accuracy: 0.8009 - val_loss: 0.4119 - val_accuracy: 0.8112 - 551ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4253 - accuracy: 0.8020 - val_loss: 0.4117 - val_accuracy: 0.8114 - 534ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 1s - loss: 0.4288 - accuracy: 0.8007 - val_loss: 0.4129 - val_accuracy: 0.8086 - 544ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4262 - accuracy: 0.8030 - val_loss: 0.4124 - val_accuracy: 0.8106 - 516ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 1s - loss: 0.4253 - accuracy: 0.8019 - val_loss: 0.4180 - val_accuracy: 0.8112 - 581ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 1s - loss: 0.4261 - accuracy: 0.8039 - val_loss: 0.4120 - val_accuracy: 0.8135 - 538ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 1s - loss: 0.4251 - accuracy: 0.8025 - val_loss: 0.4140 - val_accuracy: 0.8106 - 568ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 1s - loss: 0.4263 - accuracy: 0.8016 - val_loss: 0.4110 - val_accuracy: 0.8106 - 539ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 1s - loss: 0.4256 - accuracy: 0.8022 - val_loss: 0.4123 - val_accuracy: 0.8114 - 708ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 1s - loss: 0.4257 - accuracy: 0.8029 - val_loss: 0.4149 - val_accuracy: 0.8106 - 787ms/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 1s - loss: 0.4273 - accuracy: 0.8025 - val_loss: 0.4114 - val_accuracy: 0.8122 - 774ms/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "62/62 - 1s - loss: 0.4250 - accuracy: 0.8023 - val_loss: 0.4112 - val_accuracy: 0.8114 - 740ms/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "62/62 - 1s - loss: 0.4256 - accuracy: 0.8030 - val_loss: 0.4147 - val_accuracy: 0.8106 - 831ms/epoch - 13ms/step\n",
      "Epoch 45/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8012 - val_loss: 0.4145 - val_accuracy: 0.8112 - 916ms/epoch - 15ms/step\n",
      "Epoch 46/100\n",
      "62/62 - 1s - loss: 0.4244 - accuracy: 0.8037 - val_loss: 0.4124 - val_accuracy: 0.8104 - 702ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "62/62 - 1s - loss: 0.4252 - accuracy: 0.8025 - val_loss: 0.4109 - val_accuracy: 0.8114 - 527ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "62/62 - 1s - loss: 0.4254 - accuracy: 0.8028 - val_loss: 0.4129 - val_accuracy: 0.8112 - 511ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "62/62 - 1s - loss: 0.4240 - accuracy: 0.8029 - val_loss: 0.4125 - val_accuracy: 0.8101 - 516ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "62/62 - 1s - loss: 0.4245 - accuracy: 0.8025 - val_loss: 0.4112 - val_accuracy: 0.8109 - 613ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "62/62 - 1s - loss: 0.4243 - accuracy: 0.8030 - val_loss: 0.4141 - val_accuracy: 0.8109 - 584ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "62/62 - 1s - loss: 0.4276 - accuracy: 0.8008 - val_loss: 0.4105 - val_accuracy: 0.8101 - 592ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "62/62 - 1s - loss: 0.4251 - accuracy: 0.8013 - val_loss: 0.4114 - val_accuracy: 0.8094 - 823ms/epoch - 13ms/step\n",
      "Epoch 54/100\n",
      "62/62 - 1s - loss: 0.4238 - accuracy: 0.8034 - val_loss: 0.4113 - val_accuracy: 0.8109 - 692ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "62/62 - 1s - loss: 0.4245 - accuracy: 0.8023 - val_loss: 0.4163 - val_accuracy: 0.8048 - 989ms/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "62/62 - 1s - loss: 0.4251 - accuracy: 0.8020 - val_loss: 0.4116 - val_accuracy: 0.8114 - 583ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "62/62 - 1s - loss: 0.4253 - accuracy: 0.8016 - val_loss: 0.4137 - val_accuracy: 0.8109 - 598ms/epoch - 10ms/step\n",
      "Epoch 58/100\n",
      "62/62 - 1s - loss: 0.4247 - accuracy: 0.8030 - val_loss: 0.4115 - val_accuracy: 0.8109 - 641ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "62/62 - 1s - loss: 0.4248 - accuracy: 0.8033 - val_loss: 0.4114 - val_accuracy: 0.8109 - 572ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "62/62 - 1s - loss: 0.4238 - accuracy: 0.8026 - val_loss: 0.4117 - val_accuracy: 0.8109 - 602ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "62/62 - 1s - loss: 0.4235 - accuracy: 0.8027 - val_loss: 0.4118 - val_accuracy: 0.8081 - 621ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "62/62 - 1s - loss: 0.4257 - accuracy: 0.8010 - val_loss: 0.4162 - val_accuracy: 0.8099 - 641ms/epoch - 10ms/step\n",
      "Epoch 62: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 2.9410 - accuracy: 0.7054 - val_loss: 2.1782 - val_accuracy: 0.7656 - 2s/epoch - 39ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 1.7138 - accuracy: 0.7590 - val_loss: 1.3008 - val_accuracy: 0.7656 - 603ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 1.0622 - accuracy: 0.7740 - val_loss: 0.8389 - val_accuracy: 0.7989 - 568ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 1s - loss: 0.7294 - accuracy: 0.7948 - val_loss: 0.6152 - val_accuracy: 0.8104 - 655ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 1s - loss: 0.5677 - accuracy: 0.8016 - val_loss: 0.5053 - val_accuracy: 0.8101 - 721ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.4924 - accuracy: 0.8023 - val_loss: 0.4580 - val_accuracy: 0.8112 - 742ms/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 1s - loss: 0.4576 - accuracy: 0.8025 - val_loss: 0.4341 - val_accuracy: 0.8109 - 613ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 1s - loss: 0.4429 - accuracy: 0.8023 - val_loss: 0.4251 - val_accuracy: 0.8112 - 616ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4364 - accuracy: 0.8027 - val_loss: 0.4242 - val_accuracy: 0.8086 - 607ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4348 - accuracy: 0.8013 - val_loss: 0.4194 - val_accuracy: 0.8101 - 617ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4336 - accuracy: 0.8043 - val_loss: 0.4175 - val_accuracy: 0.8112 - 647ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4325 - accuracy: 0.8015 - val_loss: 0.4170 - val_accuracy: 0.8104 - 768ms/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4332 - accuracy: 0.8015 - val_loss: 0.4162 - val_accuracy: 0.8106 - 666ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4309 - accuracy: 0.8007 - val_loss: 0.4176 - val_accuracy: 0.8094 - 705ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4311 - accuracy: 0.8009 - val_loss: 0.4151 - val_accuracy: 0.8101 - 598ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4293 - accuracy: 0.8014 - val_loss: 0.4147 - val_accuracy: 0.8106 - 704ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4314 - accuracy: 0.8017 - val_loss: 0.4161 - val_accuracy: 0.8114 - 681ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4289 - accuracy: 0.8015 - val_loss: 0.4182 - val_accuracy: 0.8119 - 600ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4312 - accuracy: 0.7991 - val_loss: 0.4147 - val_accuracy: 0.8114 - 642ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4285 - accuracy: 0.8034 - val_loss: 0.4135 - val_accuracy: 0.8112 - 583ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4284 - accuracy: 0.8025 - val_loss: 0.4215 - val_accuracy: 0.8055 - 617ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4289 - accuracy: 0.8016 - val_loss: 0.4140 - val_accuracy: 0.8099 - 692ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4284 - accuracy: 0.8018 - val_loss: 0.4260 - val_accuracy: 0.8019 - 634ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4281 - accuracy: 0.8024 - val_loss: 0.4144 - val_accuracy: 0.8104 - 646ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4269 - accuracy: 0.8030 - val_loss: 0.4152 - val_accuracy: 0.8096 - 655ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4274 - accuracy: 0.8030 - val_loss: 0.4144 - val_accuracy: 0.8117 - 643ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8022 - val_loss: 0.4182 - val_accuracy: 0.8058 - 587ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4275 - accuracy: 0.8022 - val_loss: 0.4144 - val_accuracy: 0.8106 - 582ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4288 - accuracy: 0.8025 - val_loss: 0.4148 - val_accuracy: 0.8104 - 650ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4265 - accuracy: 0.8028 - val_loss: 0.4158 - val_accuracy: 0.8068 - 636ms/epoch - 10ms/step\n",
      "Epoch 30: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 2.9193 - accuracy: 0.7598 - val_loss: 2.1655 - val_accuracy: 0.7656 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 1.7106 - accuracy: 0.7648 - val_loss: 1.2998 - val_accuracy: 0.7886 - 635ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 1.0650 - accuracy: 0.7901 - val_loss: 0.8449 - val_accuracy: 0.8058 - 576ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 1s - loss: 0.7324 - accuracy: 0.7979 - val_loss: 0.6159 - val_accuracy: 0.8094 - 585ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 1s - loss: 0.5699 - accuracy: 0.8023 - val_loss: 0.5083 - val_accuracy: 0.8096 - 533ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.4937 - accuracy: 0.8022 - val_loss: 0.4581 - val_accuracy: 0.8109 - 517ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 1s - loss: 0.4595 - accuracy: 0.8023 - val_loss: 0.4358 - val_accuracy: 0.8096 - 614ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 1s - loss: 0.4446 - accuracy: 0.8022 - val_loss: 0.4251 - val_accuracy: 0.8106 - 648ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4376 - accuracy: 0.8021 - val_loss: 0.4241 - val_accuracy: 0.8060 - 594ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4350 - accuracy: 0.8041 - val_loss: 0.4189 - val_accuracy: 0.8112 - 645ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4322 - accuracy: 0.8024 - val_loss: 0.4228 - val_accuracy: 0.8066 - 615ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4327 - accuracy: 0.8009 - val_loss: 0.4179 - val_accuracy: 0.8091 - 636ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4322 - accuracy: 0.8020 - val_loss: 0.4196 - val_accuracy: 0.8083 - 674ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4306 - accuracy: 0.8016 - val_loss: 0.4168 - val_accuracy: 0.8101 - 781ms/epoch - 13ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4292 - accuracy: 0.8022 - val_loss: 0.4163 - val_accuracy: 0.8101 - 598ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4293 - accuracy: 0.8021 - val_loss: 0.4160 - val_accuracy: 0.8104 - 578ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4302 - accuracy: 0.8037 - val_loss: 0.4230 - val_accuracy: 0.8035 - 575ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4315 - accuracy: 0.8002 - val_loss: 0.4138 - val_accuracy: 0.8109 - 546ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4291 - accuracy: 0.8026 - val_loss: 0.4200 - val_accuracy: 0.8094 - 565ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4279 - accuracy: 0.8030 - val_loss: 0.4150 - val_accuracy: 0.8096 - 598ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4303 - accuracy: 0.7996 - val_loss: 0.4136 - val_accuracy: 0.8104 - 609ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4278 - accuracy: 0.8040 - val_loss: 0.4144 - val_accuracy: 0.8091 - 614ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4279 - accuracy: 0.8025 - val_loss: 0.4142 - val_accuracy: 0.8099 - 567ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4282 - accuracy: 0.8024 - val_loss: 0.4137 - val_accuracy: 0.8101 - 583ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4270 - accuracy: 0.8024 - val_loss: 0.4136 - val_accuracy: 0.8106 - 565ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4272 - accuracy: 0.8023 - val_loss: 0.4122 - val_accuracy: 0.8104 - 541ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4271 - accuracy: 0.8017 - val_loss: 0.4141 - val_accuracy: 0.8112 - 653ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8034 - val_loss: 0.4173 - val_accuracy: 0.8101 - 613ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4308 - accuracy: 0.8022 - val_loss: 0.4122 - val_accuracy: 0.8091 - 625ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.4134 - val_accuracy: 0.8106 - 574ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 1s - loss: 0.4262 - accuracy: 0.8026 - val_loss: 0.4127 - val_accuracy: 0.8099 - 572ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4272 - accuracy: 0.8011 - val_loss: 0.4131 - val_accuracy: 0.8086 - 612ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4266 - accuracy: 0.8027 - val_loss: 0.4120 - val_accuracy: 0.8104 - 592ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8024 - val_loss: 0.4127 - val_accuracy: 0.8109 - 633ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4258 - accuracy: 0.8039 - val_loss: 0.4163 - val_accuracy: 0.8109 - 625ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8017 - val_loss: 0.4164 - val_accuracy: 0.8086 - 600ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 1s - loss: 0.4263 - accuracy: 0.8030 - val_loss: 0.4141 - val_accuracy: 0.8106 - 591ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 1s - loss: 0.4255 - accuracy: 0.8037 - val_loss: 0.4152 - val_accuracy: 0.8094 - 572ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 1s - loss: 0.4254 - accuracy: 0.8025 - val_loss: 0.4134 - val_accuracy: 0.8078 - 580ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 1s - loss: 0.4271 - accuracy: 0.8020 - val_loss: 0.4183 - val_accuracy: 0.8099 - 675ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 1s - loss: 0.4252 - accuracy: 0.8013 - val_loss: 0.4141 - val_accuracy: 0.8091 - 623ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 1s - loss: 0.4258 - accuracy: 0.8033 - val_loss: 0.4131 - val_accuracy: 0.8078 - 632ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "62/62 - 1s - loss: 0.4242 - accuracy: 0.8032 - val_loss: 0.4119 - val_accuracy: 0.8094 - 688ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "62/62 - 1s - loss: 0.4244 - accuracy: 0.8036 - val_loss: 0.4118 - val_accuracy: 0.8071 - 569ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "62/62 - 1s - loss: 0.4251 - accuracy: 0.8045 - val_loss: 0.4127 - val_accuracy: 0.8104 - 555ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "62/62 - 1s - loss: 0.4248 - accuracy: 0.8027 - val_loss: 0.4131 - val_accuracy: 0.8094 - 580ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "62/62 - 1s - loss: 0.4266 - accuracy: 0.8027 - val_loss: 0.4290 - val_accuracy: 0.8002 - 636ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8023 - val_loss: 0.4118 - val_accuracy: 0.8099 - 609ms/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "62/62 - 1s - loss: 0.4244 - accuracy: 0.8036 - val_loss: 0.4115 - val_accuracy: 0.8101 - 590ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "62/62 - 1s - loss: 0.4252 - accuracy: 0.8027 - val_loss: 0.4117 - val_accuracy: 0.8096 - 588ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "62/62 - 1s - loss: 0.4250 - accuracy: 0.8036 - val_loss: 0.4127 - val_accuracy: 0.8109 - 578ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "62/62 - 1s - loss: 0.4260 - accuracy: 0.8012 - val_loss: 0.4187 - val_accuracy: 0.8068 - 567ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8003 - val_loss: 0.4122 - val_accuracy: 0.8081 - 706ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "62/62 - 1s - loss: 0.4255 - accuracy: 0.8043 - val_loss: 0.4113 - val_accuracy: 0.8104 - 645ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "62/62 - 1s - loss: 0.4256 - accuracy: 0.8027 - val_loss: 0.4117 - val_accuracy: 0.8101 - 634ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "62/62 - 1s - loss: 0.4241 - accuracy: 0.8029 - val_loss: 0.4124 - val_accuracy: 0.8104 - 580ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "62/62 - 1s - loss: 0.4260 - accuracy: 0.8031 - val_loss: 0.4132 - val_accuracy: 0.8086 - 584ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "62/62 - 1s - loss: 0.4257 - accuracy: 0.8020 - val_loss: 0.4112 - val_accuracy: 0.8106 - 559ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "62/62 - 1s - loss: 0.4238 - accuracy: 0.8029 - val_loss: 0.4128 - val_accuracy: 0.8073 - 560ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "62/62 - 1s - loss: 0.4239 - accuracy: 0.8039 - val_loss: 0.4149 - val_accuracy: 0.8106 - 657ms/epoch - 11ms/step\n",
      "Epoch 61/100\n",
      "62/62 - 1s - loss: 0.4258 - accuracy: 0.8017 - val_loss: 0.4117 - val_accuracy: 0.8091 - 603ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "62/62 - 1s - loss: 0.4237 - accuracy: 0.8029 - val_loss: 0.4107 - val_accuracy: 0.8104 - 691ms/epoch - 11ms/step\n",
      "Epoch 63/100\n",
      "62/62 - 1s - loss: 0.4236 - accuracy: 0.8044 - val_loss: 0.4140 - val_accuracy: 0.8109 - 610ms/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "62/62 - 1s - loss: 0.4255 - accuracy: 0.8020 - val_loss: 0.4120 - val_accuracy: 0.8104 - 567ms/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "62/62 - 1s - loss: 0.4246 - accuracy: 0.8030 - val_loss: 0.4118 - val_accuracy: 0.8096 - 592ms/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "62/62 - 1s - loss: 0.4236 - accuracy: 0.8026 - val_loss: 0.4113 - val_accuracy: 0.8083 - 635ms/epoch - 10ms/step\n",
      "Epoch 67/100\n",
      "62/62 - 1s - loss: 0.4233 - accuracy: 0.8020 - val_loss: 0.4128 - val_accuracy: 0.8081 - 732ms/epoch - 12ms/step\n",
      "Epoch 68/100\n",
      "62/62 - 1s - loss: 0.4254 - accuracy: 0.8023 - val_loss: 0.4147 - val_accuracy: 0.8101 - 613ms/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "62/62 - 1s - loss: 0.4241 - accuracy: 0.8039 - val_loss: 0.4137 - val_accuracy: 0.8101 - 595ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "62/62 - 1s - loss: 0.4249 - accuracy: 0.8038 - val_loss: 0.4115 - val_accuracy: 0.8101 - 543ms/epoch - 9ms/step\n",
      "Epoch 71/100\n",
      "62/62 - 1s - loss: 0.4241 - accuracy: 0.8029 - val_loss: 0.4176 - val_accuracy: 0.8076 - 598ms/epoch - 10ms/step\n",
      "Epoch 72/100\n",
      "62/62 - 1s - loss: 0.4255 - accuracy: 0.8018 - val_loss: 0.4103 - val_accuracy: 0.8096 - 565ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "62/62 - 1s - loss: 0.4250 - accuracy: 0.8018 - val_loss: 0.4108 - val_accuracy: 0.8104 - 659ms/epoch - 11ms/step\n",
      "Epoch 74/100\n",
      "62/62 - 1s - loss: 0.4230 - accuracy: 0.8034 - val_loss: 0.4121 - val_accuracy: 0.8109 - 604ms/epoch - 10ms/step\n",
      "Epoch 75/100\n",
      "62/62 - 1s - loss: 0.4238 - accuracy: 0.8012 - val_loss: 0.4168 - val_accuracy: 0.8078 - 604ms/epoch - 10ms/step\n",
      "Epoch 76/100\n",
      "62/62 - 1s - loss: 0.4244 - accuracy: 0.8032 - val_loss: 0.4144 - val_accuracy: 0.8089 - 647ms/epoch - 10ms/step\n",
      "Epoch 77/100\n",
      "62/62 - 1s - loss: 0.4247 - accuracy: 0.8031 - val_loss: 0.4175 - val_accuracy: 0.8078 - 578ms/epoch - 9ms/step\n",
      "Epoch 78/100\n",
      "62/62 - 1s - loss: 0.4261 - accuracy: 0.8020 - val_loss: 0.4119 - val_accuracy: 0.8091 - 570ms/epoch - 9ms/step\n",
      "Epoch 79/100\n",
      "62/62 - 1s - loss: 0.4229 - accuracy: 0.8027 - val_loss: 0.4140 - val_accuracy: 0.8081 - 623ms/epoch - 10ms/step\n",
      "Epoch 80/100\n",
      "62/62 - 1s - loss: 0.4260 - accuracy: 0.8022 - val_loss: 0.4179 - val_accuracy: 0.8071 - 639ms/epoch - 10ms/step\n",
      "Epoch 81/100\n",
      "62/62 - 1s - loss: 0.4248 - accuracy: 0.8020 - val_loss: 0.4135 - val_accuracy: 0.8083 - 683ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "62/62 - 1s - loss: 0.4235 - accuracy: 0.8030 - val_loss: 0.4124 - val_accuracy: 0.8106 - 579ms/epoch - 9ms/step\n",
      "Epoch 82: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 2.8764 - accuracy: 0.7518 - val_loss: 2.1352 - val_accuracy: 0.7656 - 2s/epoch - 38ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 1.6872 - accuracy: 0.7657 - val_loss: 1.2817 - val_accuracy: 0.7996 - 552ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 1.0490 - accuracy: 0.7942 - val_loss: 0.8313 - val_accuracy: 0.8099 - 576ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 1s - loss: 0.7220 - accuracy: 0.8017 - val_loss: 0.6084 - val_accuracy: 0.8104 - 554ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 1s - loss: 0.5629 - accuracy: 0.8018 - val_loss: 0.5018 - val_accuracy: 0.8106 - 570ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.4891 - accuracy: 0.8025 - val_loss: 0.4537 - val_accuracy: 0.8112 - 640ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 1s - loss: 0.4565 - accuracy: 0.8027 - val_loss: 0.4385 - val_accuracy: 0.8083 - 618ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 1s - loss: 0.4435 - accuracy: 0.8027 - val_loss: 0.4252 - val_accuracy: 0.8112 - 554ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4372 - accuracy: 0.8011 - val_loss: 0.4201 - val_accuracy: 0.8101 - 646ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4343 - accuracy: 0.8016 - val_loss: 0.4168 - val_accuracy: 0.8109 - 602ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4337 - accuracy: 0.8025 - val_loss: 0.4179 - val_accuracy: 0.8109 - 618ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4316 - accuracy: 0.8019 - val_loss: 0.4180 - val_accuracy: 0.8099 - 642ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4309 - accuracy: 0.8023 - val_loss: 0.4164 - val_accuracy: 0.8106 - 627ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4294 - accuracy: 0.8026 - val_loss: 0.4165 - val_accuracy: 0.8094 - 646ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4299 - accuracy: 0.8018 - val_loss: 0.4192 - val_accuracy: 0.8106 - 612ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4315 - accuracy: 0.7998 - val_loss: 0.4145 - val_accuracy: 0.8106 - 567ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4303 - accuracy: 0.8009 - val_loss: 0.4156 - val_accuracy: 0.8109 - 559ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4289 - accuracy: 0.8019 - val_loss: 0.4134 - val_accuracy: 0.8112 - 613ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4278 - accuracy: 0.8030 - val_loss: 0.4153 - val_accuracy: 0.8119 - 619ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4301 - accuracy: 0.8009 - val_loss: 0.4138 - val_accuracy: 0.8112 - 628ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4284 - accuracy: 0.8019 - val_loss: 0.4152 - val_accuracy: 0.8101 - 584ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4292 - accuracy: 0.8009 - val_loss: 0.4147 - val_accuracy: 0.8094 - 563ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4274 - accuracy: 0.8023 - val_loss: 0.4180 - val_accuracy: 0.8076 - 549ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4263 - accuracy: 0.8024 - val_loss: 0.4134 - val_accuracy: 0.8099 - 601ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8016 - val_loss: 0.4124 - val_accuracy: 0.8106 - 625ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8016 - val_loss: 0.4134 - val_accuracy: 0.8106 - 619ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8007 - val_loss: 0.4173 - val_accuracy: 0.8071 - 620ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4273 - accuracy: 0.8023 - val_loss: 0.4154 - val_accuracy: 0.8094 - 634ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8009 - val_loss: 0.4157 - val_accuracy: 0.8086 - 583ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4269 - accuracy: 0.8027 - val_loss: 0.4130 - val_accuracy: 0.8099 - 578ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8030 - val_loss: 0.4136 - val_accuracy: 0.8083 - 585ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4259 - accuracy: 0.8025 - val_loss: 0.4179 - val_accuracy: 0.8086 - 689ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4282 - accuracy: 0.8011 - val_loss: 0.4130 - val_accuracy: 0.8119 - 608ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 1s - loss: 0.4259 - accuracy: 0.8030 - val_loss: 0.4137 - val_accuracy: 0.8099 - 582ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4256 - accuracy: 0.8025 - val_loss: 0.4140 - val_accuracy: 0.8109 - 556ms/epoch - 9ms/step\n",
      "Epoch 35: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 3.0020 - accuracy: 0.7250 - val_loss: 2.2255 - val_accuracy: 0.7656 - 2s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 1.7527 - accuracy: 0.7590 - val_loss: 1.3322 - val_accuracy: 0.7748 - 556ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 1.0888 - accuracy: 0.7873 - val_loss: 0.8612 - val_accuracy: 0.8025 - 533ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 1s - loss: 0.7458 - accuracy: 0.7986 - val_loss: 0.6241 - val_accuracy: 0.8109 - 543ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 1s - loss: 0.5763 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.8104 - 588ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.4967 - accuracy: 0.8022 - val_loss: 0.4591 - val_accuracy: 0.8101 - 634ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 1s - loss: 0.4606 - accuracy: 0.8013 - val_loss: 0.4360 - val_accuracy: 0.8094 - 683ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 1s - loss: 0.4443 - accuracy: 0.8036 - val_loss: 0.4252 - val_accuracy: 0.8104 - 582ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4380 - accuracy: 0.8020 - val_loss: 0.4213 - val_accuracy: 0.8127 - 590ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4343 - accuracy: 0.8023 - val_loss: 0.4181 - val_accuracy: 0.8124 - 590ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4322 - accuracy: 0.8027 - val_loss: 0.4165 - val_accuracy: 0.8114 - 566ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4317 - accuracy: 0.8020 - val_loss: 0.4167 - val_accuracy: 0.8106 - 664ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4319 - accuracy: 0.8020 - val_loss: 0.4155 - val_accuracy: 0.8101 - 609ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4316 - accuracy: 0.8011 - val_loss: 0.4184 - val_accuracy: 0.8083 - 605ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4306 - accuracy: 0.8020 - val_loss: 0.4172 - val_accuracy: 0.8109 - 592ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4303 - accuracy: 0.8020 - val_loss: 0.4138 - val_accuracy: 0.8109 - 574ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4297 - accuracy: 0.8015 - val_loss: 0.4204 - val_accuracy: 0.8127 - 577ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4283 - accuracy: 0.8017 - val_loss: 0.4141 - val_accuracy: 0.8114 - 573ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4290 - accuracy: 0.8017 - val_loss: 0.4138 - val_accuracy: 0.8086 - 643ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4298 - accuracy: 0.8022 - val_loss: 0.4145 - val_accuracy: 0.8101 - 618ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4277 - accuracy: 0.8022 - val_loss: 0.4136 - val_accuracy: 0.8112 - 579ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4294 - accuracy: 0.8010 - val_loss: 0.4138 - val_accuracy: 0.8109 - 625ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4276 - accuracy: 0.8025 - val_loss: 0.4142 - val_accuracy: 0.8119 - 565ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8013 - val_loss: 0.4146 - val_accuracy: 0.8078 - 602ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4277 - accuracy: 0.8018 - val_loss: 0.4133 - val_accuracy: 0.8112 - 635ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4278 - accuracy: 0.8028 - val_loss: 0.4224 - val_accuracy: 0.8045 - 615ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4286 - accuracy: 0.8010 - val_loss: 0.4115 - val_accuracy: 0.8114 - 607ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4281 - accuracy: 0.8010 - val_loss: 0.4124 - val_accuracy: 0.8117 - 595ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8030 - val_loss: 0.4155 - val_accuracy: 0.8096 - 586ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4259 - accuracy: 0.8024 - val_loss: 0.4124 - val_accuracy: 0.8137 - 556ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 1s - loss: 0.4261 - accuracy: 0.8018 - val_loss: 0.4126 - val_accuracy: 0.8114 - 567ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8014 - val_loss: 0.4122 - val_accuracy: 0.8094 - 642ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4258 - accuracy: 0.8015 - val_loss: 0.4149 - val_accuracy: 0.8081 - 644ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8008 - val_loss: 0.4121 - val_accuracy: 0.8109 - 670ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4276 - accuracy: 0.8005 - val_loss: 0.4127 - val_accuracy: 0.8094 - 585ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 1s - loss: 0.4261 - accuracy: 0.8026 - val_loss: 0.4141 - val_accuracy: 0.8109 - 568ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 1s - loss: 0.4261 - accuracy: 0.8025 - val_loss: 0.4113 - val_accuracy: 0.8094 - 564ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 1s - loss: 0.4256 - accuracy: 0.8030 - val_loss: 0.4211 - val_accuracy: 0.8048 - 610ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 1s - loss: 0.4272 - accuracy: 0.7997 - val_loss: 0.4140 - val_accuracy: 0.8096 - 620ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 1s - loss: 0.4265 - accuracy: 0.8013 - val_loss: 0.4164 - val_accuracy: 0.8071 - 608ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 1s - loss: 0.4265 - accuracy: 0.8018 - val_loss: 0.4235 - val_accuracy: 0.8040 - 584ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 1s - loss: 0.4260 - accuracy: 0.8022 - val_loss: 0.4119 - val_accuracy: 0.8104 - 560ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "62/62 - 1s - loss: 0.4246 - accuracy: 0.8041 - val_loss: 0.4114 - val_accuracy: 0.8112 - 561ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "62/62 - 1s - loss: 0.4260 - accuracy: 0.8011 - val_loss: 0.4115 - val_accuracy: 0.8101 - 648ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "62/62 - 1s - loss: 0.4253 - accuracy: 0.8027 - val_loss: 0.4136 - val_accuracy: 0.8081 - 635ms/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "62/62 - 1s - loss: 0.4249 - accuracy: 0.8038 - val_loss: 0.4109 - val_accuracy: 0.8109 - 597ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "62/62 - 1s - loss: 0.4241 - accuracy: 0.8037 - val_loss: 0.4132 - val_accuracy: 0.8101 - 630ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "62/62 - 1s - loss: 0.4244 - accuracy: 0.8034 - val_loss: 0.4131 - val_accuracy: 0.8089 - 682ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "62/62 - 1s - loss: 0.4243 - accuracy: 0.8031 - val_loss: 0.4168 - val_accuracy: 0.8060 - 582ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "62/62 - 1s - loss: 0.4255 - accuracy: 0.8025 - val_loss: 0.4130 - val_accuracy: 0.8106 - 583ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8001 - val_loss: 0.4112 - val_accuracy: 0.8109 - 583ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8007 - val_loss: 0.4118 - val_accuracy: 0.8094 - 682ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "62/62 - 1s - loss: 0.4245 - accuracy: 0.8031 - val_loss: 0.4135 - val_accuracy: 0.8096 - 611ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "62/62 - 1s - loss: 0.4254 - accuracy: 0.8032 - val_loss: 0.4124 - val_accuracy: 0.8094 - 596ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "62/62 - 1s - loss: 0.4241 - accuracy: 0.8033 - val_loss: 0.4145 - val_accuracy: 0.8091 - 568ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "62/62 - 1s - loss: 0.4247 - accuracy: 0.8025 - val_loss: 0.4121 - val_accuracy: 0.8104 - 662ms/epoch - 11ms/step\n",
      "Epoch 56: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 3.0607 - accuracy: 0.6235 - val_loss: 2.2826 - val_accuracy: 0.7659 - 2s/epoch - 31ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 1.8010 - accuracy: 0.7590 - val_loss: 1.3794 - val_accuracy: 0.7656 - 631ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 1.1302 - accuracy: 0.7590 - val_loss: 0.9044 - val_accuracy: 0.7656 - 658ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 1s - loss: 0.7777 - accuracy: 0.7662 - val_loss: 0.6525 - val_accuracy: 0.8048 - 667ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 1s - loss: 0.5915 - accuracy: 0.7976 - val_loss: 0.5217 - val_accuracy: 0.8096 - 569ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.5009 - accuracy: 0.8021 - val_loss: 0.4638 - val_accuracy: 0.8091 - 615ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 1s - loss: 0.4633 - accuracy: 0.7996 - val_loss: 0.4370 - val_accuracy: 0.8112 - 672ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 1s - loss: 0.4454 - accuracy: 0.8015 - val_loss: 0.4278 - val_accuracy: 0.8104 - 626ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4385 - accuracy: 0.8024 - val_loss: 0.4277 - val_accuracy: 0.8078 - 641ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4364 - accuracy: 0.8014 - val_loss: 0.4198 - val_accuracy: 0.8112 - 587ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4321 - accuracy: 0.8021 - val_loss: 0.4171 - val_accuracy: 0.8109 - 568ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4325 - accuracy: 0.8014 - val_loss: 0.4193 - val_accuracy: 0.8094 - 543ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4315 - accuracy: 0.8011 - val_loss: 0.4196 - val_accuracy: 0.8101 - 696ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4308 - accuracy: 0.8015 - val_loss: 0.4149 - val_accuracy: 0.8109 - 706ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4299 - accuracy: 0.8022 - val_loss: 0.4140 - val_accuracy: 0.8109 - 606ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4286 - accuracy: 0.8027 - val_loss: 0.4147 - val_accuracy: 0.8096 - 593ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4282 - accuracy: 0.8015 - val_loss: 0.4131 - val_accuracy: 0.8104 - 763ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4290 - accuracy: 0.8033 - val_loss: 0.4266 - val_accuracy: 0.7989 - 633ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4301 - accuracy: 0.8002 - val_loss: 0.4128 - val_accuracy: 0.8109 - 508ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4284 - accuracy: 0.8015 - val_loss: 0.4130 - val_accuracy: 0.8096 - 679ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4277 - accuracy: 0.8024 - val_loss: 0.4123 - val_accuracy: 0.8106 - 743ms/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4273 - accuracy: 0.8022 - val_loss: 0.4119 - val_accuracy: 0.8124 - 723ms/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4271 - accuracy: 0.8022 - val_loss: 0.4125 - val_accuracy: 0.8104 - 651ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4269 - accuracy: 0.8030 - val_loss: 0.4162 - val_accuracy: 0.8071 - 639ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4272 - accuracy: 0.8034 - val_loss: 0.4129 - val_accuracy: 0.8109 - 619ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4271 - accuracy: 0.7999 - val_loss: 0.4126 - val_accuracy: 0.8104 - 623ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4269 - accuracy: 0.8014 - val_loss: 0.4125 - val_accuracy: 0.8109 - 613ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4274 - accuracy: 0.8023 - val_loss: 0.4159 - val_accuracy: 0.8083 - 694ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8037 - val_loss: 0.4132 - val_accuracy: 0.8109 - 677ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8024 - val_loss: 0.4133 - val_accuracy: 0.8091 - 554ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 1s - loss: 0.4261 - accuracy: 0.8024 - val_loss: 0.4160 - val_accuracy: 0.8094 - 560ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4267 - accuracy: 0.8024 - val_loss: 0.4114 - val_accuracy: 0.8106 - 640ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4252 - accuracy: 0.8025 - val_loss: 0.4115 - val_accuracy: 0.8104 - 633ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8022 - val_loss: 0.4109 - val_accuracy: 0.8101 - 670ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4257 - accuracy: 0.8034 - val_loss: 0.4111 - val_accuracy: 0.8109 - 685ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 1s - loss: 0.4262 - accuracy: 0.8015 - val_loss: 0.4117 - val_accuracy: 0.8104 - 585ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 1s - loss: 0.4253 - accuracy: 0.8030 - val_loss: 0.4132 - val_accuracy: 0.8117 - 550ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 1s - loss: 0.4253 - accuracy: 0.8023 - val_loss: 0.4120 - val_accuracy: 0.8091 - 601ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 1s - loss: 0.4255 - accuracy: 0.8019 - val_loss: 0.4137 - val_accuracy: 0.8101 - 590ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 1s - loss: 0.4277 - accuracy: 0.8002 - val_loss: 0.4139 - val_accuracy: 0.8081 - 612ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 1s - loss: 0.4252 - accuracy: 0.8023 - val_loss: 0.4108 - val_accuracy: 0.8106 - 725ms/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8023 - val_loss: 0.4254 - val_accuracy: 0.8037 - 545ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "62/62 - 1s - loss: 0.4242 - accuracy: 0.8030 - val_loss: 0.4114 - val_accuracy: 0.8099 - 680ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "62/62 - 1s - loss: 0.4253 - accuracy: 0.8030 - val_loss: 0.4105 - val_accuracy: 0.8114 - 660ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "62/62 - 1s - loss: 0.4241 - accuracy: 0.8035 - val_loss: 0.4120 - val_accuracy: 0.8081 - 707ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "62/62 - 1s - loss: 0.4248 - accuracy: 0.8020 - val_loss: 0.4119 - val_accuracy: 0.8109 - 656ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "62/62 - 1s - loss: 0.4247 - accuracy: 0.8029 - val_loss: 0.4128 - val_accuracy: 0.8104 - 761ms/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "62/62 - 1s - loss: 0.4243 - accuracy: 0.8007 - val_loss: 0.4115 - val_accuracy: 0.8101 - 705ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "62/62 - 1s - loss: 0.4246 - accuracy: 0.8026 - val_loss: 0.4131 - val_accuracy: 0.8101 - 686ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "62/62 - 1s - loss: 0.4262 - accuracy: 0.8004 - val_loss: 0.4115 - val_accuracy: 0.8096 - 676ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "62/62 - 1s - loss: 0.4243 - accuracy: 0.8036 - val_loss: 0.4139 - val_accuracy: 0.8106 - 681ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "62/62 - 1s - loss: 0.4251 - accuracy: 0.8027 - val_loss: 0.4116 - val_accuracy: 0.8106 - 611ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "62/62 - 1s - loss: 0.4254 - accuracy: 0.8019 - val_loss: 0.4120 - val_accuracy: 0.8099 - 611ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "62/62 - 1s - loss: 0.4252 - accuracy: 0.8012 - val_loss: 0.4112 - val_accuracy: 0.8109 - 573ms/epoch - 9ms/step\n",
      "Epoch 54: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 3.1968 - accuracy: 0.6823 - val_loss: 2.3920 - val_accuracy: 0.7656 - 2s/epoch - 34ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 1.8963 - accuracy: 0.7590 - val_loss: 1.4538 - val_accuracy: 0.7656 - 663ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 1.1869 - accuracy: 0.7600 - val_loss: 0.9405 - val_accuracy: 0.7733 - 601ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 1s - loss: 0.8002 - accuracy: 0.7862 - val_loss: 0.6647 - val_accuracy: 0.8096 - 561ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 1s - loss: 0.6024 - accuracy: 0.8007 - val_loss: 0.5296 - val_accuracy: 0.8109 - 564ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.5087 - accuracy: 0.8027 - val_loss: 0.4698 - val_accuracy: 0.8099 - 670ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 1s - loss: 0.4668 - accuracy: 0.8025 - val_loss: 0.4399 - val_accuracy: 0.8109 - 629ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 1s - loss: 0.4479 - accuracy: 0.8019 - val_loss: 0.4309 - val_accuracy: 0.8106 - 551ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4425 - accuracy: 0.8026 - val_loss: 0.4243 - val_accuracy: 0.8109 - 631ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4366 - accuracy: 0.8027 - val_loss: 0.4205 - val_accuracy: 0.8112 - 591ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4336 - accuracy: 0.8038 - val_loss: 0.4183 - val_accuracy: 0.8112 - 576ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4320 - accuracy: 0.8030 - val_loss: 0.4179 - val_accuracy: 0.8106 - 535ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4321 - accuracy: 0.8021 - val_loss: 0.4183 - val_accuracy: 0.8106 - 635ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4315 - accuracy: 0.8020 - val_loss: 0.4163 - val_accuracy: 0.8106 - 634ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4296 - accuracy: 0.8025 - val_loss: 0.4155 - val_accuracy: 0.8109 - 578ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4308 - accuracy: 0.8014 - val_loss: 0.4140 - val_accuracy: 0.8106 - 604ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4294 - accuracy: 0.8027 - val_loss: 0.4169 - val_accuracy: 0.8089 - 546ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4314 - accuracy: 0.8013 - val_loss: 0.4158 - val_accuracy: 0.8101 - 567ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4319 - accuracy: 0.8006 - val_loss: 0.4143 - val_accuracy: 0.8099 - 586ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4289 - accuracy: 0.8034 - val_loss: 0.4136 - val_accuracy: 0.8101 - 645ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4276 - accuracy: 0.8023 - val_loss: 0.4135 - val_accuracy: 0.8104 - 614ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4283 - accuracy: 0.8020 - val_loss: 0.4162 - val_accuracy: 0.8106 - 566ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4280 - accuracy: 0.8024 - val_loss: 0.4150 - val_accuracy: 0.8112 - 656ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4281 - accuracy: 0.8024 - val_loss: 0.4160 - val_accuracy: 0.8101 - 612ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4269 - accuracy: 0.8032 - val_loss: 0.4130 - val_accuracy: 0.8109 - 545ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4290 - accuracy: 0.8009 - val_loss: 0.4135 - val_accuracy: 0.8112 - 595ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4261 - accuracy: 0.8023 - val_loss: 0.4123 - val_accuracy: 0.8101 - 674ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4281 - accuracy: 0.8009 - val_loss: 0.4192 - val_accuracy: 0.8089 - 717ms/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4269 - accuracy: 0.8020 - val_loss: 0.4125 - val_accuracy: 0.8083 - 614ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4279 - accuracy: 0.8016 - val_loss: 0.4180 - val_accuracy: 0.8096 - 563ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 1s - loss: 0.4272 - accuracy: 0.8007 - val_loss: 0.4119 - val_accuracy: 0.8104 - 552ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4261 - accuracy: 0.8030 - val_loss: 0.4127 - val_accuracy: 0.8094 - 574ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4261 - accuracy: 0.8022 - val_loss: 0.4162 - val_accuracy: 0.8094 - 679ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 1s - loss: 0.4265 - accuracy: 0.8012 - val_loss: 0.4129 - val_accuracy: 0.8112 - 553ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4280 - accuracy: 0.8004 - val_loss: 0.4123 - val_accuracy: 0.8104 - 549ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 1s - loss: 0.4258 - accuracy: 0.8019 - val_loss: 0.4148 - val_accuracy: 0.8106 - 602ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8022 - val_loss: 0.4120 - val_accuracy: 0.8104 - 736ms/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 1s - loss: 0.4266 - accuracy: 0.8018 - val_loss: 0.4126 - val_accuracy: 0.8099 - 534ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 1s - loss: 0.4271 - accuracy: 0.8033 - val_loss: 0.4144 - val_accuracy: 0.8091 - 638ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 1s - loss: 0.4247 - accuracy: 0.8030 - val_loss: 0.4115 - val_accuracy: 0.8106 - 673ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 1s - loss: 0.4252 - accuracy: 0.8034 - val_loss: 0.4133 - val_accuracy: 0.8104 - 622ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 1s - loss: 0.4253 - accuracy: 0.8025 - val_loss: 0.4123 - val_accuracy: 0.8106 - 683ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "62/62 - 1s - loss: 0.4247 - accuracy: 0.8039 - val_loss: 0.4119 - val_accuracy: 0.8106 - 603ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "62/62 - 1s - loss: 0.4252 - accuracy: 0.8028 - val_loss: 0.4119 - val_accuracy: 0.8091 - 581ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "62/62 - 1s - loss: 0.4252 - accuracy: 0.8036 - val_loss: 0.4142 - val_accuracy: 0.8109 - 660ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "62/62 - 1s - loss: 0.4271 - accuracy: 0.8019 - val_loss: 0.4118 - val_accuracy: 0.8104 - 802ms/epoch - 13ms/step\n",
      "Epoch 47/100\n",
      "62/62 - 1s - loss: 0.4256 - accuracy: 0.8036 - val_loss: 0.4125 - val_accuracy: 0.8083 - 583ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "62/62 - 0s - loss: 0.4249 - accuracy: 0.8032 - val_loss: 0.4211 - val_accuracy: 0.8050 - 463ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "62/62 - 1s - loss: 0.4251 - accuracy: 0.8034 - val_loss: 0.4150 - val_accuracy: 0.8096 - 563ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "62/62 - 0s - loss: 0.4260 - accuracy: 0.8008 - val_loss: 0.4148 - val_accuracy: 0.8101 - 482ms/epoch - 8ms/step\n",
      "Epoch 50: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "62/62 - 1s - loss: 3.1160 - accuracy: 0.6508 - val_loss: 2.3399 - val_accuracy: 0.7656 - 1s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 0s - loss: 1.8445 - accuracy: 0.7590 - val_loss: 1.4065 - val_accuracy: 0.7656 - 454ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 1.1451 - accuracy: 0.7611 - val_loss: 0.9028 - val_accuracy: 0.7909 - 449ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.7717 - accuracy: 0.7932 - val_loss: 0.6427 - val_accuracy: 0.8066 - 448ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.5882 - accuracy: 0.7998 - val_loss: 0.5192 - val_accuracy: 0.8109 - 454ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.5021 - accuracy: 0.8020 - val_loss: 0.4642 - val_accuracy: 0.8094 - 554ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4624 - accuracy: 0.8023 - val_loss: 0.4366 - val_accuracy: 0.8109 - 466ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4464 - accuracy: 0.8017 - val_loss: 0.4263 - val_accuracy: 0.8101 - 437ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.4386 - accuracy: 0.8022 - val_loss: 0.4231 - val_accuracy: 0.8117 - 489ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4364 - accuracy: 0.8020 - val_loss: 0.4218 - val_accuracy: 0.8104 - 508ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4342 - accuracy: 0.8023 - val_loss: 0.4230 - val_accuracy: 0.8099 - 517ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4330 - accuracy: 0.8027 - val_loss: 0.4178 - val_accuracy: 0.8117 - 557ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4320 - accuracy: 0.8026 - val_loss: 0.4168 - val_accuracy: 0.8101 - 616ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4299 - accuracy: 0.8039 - val_loss: 0.4161 - val_accuracy: 0.8104 - 624ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4300 - accuracy: 0.8025 - val_loss: 0.4151 - val_accuracy: 0.8109 - 612ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4295 - accuracy: 0.8032 - val_loss: 0.4158 - val_accuracy: 0.8096 - 554ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4302 - accuracy: 0.8028 - val_loss: 0.4150 - val_accuracy: 0.8112 - 506ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4298 - accuracy: 0.8028 - val_loss: 0.4140 - val_accuracy: 0.8106 - 545ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4284 - accuracy: 0.8027 - val_loss: 0.4138 - val_accuracy: 0.8106 - 681ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4294 - accuracy: 0.8018 - val_loss: 0.4186 - val_accuracy: 0.8096 - 886ms/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4301 - accuracy: 0.8030 - val_loss: 0.4142 - val_accuracy: 0.8106 - 774ms/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4286 - accuracy: 0.8020 - val_loss: 0.4177 - val_accuracy: 0.8096 - 754ms/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4287 - accuracy: 0.8031 - val_loss: 0.4135 - val_accuracy: 0.8101 - 706ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4276 - accuracy: 0.8025 - val_loss: 0.4167 - val_accuracy: 0.8117 - 732ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4292 - accuracy: 0.8026 - val_loss: 0.4161 - val_accuracy: 0.8109 - 700ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4273 - accuracy: 0.8030 - val_loss: 0.4128 - val_accuracy: 0.8106 - 856ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4279 - accuracy: 0.8023 - val_loss: 0.4136 - val_accuracy: 0.8104 - 661ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4275 - accuracy: 0.8024 - val_loss: 0.4141 - val_accuracy: 0.8101 - 657ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4277 - accuracy: 0.8026 - val_loss: 0.4130 - val_accuracy: 0.8106 - 606ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4274 - accuracy: 0.8028 - val_loss: 0.4125 - val_accuracy: 0.8104 - 562ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 1s - loss: 0.4258 - accuracy: 0.8020 - val_loss: 0.4133 - val_accuracy: 0.8099 - 596ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4272 - accuracy: 0.8016 - val_loss: 0.4124 - val_accuracy: 0.8106 - 511ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4278 - accuracy: 0.8018 - val_loss: 0.4118 - val_accuracy: 0.8119 - 551ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 1s - loss: 0.4266 - accuracy: 0.8019 - val_loss: 0.4131 - val_accuracy: 0.8124 - 514ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8029 - val_loss: 0.4147 - val_accuracy: 0.8112 - 529ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 1s - loss: 0.4266 - accuracy: 0.8022 - val_loss: 0.4116 - val_accuracy: 0.8091 - 501ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 1s - loss: 0.4263 - accuracy: 0.8019 - val_loss: 0.4127 - val_accuracy: 0.8106 - 503ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 1s - loss: 0.4257 - accuracy: 0.8032 - val_loss: 0.4117 - val_accuracy: 0.8104 - 513ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 1s - loss: 0.4260 - accuracy: 0.8017 - val_loss: 0.4141 - val_accuracy: 0.8083 - 575ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 1s - loss: 0.4259 - accuracy: 0.8020 - val_loss: 0.4148 - val_accuracy: 0.8101 - 602ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 1s - loss: 0.4251 - accuracy: 0.8027 - val_loss: 0.4154 - val_accuracy: 0.8096 - 646ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 1s - loss: 0.4255 - accuracy: 0.8020 - val_loss: 0.4247 - val_accuracy: 0.8035 - 757ms/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "62/62 - 1s - loss: 0.4276 - accuracy: 0.8007 - val_loss: 0.4125 - val_accuracy: 0.8101 - 678ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "62/62 - 0s - loss: 0.4251 - accuracy: 0.8027 - val_loss: 0.4140 - val_accuracy: 0.8086 - 487ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "62/62 - 0s - loss: 0.4256 - accuracy: 0.8029 - val_loss: 0.4152 - val_accuracy: 0.8117 - 486ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "62/62 - 1s - loss: 0.4257 - accuracy: 0.8041 - val_loss: 0.4186 - val_accuracy: 0.8096 - 507ms/epoch - 8ms/step\n",
      "Epoch 46: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 3.0842 - accuracy: 0.5857 - val_loss: 2.2598 - val_accuracy: 0.7656 - 2s/epoch - 34ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 0s - loss: 1.7930 - accuracy: 0.7590 - val_loss: 1.3791 - val_accuracy: 0.7656 - 464ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 1.1307 - accuracy: 0.7597 - val_loss: 0.9013 - val_accuracy: 0.7697 - 588ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 1s - loss: 0.7724 - accuracy: 0.7878 - val_loss: 0.6471 - val_accuracy: 0.8089 - 643ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.5900 - accuracy: 0.8019 - val_loss: 0.5258 - val_accuracy: 0.8083 - 480ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.5055 - accuracy: 0.8025 - val_loss: 0.4671 - val_accuracy: 0.8119 - 579ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 1s - loss: 0.4664 - accuracy: 0.8029 - val_loss: 0.4420 - val_accuracy: 0.8101 - 594ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 1s - loss: 0.4480 - accuracy: 0.8022 - val_loss: 0.4293 - val_accuracy: 0.8114 - 665ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4409 - accuracy: 0.8027 - val_loss: 0.4236 - val_accuracy: 0.8099 - 684ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4353 - accuracy: 0.8020 - val_loss: 0.4325 - val_accuracy: 0.7999 - 594ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4357 - accuracy: 0.8018 - val_loss: 0.4222 - val_accuracy: 0.8096 - 515ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.4325 - accuracy: 0.8025 - val_loss: 0.4178 - val_accuracy: 0.8101 - 486ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4318 - accuracy: 0.8032 - val_loss: 0.4180 - val_accuracy: 0.8094 - 592ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4317 - accuracy: 0.8033 - val_loss: 0.4182 - val_accuracy: 0.8109 - 585ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4305 - accuracy: 0.8022 - val_loss: 0.4159 - val_accuracy: 0.8109 - 604ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4300 - accuracy: 0.8029 - val_loss: 0.4146 - val_accuracy: 0.8099 - 530ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4288 - accuracy: 0.8030 - val_loss: 0.4165 - val_accuracy: 0.8099 - 554ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.4289 - accuracy: 0.8023 - val_loss: 0.4143 - val_accuracy: 0.8094 - 470ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4282 - accuracy: 0.8030 - val_loss: 0.4153 - val_accuracy: 0.8122 - 521ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.4285 - accuracy: 0.8025 - val_loss: 0.4143 - val_accuracy: 0.8104 - 474ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.4282 - accuracy: 0.8025 - val_loss: 0.4146 - val_accuracy: 0.8104 - 497ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4278 - accuracy: 0.8026 - val_loss: 0.4142 - val_accuracy: 0.8094 - 555ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4277 - accuracy: 0.8030 - val_loss: 0.4144 - val_accuracy: 0.8086 - 506ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4276 - accuracy: 0.8024 - val_loss: 0.4146 - val_accuracy: 0.8096 - 567ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4264 - accuracy: 0.8029 - val_loss: 0.4132 - val_accuracy: 0.8091 - 558ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4278 - accuracy: 0.8021 - val_loss: 0.4128 - val_accuracy: 0.8091 - 534ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4270 - accuracy: 0.8027 - val_loss: 0.4134 - val_accuracy: 0.8094 - 576ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4266 - accuracy: 0.8039 - val_loss: 0.4136 - val_accuracy: 0.8101 - 568ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4284 - accuracy: 0.8027 - val_loss: 0.4135 - val_accuracy: 0.8104 - 644ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4263 - accuracy: 0.8036 - val_loss: 0.4154 - val_accuracy: 0.8094 - 806ms/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 1s - loss: 0.4268 - accuracy: 0.8025 - val_loss: 0.4146 - val_accuracy: 0.8083 - 627ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4284 - accuracy: 0.8023 - val_loss: 0.4138 - val_accuracy: 0.8106 - 719ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4277 - accuracy: 0.8019 - val_loss: 0.4145 - val_accuracy: 0.8106 - 721ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 0s - loss: 0.4261 - accuracy: 0.8023 - val_loss: 0.4138 - val_accuracy: 0.8101 - 499ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4252 - accuracy: 0.8030 - val_loss: 0.4204 - val_accuracy: 0.8060 - 608ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 1s - loss: 0.4279 - accuracy: 0.7997 - val_loss: 0.4134 - val_accuracy: 0.8094 - 504ms/epoch - 8ms/step\n",
      "Epoch 36: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.45362373209834017\n",
      "epi entropy:  0.4280003503733929\n",
      "\n",
      "dataset size:  0.6\n",
      "Epoch 1/100\n",
      "74/74 - 3s - loss: 2.9014 - accuracy: 0.6814 - val_loss: 2.0301 - val_accuracy: 0.7643 - 3s/epoch - 42ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 1.5406 - accuracy: 0.7681 - val_loss: 1.1399 - val_accuracy: 0.7957 - 708ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.9109 - accuracy: 0.7975 - val_loss: 0.7325 - val_accuracy: 0.8025 - 779ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.6291 - accuracy: 0.8002 - val_loss: 0.5560 - val_accuracy: 0.7980 - 701ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.5103 - accuracy: 0.7990 - val_loss: 0.4832 - val_accuracy: 0.8015 - 652ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4611 - accuracy: 0.8005 - val_loss: 0.4547 - val_accuracy: 0.8023 - 563ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4423 - accuracy: 0.8008 - val_loss: 0.4458 - val_accuracy: 0.8019 - 670ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4363 - accuracy: 0.7992 - val_loss: 0.4407 - val_accuracy: 0.7993 - 682ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4324 - accuracy: 0.8005 - val_loss: 0.4392 - val_accuracy: 0.8025 - 530ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4303 - accuracy: 0.7996 - val_loss: 0.4403 - val_accuracy: 0.8017 - 714ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4298 - accuracy: 0.8000 - val_loss: 0.4384 - val_accuracy: 0.7991 - 674ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4298 - accuracy: 0.7985 - val_loss: 0.4371 - val_accuracy: 0.8015 - 715ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.4373 - val_accuracy: 0.8002 - 655ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4274 - accuracy: 0.8000 - val_loss: 0.4358 - val_accuracy: 0.8021 - 663ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4283 - accuracy: 0.7999 - val_loss: 0.4363 - val_accuracy: 0.8019 - 637ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4273 - accuracy: 0.7992 - val_loss: 0.4363 - val_accuracy: 0.8012 - 664ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4262 - accuracy: 0.8000 - val_loss: 0.4395 - val_accuracy: 0.7995 - 693ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4269 - accuracy: 0.7984 - val_loss: 0.4343 - val_accuracy: 0.8021 - 741ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4258 - accuracy: 0.8029 - val_loss: 0.4333 - val_accuracy: 0.8012 - 801ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4262 - accuracy: 0.8002 - val_loss: 0.4344 - val_accuracy: 0.8006 - 629ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4259 - accuracy: 0.7999 - val_loss: 0.4324 - val_accuracy: 0.8021 - 569ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4264 - accuracy: 0.7993 - val_loss: 0.4346 - val_accuracy: 0.8017 - 579ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4262 - accuracy: 0.7988 - val_loss: 0.4347 - val_accuracy: 0.8006 - 714ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4266 - accuracy: 0.7982 - val_loss: 0.4339 - val_accuracy: 0.8051 - 684ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4248 - accuracy: 0.8011 - val_loss: 0.4336 - val_accuracy: 0.7991 - 623ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4252 - accuracy: 0.7988 - val_loss: 0.4331 - val_accuracy: 0.8012 - 597ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4241 - accuracy: 0.8006 - val_loss: 0.4347 - val_accuracy: 0.7933 - 625ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4244 - accuracy: 0.8001 - val_loss: 0.4363 - val_accuracy: 0.7959 - 654ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4241 - accuracy: 0.8000 - val_loss: 0.4330 - val_accuracy: 0.8023 - 612ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.4345 - val_accuracy: 0.8015 - 596ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4246 - accuracy: 0.7997 - val_loss: 0.4338 - val_accuracy: 0.8021 - 732ms/epoch - 10ms/step\n",
      "Epoch 31: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 2.7656 - accuracy: 0.7490 - val_loss: 1.9414 - val_accuracy: 0.7643 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 1.4644 - accuracy: 0.7694 - val_loss: 1.0775 - val_accuracy: 0.7938 - 599ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.8620 - accuracy: 0.7964 - val_loss: 0.6954 - val_accuracy: 0.8010 - 610ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.6004 - accuracy: 0.7995 - val_loss: 0.5376 - val_accuracy: 0.7963 - 566ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4943 - accuracy: 0.7996 - val_loss: 0.4774 - val_accuracy: 0.8017 - 561ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4539 - accuracy: 0.8003 - val_loss: 0.4508 - val_accuracy: 0.8017 - 565ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4390 - accuracy: 0.7995 - val_loss: 0.4424 - val_accuracy: 0.8023 - 540ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4343 - accuracy: 0.8006 - val_loss: 0.4400 - val_accuracy: 0.8019 - 530ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4308 - accuracy: 0.8004 - val_loss: 0.4402 - val_accuracy: 0.8008 - 582ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4295 - accuracy: 0.8000 - val_loss: 0.4434 - val_accuracy: 0.7978 - 583ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.4357 - val_accuracy: 0.8012 - 579ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4278 - accuracy: 0.8007 - val_loss: 0.4377 - val_accuracy: 0.7995 - 613ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.4357 - val_accuracy: 0.8002 - 611ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4273 - accuracy: 0.8012 - val_loss: 0.4349 - val_accuracy: 0.8010 - 571ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4265 - accuracy: 0.8012 - val_loss: 0.4350 - val_accuracy: 0.8000 - 614ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4270 - accuracy: 0.8006 - val_loss: 0.4340 - val_accuracy: 0.7989 - 589ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4259 - accuracy: 0.8005 - val_loss: 0.4360 - val_accuracy: 0.8006 - 556ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4262 - accuracy: 0.7995 - val_loss: 0.4330 - val_accuracy: 0.8006 - 583ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4271 - accuracy: 0.7981 - val_loss: 0.4418 - val_accuracy: 0.7968 - 682ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4254 - accuracy: 0.7997 - val_loss: 0.4339 - val_accuracy: 0.8015 - 592ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4250 - accuracy: 0.8017 - val_loss: 0.4346 - val_accuracy: 0.8008 - 556ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4250 - accuracy: 0.7992 - val_loss: 0.4338 - val_accuracy: 0.8015 - 557ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.4366 - val_accuracy: 0.8025 - 565ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4255 - accuracy: 0.8008 - val_loss: 0.4342 - val_accuracy: 0.8038 - 557ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4241 - accuracy: 0.8004 - val_loss: 0.4345 - val_accuracy: 0.8004 - 564ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4239 - accuracy: 0.8004 - val_loss: 0.4324 - val_accuracy: 0.7991 - 536ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4235 - accuracy: 0.8002 - val_loss: 0.4335 - val_accuracy: 0.8017 - 570ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.8015 - val_loss: 0.4347 - val_accuracy: 0.8034 - 586ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4241 - accuracy: 0.7997 - val_loss: 0.4342 - val_accuracy: 0.8006 - 564ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4234 - accuracy: 0.8004 - val_loss: 0.4331 - val_accuracy: 0.8002 - 623ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.7990 - val_loss: 0.4348 - val_accuracy: 0.8002 - 545ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4255 - accuracy: 0.8001 - val_loss: 0.4339 - val_accuracy: 0.8044 - 587ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4233 - accuracy: 0.8008 - val_loss: 0.4359 - val_accuracy: 0.8012 - 573ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4237 - accuracy: 0.8009 - val_loss: 0.4320 - val_accuracy: 0.8025 - 562ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4239 - accuracy: 0.8005 - val_loss: 0.4334 - val_accuracy: 0.8015 - 545ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4240 - accuracy: 0.7999 - val_loss: 0.4374 - val_accuracy: 0.8032 - 549ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4237 - accuracy: 0.8017 - val_loss: 0.4316 - val_accuracy: 0.8036 - 580ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4234 - accuracy: 0.8006 - val_loss: 0.4334 - val_accuracy: 0.8019 - 582ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4224 - accuracy: 0.7999 - val_loss: 0.4335 - val_accuracy: 0.8010 - 546ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4225 - accuracy: 0.8001 - val_loss: 0.4330 - val_accuracy: 0.8010 - 574ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4238 - accuracy: 0.8008 - val_loss: 0.4328 - val_accuracy: 0.8017 - 548ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 1s - loss: 0.4245 - accuracy: 0.7980 - val_loss: 0.4326 - val_accuracy: 0.8040 - 566ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.8003 - val_loss: 0.4309 - val_accuracy: 0.8008 - 564ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "74/74 - 1s - loss: 0.4237 - accuracy: 0.8006 - val_loss: 0.4339 - val_accuracy: 0.8034 - 542ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "74/74 - 1s - loss: 0.4228 - accuracy: 0.8014 - val_loss: 0.4316 - val_accuracy: 0.8027 - 540ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "74/74 - 1s - loss: 0.4233 - accuracy: 0.7990 - val_loss: 0.4408 - val_accuracy: 0.7995 - 573ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.8001 - val_loss: 0.4387 - val_accuracy: 0.7961 - 560ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "74/74 - 1s - loss: 0.4240 - accuracy: 0.7992 - val_loss: 0.4375 - val_accuracy: 0.7995 - 541ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "74/74 - 1s - loss: 0.4228 - accuracy: 0.8014 - val_loss: 0.4326 - val_accuracy: 0.8025 - 620ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "74/74 - 1s - loss: 0.4223 - accuracy: 0.8001 - val_loss: 0.4328 - val_accuracy: 0.8008 - 563ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "74/74 - 1s - loss: 0.4233 - accuracy: 0.8000 - val_loss: 0.4332 - val_accuracy: 0.8010 - 568ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "74/74 - 1s - loss: 0.4223 - accuracy: 0.8002 - val_loss: 0.4342 - val_accuracy: 0.8021 - 547ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "74/74 - 1s - loss: 0.4222 - accuracy: 0.8008 - val_loss: 0.4380 - val_accuracy: 0.7951 - 557ms/epoch - 8ms/step\n",
      "Epoch 53: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 2.6920 - accuracy: 0.7438 - val_loss: 1.8948 - val_accuracy: 0.7643 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 1.4299 - accuracy: 0.7814 - val_loss: 1.0559 - val_accuracy: 0.7991 - 520ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.8467 - accuracy: 0.8004 - val_loss: 0.6882 - val_accuracy: 0.8010 - 543ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.5944 - accuracy: 0.8001 - val_loss: 0.5315 - val_accuracy: 0.8017 - 554ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4922 - accuracy: 0.7999 - val_loss: 0.4725 - val_accuracy: 0.8010 - 559ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4533 - accuracy: 0.7994 - val_loss: 0.4510 - val_accuracy: 0.8000 - 500ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4380 - accuracy: 0.8013 - val_loss: 0.4425 - val_accuracy: 0.8008 - 612ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4329 - accuracy: 0.8001 - val_loss: 0.4395 - val_accuracy: 0.8012 - 551ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4319 - accuracy: 0.7990 - val_loss: 0.4383 - val_accuracy: 0.8006 - 534ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4293 - accuracy: 0.7990 - val_loss: 0.4396 - val_accuracy: 0.8004 - 588ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4303 - accuracy: 0.7980 - val_loss: 0.4363 - val_accuracy: 0.8025 - 519ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4294 - accuracy: 0.7993 - val_loss: 0.4370 - val_accuracy: 0.8021 - 531ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4291 - accuracy: 0.7997 - val_loss: 0.4361 - val_accuracy: 0.8019 - 566ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4294 - accuracy: 0.7983 - val_loss: 0.4397 - val_accuracy: 0.8015 - 538ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4284 - accuracy: 0.7997 - val_loss: 0.4391 - val_accuracy: 0.8021 - 573ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4277 - accuracy: 0.7993 - val_loss: 0.4390 - val_accuracy: 0.8019 - 550ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4273 - accuracy: 0.8005 - val_loss: 0.4370 - val_accuracy: 0.8032 - 536ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4284 - accuracy: 0.7987 - val_loss: 0.4396 - val_accuracy: 0.8015 - 580ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4260 - accuracy: 0.8008 - val_loss: 0.4357 - val_accuracy: 0.8006 - 540ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4270 - accuracy: 0.7985 - val_loss: 0.4413 - val_accuracy: 0.7972 - 553ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4263 - accuracy: 0.8001 - val_loss: 0.4349 - val_accuracy: 0.8012 - 541ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4248 - accuracy: 0.8009 - val_loss: 0.4340 - val_accuracy: 0.8012 - 563ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4260 - accuracy: 0.8011 - val_loss: 0.4381 - val_accuracy: 0.7991 - 541ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4251 - accuracy: 0.8016 - val_loss: 0.4340 - val_accuracy: 0.8034 - 567ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4257 - accuracy: 0.8000 - val_loss: 0.4391 - val_accuracy: 0.7953 - 535ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.4340 - val_accuracy: 0.8029 - 539ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4242 - accuracy: 0.8015 - val_loss: 0.4334 - val_accuracy: 0.8015 - 559ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4244 - accuracy: 0.8007 - val_loss: 0.4345 - val_accuracy: 0.8015 - 564ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4263 - accuracy: 0.7977 - val_loss: 0.4334 - val_accuracy: 0.8017 - 551ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4239 - accuracy: 0.8012 - val_loss: 0.4330 - val_accuracy: 0.8017 - 547ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4245 - accuracy: 0.7998 - val_loss: 0.4327 - val_accuracy: 0.8021 - 554ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4238 - accuracy: 0.8006 - val_loss: 0.4343 - val_accuracy: 0.8025 - 564ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4240 - accuracy: 0.7999 - val_loss: 0.4369 - val_accuracy: 0.8017 - 538ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.4352 - val_accuracy: 0.8010 - 557ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4238 - accuracy: 0.8012 - val_loss: 0.4347 - val_accuracy: 0.8021 - 561ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.8005 - val_loss: 0.4347 - val_accuracy: 0.8017 - 573ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4244 - accuracy: 0.8020 - val_loss: 0.4328 - val_accuracy: 0.7993 - 609ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4238 - accuracy: 0.7992 - val_loss: 0.4365 - val_accuracy: 0.7985 - 568ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4231 - accuracy: 0.8006 - val_loss: 0.4340 - val_accuracy: 0.8034 - 544ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.7991 - val_loss: 0.4322 - val_accuracy: 0.8017 - 570ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4239 - accuracy: 0.8005 - val_loss: 0.4372 - val_accuracy: 0.7936 - 573ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 1s - loss: 0.4245 - accuracy: 0.7988 - val_loss: 0.4326 - val_accuracy: 0.8015 - 559ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4231 - accuracy: 0.7996 - val_loss: 0.4327 - val_accuracy: 0.8019 - 561ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "74/74 - 1s - loss: 0.4239 - accuracy: 0.8001 - val_loss: 0.4329 - val_accuracy: 0.8015 - 556ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "74/74 - 1s - loss: 0.4233 - accuracy: 0.8012 - val_loss: 0.4375 - val_accuracy: 0.7951 - 538ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "74/74 - 1s - loss: 0.4248 - accuracy: 0.8002 - val_loss: 0.4337 - val_accuracy: 0.8004 - 545ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "74/74 - 1s - loss: 0.4229 - accuracy: 0.8012 - val_loss: 0.4331 - val_accuracy: 0.8015 - 561ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "74/74 - 1s - loss: 0.4244 - accuracy: 0.7991 - val_loss: 0.4330 - val_accuracy: 0.8012 - 561ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.7999 - val_loss: 0.4338 - val_accuracy: 0.8034 - 595ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "74/74 - 1s - loss: 0.4237 - accuracy: 0.7992 - val_loss: 0.4324 - val_accuracy: 0.8012 - 645ms/epoch - 9ms/step\n",
      "Epoch 50: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 2.8734 - accuracy: 0.7524 - val_loss: 2.0355 - val_accuracy: 0.7643 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 1.5446 - accuracy: 0.7622 - val_loss: 1.1370 - val_accuracy: 0.7835 - 646ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.9049 - accuracy: 0.7907 - val_loss: 0.7248 - val_accuracy: 0.8015 - 548ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.6209 - accuracy: 0.8001 - val_loss: 0.5484 - val_accuracy: 0.8025 - 511ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.5027 - accuracy: 0.8004 - val_loss: 0.4787 - val_accuracy: 0.8027 - 537ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4578 - accuracy: 0.8000 - val_loss: 0.4512 - val_accuracy: 0.8023 - 576ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4414 - accuracy: 0.7998 - val_loss: 0.4451 - val_accuracy: 0.8019 - 506ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4330 - accuracy: 0.8001 - val_loss: 0.4429 - val_accuracy: 0.8036 - 563ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 0s - loss: 0.4309 - accuracy: 0.8006 - val_loss: 0.4386 - val_accuracy: 0.8029 - 491ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 0s - loss: 0.4302 - accuracy: 0.8007 - val_loss: 0.4369 - val_accuracy: 0.8025 - 496ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4285 - accuracy: 0.8012 - val_loss: 0.4361 - val_accuracy: 0.8019 - 536ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4279 - accuracy: 0.8010 - val_loss: 0.4362 - val_accuracy: 0.8032 - 531ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4273 - accuracy: 0.8002 - val_loss: 0.4352 - val_accuracy: 0.8012 - 551ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4278 - accuracy: 0.8005 - val_loss: 0.4344 - val_accuracy: 0.8010 - 537ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4264 - accuracy: 0.8004 - val_loss: 0.4375 - val_accuracy: 0.8021 - 569ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4263 - accuracy: 0.8008 - val_loss: 0.4352 - val_accuracy: 0.8015 - 553ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4266 - accuracy: 0.7994 - val_loss: 0.4348 - val_accuracy: 0.8021 - 544ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4259 - accuracy: 0.8014 - val_loss: 0.4362 - val_accuracy: 0.8015 - 548ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4255 - accuracy: 0.8007 - val_loss: 0.4333 - val_accuracy: 0.8019 - 534ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4247 - accuracy: 0.8011 - val_loss: 0.4337 - val_accuracy: 0.8015 - 581ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4259 - accuracy: 0.8013 - val_loss: 0.4326 - val_accuracy: 0.8015 - 556ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4260 - accuracy: 0.7990 - val_loss: 0.4325 - val_accuracy: 0.8015 - 554ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4266 - accuracy: 0.7992 - val_loss: 0.4419 - val_accuracy: 0.8015 - 555ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4266 - accuracy: 0.7995 - val_loss: 0.4343 - val_accuracy: 0.8015 - 534ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.8004 - val_loss: 0.4417 - val_accuracy: 0.7991 - 527ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4257 - accuracy: 0.7990 - val_loss: 0.4331 - val_accuracy: 0.8015 - 550ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4259 - accuracy: 0.7984 - val_loss: 0.4326 - val_accuracy: 0.8010 - 531ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4325 - val_accuracy: 0.8025 - 527ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4246 - accuracy: 0.8010 - val_loss: 0.4326 - val_accuracy: 0.8023 - 539ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4240 - accuracy: 0.8013 - val_loss: 0.4321 - val_accuracy: 0.8017 - 552ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4240 - accuracy: 0.8006 - val_loss: 0.4316 - val_accuracy: 0.8017 - 600ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4253 - accuracy: 0.7992 - val_loss: 0.4323 - val_accuracy: 0.8021 - 578ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4239 - accuracy: 0.7997 - val_loss: 0.4322 - val_accuracy: 0.8021 - 534ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4242 - accuracy: 0.8001 - val_loss: 0.4319 - val_accuracy: 0.8025 - 559ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4228 - accuracy: 0.8011 - val_loss: 0.4331 - val_accuracy: 0.8010 - 550ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4246 - accuracy: 0.8001 - val_loss: 0.4320 - val_accuracy: 0.8023 - 589ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4234 - accuracy: 0.8011 - val_loss: 0.4327 - val_accuracy: 0.8023 - 568ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4234 - accuracy: 0.8007 - val_loss: 0.4319 - val_accuracy: 0.8023 - 553ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4242 - accuracy: 0.7998 - val_loss: 0.4318 - val_accuracy: 0.8017 - 593ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4228 - accuracy: 0.8006 - val_loss: 0.4329 - val_accuracy: 0.8019 - 550ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4238 - accuracy: 0.8015 - val_loss: 0.4323 - val_accuracy: 0.8025 - 545ms/epoch - 7ms/step\n",
      "Epoch 41: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 2.9573 - accuracy: 0.7076 - val_loss: 2.0847 - val_accuracy: 0.7643 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 1.5784 - accuracy: 0.7591 - val_loss: 1.1629 - val_accuracy: 0.7686 - 595ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.9273 - accuracy: 0.7822 - val_loss: 0.7385 - val_accuracy: 0.7959 - 514ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.6335 - accuracy: 0.7976 - val_loss: 0.5567 - val_accuracy: 0.8006 - 579ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.5100 - accuracy: 0.8001 - val_loss: 0.4831 - val_accuracy: 0.8017 - 558ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4612 - accuracy: 0.7999 - val_loss: 0.4564 - val_accuracy: 0.8021 - 519ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 0s - loss: 0.4420 - accuracy: 0.8005 - val_loss: 0.4466 - val_accuracy: 0.8008 - 496ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4357 - accuracy: 0.8000 - val_loss: 0.4432 - val_accuracy: 0.8036 - 545ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4337 - accuracy: 0.8007 - val_loss: 0.4417 - val_accuracy: 0.8027 - 513ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4307 - accuracy: 0.8007 - val_loss: 0.4382 - val_accuracy: 0.8006 - 512ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4292 - accuracy: 0.8009 - val_loss: 0.4376 - val_accuracy: 0.8015 - 515ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4291 - accuracy: 0.8001 - val_loss: 0.4395 - val_accuracy: 0.8002 - 528ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 0s - loss: 0.4324 - accuracy: 0.7965 - val_loss: 0.4385 - val_accuracy: 0.8015 - 494ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4284 - accuracy: 0.8008 - val_loss: 0.4441 - val_accuracy: 0.7987 - 509ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4281 - accuracy: 0.7999 - val_loss: 0.4368 - val_accuracy: 0.8004 - 526ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4280 - accuracy: 0.8011 - val_loss: 0.4350 - val_accuracy: 0.8006 - 521ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4269 - accuracy: 0.8016 - val_loss: 0.4349 - val_accuracy: 0.8023 - 538ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4271 - accuracy: 0.8008 - val_loss: 0.4395 - val_accuracy: 0.8034 - 526ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4265 - accuracy: 0.8001 - val_loss: 0.4334 - val_accuracy: 0.8010 - 527ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4262 - accuracy: 0.8012 - val_loss: 0.4356 - val_accuracy: 0.8002 - 531ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4276 - accuracy: 0.8001 - val_loss: 0.4362 - val_accuracy: 0.8017 - 529ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4269 - accuracy: 0.8001 - val_loss: 0.4369 - val_accuracy: 0.8002 - 539ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4268 - accuracy: 0.8001 - val_loss: 0.4338 - val_accuracy: 0.8032 - 571ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4256 - accuracy: 0.8008 - val_loss: 0.4345 - val_accuracy: 0.8008 - 590ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4250 - accuracy: 0.8000 - val_loss: 0.4347 - val_accuracy: 0.8015 - 516ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4242 - accuracy: 0.8005 - val_loss: 0.4357 - val_accuracy: 0.8002 - 540ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.8012 - val_loss: 0.4338 - val_accuracy: 0.8015 - 527ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4242 - accuracy: 0.8006 - val_loss: 0.4424 - val_accuracy: 0.7972 - 531ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4246 - accuracy: 0.8000 - val_loss: 0.4340 - val_accuracy: 0.8017 - 543ms/epoch - 7ms/step\n",
      "Epoch 29: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 2.8519 - accuracy: 0.7369 - val_loss: 2.0019 - val_accuracy: 0.7643 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 1.5045 - accuracy: 0.7624 - val_loss: 1.0989 - val_accuracy: 0.7840 - 506ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.8745 - accuracy: 0.7960 - val_loss: 0.7025 - val_accuracy: 0.8008 - 535ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.6046 - accuracy: 0.8003 - val_loss: 0.5372 - val_accuracy: 0.8023 - 531ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4941 - accuracy: 0.8005 - val_loss: 0.4730 - val_accuracy: 0.8012 - 539ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4520 - accuracy: 0.8012 - val_loss: 0.4489 - val_accuracy: 0.8027 - 526ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4389 - accuracy: 0.7994 - val_loss: 0.4414 - val_accuracy: 0.8021 - 532ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4320 - accuracy: 0.8012 - val_loss: 0.4379 - val_accuracy: 0.8021 - 543ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4295 - accuracy: 0.8002 - val_loss: 0.4366 - val_accuracy: 0.8027 - 580ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4291 - accuracy: 0.8011 - val_loss: 0.4388 - val_accuracy: 0.7980 - 535ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4283 - accuracy: 0.8009 - val_loss: 0.4369 - val_accuracy: 0.8019 - 529ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4277 - accuracy: 0.8000 - val_loss: 0.4346 - val_accuracy: 0.8021 - 528ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4263 - accuracy: 0.8013 - val_loss: 0.4350 - val_accuracy: 0.8015 - 511ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4270 - accuracy: 0.8000 - val_loss: 0.4339 - val_accuracy: 0.8029 - 558ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4268 - accuracy: 0.7999 - val_loss: 0.4337 - val_accuracy: 0.8025 - 554ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4258 - accuracy: 0.8006 - val_loss: 0.4370 - val_accuracy: 0.8019 - 518ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4258 - accuracy: 0.8012 - val_loss: 0.4343 - val_accuracy: 0.8017 - 579ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4263 - accuracy: 0.8022 - val_loss: 0.4347 - val_accuracy: 0.8021 - 536ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4255 - accuracy: 0.8018 - val_loss: 0.4325 - val_accuracy: 0.8025 - 544ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4262 - accuracy: 0.7997 - val_loss: 0.4320 - val_accuracy: 0.8032 - 544ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4248 - accuracy: 0.8019 - val_loss: 0.4333 - val_accuracy: 0.8023 - 674ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4253 - accuracy: 0.8002 - val_loss: 0.4360 - val_accuracy: 0.8053 - 648ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4247 - accuracy: 0.8004 - val_loss: 0.4340 - val_accuracy: 0.8036 - 555ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.8011 - val_loss: 0.4379 - val_accuracy: 0.8021 - 517ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4241 - accuracy: 0.8004 - val_loss: 0.4328 - val_accuracy: 0.8010 - 526ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 0s - loss: 0.4236 - accuracy: 0.8003 - val_loss: 0.4414 - val_accuracy: 0.7978 - 496ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4257 - accuracy: 0.8005 - val_loss: 0.4337 - val_accuracy: 0.8021 - 531ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4251 - accuracy: 0.8000 - val_loss: 0.4360 - val_accuracy: 0.7951 - 543ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4245 - accuracy: 0.8004 - val_loss: 0.4329 - val_accuracy: 0.8023 - 572ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4239 - accuracy: 0.8011 - val_loss: 0.4356 - val_accuracy: 0.8017 - 520ms/epoch - 7ms/step\n",
      "Epoch 30: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 2.9056 - accuracy: 0.7289 - val_loss: 2.0510 - val_accuracy: 0.7643 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 1.5559 - accuracy: 0.7588 - val_loss: 1.1488 - val_accuracy: 0.7643 - 574ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.9173 - accuracy: 0.7734 - val_loss: 0.7319 - val_accuracy: 0.7936 - 609ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.6294 - accuracy: 0.7956 - val_loss: 0.5546 - val_accuracy: 0.8027 - 549ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.5074 - accuracy: 0.8003 - val_loss: 0.4818 - val_accuracy: 0.8021 - 565ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4601 - accuracy: 0.8004 - val_loss: 0.4531 - val_accuracy: 0.8021 - 565ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4412 - accuracy: 0.7996 - val_loss: 0.4458 - val_accuracy: 0.8012 - 570ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4360 - accuracy: 0.7992 - val_loss: 0.4417 - val_accuracy: 0.8000 - 559ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4316 - accuracy: 0.8004 - val_loss: 0.4391 - val_accuracy: 0.8019 - 529ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.4461 - val_accuracy: 0.7968 - 552ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4302 - accuracy: 0.8002 - val_loss: 0.4368 - val_accuracy: 0.8019 - 519ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4298 - accuracy: 0.8007 - val_loss: 0.4383 - val_accuracy: 0.8021 - 524ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.4355 - val_accuracy: 0.8019 - 539ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4285 - accuracy: 0.8004 - val_loss: 0.4358 - val_accuracy: 0.8021 - 565ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4279 - accuracy: 0.7993 - val_loss: 0.4349 - val_accuracy: 0.8012 - 511ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4271 - accuracy: 0.8005 - val_loss: 0.4350 - val_accuracy: 0.8008 - 547ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4261 - accuracy: 0.7997 - val_loss: 0.4476 - val_accuracy: 0.7929 - 518ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4282 - accuracy: 0.8006 - val_loss: 0.4351 - val_accuracy: 0.8023 - 582ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4278 - accuracy: 0.8006 - val_loss: 0.4343 - val_accuracy: 0.8019 - 541ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4260 - accuracy: 0.8006 - val_loss: 0.4339 - val_accuracy: 0.8027 - 532ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4262 - accuracy: 0.8012 - val_loss: 0.4342 - val_accuracy: 0.8015 - 563ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4261 - accuracy: 0.8001 - val_loss: 0.4339 - val_accuracy: 0.8010 - 544ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4266 - accuracy: 0.8005 - val_loss: 0.4339 - val_accuracy: 0.8019 - 590ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 0s - loss: 0.4256 - accuracy: 0.7998 - val_loss: 0.4333 - val_accuracy: 0.8002 - 498ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4258 - accuracy: 0.8011 - val_loss: 0.4348 - val_accuracy: 0.8019 - 514ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.8012 - val_loss: 0.4358 - val_accuracy: 0.8027 - 546ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4252 - accuracy: 0.8010 - val_loss: 0.4353 - val_accuracy: 0.8008 - 540ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4248 - accuracy: 0.8001 - val_loss: 0.4336 - val_accuracy: 0.8008 - 521ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.4325 - val_accuracy: 0.8017 - 557ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4252 - accuracy: 0.8004 - val_loss: 0.4365 - val_accuracy: 0.8029 - 566ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4256 - accuracy: 0.7998 - val_loss: 0.4346 - val_accuracy: 0.8023 - 543ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.8001 - val_loss: 0.4337 - val_accuracy: 0.8019 - 563ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4250 - accuracy: 0.8008 - val_loss: 0.4329 - val_accuracy: 0.8015 - 559ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4241 - accuracy: 0.8017 - val_loss: 0.4345 - val_accuracy: 0.8017 - 573ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4241 - accuracy: 0.8020 - val_loss: 0.4329 - val_accuracy: 0.8006 - 595ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.4343 - val_accuracy: 0.8010 - 542ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4242 - accuracy: 0.7997 - val_loss: 0.4362 - val_accuracy: 0.8038 - 554ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4246 - accuracy: 0.7995 - val_loss: 0.4316 - val_accuracy: 0.8021 - 559ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4261 - accuracy: 0.7988 - val_loss: 0.4369 - val_accuracy: 0.7957 - 526ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4253 - accuracy: 0.7997 - val_loss: 0.4325 - val_accuracy: 0.8027 - 508ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4251 - accuracy: 0.8004 - val_loss: 0.4345 - val_accuracy: 0.8032 - 573ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 1s - loss: 0.4243 - accuracy: 0.8000 - val_loss: 0.4362 - val_accuracy: 0.8034 - 540ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4238 - accuracy: 0.8015 - val_loss: 0.4320 - val_accuracy: 0.8008 - 546ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "74/74 - 1s - loss: 0.4239 - accuracy: 0.8003 - val_loss: 0.4341 - val_accuracy: 0.8002 - 546ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "74/74 - 1s - loss: 0.4240 - accuracy: 0.8001 - val_loss: 0.4319 - val_accuracy: 0.8012 - 572ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "74/74 - 1s - loss: 0.4237 - accuracy: 0.8003 - val_loss: 0.4354 - val_accuracy: 0.8010 - 526ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.8005 - val_loss: 0.4324 - val_accuracy: 0.8027 - 545ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "74/74 - 1s - loss: 0.4240 - accuracy: 0.7993 - val_loss: 0.4350 - val_accuracy: 0.8034 - 540ms/epoch - 7ms/step\n",
      "Epoch 48: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 2.7530 - accuracy: 0.7170 - val_loss: 1.9277 - val_accuracy: 0.7643 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 1.4686 - accuracy: 0.7588 - val_loss: 1.0890 - val_accuracy: 0.7643 - 558ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.8746 - accuracy: 0.7672 - val_loss: 0.7018 - val_accuracy: 0.7887 - 531ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.6063 - accuracy: 0.7952 - val_loss: 0.5408 - val_accuracy: 0.7970 - 580ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4969 - accuracy: 0.7992 - val_loss: 0.4750 - val_accuracy: 0.8015 - 534ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4560 - accuracy: 0.7999 - val_loss: 0.4563 - val_accuracy: 0.8019 - 560ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4398 - accuracy: 0.8001 - val_loss: 0.4431 - val_accuracy: 0.8027 - 561ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4340 - accuracy: 0.7996 - val_loss: 0.4384 - val_accuracy: 0.8021 - 568ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4304 - accuracy: 0.8005 - val_loss: 0.4379 - val_accuracy: 0.8017 - 535ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4303 - accuracy: 0.7991 - val_loss: 0.4369 - val_accuracy: 0.8015 - 551ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4294 - accuracy: 0.8013 - val_loss: 0.4357 - val_accuracy: 0.8027 - 530ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4281 - accuracy: 0.8001 - val_loss: 0.4356 - val_accuracy: 0.8008 - 521ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4282 - accuracy: 0.8007 - val_loss: 0.4363 - val_accuracy: 0.8055 - 531ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4268 - accuracy: 0.8004 - val_loss: 0.4350 - val_accuracy: 0.8021 - 554ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4277 - accuracy: 0.8009 - val_loss: 0.4365 - val_accuracy: 0.8023 - 548ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4269 - accuracy: 0.8007 - val_loss: 0.4375 - val_accuracy: 0.8006 - 544ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4271 - accuracy: 0.7993 - val_loss: 0.4351 - val_accuracy: 0.8019 - 528ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4268 - accuracy: 0.7995 - val_loss: 0.4365 - val_accuracy: 0.8010 - 536ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4260 - accuracy: 0.8013 - val_loss: 0.4339 - val_accuracy: 0.8006 - 567ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4256 - accuracy: 0.8013 - val_loss: 0.4347 - val_accuracy: 0.8017 - 523ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.8008 - val_loss: 0.4330 - val_accuracy: 0.8019 - 585ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4252 - accuracy: 0.8012 - val_loss: 0.4340 - val_accuracy: 0.8023 - 555ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4259 - accuracy: 0.8002 - val_loss: 0.4354 - val_accuracy: 0.8004 - 539ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4261 - accuracy: 0.8013 - val_loss: 0.4338 - val_accuracy: 0.8012 - 531ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4244 - accuracy: 0.8013 - val_loss: 0.4321 - val_accuracy: 0.8012 - 540ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4248 - accuracy: 0.8011 - val_loss: 0.4334 - val_accuracy: 0.8010 - 598ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4243 - accuracy: 0.8013 - val_loss: 0.4349 - val_accuracy: 0.8012 - 535ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4244 - accuracy: 0.7998 - val_loss: 0.4339 - val_accuracy: 0.8025 - 554ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4248 - accuracy: 0.8004 - val_loss: 0.4325 - val_accuracy: 0.8044 - 544ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.8004 - val_loss: 0.4324 - val_accuracy: 0.8012 - 539ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4250 - accuracy: 0.8000 - val_loss: 0.4323 - val_accuracy: 0.8027 - 545ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4253 - accuracy: 0.8007 - val_loss: 0.4363 - val_accuracy: 0.8010 - 535ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4243 - accuracy: 0.8006 - val_loss: 0.4317 - val_accuracy: 0.8015 - 531ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4255 - accuracy: 0.7996 - val_loss: 0.4320 - val_accuracy: 0.8017 - 532ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4253 - accuracy: 0.7998 - val_loss: 0.4326 - val_accuracy: 0.8006 - 559ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4242 - accuracy: 0.8000 - val_loss: 0.4335 - val_accuracy: 0.8021 - 547ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4233 - accuracy: 0.8008 - val_loss: 0.4313 - val_accuracy: 0.8015 - 562ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4246 - accuracy: 0.7989 - val_loss: 0.4347 - val_accuracy: 0.8025 - 539ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4270 - accuracy: 0.7987 - val_loss: 0.4329 - val_accuracy: 0.8006 - 530ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4233 - accuracy: 0.8010 - val_loss: 0.4353 - val_accuracy: 0.8015 - 599ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4244 - accuracy: 0.8001 - val_loss: 0.4360 - val_accuracy: 0.8019 - 524ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 1s - loss: 0.4235 - accuracy: 0.8000 - val_loss: 0.4309 - val_accuracy: 0.8019 - 507ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4233 - accuracy: 0.8006 - val_loss: 0.4317 - val_accuracy: 0.8029 - 557ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "74/74 - 1s - loss: 0.4251 - accuracy: 0.7993 - val_loss: 0.4382 - val_accuracy: 0.7974 - 549ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "74/74 - 1s - loss: 0.4237 - accuracy: 0.8004 - val_loss: 0.4334 - val_accuracy: 0.8019 - 636ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "74/74 - 1s - loss: 0.4233 - accuracy: 0.8014 - val_loss: 0.4318 - val_accuracy: 0.8019 - 579ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "74/74 - 1s - loss: 0.4237 - accuracy: 0.8017 - val_loss: 0.4329 - val_accuracy: 0.8029 - 529ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "74/74 - 1s - loss: 0.4227 - accuracy: 0.8000 - val_loss: 0.4309 - val_accuracy: 0.8012 - 537ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.7990 - val_loss: 0.4322 - val_accuracy: 0.8002 - 551ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.7992 - val_loss: 0.4323 - val_accuracy: 0.8017 - 543ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "74/74 - 1s - loss: 0.4237 - accuracy: 0.7989 - val_loss: 0.4311 - val_accuracy: 0.8019 - 525ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "74/74 - 1s - loss: 0.4238 - accuracy: 0.8004 - val_loss: 0.4336 - val_accuracy: 0.7987 - 563ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "74/74 - 1s - loss: 0.4224 - accuracy: 0.8002 - val_loss: 0.4357 - val_accuracy: 0.8057 - 547ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "74/74 - 1s - loss: 0.4228 - accuracy: 0.8007 - val_loss: 0.4320 - val_accuracy: 0.8027 - 514ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "74/74 - 1s - loss: 0.4227 - accuracy: 0.8009 - val_loss: 0.4315 - val_accuracy: 0.8006 - 587ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "74/74 - 1s - loss: 0.4234 - accuracy: 0.8005 - val_loss: 0.4340 - val_accuracy: 0.8040 - 515ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "74/74 - 1s - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.4310 - val_accuracy: 0.8019 - 547ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "74/74 - 1s - loss: 0.4227 - accuracy: 0.8010 - val_loss: 0.4316 - val_accuracy: 0.8008 - 544ms/epoch - 7ms/step\n",
      "Epoch 58: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 2.7967 - accuracy: 0.7041 - val_loss: 1.9573 - val_accuracy: 0.7643 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 1.4862 - accuracy: 0.7591 - val_loss: 1.0979 - val_accuracy: 0.7686 - 624ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.8782 - accuracy: 0.7837 - val_loss: 0.7043 - val_accuracy: 0.7974 - 546ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.6077 - accuracy: 0.7994 - val_loss: 0.5395 - val_accuracy: 0.8023 - 540ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4977 - accuracy: 0.8003 - val_loss: 0.4756 - val_accuracy: 0.8025 - 571ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4553 - accuracy: 0.8003 - val_loss: 0.4514 - val_accuracy: 0.8017 - 631ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4399 - accuracy: 0.7996 - val_loss: 0.4425 - val_accuracy: 0.8010 - 598ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4341 - accuracy: 0.7998 - val_loss: 0.4444 - val_accuracy: 0.7955 - 615ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4312 - accuracy: 0.8004 - val_loss: 0.4378 - val_accuracy: 0.8021 - 596ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4293 - accuracy: 0.8007 - val_loss: 0.4386 - val_accuracy: 0.8032 - 638ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4277 - accuracy: 0.8007 - val_loss: 0.4354 - val_accuracy: 0.8017 - 619ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4280 - accuracy: 0.8009 - val_loss: 0.4378 - val_accuracy: 0.8040 - 504ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4290 - accuracy: 0.7995 - val_loss: 0.4375 - val_accuracy: 0.8000 - 506ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4277 - accuracy: 0.8005 - val_loss: 0.4347 - val_accuracy: 0.8015 - 614ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4261 - accuracy: 0.8015 - val_loss: 0.4345 - val_accuracy: 0.8012 - 587ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4276 - accuracy: 0.7998 - val_loss: 0.4374 - val_accuracy: 0.7993 - 519ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4281 - accuracy: 0.7996 - val_loss: 0.4339 - val_accuracy: 0.8012 - 544ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4274 - accuracy: 0.7992 - val_loss: 0.4331 - val_accuracy: 0.8019 - 516ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4260 - accuracy: 0.8008 - val_loss: 0.4333 - val_accuracy: 0.8017 - 550ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4258 - accuracy: 0.8014 - val_loss: 0.4334 - val_accuracy: 0.8008 - 550ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4250 - accuracy: 0.8010 - val_loss: 0.4350 - val_accuracy: 0.8021 - 542ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4252 - accuracy: 0.7997 - val_loss: 0.4371 - val_accuracy: 0.8015 - 525ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4251 - accuracy: 0.8007 - val_loss: 0.4358 - val_accuracy: 0.8015 - 569ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.4352 - val_accuracy: 0.8010 - 540ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.4350 - val_accuracy: 0.8010 - 548ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4242 - accuracy: 0.8000 - val_loss: 0.4366 - val_accuracy: 0.8044 - 566ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 0s - loss: 0.4235 - accuracy: 0.8005 - val_loss: 0.4345 - val_accuracy: 0.8012 - 494ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4352 - val_accuracy: 0.8019 - 551ms/epoch - 7ms/step\n",
      "Epoch 28: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 2.9693 - accuracy: 0.7260 - val_loss: 2.1001 - val_accuracy: 0.7643 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 1.5948 - accuracy: 0.7617 - val_loss: 1.1758 - val_accuracy: 0.7761 - 588ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.9330 - accuracy: 0.7848 - val_loss: 0.7387 - val_accuracy: 0.7955 - 548ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.6312 - accuracy: 0.7949 - val_loss: 0.5537 - val_accuracy: 0.8019 - 517ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.5076 - accuracy: 0.7989 - val_loss: 0.4816 - val_accuracy: 0.8032 - 558ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4595 - accuracy: 0.7996 - val_loss: 0.4553 - val_accuracy: 0.7993 - 559ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4416 - accuracy: 0.8006 - val_loss: 0.4443 - val_accuracy: 0.8023 - 522ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4355 - accuracy: 0.7995 - val_loss: 0.4404 - val_accuracy: 0.8025 - 559ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4317 - accuracy: 0.8008 - val_loss: 0.4386 - val_accuracy: 0.8017 - 503ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4306 - accuracy: 0.7995 - val_loss: 0.4409 - val_accuracy: 0.7978 - 505ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4304 - accuracy: 0.8000 - val_loss: 0.4478 - val_accuracy: 0.7929 - 537ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4302 - accuracy: 0.7995 - val_loss: 0.4369 - val_accuracy: 0.8025 - 571ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4289 - accuracy: 0.8010 - val_loss: 0.4377 - val_accuracy: 0.8029 - 541ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4273 - accuracy: 0.8009 - val_loss: 0.4387 - val_accuracy: 0.8015 - 516ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4289 - accuracy: 0.7995 - val_loss: 0.4417 - val_accuracy: 0.7953 - 567ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4284 - accuracy: 0.8000 - val_loss: 0.4351 - val_accuracy: 0.8015 - 522ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4272 - accuracy: 0.8007 - val_loss: 0.4358 - val_accuracy: 0.8023 - 516ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4267 - accuracy: 0.8013 - val_loss: 0.4369 - val_accuracy: 0.8025 - 529ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4262 - accuracy: 0.8008 - val_loss: 0.4353 - val_accuracy: 0.8025 - 547ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4260 - accuracy: 0.8004 - val_loss: 0.4369 - val_accuracy: 0.8025 - 590ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.4341 - val_accuracy: 0.8004 - 560ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4248 - accuracy: 0.8009 - val_loss: 0.4348 - val_accuracy: 0.8034 - 533ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4253 - accuracy: 0.8001 - val_loss: 0.4351 - val_accuracy: 0.8017 - 533ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.7998 - val_loss: 0.4346 - val_accuracy: 0.8044 - 609ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4247 - accuracy: 0.8006 - val_loss: 0.4331 - val_accuracy: 0.8027 - 531ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4251 - accuracy: 0.8006 - val_loss: 0.4341 - val_accuracy: 0.8008 - 522ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4248 - accuracy: 0.8008 - val_loss: 0.4334 - val_accuracy: 0.8027 - 559ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4244 - accuracy: 0.8001 - val_loss: 0.4334 - val_accuracy: 0.8008 - 537ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4256 - accuracy: 0.7998 - val_loss: 0.4349 - val_accuracy: 0.8027 - 519ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4267 - accuracy: 0.7981 - val_loss: 0.4364 - val_accuracy: 0.7965 - 539ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4246 - accuracy: 0.8008 - val_loss: 0.4329 - val_accuracy: 0.8023 - 502ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4250 - accuracy: 0.8008 - val_loss: 0.4350 - val_accuracy: 0.8019 - 567ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.8017 - val_loss: 0.4333 - val_accuracy: 0.8038 - 559ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4239 - accuracy: 0.7995 - val_loss: 0.4323 - val_accuracy: 0.8008 - 510ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.8017 - val_loss: 0.4366 - val_accuracy: 0.8046 - 577ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4235 - accuracy: 0.8008 - val_loss: 0.4334 - val_accuracy: 0.8023 - 560ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4241 - accuracy: 0.8007 - val_loss: 0.4335 - val_accuracy: 0.8032 - 540ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4235 - accuracy: 0.8006 - val_loss: 0.4341 - val_accuracy: 0.7976 - 523ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4232 - accuracy: 0.8000 - val_loss: 0.4347 - val_accuracy: 0.8019 - 572ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4273 - accuracy: 0.7978 - val_loss: 0.4379 - val_accuracy: 0.8017 - 526ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4249 - accuracy: 0.7996 - val_loss: 0.4321 - val_accuracy: 0.8017 - 575ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 1s - loss: 0.4234 - accuracy: 0.7998 - val_loss: 0.4347 - val_accuracy: 0.8008 - 536ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4240 - accuracy: 0.8000 - val_loss: 0.4325 - val_accuracy: 0.8010 - 529ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "74/74 - 1s - loss: 0.4228 - accuracy: 0.8004 - val_loss: 0.4313 - val_accuracy: 0.8027 - 551ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "74/74 - 1s - loss: 0.4230 - accuracy: 0.8011 - val_loss: 0.4324 - val_accuracy: 0.8012 - 538ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "74/74 - 1s - loss: 0.4234 - accuracy: 0.7995 - val_loss: 0.4322 - val_accuracy: 0.7993 - 527ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "74/74 - 1s - loss: 0.4240 - accuracy: 0.8001 - val_loss: 0.4367 - val_accuracy: 0.7983 - 540ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "74/74 - 1s - loss: 0.4231 - accuracy: 0.8003 - val_loss: 0.4346 - val_accuracy: 0.8023 - 548ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "74/74 - 1s - loss: 0.4226 - accuracy: 0.8020 - val_loss: 0.4331 - val_accuracy: 0.8012 - 549ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "74/74 - 1s - loss: 0.4224 - accuracy: 0.8009 - val_loss: 0.4321 - val_accuracy: 0.8000 - 599ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "74/74 - 1s - loss: 0.4236 - accuracy: 0.7984 - val_loss: 0.4334 - val_accuracy: 0.8023 - 548ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "74/74 - 1s - loss: 0.4248 - accuracy: 0.7982 - val_loss: 0.4322 - val_accuracy: 0.8017 - 560ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "74/74 - 1s - loss: 0.4229 - accuracy: 0.8022 - val_loss: 0.4346 - val_accuracy: 0.8025 - 530ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "74/74 - 1s - loss: 0.4232 - accuracy: 0.8003 - val_loss: 0.4319 - val_accuracy: 0.7989 - 549ms/epoch - 7ms/step\n",
      "Epoch 54: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.44274364391730997\n",
      "epi entropy:  0.4185807097705979\n",
      "\n",
      "dataset size:  0.7\n",
      "Epoch 1/100\n",
      "86/86 - 3s - loss: 2.8499 - accuracy: 0.6611 - val_loss: 1.9175 - val_accuracy: 0.7637 - 3s/epoch - 30ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 1.4055 - accuracy: 0.7615 - val_loss: 1.0039 - val_accuracy: 0.7686 - 640ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.7908 - accuracy: 0.7954 - val_loss: 0.6334 - val_accuracy: 0.7938 - 602ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.5528 - accuracy: 0.8032 - val_loss: 0.4986 - val_accuracy: 0.8006 - 630ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4689 - accuracy: 0.8052 - val_loss: 0.4543 - val_accuracy: 0.8008 - 631ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4417 - accuracy: 0.8048 - val_loss: 0.4396 - val_accuracy: 0.8008 - 716ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4327 - accuracy: 0.8053 - val_loss: 0.4393 - val_accuracy: 0.8000 - 779ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4291 - accuracy: 0.8046 - val_loss: 0.4331 - val_accuracy: 0.7997 - 668ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4277 - accuracy: 0.8046 - val_loss: 0.4321 - val_accuracy: 0.7999 - 590ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4268 - accuracy: 0.8054 - val_loss: 0.4313 - val_accuracy: 0.8006 - 630ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4280 - accuracy: 0.8055 - val_loss: 0.4305 - val_accuracy: 0.8015 - 669ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4249 - accuracy: 0.8060 - val_loss: 0.4285 - val_accuracy: 0.8017 - 590ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4262 - accuracy: 0.8053 - val_loss: 0.4294 - val_accuracy: 0.8017 - 608ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4255 - accuracy: 0.8045 - val_loss: 0.4327 - val_accuracy: 0.8008 - 616ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4247 - accuracy: 0.8047 - val_loss: 0.4285 - val_accuracy: 0.7993 - 590ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4236 - accuracy: 0.8049 - val_loss: 0.4289 - val_accuracy: 0.8022 - 613ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4236 - accuracy: 0.8042 - val_loss: 0.4312 - val_accuracy: 0.8011 - 667ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4242 - accuracy: 0.8035 - val_loss: 0.4287 - val_accuracy: 0.8002 - 690ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4245 - accuracy: 0.8042 - val_loss: 0.4281 - val_accuracy: 0.8022 - 903ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4226 - accuracy: 0.8064 - val_loss: 0.4272 - val_accuracy: 0.8008 - 652ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4237 - accuracy: 0.8052 - val_loss: 0.4272 - val_accuracy: 0.8010 - 664ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8051 - val_loss: 0.4329 - val_accuracy: 0.7931 - 652ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4227 - accuracy: 0.8051 - val_loss: 0.4287 - val_accuracy: 0.8013 - 663ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4227 - accuracy: 0.8052 - val_loss: 0.4281 - val_accuracy: 0.8000 - 741ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8048 - val_loss: 0.4266 - val_accuracy: 0.8002 - 943ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8041 - val_loss: 0.4335 - val_accuracy: 0.8002 - 823ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4225 - accuracy: 0.8056 - val_loss: 0.4283 - val_accuracy: 0.7997 - 906ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4237 - accuracy: 0.8044 - val_loss: 0.4282 - val_accuracy: 0.8000 - 826ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8047 - val_loss: 0.4294 - val_accuracy: 0.7993 - 817ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4220 - accuracy: 0.8059 - val_loss: 0.4272 - val_accuracy: 0.7999 - 874ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8054 - val_loss: 0.4294 - val_accuracy: 0.7997 - 914ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8052 - val_loss: 0.4285 - val_accuracy: 0.8010 - 829ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8049 - val_loss: 0.4257 - val_accuracy: 0.8008 - 814ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4210 - accuracy: 0.8063 - val_loss: 0.4267 - val_accuracy: 0.8017 - 953ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4225 - accuracy: 0.8058 - val_loss: 0.4336 - val_accuracy: 0.7971 - 927ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8053 - val_loss: 0.4277 - val_accuracy: 0.7997 - 808ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8056 - val_loss: 0.4265 - val_accuracy: 0.8024 - 823ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4238 - accuracy: 0.8048 - val_loss: 0.4261 - val_accuracy: 0.8017 - 754ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8053 - val_loss: 0.4257 - val_accuracy: 0.7999 - 889ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4214 - accuracy: 0.8052 - val_loss: 0.4270 - val_accuracy: 0.8000 - 964ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8053 - val_loss: 0.4294 - val_accuracy: 0.8011 - 749ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8061 - val_loss: 0.4272 - val_accuracy: 0.8008 - 594ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8050 - val_loss: 0.4260 - val_accuracy: 0.8004 - 578ms/epoch - 7ms/step\n",
      "Epoch 43: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 2.8191 - accuracy: 0.7309 - val_loss: 1.8721 - val_accuracy: 0.7637 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 1.3599 - accuracy: 0.7679 - val_loss: 0.9676 - val_accuracy: 0.7858 - 708ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.7631 - accuracy: 0.7979 - val_loss: 0.6166 - val_accuracy: 0.7999 - 666ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.5405 - accuracy: 0.8038 - val_loss: 0.4916 - val_accuracy: 0.8008 - 634ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4637 - accuracy: 0.8048 - val_loss: 0.4514 - val_accuracy: 0.8002 - 675ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4398 - accuracy: 0.8049 - val_loss: 0.4397 - val_accuracy: 0.7993 - 830ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4327 - accuracy: 0.8027 - val_loss: 0.4348 - val_accuracy: 0.7997 - 711ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4287 - accuracy: 0.8048 - val_loss: 0.4322 - val_accuracy: 0.8000 - 737ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4269 - accuracy: 0.8060 - val_loss: 0.4311 - val_accuracy: 0.7997 - 738ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4269 - accuracy: 0.8047 - val_loss: 0.4305 - val_accuracy: 0.8000 - 728ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4253 - accuracy: 0.8043 - val_loss: 0.4300 - val_accuracy: 0.8004 - 814ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4250 - accuracy: 0.8055 - val_loss: 0.4300 - val_accuracy: 0.8000 - 759ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4249 - accuracy: 0.8051 - val_loss: 0.4282 - val_accuracy: 0.8002 - 764ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4250 - accuracy: 0.8037 - val_loss: 0.4287 - val_accuracy: 0.8002 - 780ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4254 - accuracy: 0.8043 - val_loss: 0.4285 - val_accuracy: 0.8004 - 729ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.4276 - val_accuracy: 0.7999 - 772ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4231 - accuracy: 0.8057 - val_loss: 0.4281 - val_accuracy: 0.8006 - 794ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4229 - accuracy: 0.8054 - val_loss: 0.4273 - val_accuracy: 0.8017 - 877ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4229 - accuracy: 0.8057 - val_loss: 0.4277 - val_accuracy: 0.7999 - 890ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4226 - accuracy: 0.8047 - val_loss: 0.4303 - val_accuracy: 0.7989 - 886ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4238 - accuracy: 0.8049 - val_loss: 0.4276 - val_accuracy: 0.8026 - 915ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8053 - val_loss: 0.4273 - val_accuracy: 0.8031 - 937ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8052 - val_loss: 0.4277 - val_accuracy: 0.8020 - 893ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4239 - accuracy: 0.8043 - val_loss: 0.4294 - val_accuracy: 0.8008 - 788ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4225 - accuracy: 0.8037 - val_loss: 0.4310 - val_accuracy: 0.7971 - 742ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4224 - accuracy: 0.8065 - val_loss: 0.4268 - val_accuracy: 0.8006 - 992ms/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4225 - accuracy: 0.8032 - val_loss: 0.4267 - val_accuracy: 0.7997 - 690ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4220 - accuracy: 0.8043 - val_loss: 0.4262 - val_accuracy: 0.8010 - 1s/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4227 - accuracy: 0.8056 - val_loss: 0.4277 - val_accuracy: 0.8006 - 1s/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8048 - val_loss: 0.4262 - val_accuracy: 0.7997 - 827ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4214 - accuracy: 0.8065 - val_loss: 0.4266 - val_accuracy: 0.8006 - 770ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4214 - accuracy: 0.8050 - val_loss: 0.4261 - val_accuracy: 0.8006 - 731ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8043 - val_loss: 0.4262 - val_accuracy: 0.8019 - 783ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8042 - val_loss: 0.4335 - val_accuracy: 0.7935 - 744ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4214 - accuracy: 0.8042 - val_loss: 0.4265 - val_accuracy: 0.7997 - 733ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4210 - accuracy: 0.8059 - val_loss: 0.4275 - val_accuracy: 0.7997 - 774ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4211 - accuracy: 0.8060 - val_loss: 0.4282 - val_accuracy: 0.8006 - 703ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4210 - accuracy: 0.8058 - val_loss: 0.4256 - val_accuracy: 0.8024 - 680ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8047 - val_loss: 0.4277 - val_accuracy: 0.7997 - 811ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4214 - accuracy: 0.8048 - val_loss: 0.4260 - val_accuracy: 0.8013 - 883ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8063 - val_loss: 0.4258 - val_accuracy: 0.8002 - 837ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8056 - val_loss: 0.4252 - val_accuracy: 0.8011 - 964ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4221 - accuracy: 0.8035 - val_loss: 0.4319 - val_accuracy: 0.7980 - 885ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4208 - accuracy: 0.8046 - val_loss: 0.4261 - val_accuracy: 0.8017 - 920ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8051 - val_loss: 0.4260 - val_accuracy: 0.8002 - 881ms/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8060 - val_loss: 0.4288 - val_accuracy: 0.7973 - 792ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "86/86 - 1s - loss: 0.4205 - accuracy: 0.8049 - val_loss: 0.4262 - val_accuracy: 0.8022 - 801ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8057 - val_loss: 0.4252 - val_accuracy: 0.8010 - 786ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "86/86 - 1s - loss: 0.4206 - accuracy: 0.8047 - val_loss: 0.4255 - val_accuracy: 0.8000 - 846ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "86/86 - 1s - loss: 0.4206 - accuracy: 0.8045 - val_loss: 0.4290 - val_accuracy: 0.7995 - 808ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "86/86 - 1s - loss: 0.4201 - accuracy: 0.8045 - val_loss: 0.4305 - val_accuracy: 0.8008 - 864ms/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "86/86 - 1s - loss: 0.4228 - accuracy: 0.8035 - val_loss: 0.4257 - val_accuracy: 0.8019 - 853ms/epoch - 10ms/step\n",
      "Epoch 52: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 2.7772 - accuracy: 0.6489 - val_loss: 1.8519 - val_accuracy: 0.7637 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 1.3571 - accuracy: 0.7615 - val_loss: 0.9672 - val_accuracy: 0.7684 - 719ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.7642 - accuracy: 0.7950 - val_loss: 0.6156 - val_accuracy: 0.7984 - 688ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.5417 - accuracy: 0.8010 - val_loss: 0.4921 - val_accuracy: 0.8013 - 625ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4648 - accuracy: 0.8039 - val_loss: 0.4508 - val_accuracy: 0.8011 - 655ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4404 - accuracy: 0.8038 - val_loss: 0.4389 - val_accuracy: 0.8041 - 687ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4320 - accuracy: 0.8053 - val_loss: 0.4345 - val_accuracy: 0.8017 - 687ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4291 - accuracy: 0.8050 - val_loss: 0.4320 - val_accuracy: 0.8033 - 766ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4272 - accuracy: 0.8056 - val_loss: 0.4315 - val_accuracy: 0.8010 - 828ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4261 - accuracy: 0.8043 - val_loss: 0.4305 - val_accuracy: 0.8013 - 781ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4264 - accuracy: 0.8037 - val_loss: 0.4317 - val_accuracy: 0.7993 - 750ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4251 - accuracy: 0.8054 - val_loss: 0.4291 - val_accuracy: 0.8015 - 719ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4245 - accuracy: 0.8053 - val_loss: 0.4285 - val_accuracy: 0.8004 - 687ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4247 - accuracy: 0.8052 - val_loss: 0.4286 - val_accuracy: 0.8011 - 686ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4234 - accuracy: 0.8050 - val_loss: 0.4293 - val_accuracy: 0.8000 - 703ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4242 - accuracy: 0.8050 - val_loss: 0.4290 - val_accuracy: 0.8022 - 672ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4235 - accuracy: 0.8048 - val_loss: 0.4288 - val_accuracy: 0.8013 - 625ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4252 - accuracy: 0.8051 - val_loss: 0.4285 - val_accuracy: 0.7999 - 641ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4228 - accuracy: 0.8054 - val_loss: 0.4318 - val_accuracy: 0.7997 - 641ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4240 - accuracy: 0.8039 - val_loss: 0.4268 - val_accuracy: 0.8010 - 625ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4235 - accuracy: 0.8053 - val_loss: 0.4279 - val_accuracy: 0.8013 - 625ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8059 - val_loss: 0.4277 - val_accuracy: 0.8026 - 719ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8054 - val_loss: 0.4270 - val_accuracy: 0.8030 - 641ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4242 - accuracy: 0.8034 - val_loss: 0.4270 - val_accuracy: 0.8024 - 688ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4220 - accuracy: 0.8059 - val_loss: 0.4270 - val_accuracy: 0.8008 - 641ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8064 - val_loss: 0.4269 - val_accuracy: 0.8024 - 625ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8061 - val_loss: 0.4330 - val_accuracy: 0.8004 - 641ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4228 - accuracy: 0.8037 - val_loss: 0.4275 - val_accuracy: 0.7980 - 794ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8057 - val_loss: 0.4266 - val_accuracy: 0.8004 - 657ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8055 - val_loss: 0.4320 - val_accuracy: 0.7993 - 688ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4226 - accuracy: 0.8035 - val_loss: 0.4305 - val_accuracy: 0.7999 - 722ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4208 - accuracy: 0.8058 - val_loss: 0.4267 - val_accuracy: 0.8004 - 656ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8051 - val_loss: 0.4268 - val_accuracy: 0.7993 - 672ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8057 - val_loss: 0.4287 - val_accuracy: 0.8026 - 656ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8029 - val_loss: 0.4286 - val_accuracy: 0.7999 - 641ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8051 - val_loss: 0.4272 - val_accuracy: 0.8004 - 672ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8053 - val_loss: 0.4266 - val_accuracy: 0.8013 - 641ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4206 - accuracy: 0.8051 - val_loss: 0.4263 - val_accuracy: 0.8002 - 625ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4206 - accuracy: 0.8064 - val_loss: 0.4321 - val_accuracy: 0.7978 - 1s/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4209 - accuracy: 0.8050 - val_loss: 0.4252 - val_accuracy: 0.8002 - 783ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4214 - accuracy: 0.8051 - val_loss: 0.4297 - val_accuracy: 0.7973 - 734ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8052 - val_loss: 0.4256 - val_accuracy: 0.8002 - 695ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8054 - val_loss: 0.4277 - val_accuracy: 0.8010 - 703ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8052 - val_loss: 0.4255 - val_accuracy: 0.8011 - 803ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8047 - val_loss: 0.4266 - val_accuracy: 0.8002 - 759ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8051 - val_loss: 0.4265 - val_accuracy: 0.8004 - 695ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "86/86 - 1s - loss: 0.4198 - accuracy: 0.8062 - val_loss: 0.4259 - val_accuracy: 0.8011 - 919ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8037 - val_loss: 0.4277 - val_accuracy: 0.8008 - 693ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8045 - val_loss: 0.4253 - val_accuracy: 0.8013 - 641ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "86/86 - 1s - loss: 0.4198 - accuracy: 0.8061 - val_loss: 0.4284 - val_accuracy: 0.8000 - 799ms/epoch - 9ms/step\n",
      "Epoch 50: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "86/86 - 3s - loss: 2.7329 - accuracy: 0.7270 - val_loss: 1.8167 - val_accuracy: 0.7637 - 3s/epoch - 38ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 1.3266 - accuracy: 0.7840 - val_loss: 0.9520 - val_accuracy: 0.7960 - 754ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.7553 - accuracy: 0.8036 - val_loss: 0.6125 - val_accuracy: 0.7991 - 656ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.5371 - accuracy: 0.8048 - val_loss: 0.4910 - val_accuracy: 0.8013 - 736ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4619 - accuracy: 0.8048 - val_loss: 0.4494 - val_accuracy: 0.7993 - 1s/epoch - 15ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4384 - accuracy: 0.8054 - val_loss: 0.4382 - val_accuracy: 0.7991 - 753ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4322 - accuracy: 0.8035 - val_loss: 0.4332 - val_accuracy: 0.7999 - 826ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4285 - accuracy: 0.8057 - val_loss: 0.4316 - val_accuracy: 0.8002 - 894ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4270 - accuracy: 0.8054 - val_loss: 0.4326 - val_accuracy: 0.8010 - 912ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4261 - accuracy: 0.8048 - val_loss: 0.4309 - val_accuracy: 0.8013 - 705ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4263 - accuracy: 0.8054 - val_loss: 0.4296 - val_accuracy: 0.8004 - 759ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4249 - accuracy: 0.8048 - val_loss: 0.4289 - val_accuracy: 0.8026 - 718ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4246 - accuracy: 0.8044 - val_loss: 0.4303 - val_accuracy: 0.8013 - 914ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4235 - accuracy: 0.8051 - val_loss: 0.4283 - val_accuracy: 0.8010 - 998ms/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4243 - accuracy: 0.8048 - val_loss: 0.4282 - val_accuracy: 0.8000 - 675ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4238 - accuracy: 0.8056 - val_loss: 0.4284 - val_accuracy: 0.7995 - 623ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4240 - accuracy: 0.8042 - val_loss: 0.4279 - val_accuracy: 0.8002 - 679ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4231 - accuracy: 0.8058 - val_loss: 0.4283 - val_accuracy: 0.8006 - 749ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8065 - val_loss: 0.4285 - val_accuracy: 0.8013 - 799ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4239 - accuracy: 0.8037 - val_loss: 0.4284 - val_accuracy: 0.7993 - 672ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4227 - accuracy: 0.8071 - val_loss: 0.4272 - val_accuracy: 0.7999 - 714ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4233 - accuracy: 0.8051 - val_loss: 0.4292 - val_accuracy: 0.7991 - 681ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4227 - accuracy: 0.8048 - val_loss: 0.4293 - val_accuracy: 0.8006 - 688ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8058 - val_loss: 0.4271 - val_accuracy: 0.7997 - 854ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8051 - val_loss: 0.4437 - val_accuracy: 0.7927 - 703ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4257 - accuracy: 0.8027 - val_loss: 0.4282 - val_accuracy: 0.7980 - 696ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8057 - val_loss: 0.4276 - val_accuracy: 0.7995 - 675ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8051 - val_loss: 0.4287 - val_accuracy: 0.8017 - 639ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8051 - val_loss: 0.4261 - val_accuracy: 0.8010 - 798ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8059 - val_loss: 0.4284 - val_accuracy: 0.8006 - 681ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4224 - accuracy: 0.8045 - val_loss: 0.4296 - val_accuracy: 0.8006 - 645ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4225 - accuracy: 0.8043 - val_loss: 0.4267 - val_accuracy: 0.8006 - 659ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8052 - val_loss: 0.4282 - val_accuracy: 0.8024 - 709ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8060 - val_loss: 0.4281 - val_accuracy: 0.8010 - 727ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8054 - val_loss: 0.4277 - val_accuracy: 0.7997 - 767ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8049 - val_loss: 0.4287 - val_accuracy: 0.8010 - 867ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4209 - accuracy: 0.8055 - val_loss: 0.4264 - val_accuracy: 0.7993 - 749ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8059 - val_loss: 0.4273 - val_accuracy: 0.8013 - 725ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8059 - val_loss: 0.4264 - val_accuracy: 0.8000 - 654ms/epoch - 8ms/step\n",
      "Epoch 39: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 2.6693 - accuracy: 0.7609 - val_loss: 1.7825 - val_accuracy: 0.7801 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 1.3008 - accuracy: 0.7856 - val_loss: 0.9353 - val_accuracy: 0.7929 - 632ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.7413 - accuracy: 0.8020 - val_loss: 0.6042 - val_accuracy: 0.8000 - 649ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.5313 - accuracy: 0.8045 - val_loss: 0.4858 - val_accuracy: 0.7999 - 734ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4593 - accuracy: 0.8050 - val_loss: 0.4473 - val_accuracy: 0.7993 - 663ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4366 - accuracy: 0.8048 - val_loss: 0.4357 - val_accuracy: 0.8000 - 730ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4301 - accuracy: 0.8044 - val_loss: 0.4321 - val_accuracy: 0.8004 - 743ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4272 - accuracy: 0.8053 - val_loss: 0.4313 - val_accuracy: 0.8010 - 815ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4256 - accuracy: 0.8055 - val_loss: 0.4288 - val_accuracy: 0.8002 - 750ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4248 - accuracy: 0.8044 - val_loss: 0.4341 - val_accuracy: 0.8004 - 759ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4243 - accuracy: 0.8048 - val_loss: 0.4290 - val_accuracy: 0.8008 - 713ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4251 - accuracy: 0.8044 - val_loss: 0.4282 - val_accuracy: 0.8008 - 636ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4237 - accuracy: 0.8053 - val_loss: 0.4276 - val_accuracy: 0.8015 - 686ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4239 - accuracy: 0.8042 - val_loss: 0.4280 - val_accuracy: 0.7999 - 893ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4239 - accuracy: 0.8047 - val_loss: 0.4296 - val_accuracy: 0.7999 - 790ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4229 - accuracy: 0.8055 - val_loss: 0.4267 - val_accuracy: 0.7999 - 659ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4242 - accuracy: 0.8037 - val_loss: 0.4286 - val_accuracy: 0.8004 - 651ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4228 - accuracy: 0.8053 - val_loss: 0.4264 - val_accuracy: 0.7999 - 682ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8052 - val_loss: 0.4335 - val_accuracy: 0.7956 - 657ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8058 - val_loss: 0.4268 - val_accuracy: 0.8015 - 704ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4220 - accuracy: 0.8041 - val_loss: 0.4285 - val_accuracy: 0.8006 - 657ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8058 - val_loss: 0.4261 - val_accuracy: 0.8008 - 681ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8049 - val_loss: 0.4264 - val_accuracy: 0.8000 - 662ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8057 - val_loss: 0.4263 - val_accuracy: 0.7999 - 684ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8031 - val_loss: 0.4291 - val_accuracy: 0.8000 - 688ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4221 - accuracy: 0.8039 - val_loss: 0.4271 - val_accuracy: 0.8017 - 751ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8037 - val_loss: 0.4256 - val_accuracy: 0.8010 - 691ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8056 - val_loss: 0.4265 - val_accuracy: 0.7999 - 695ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8036 - val_loss: 0.4260 - val_accuracy: 0.8020 - 627ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8055 - val_loss: 0.4279 - val_accuracy: 0.8033 - 747ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4220 - accuracy: 0.8060 - val_loss: 0.4282 - val_accuracy: 0.7971 - 690ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8059 - val_loss: 0.4259 - val_accuracy: 0.8013 - 673ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8050 - val_loss: 0.4277 - val_accuracy: 0.8022 - 688ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8064 - val_loss: 0.4269 - val_accuracy: 0.8006 - 676ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8057 - val_loss: 0.4263 - val_accuracy: 0.8006 - 703ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8052 - val_loss: 0.4291 - val_accuracy: 0.7988 - 644ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4208 - accuracy: 0.8051 - val_loss: 0.4251 - val_accuracy: 0.8000 - 676ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8058 - val_loss: 0.4266 - val_accuracy: 0.8004 - 716ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4205 - accuracy: 0.8054 - val_loss: 0.4256 - val_accuracy: 0.8004 - 696ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8049 - val_loss: 0.4297 - val_accuracy: 0.7969 - 707ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8056 - val_loss: 0.4250 - val_accuracy: 0.8002 - 712ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4202 - accuracy: 0.8049 - val_loss: 0.4264 - val_accuracy: 0.8010 - 681ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8039 - val_loss: 0.4253 - val_accuracy: 0.8002 - 717ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8045 - val_loss: 0.4263 - val_accuracy: 0.8006 - 758ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8062 - val_loss: 0.4253 - val_accuracy: 0.8010 - 713ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "86/86 - 1s - loss: 0.4199 - accuracy: 0.8060 - val_loss: 0.4252 - val_accuracy: 0.8015 - 743ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "86/86 - 1s - loss: 0.4202 - accuracy: 0.8048 - val_loss: 0.4262 - val_accuracy: 0.8017 - 733ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "86/86 - 1s - loss: 0.4226 - accuracy: 0.8049 - val_loss: 0.4292 - val_accuracy: 0.8004 - 699ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "86/86 - 1s - loss: 0.4206 - accuracy: 0.8051 - val_loss: 0.4246 - val_accuracy: 0.8008 - 719ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "86/86 - 1s - loss: 0.4211 - accuracy: 0.8052 - val_loss: 0.4255 - val_accuracy: 0.8002 - 663ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8053 - val_loss: 0.4280 - val_accuracy: 0.7993 - 659ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "86/86 - 1s - loss: 0.4197 - accuracy: 0.8059 - val_loss: 0.4252 - val_accuracy: 0.8026 - 658ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "86/86 - 1s - loss: 0.4199 - accuracy: 0.8068 - val_loss: 0.4266 - val_accuracy: 0.8026 - 643ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "86/86 - 1s - loss: 0.4202 - accuracy: 0.8044 - val_loss: 0.4276 - val_accuracy: 0.8011 - 626ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "86/86 - 1s - loss: 0.4198 - accuracy: 0.8057 - val_loss: 0.4253 - val_accuracy: 0.8019 - 705ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "86/86 - 1s - loss: 0.4202 - accuracy: 0.8049 - val_loss: 0.4258 - val_accuracy: 0.7993 - 648ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "86/86 - 1s - loss: 0.4200 - accuracy: 0.8055 - val_loss: 0.4256 - val_accuracy: 0.8004 - 647ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "86/86 - 1s - loss: 0.4195 - accuracy: 0.8054 - val_loss: 0.4269 - val_accuracy: 0.7991 - 653ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "86/86 - 1s - loss: 0.4201 - accuracy: 0.8054 - val_loss: 0.4253 - val_accuracy: 0.8010 - 703ms/epoch - 8ms/step\n",
      "Epoch 59: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 2.7453 - accuracy: 0.7150 - val_loss: 1.8398 - val_accuracy: 0.7637 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 1.3537 - accuracy: 0.7614 - val_loss: 0.9739 - val_accuracy: 0.7646 - 611ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.7692 - accuracy: 0.7916 - val_loss: 0.6207 - val_accuracy: 0.7966 - 662ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.5431 - accuracy: 0.8050 - val_loss: 0.4949 - val_accuracy: 0.8011 - 662ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4651 - accuracy: 0.8053 - val_loss: 0.4513 - val_accuracy: 0.8011 - 659ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4397 - accuracy: 0.8051 - val_loss: 0.4387 - val_accuracy: 0.7993 - 687ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4310 - accuracy: 0.8055 - val_loss: 0.4349 - val_accuracy: 0.8004 - 698ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4285 - accuracy: 0.8052 - val_loss: 0.4335 - val_accuracy: 0.8022 - 625ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4270 - accuracy: 0.8049 - val_loss: 0.4319 - val_accuracy: 0.8010 - 716ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4280 - accuracy: 0.8029 - val_loss: 0.4297 - val_accuracy: 0.8011 - 619ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4261 - accuracy: 0.8055 - val_loss: 0.4321 - val_accuracy: 0.8022 - 664ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4247 - accuracy: 0.8059 - val_loss: 0.4318 - val_accuracy: 0.8006 - 655ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4239 - accuracy: 0.8057 - val_loss: 0.4283 - val_accuracy: 0.8022 - 622ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4245 - accuracy: 0.8049 - val_loss: 0.4287 - val_accuracy: 0.8015 - 653ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4237 - accuracy: 0.8045 - val_loss: 0.4281 - val_accuracy: 0.8008 - 646ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4243 - accuracy: 0.8050 - val_loss: 0.4280 - val_accuracy: 0.8006 - 655ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4229 - accuracy: 0.8054 - val_loss: 0.4299 - val_accuracy: 0.8020 - 668ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4232 - accuracy: 0.8038 - val_loss: 0.4285 - val_accuracy: 0.8008 - 766ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4236 - accuracy: 0.8058 - val_loss: 0.4285 - val_accuracy: 0.8022 - 673ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8071 - val_loss: 0.4280 - val_accuracy: 0.8008 - 645ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8051 - val_loss: 0.4284 - val_accuracy: 0.8006 - 640ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8061 - val_loss: 0.4279 - val_accuracy: 0.7999 - 600ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8053 - val_loss: 0.4336 - val_accuracy: 0.7953 - 670ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8045 - val_loss: 0.4265 - val_accuracy: 0.8002 - 702ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4206 - accuracy: 0.8060 - val_loss: 0.4266 - val_accuracy: 0.8004 - 730ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8052 - val_loss: 0.4273 - val_accuracy: 0.8019 - 704ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8049 - val_loss: 0.4298 - val_accuracy: 0.7991 - 687ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8052 - val_loss: 0.4292 - val_accuracy: 0.8002 - 689ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4208 - accuracy: 0.8043 - val_loss: 0.4272 - val_accuracy: 0.7993 - 715ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8048 - val_loss: 0.4276 - val_accuracy: 0.8026 - 674ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8043 - val_loss: 0.4267 - val_accuracy: 0.7999 - 752ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4208 - accuracy: 0.8045 - val_loss: 0.4264 - val_accuracy: 0.8002 - 690ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8052 - val_loss: 0.4300 - val_accuracy: 0.8011 - 656ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4211 - accuracy: 0.8050 - val_loss: 0.4259 - val_accuracy: 0.8004 - 687ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8062 - val_loss: 0.4299 - val_accuracy: 0.8000 - 749ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4211 - accuracy: 0.8052 - val_loss: 0.4290 - val_accuracy: 0.7986 - 686ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4220 - accuracy: 0.8043 - val_loss: 0.4298 - val_accuracy: 0.7975 - 696ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8053 - val_loss: 0.4273 - val_accuracy: 0.8000 - 704ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4209 - accuracy: 0.8057 - val_loss: 0.4307 - val_accuracy: 0.7966 - 705ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8034 - val_loss: 0.4261 - val_accuracy: 0.8004 - 701ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4199 - accuracy: 0.8062 - val_loss: 0.4267 - val_accuracy: 0.8017 - 748ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4201 - accuracy: 0.8043 - val_loss: 0.4330 - val_accuracy: 0.7980 - 708ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4209 - accuracy: 0.8059 - val_loss: 0.4259 - val_accuracy: 0.8008 - 666ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4210 - accuracy: 0.8043 - val_loss: 0.4283 - val_accuracy: 0.7991 - 650ms/epoch - 8ms/step\n",
      "Epoch 44: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 2.6879 - accuracy: 0.7083 - val_loss: 1.7848 - val_accuracy: 0.7637 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 1.3062 - accuracy: 0.7778 - val_loss: 0.9375 - val_accuracy: 0.7947 - 652ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.7466 - accuracy: 0.8015 - val_loss: 0.6072 - val_accuracy: 0.8010 - 686ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.5356 - accuracy: 0.8041 - val_loss: 0.4906 - val_accuracy: 0.7997 - 662ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4636 - accuracy: 0.8033 - val_loss: 0.4513 - val_accuracy: 0.8008 - 726ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4397 - accuracy: 0.8055 - val_loss: 0.4403 - val_accuracy: 0.8019 - 713ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4317 - accuracy: 0.8050 - val_loss: 0.4341 - val_accuracy: 0.7999 - 697ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4290 - accuracy: 0.8052 - val_loss: 0.4349 - val_accuracy: 0.8004 - 684ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4274 - accuracy: 0.8045 - val_loss: 0.4311 - val_accuracy: 0.7999 - 643ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4273 - accuracy: 0.8053 - val_loss: 0.4314 - val_accuracy: 0.8026 - 682ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4269 - accuracy: 0.8046 - val_loss: 0.4316 - val_accuracy: 0.7999 - 724ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4257 - accuracy: 0.8053 - val_loss: 0.4308 - val_accuracy: 0.8006 - 697ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4252 - accuracy: 0.8043 - val_loss: 0.4292 - val_accuracy: 0.8000 - 659ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4253 - accuracy: 0.8040 - val_loss: 0.4291 - val_accuracy: 0.8011 - 680ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4242 - accuracy: 0.8041 - val_loss: 0.4306 - val_accuracy: 0.7991 - 666ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4246 - accuracy: 0.8037 - val_loss: 0.4300 - val_accuracy: 0.8010 - 686ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4248 - accuracy: 0.8037 - val_loss: 0.4290 - val_accuracy: 0.8008 - 708ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4237 - accuracy: 0.8050 - val_loss: 0.4280 - val_accuracy: 0.7999 - 691ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4241 - accuracy: 0.8034 - val_loss: 0.4283 - val_accuracy: 0.7989 - 678ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4228 - accuracy: 0.8052 - val_loss: 0.4351 - val_accuracy: 0.7978 - 685ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4242 - accuracy: 0.8042 - val_loss: 0.4281 - val_accuracy: 0.8020 - 678ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4226 - accuracy: 0.8046 - val_loss: 0.4286 - val_accuracy: 0.8013 - 686ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4233 - accuracy: 0.8057 - val_loss: 0.4278 - val_accuracy: 0.8010 - 706ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4220 - accuracy: 0.8064 - val_loss: 0.4270 - val_accuracy: 0.8015 - 675ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4224 - accuracy: 0.8052 - val_loss: 0.4270 - val_accuracy: 0.7999 - 645ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4237 - accuracy: 0.8035 - val_loss: 0.4335 - val_accuracy: 0.7955 - 654ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4231 - accuracy: 0.8035 - val_loss: 0.4275 - val_accuracy: 0.8022 - 671ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4220 - accuracy: 0.8057 - val_loss: 0.4272 - val_accuracy: 0.8006 - 745ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4227 - accuracy: 0.8044 - val_loss: 0.4276 - val_accuracy: 0.7999 - 749ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4232 - accuracy: 0.8048 - val_loss: 0.4313 - val_accuracy: 0.7966 - 684ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8047 - val_loss: 0.4263 - val_accuracy: 0.8002 - 677ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4214 - accuracy: 0.8055 - val_loss: 0.4300 - val_accuracy: 0.7984 - 690ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8041 - val_loss: 0.4265 - val_accuracy: 0.8006 - 684ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4211 - accuracy: 0.8062 - val_loss: 0.4290 - val_accuracy: 0.7980 - 739ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8060 - val_loss: 0.4268 - val_accuracy: 0.8010 - 735ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8047 - val_loss: 0.4266 - val_accuracy: 0.7999 - 695ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8053 - val_loss: 0.4280 - val_accuracy: 0.8002 - 688ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4225 - accuracy: 0.8038 - val_loss: 0.4272 - val_accuracy: 0.8024 - 705ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4209 - accuracy: 0.8048 - val_loss: 0.4257 - val_accuracy: 0.8000 - 683ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8053 - val_loss: 0.4277 - val_accuracy: 0.8004 - 704ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8050 - val_loss: 0.4280 - val_accuracy: 0.7973 - 690ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4208 - accuracy: 0.8056 - val_loss: 0.4254 - val_accuracy: 0.8000 - 642ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4202 - accuracy: 0.8064 - val_loss: 0.4269 - val_accuracy: 0.8004 - 627ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8044 - val_loss: 0.4266 - val_accuracy: 0.7999 - 692ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4205 - accuracy: 0.8058 - val_loss: 0.4260 - val_accuracy: 0.7989 - 671ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "86/86 - 1s - loss: 0.4235 - accuracy: 0.8025 - val_loss: 0.4343 - val_accuracy: 0.7935 - 686ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8031 - val_loss: 0.4289 - val_accuracy: 0.7986 - 704ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "86/86 - 1s - loss: 0.4210 - accuracy: 0.8043 - val_loss: 0.4257 - val_accuracy: 0.7997 - 690ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "86/86 - 1s - loss: 0.4206 - accuracy: 0.8050 - val_loss: 0.4295 - val_accuracy: 0.8000 - 643ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8053 - val_loss: 0.4271 - val_accuracy: 0.8000 - 689ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8053 - val_loss: 0.4303 - val_accuracy: 0.7997 - 657ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8048 - val_loss: 0.4277 - val_accuracy: 0.8004 - 722ms/epoch - 8ms/step\n",
      "Epoch 52: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 2.6143 - accuracy: 0.7620 - val_loss: 1.7426 - val_accuracy: 0.7708 - 2s/epoch - 27ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 1.2741 - accuracy: 0.7957 - val_loss: 0.9197 - val_accuracy: 0.7982 - 797ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.7330 - accuracy: 0.8036 - val_loss: 0.5996 - val_accuracy: 0.8006 - 663ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.5308 - accuracy: 0.8057 - val_loss: 0.4861 - val_accuracy: 0.8006 - 732ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4598 - accuracy: 0.8049 - val_loss: 0.4478 - val_accuracy: 0.8000 - 742ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4378 - accuracy: 0.8042 - val_loss: 0.4352 - val_accuracy: 0.8008 - 710ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4301 - accuracy: 0.8046 - val_loss: 0.4334 - val_accuracy: 0.8008 - 680ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.8059 - val_loss: 0.4322 - val_accuracy: 0.8015 - 681ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4289 - accuracy: 0.8032 - val_loss: 0.4315 - val_accuracy: 0.8026 - 644ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4257 - accuracy: 0.8062 - val_loss: 0.4303 - val_accuracy: 0.8002 - 660ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4248 - accuracy: 0.8058 - val_loss: 0.4353 - val_accuracy: 0.8002 - 666ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4244 - accuracy: 0.8053 - val_loss: 0.4301 - val_accuracy: 0.8026 - 676ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4239 - accuracy: 0.8046 - val_loss: 0.4282 - val_accuracy: 0.8008 - 704ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4246 - accuracy: 0.8044 - val_loss: 0.4316 - val_accuracy: 0.7980 - 643ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4253 - accuracy: 0.8031 - val_loss: 0.4346 - val_accuracy: 0.7944 - 639ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4230 - accuracy: 0.8060 - val_loss: 0.4283 - val_accuracy: 0.7991 - 644ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4237 - accuracy: 0.8045 - val_loss: 0.4265 - val_accuracy: 0.8004 - 706ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4230 - accuracy: 0.8055 - val_loss: 0.4282 - val_accuracy: 0.7995 - 866ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4225 - accuracy: 0.8056 - val_loss: 0.4284 - val_accuracy: 0.7986 - 759ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4220 - accuracy: 0.8053 - val_loss: 0.4287 - val_accuracy: 0.8004 - 712ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4230 - accuracy: 0.8044 - val_loss: 0.4271 - val_accuracy: 0.8013 - 692ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8055 - val_loss: 0.4293 - val_accuracy: 0.7997 - 642ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8053 - val_loss: 0.4280 - val_accuracy: 0.8008 - 704ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4227 - accuracy: 0.8047 - val_loss: 0.4283 - val_accuracy: 0.8004 - 657ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8055 - val_loss: 0.4276 - val_accuracy: 0.8024 - 662ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8059 - val_loss: 0.4264 - val_accuracy: 0.8008 - 670ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4240 - accuracy: 0.8025 - val_loss: 0.4264 - val_accuracy: 0.8019 - 703ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4224 - accuracy: 0.8050 - val_loss: 0.4271 - val_accuracy: 0.7995 - 672ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4205 - accuracy: 0.8061 - val_loss: 0.4284 - val_accuracy: 0.8006 - 725ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4224 - accuracy: 0.8056 - val_loss: 0.4262 - val_accuracy: 0.7999 - 746ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8050 - val_loss: 0.4296 - val_accuracy: 0.8013 - 716ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8039 - val_loss: 0.4267 - val_accuracy: 0.8004 - 707ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8047 - val_loss: 0.4270 - val_accuracy: 0.8000 - 700ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4209 - accuracy: 0.8046 - val_loss: 0.4260 - val_accuracy: 0.8015 - 719ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8052 - val_loss: 0.4323 - val_accuracy: 0.7940 - 712ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4208 - accuracy: 0.8041 - val_loss: 0.4255 - val_accuracy: 0.7997 - 693ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8049 - val_loss: 0.4257 - val_accuracy: 0.8006 - 713ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4206 - accuracy: 0.8041 - val_loss: 0.4259 - val_accuracy: 0.8020 - 684ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8059 - val_loss: 0.4259 - val_accuracy: 0.8010 - 682ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8039 - val_loss: 0.4269 - val_accuracy: 0.8006 - 704ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8038 - val_loss: 0.4288 - val_accuracy: 0.7986 - 706ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4211 - accuracy: 0.8040 - val_loss: 0.4256 - val_accuracy: 0.8004 - 747ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4211 - accuracy: 0.8055 - val_loss: 0.4310 - val_accuracy: 0.7978 - 908ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8035 - val_loss: 0.4254 - val_accuracy: 0.8000 - 786ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4209 - accuracy: 0.8052 - val_loss: 0.4265 - val_accuracy: 0.7997 - 1s/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "86/86 - 1s - loss: 0.4201 - accuracy: 0.8067 - val_loss: 0.4256 - val_accuracy: 0.8002 - 870ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8042 - val_loss: 0.4264 - val_accuracy: 0.7995 - 1s/epoch - 13ms/step\n",
      "Epoch 48/100\n",
      "86/86 - 1s - loss: 0.4197 - accuracy: 0.8060 - val_loss: 0.4252 - val_accuracy: 0.8024 - 751ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8043 - val_loss: 0.4263 - val_accuracy: 0.8013 - 716ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "86/86 - 1s - loss: 0.4200 - accuracy: 0.8054 - val_loss: 0.4268 - val_accuracy: 0.8008 - 892ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "86/86 - 1s - loss: 0.4202 - accuracy: 0.8043 - val_loss: 0.4264 - val_accuracy: 0.8011 - 720ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "86/86 - 1s - loss: 0.4202 - accuracy: 0.8053 - val_loss: 0.4259 - val_accuracy: 0.8002 - 686ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8047 - val_loss: 0.4251 - val_accuracy: 0.8011 - 660ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "86/86 - 1s - loss: 0.4199 - accuracy: 0.8054 - val_loss: 0.4304 - val_accuracy: 0.8004 - 673ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "86/86 - 1s - loss: 0.4202 - accuracy: 0.8046 - val_loss: 0.4250 - val_accuracy: 0.8008 - 707ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8057 - val_loss: 0.4278 - val_accuracy: 0.8013 - 724ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8060 - val_loss: 0.4277 - val_accuracy: 0.8008 - 702ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "86/86 - 1s - loss: 0.4197 - accuracy: 0.8059 - val_loss: 0.4255 - val_accuracy: 0.7991 - 731ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "86/86 - 1s - loss: 0.4197 - accuracy: 0.8054 - val_loss: 0.4254 - val_accuracy: 0.8015 - 727ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "86/86 - 1s - loss: 0.4199 - accuracy: 0.8054 - val_loss: 0.4255 - val_accuracy: 0.8010 - 724ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8044 - val_loss: 0.4253 - val_accuracy: 0.8015 - 726ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "86/86 - 1s - loss: 0.4205 - accuracy: 0.8048 - val_loss: 0.4253 - val_accuracy: 0.8000 - 703ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "86/86 - 1s - loss: 0.4206 - accuracy: 0.8055 - val_loss: 0.4266 - val_accuracy: 0.8022 - 742ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8046 - val_loss: 0.4252 - val_accuracy: 0.8002 - 689ms/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "86/86 - 1s - loss: 0.4197 - accuracy: 0.8057 - val_loss: 0.4259 - val_accuracy: 0.8015 - 702ms/epoch - 8ms/step\n",
      "Epoch 65: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 2.7700 - accuracy: 0.6766 - val_loss: 1.8709 - val_accuracy: 0.7637 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 1.3838 - accuracy: 0.7614 - val_loss: 1.0021 - val_accuracy: 0.7637 - 661ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.7941 - accuracy: 0.7832 - val_loss: 0.6373 - val_accuracy: 0.7927 - 714ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.5549 - accuracy: 0.8021 - val_loss: 0.4981 - val_accuracy: 0.8015 - 647ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4693 - accuracy: 0.8043 - val_loss: 0.4544 - val_accuracy: 0.8006 - 672ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4408 - accuracy: 0.8043 - val_loss: 0.4406 - val_accuracy: 0.8006 - 690ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4323 - accuracy: 0.8047 - val_loss: 0.4342 - val_accuracy: 0.7993 - 808ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4282 - accuracy: 0.8052 - val_loss: 0.4328 - val_accuracy: 0.8000 - 847ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4266 - accuracy: 0.8053 - val_loss: 0.4305 - val_accuracy: 0.8020 - 818ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.8055 - val_loss: 0.4310 - val_accuracy: 0.8013 - 760ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4256 - accuracy: 0.8050 - val_loss: 0.4303 - val_accuracy: 0.8017 - 746ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4245 - accuracy: 0.8050 - val_loss: 0.4291 - val_accuracy: 0.8008 - 662ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4243 - accuracy: 0.8039 - val_loss: 0.4291 - val_accuracy: 0.8006 - 692ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4242 - accuracy: 0.8058 - val_loss: 0.4314 - val_accuracy: 0.8020 - 733ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4243 - accuracy: 0.8048 - val_loss: 0.4290 - val_accuracy: 0.8004 - 690ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4249 - accuracy: 0.8049 - val_loss: 0.4284 - val_accuracy: 0.8008 - 674ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4233 - accuracy: 0.8049 - val_loss: 0.4287 - val_accuracy: 0.8010 - 669ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4235 - accuracy: 0.8053 - val_loss: 0.4314 - val_accuracy: 0.7929 - 659ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4244 - accuracy: 0.8048 - val_loss: 0.4324 - val_accuracy: 0.7929 - 706ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4230 - accuracy: 0.8053 - val_loss: 0.4272 - val_accuracy: 0.7999 - 704ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8052 - val_loss: 0.4298 - val_accuracy: 0.8020 - 701ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4236 - accuracy: 0.8046 - val_loss: 0.4354 - val_accuracy: 0.7988 - 664ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4224 - accuracy: 0.8045 - val_loss: 0.4273 - val_accuracy: 0.7997 - 663ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4224 - accuracy: 0.8051 - val_loss: 0.4276 - val_accuracy: 0.8011 - 706ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4221 - accuracy: 0.8056 - val_loss: 0.4269 - val_accuracy: 0.8004 - 710ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8047 - val_loss: 0.4262 - val_accuracy: 0.8004 - 683ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4217 - accuracy: 0.8063 - val_loss: 0.4265 - val_accuracy: 0.8019 - 696ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4216 - accuracy: 0.8052 - val_loss: 0.4270 - val_accuracy: 0.7997 - 695ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8053 - val_loss: 0.4263 - val_accuracy: 0.8000 - 668ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8051 - val_loss: 0.4262 - val_accuracy: 0.8013 - 737ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8052 - val_loss: 0.4297 - val_accuracy: 0.8011 - 711ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4222 - accuracy: 0.8043 - val_loss: 0.4266 - val_accuracy: 0.8026 - 733ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4226 - accuracy: 0.8035 - val_loss: 0.4309 - val_accuracy: 0.7999 - 667ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4223 - accuracy: 0.8045 - val_loss: 0.4381 - val_accuracy: 0.7931 - 709ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4221 - accuracy: 0.8039 - val_loss: 0.4284 - val_accuracy: 0.8020 - 670ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4228 - accuracy: 0.8041 - val_loss: 0.4257 - val_accuracy: 0.8008 - 836ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8053 - val_loss: 0.4258 - val_accuracy: 0.8013 - 856ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8036 - val_loss: 0.4287 - val_accuracy: 0.8004 - 1s/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8044 - val_loss: 0.4284 - val_accuracy: 0.7999 - 834ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4201 - accuracy: 0.8062 - val_loss: 0.4268 - val_accuracy: 0.8015 - 847ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4208 - accuracy: 0.8042 - val_loss: 0.4262 - val_accuracy: 0.8019 - 884ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8054 - val_loss: 0.4264 - val_accuracy: 0.8010 - 728ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8053 - val_loss: 0.4283 - val_accuracy: 0.8011 - 721ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4205 - accuracy: 0.8048 - val_loss: 0.4256 - val_accuracy: 0.7999 - 675ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8042 - val_loss: 0.4283 - val_accuracy: 0.8019 - 703ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "86/86 - 1s - loss: 0.4202 - accuracy: 0.8055 - val_loss: 0.4284 - val_accuracy: 0.8010 - 716ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8054 - val_loss: 0.4273 - val_accuracy: 0.7999 - 717ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "86/86 - 1s - loss: 0.4203 - accuracy: 0.8048 - val_loss: 0.4272 - val_accuracy: 0.7997 - 712ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8048 - val_loss: 0.4295 - val_accuracy: 0.8017 - 696ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8049 - val_loss: 0.4290 - val_accuracy: 0.8011 - 708ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8059 - val_loss: 0.4305 - val_accuracy: 0.7995 - 685ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8046 - val_loss: 0.4261 - val_accuracy: 0.8020 - 722ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8055 - val_loss: 0.4251 - val_accuracy: 0.8024 - 688ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8052 - val_loss: 0.4256 - val_accuracy: 0.8015 - 675ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "86/86 - 1s - loss: 0.4201 - accuracy: 0.8052 - val_loss: 0.4259 - val_accuracy: 0.7999 - 647ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "86/86 - 1s - loss: 0.4200 - accuracy: 0.8054 - val_loss: 0.4266 - val_accuracy: 0.8006 - 705ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "86/86 - 1s - loss: 0.4210 - accuracy: 0.8037 - val_loss: 0.4255 - val_accuracy: 0.8008 - 710ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "86/86 - 1s - loss: 0.4209 - accuracy: 0.8047 - val_loss: 0.4350 - val_accuracy: 0.7960 - 681ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8038 - val_loss: 0.4252 - val_accuracy: 0.8013 - 699ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "86/86 - 1s - loss: 0.4205 - accuracy: 0.8045 - val_loss: 0.4257 - val_accuracy: 0.8011 - 696ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "86/86 - 1s - loss: 0.4198 - accuracy: 0.8063 - val_loss: 0.4272 - val_accuracy: 0.8004 - 704ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "86/86 - 1s - loss: 0.4199 - accuracy: 0.8064 - val_loss: 0.4253 - val_accuracy: 0.8020 - 675ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "86/86 - 1s - loss: 0.4197 - accuracy: 0.8065 - val_loss: 0.4269 - val_accuracy: 0.7993 - 758ms/epoch - 9ms/step\n",
      "Epoch 63: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 2.7497 - accuracy: 0.7501 - val_loss: 1.8340 - val_accuracy: 0.7638 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 1.3412 - accuracy: 0.7676 - val_loss: 0.9615 - val_accuracy: 0.7792 - 739ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.7611 - accuracy: 0.7986 - val_loss: 0.6148 - val_accuracy: 0.8000 - 716ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.5403 - accuracy: 0.8041 - val_loss: 0.4919 - val_accuracy: 0.8010 - 763ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4645 - accuracy: 0.8049 - val_loss: 0.4508 - val_accuracy: 0.8006 - 708ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4394 - accuracy: 0.8052 - val_loss: 0.4380 - val_accuracy: 0.8010 - 717ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4314 - accuracy: 0.8061 - val_loss: 0.4359 - val_accuracy: 0.8013 - 764ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4290 - accuracy: 0.8048 - val_loss: 0.4336 - val_accuracy: 0.8033 - 734ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4268 - accuracy: 0.8055 - val_loss: 0.4326 - val_accuracy: 0.8006 - 705ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4285 - accuracy: 0.8035 - val_loss: 0.4307 - val_accuracy: 0.7989 - 715ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4252 - accuracy: 0.8059 - val_loss: 0.4310 - val_accuracy: 0.8002 - 718ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4248 - accuracy: 0.8060 - val_loss: 0.4336 - val_accuracy: 0.7997 - 679ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4256 - accuracy: 0.8039 - val_loss: 0.4298 - val_accuracy: 0.8006 - 775ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4246 - accuracy: 0.8048 - val_loss: 0.4317 - val_accuracy: 0.8008 - 728ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4247 - accuracy: 0.8037 - val_loss: 0.4283 - val_accuracy: 0.8020 - 741ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4242 - accuracy: 0.8062 - val_loss: 0.4279 - val_accuracy: 0.8013 - 861ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4240 - accuracy: 0.8052 - val_loss: 0.4290 - val_accuracy: 0.8002 - 837ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4229 - accuracy: 0.8047 - val_loss: 0.4314 - val_accuracy: 0.8002 - 723ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4231 - accuracy: 0.8034 - val_loss: 0.4272 - val_accuracy: 0.8008 - 729ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4226 - accuracy: 0.8054 - val_loss: 0.4293 - val_accuracy: 0.8006 - 712ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4230 - accuracy: 0.8048 - val_loss: 0.4275 - val_accuracy: 0.8011 - 690ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4231 - accuracy: 0.8058 - val_loss: 0.4269 - val_accuracy: 0.8006 - 719ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4226 - accuracy: 0.8055 - val_loss: 0.4273 - val_accuracy: 0.8011 - 712ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4220 - accuracy: 0.8057 - val_loss: 0.4315 - val_accuracy: 0.7982 - 753ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4224 - accuracy: 0.8053 - val_loss: 0.4274 - val_accuracy: 0.8024 - 673ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4221 - accuracy: 0.8036 - val_loss: 0.4278 - val_accuracy: 0.8024 - 656ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8049 - val_loss: 0.4325 - val_accuracy: 0.7982 - 629ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4225 - accuracy: 0.8033 - val_loss: 0.4278 - val_accuracy: 0.7999 - 658ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4214 - accuracy: 0.8052 - val_loss: 0.4274 - val_accuracy: 0.8028 - 691ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4221 - accuracy: 0.8050 - val_loss: 0.4270 - val_accuracy: 0.8002 - 727ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4233 - accuracy: 0.8029 - val_loss: 0.4267 - val_accuracy: 0.8013 - 615ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4219 - accuracy: 0.8052 - val_loss: 0.4264 - val_accuracy: 0.8000 - 690ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4218 - accuracy: 0.8050 - val_loss: 0.4258 - val_accuracy: 0.7999 - 678ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8046 - val_loss: 0.4266 - val_accuracy: 0.8006 - 636ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8046 - val_loss: 0.4267 - val_accuracy: 0.8024 - 1s/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4213 - accuracy: 0.8060 - val_loss: 0.4255 - val_accuracy: 0.8000 - 837ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8053 - val_loss: 0.4262 - val_accuracy: 0.8026 - 679ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4211 - accuracy: 0.8052 - val_loss: 0.4256 - val_accuracy: 0.8000 - 795ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4205 - accuracy: 0.8048 - val_loss: 0.4253 - val_accuracy: 0.8011 - 746ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4204 - accuracy: 0.8070 - val_loss: 0.4270 - val_accuracy: 0.8004 - 760ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4214 - accuracy: 0.8045 - val_loss: 0.4266 - val_accuracy: 0.7997 - 730ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4211 - accuracy: 0.8059 - val_loss: 0.4270 - val_accuracy: 0.8002 - 823ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4210 - accuracy: 0.8050 - val_loss: 0.4264 - val_accuracy: 0.8002 - 858ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4198 - accuracy: 0.8051 - val_loss: 0.4259 - val_accuracy: 0.7995 - 1s/epoch - 13ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4206 - accuracy: 0.8060 - val_loss: 0.4283 - val_accuracy: 0.7958 - 1s/epoch - 13ms/step\n",
      "Epoch 46/100\n",
      "86/86 - 1s - loss: 0.4215 - accuracy: 0.8042 - val_loss: 0.4270 - val_accuracy: 0.7999 - 1s/epoch - 13ms/step\n",
      "Epoch 47/100\n",
      "86/86 - 1s - loss: 0.4205 - accuracy: 0.8054 - val_loss: 0.4255 - val_accuracy: 0.8019 - 1s/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "86/86 - 1s - loss: 0.4196 - accuracy: 0.8055 - val_loss: 0.4259 - val_accuracy: 0.8004 - 982ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "86/86 - 1s - loss: 0.4207 - accuracy: 0.8048 - val_loss: 0.4259 - val_accuracy: 0.7993 - 1s/epoch - 13ms/step\n",
      "Epoch 49: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.4335625447171057\n",
      "epi entropy:  0.41136076525460186\n",
      "\n",
      "dataset size:  0.8\n",
      "Epoch 1/100\n",
      "98/98 - 3s - loss: 2.6040 - accuracy: 0.7242 - val_loss: 1.6322 - val_accuracy: 0.7623 - 3s/epoch - 27ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 1.1603 - accuracy: 0.7832 - val_loss: 0.8224 - val_accuracy: 0.8023 - 808ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.6563 - accuracy: 0.8021 - val_loss: 0.5474 - val_accuracy: 0.8031 - 851ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4935 - accuracy: 0.8033 - val_loss: 0.4640 - val_accuracy: 0.8031 - 841ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4463 - accuracy: 0.8044 - val_loss: 0.4432 - val_accuracy: 0.8025 - 835ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4339 - accuracy: 0.8024 - val_loss: 0.4363 - val_accuracy: 0.8034 - 776ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4302 - accuracy: 0.8035 - val_loss: 0.4348 - val_accuracy: 0.8026 - 876ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4293 - accuracy: 0.8036 - val_loss: 0.4333 - val_accuracy: 0.8037 - 876ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4284 - accuracy: 0.8034 - val_loss: 0.4334 - val_accuracy: 0.8017 - 843ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4272 - accuracy: 0.8038 - val_loss: 0.4325 - val_accuracy: 0.8026 - 820ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4272 - accuracy: 0.8028 - val_loss: 0.4319 - val_accuracy: 0.8033 - 785ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4278 - accuracy: 0.8032 - val_loss: 0.4331 - val_accuracy: 0.8033 - 789ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4263 - accuracy: 0.8027 - val_loss: 0.4311 - val_accuracy: 0.8037 - 903ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4258 - accuracy: 0.8037 - val_loss: 0.4315 - val_accuracy: 0.8037 - 829ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.8037 - val_loss: 0.4316 - val_accuracy: 0.8025 - 837ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4256 - accuracy: 0.8038 - val_loss: 0.4324 - val_accuracy: 0.8021 - 861ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4250 - accuracy: 0.8041 - val_loss: 0.4316 - val_accuracy: 0.8025 - 873ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4256 - accuracy: 0.8023 - val_loss: 0.4313 - val_accuracy: 0.8037 - 813ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4256 - accuracy: 0.8023 - val_loss: 0.4298 - val_accuracy: 0.8033 - 815ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4261 - accuracy: 0.8036 - val_loss: 0.4301 - val_accuracy: 0.8028 - 756ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4255 - accuracy: 0.8034 - val_loss: 0.4294 - val_accuracy: 0.8029 - 802ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4250 - accuracy: 0.8042 - val_loss: 0.4362 - val_accuracy: 0.7986 - 825ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4256 - accuracy: 0.8030 - val_loss: 0.4321 - val_accuracy: 0.8017 - 770ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4241 - accuracy: 0.8044 - val_loss: 0.4299 - val_accuracy: 0.8039 - 817ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4245 - accuracy: 0.8033 - val_loss: 0.4304 - val_accuracy: 0.8020 - 855ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4238 - accuracy: 0.8031 - val_loss: 0.4366 - val_accuracy: 0.7954 - 815ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4250 - accuracy: 0.8039 - val_loss: 0.4292 - val_accuracy: 0.8012 - 1s/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4241 - accuracy: 0.8027 - val_loss: 0.4294 - val_accuracy: 0.8029 - 964ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4234 - accuracy: 0.8040 - val_loss: 0.4298 - val_accuracy: 0.8025 - 915ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8031 - val_loss: 0.4286 - val_accuracy: 0.8031 - 821ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4238 - accuracy: 0.8031 - val_loss: 0.4302 - val_accuracy: 0.8018 - 903ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4229 - accuracy: 0.8033 - val_loss: 0.4291 - val_accuracy: 0.8033 - 898ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4244 - accuracy: 0.8031 - val_loss: 0.4314 - val_accuracy: 0.8020 - 848ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8034 - val_loss: 0.4293 - val_accuracy: 0.8034 - 822ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4246 - accuracy: 0.8019 - val_loss: 0.4290 - val_accuracy: 0.8025 - 868ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8028 - val_loss: 0.4291 - val_accuracy: 0.8025 - 759ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8032 - val_loss: 0.4320 - val_accuracy: 0.8025 - 733ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4232 - accuracy: 0.8038 - val_loss: 0.4284 - val_accuracy: 0.8033 - 823ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4226 - accuracy: 0.8036 - val_loss: 0.4304 - val_accuracy: 0.8007 - 802ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.4226 - accuracy: 0.8039 - val_loss: 0.4290 - val_accuracy: 0.8029 - 853ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8039 - val_loss: 0.4289 - val_accuracy: 0.8023 - 835ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "98/98 - 1s - loss: 0.4228 - accuracy: 0.8029 - val_loss: 0.4282 - val_accuracy: 0.8020 - 779ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "98/98 - 1s - loss: 0.4229 - accuracy: 0.8040 - val_loss: 0.4280 - val_accuracy: 0.8023 - 789ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8035 - val_loss: 0.4315 - val_accuracy: 0.8005 - 791ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8025 - val_loss: 0.4283 - val_accuracy: 0.8036 - 860ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8043 - val_loss: 0.4283 - val_accuracy: 0.8033 - 834ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "98/98 - 1s - loss: 0.4227 - accuracy: 0.8026 - val_loss: 0.4293 - val_accuracy: 0.7993 - 849ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "98/98 - 1s - loss: 0.4223 - accuracy: 0.8034 - val_loss: 0.4308 - val_accuracy: 0.8007 - 785ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "98/98 - 1s - loss: 0.4225 - accuracy: 0.8029 - val_loss: 0.4279 - val_accuracy: 0.8029 - 788ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "98/98 - 1s - loss: 0.4226 - accuracy: 0.8044 - val_loss: 0.4287 - val_accuracy: 0.8012 - 899ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8042 - val_loss: 0.4307 - val_accuracy: 0.8009 - 868ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8038 - val_loss: 0.4307 - val_accuracy: 0.8028 - 807ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8033 - val_loss: 0.4281 - val_accuracy: 0.8026 - 850ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "98/98 - 1s - loss: 0.4225 - accuracy: 0.8046 - val_loss: 0.4279 - val_accuracy: 0.8017 - 828ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "98/98 - 1s - loss: 0.4224 - accuracy: 0.8018 - val_loss: 0.4315 - val_accuracy: 0.8025 - 874ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "98/98 - 1s - loss: 0.4228 - accuracy: 0.8035 - val_loss: 0.4289 - val_accuracy: 0.8017 - 808ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "98/98 - 1s - loss: 0.4229 - accuracy: 0.8028 - val_loss: 0.4282 - val_accuracy: 0.8042 - 801ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "98/98 - 1s - loss: 0.4227 - accuracy: 0.8033 - val_loss: 0.4319 - val_accuracy: 0.8015 - 799ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "98/98 - 1s - loss: 0.4223 - accuracy: 0.8040 - val_loss: 0.4315 - val_accuracy: 0.7999 - 815ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8035 - val_loss: 0.4289 - val_accuracy: 0.8004 - 844ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "98/98 - 1s - loss: 0.4218 - accuracy: 0.8038 - val_loss: 0.4295 - val_accuracy: 0.8010 - 843ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "98/98 - 1s - loss: 0.4229 - accuracy: 0.8033 - val_loss: 0.4279 - val_accuracy: 0.7999 - 785ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "98/98 - 1s - loss: 0.4228 - accuracy: 0.8028 - val_loss: 0.4337 - val_accuracy: 0.8020 - 813ms/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "98/98 - 1s - loss: 0.4246 - accuracy: 0.8012 - val_loss: 0.4316 - val_accuracy: 0.8023 - 824ms/epoch - 8ms/step\n",
      "Epoch 64: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "98/98 - 2s - loss: 2.6162 - accuracy: 0.6968 - val_loss: 1.6562 - val_accuracy: 0.7620 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 1.1792 - accuracy: 0.7636 - val_loss: 0.8304 - val_accuracy: 0.7845 - 779ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.6632 - accuracy: 0.7981 - val_loss: 0.5534 - val_accuracy: 0.7978 - 814ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4974 - accuracy: 0.8034 - val_loss: 0.4669 - val_accuracy: 0.8025 - 734ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4490 - accuracy: 0.8033 - val_loss: 0.4441 - val_accuracy: 0.8026 - 882ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4352 - accuracy: 0.8041 - val_loss: 0.4430 - val_accuracy: 0.7988 - 766ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4311 - accuracy: 0.8035 - val_loss: 0.4362 - val_accuracy: 0.8031 - 821ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4296 - accuracy: 0.8037 - val_loss: 0.4387 - val_accuracy: 0.8018 - 834ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4280 - accuracy: 0.8037 - val_loss: 0.4329 - val_accuracy: 0.8026 - 779ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4277 - accuracy: 0.8034 - val_loss: 0.4336 - val_accuracy: 0.8028 - 879ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4278 - accuracy: 0.8030 - val_loss: 0.4317 - val_accuracy: 0.8023 - 841ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.4316 - val_accuracy: 0.8021 - 780ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4267 - accuracy: 0.8027 - val_loss: 0.4322 - val_accuracy: 0.8010 - 822ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4273 - accuracy: 0.8024 - val_loss: 0.4408 - val_accuracy: 0.7970 - 911ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4288 - accuracy: 0.8020 - val_loss: 0.4335 - val_accuracy: 0.7989 - 819ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4258 - accuracy: 0.8031 - val_loss: 0.4310 - val_accuracy: 0.8026 - 788ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.8043 - val_loss: 0.4336 - val_accuracy: 0.8028 - 860ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4258 - accuracy: 0.8039 - val_loss: 0.4312 - val_accuracy: 0.8018 - 793ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4265 - accuracy: 0.8026 - val_loss: 0.4336 - val_accuracy: 0.8005 - 967ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.8033 - val_loss: 0.4339 - val_accuracy: 0.8013 - 916ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4265 - accuracy: 0.8033 - val_loss: 0.4300 - val_accuracy: 0.8029 - 830ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4248 - accuracy: 0.8038 - val_loss: 0.4297 - val_accuracy: 0.8029 - 863ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.4311 - val_accuracy: 0.8023 - 892ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4258 - accuracy: 0.8016 - val_loss: 0.4304 - val_accuracy: 0.8026 - 880ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4263 - accuracy: 0.8020 - val_loss: 0.4307 - val_accuracy: 0.8025 - 804ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4249 - accuracy: 0.8052 - val_loss: 0.4303 - val_accuracy: 0.8025 - 809ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4235 - accuracy: 0.8044 - val_loss: 0.4311 - val_accuracy: 0.8018 - 751ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8042 - val_loss: 0.4376 - val_accuracy: 0.7964 - 788ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8046 - val_loss: 0.4331 - val_accuracy: 0.8020 - 796ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4244 - accuracy: 0.8026 - val_loss: 0.4295 - val_accuracy: 0.8028 - 832ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4235 - accuracy: 0.8045 - val_loss: 0.4288 - val_accuracy: 0.8020 - 763ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8031 - val_loss: 0.4313 - val_accuracy: 0.8013 - 756ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8038 - val_loss: 0.4305 - val_accuracy: 0.8010 - 826ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8041 - val_loss: 0.4295 - val_accuracy: 0.8029 - 868ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8040 - val_loss: 0.4307 - val_accuracy: 0.8001 - 843ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8036 - val_loss: 0.4296 - val_accuracy: 0.8028 - 797ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4242 - accuracy: 0.8030 - val_loss: 0.4315 - val_accuracy: 0.8004 - 806ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8033 - val_loss: 0.4290 - val_accuracy: 0.8021 - 796ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4242 - accuracy: 0.8027 - val_loss: 0.4292 - val_accuracy: 0.8025 - 769ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.4234 - accuracy: 0.8032 - val_loss: 0.4339 - val_accuracy: 0.8013 - 866ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.4235 - accuracy: 0.8026 - val_loss: 0.4288 - val_accuracy: 0.8029 - 844ms/epoch - 9ms/step\n",
      "Epoch 41: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "98/98 - 2s - loss: 2.6253 - accuracy: 0.7596 - val_loss: 1.6782 - val_accuracy: 0.7620 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 1.2006 - accuracy: 0.7637 - val_loss: 0.8457 - val_accuracy: 0.7871 - 822ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.6736 - accuracy: 0.7934 - val_loss: 0.5551 - val_accuracy: 0.8010 - 817ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4990 - accuracy: 0.8027 - val_loss: 0.4679 - val_accuracy: 0.8031 - 796ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4488 - accuracy: 0.8030 - val_loss: 0.4438 - val_accuracy: 0.8026 - 742ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4356 - accuracy: 0.8041 - val_loss: 0.4404 - val_accuracy: 0.8021 - 785ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4319 - accuracy: 0.8035 - val_loss: 0.4344 - val_accuracy: 0.8025 - 822ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4285 - accuracy: 0.8042 - val_loss: 0.4334 - val_accuracy: 0.8039 - 844ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4291 - accuracy: 0.8042 - val_loss: 0.4337 - val_accuracy: 0.8041 - 849ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4287 - accuracy: 0.8017 - val_loss: 0.4334 - val_accuracy: 0.8025 - 821ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4272 - accuracy: 0.8039 - val_loss: 0.4313 - val_accuracy: 0.8031 - 863ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4261 - accuracy: 0.8044 - val_loss: 0.4323 - val_accuracy: 0.8005 - 805ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4261 - accuracy: 0.8033 - val_loss: 0.4378 - val_accuracy: 0.7993 - 759ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4276 - accuracy: 0.8030 - val_loss: 0.4311 - val_accuracy: 0.8031 - 798ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4256 - accuracy: 0.8037 - val_loss: 0.4309 - val_accuracy: 0.8031 - 770ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4245 - accuracy: 0.8030 - val_loss: 0.4321 - val_accuracy: 0.8031 - 762ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4255 - accuracy: 0.8036 - val_loss: 0.4315 - val_accuracy: 0.8033 - 790ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4245 - accuracy: 0.8036 - val_loss: 0.4299 - val_accuracy: 0.8041 - 805ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4247 - accuracy: 0.8038 - val_loss: 0.4354 - val_accuracy: 0.8013 - 749ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4252 - accuracy: 0.8028 - val_loss: 0.4300 - val_accuracy: 0.8029 - 774ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4238 - accuracy: 0.8042 - val_loss: 0.4289 - val_accuracy: 0.8045 - 819ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4240 - accuracy: 0.8043 - val_loss: 0.4313 - val_accuracy: 0.8004 - 892ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8034 - val_loss: 0.4319 - val_accuracy: 0.8010 - 799ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.4292 - val_accuracy: 0.8034 - 829ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4238 - accuracy: 0.8043 - val_loss: 0.4291 - val_accuracy: 0.8017 - 786ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8037 - val_loss: 0.4303 - val_accuracy: 0.8007 - 779ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8023 - val_loss: 0.4388 - val_accuracy: 0.7957 - 850ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8031 - val_loss: 0.4343 - val_accuracy: 0.7964 - 840ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4250 - accuracy: 0.8034 - val_loss: 0.4333 - val_accuracy: 0.8029 - 870ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4248 - accuracy: 0.8037 - val_loss: 0.4293 - val_accuracy: 0.8001 - 839ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4234 - accuracy: 0.8040 - val_loss: 0.4306 - val_accuracy: 0.8026 - 822ms/epoch - 8ms/step\n",
      "Epoch 31: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "98/98 - 2s - loss: 2.6811 - accuracy: 0.7242 - val_loss: 1.6972 - val_accuracy: 0.7620 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 1.2015 - accuracy: 0.7641 - val_loss: 0.8373 - val_accuracy: 0.7895 - 790ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.6664 - accuracy: 0.7942 - val_loss: 0.5519 - val_accuracy: 0.7994 - 817ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4978 - accuracy: 0.8023 - val_loss: 0.4711 - val_accuracy: 0.8029 - 732ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4495 - accuracy: 0.8033 - val_loss: 0.4478 - val_accuracy: 0.8020 - 825ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4365 - accuracy: 0.8034 - val_loss: 0.4372 - val_accuracy: 0.8033 - 869ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4311 - accuracy: 0.8025 - val_loss: 0.4356 - val_accuracy: 0.8029 - 767ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4310 - accuracy: 0.8038 - val_loss: 0.4346 - val_accuracy: 0.8025 - 764ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4298 - accuracy: 0.8031 - val_loss: 0.4330 - val_accuracy: 0.8031 - 817ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4275 - accuracy: 0.8040 - val_loss: 0.4343 - val_accuracy: 0.8001 - 812ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4282 - accuracy: 0.8041 - val_loss: 0.4317 - val_accuracy: 0.8047 - 753ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4276 - accuracy: 0.8032 - val_loss: 0.4353 - val_accuracy: 0.8025 - 813ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4280 - accuracy: 0.8022 - val_loss: 0.4421 - val_accuracy: 0.7930 - 719ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4274 - accuracy: 0.8022 - val_loss: 0.4348 - val_accuracy: 0.8001 - 802ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4262 - accuracy: 0.8028 - val_loss: 0.4316 - val_accuracy: 0.8025 - 849ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4258 - accuracy: 0.8040 - val_loss: 0.4299 - val_accuracy: 0.8023 - 823ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4257 - accuracy: 0.8040 - val_loss: 0.4367 - val_accuracy: 0.8023 - 796ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4257 - accuracy: 0.8033 - val_loss: 0.4341 - val_accuracy: 0.7994 - 796ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4256 - accuracy: 0.8037 - val_loss: 0.4298 - val_accuracy: 0.8033 - 764ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4249 - accuracy: 0.8029 - val_loss: 0.4328 - val_accuracy: 0.8023 - 795ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4247 - accuracy: 0.8036 - val_loss: 0.4347 - val_accuracy: 0.7981 - 830ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4246 - accuracy: 0.8040 - val_loss: 0.4338 - val_accuracy: 0.8023 - 771ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4255 - accuracy: 0.8038 - val_loss: 0.4306 - val_accuracy: 0.8026 - 870ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4266 - accuracy: 0.8014 - val_loss: 0.4326 - val_accuracy: 0.7999 - 833ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4245 - accuracy: 0.8034 - val_loss: 0.4291 - val_accuracy: 0.8039 - 795ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4247 - accuracy: 0.8030 - val_loss: 0.4293 - val_accuracy: 0.8037 - 949ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8043 - val_loss: 0.4297 - val_accuracy: 0.8029 - 860ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4238 - accuracy: 0.8048 - val_loss: 0.4287 - val_accuracy: 0.8023 - 780ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4238 - accuracy: 0.8045 - val_loss: 0.4311 - val_accuracy: 0.8025 - 807ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8032 - val_loss: 0.4330 - val_accuracy: 0.8023 - 822ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4242 - accuracy: 0.8039 - val_loss: 0.4379 - val_accuracy: 0.7940 - 822ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4238 - accuracy: 0.8040 - val_loss: 0.4311 - val_accuracy: 0.8021 - 730ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8038 - val_loss: 0.4302 - val_accuracy: 0.8009 - 793ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4247 - accuracy: 0.8028 - val_loss: 0.4356 - val_accuracy: 0.7945 - 755ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4247 - accuracy: 0.8028 - val_loss: 0.4298 - val_accuracy: 0.8041 - 811ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8022 - val_loss: 0.4297 - val_accuracy: 0.8017 - 850ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4242 - accuracy: 0.8035 - val_loss: 0.4285 - val_accuracy: 0.8031 - 765ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4253 - accuracy: 0.8018 - val_loss: 0.4284 - val_accuracy: 0.8031 - 839ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8022 - val_loss: 0.4301 - val_accuracy: 0.8010 - 815ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8042 - val_loss: 0.4282 - val_accuracy: 0.8028 - 837ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.4227 - accuracy: 0.8032 - val_loss: 0.4285 - val_accuracy: 0.8036 - 762ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8031 - val_loss: 0.4312 - val_accuracy: 0.8034 - 822ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "98/98 - 1s - loss: 0.4241 - accuracy: 0.8037 - val_loss: 0.4294 - val_accuracy: 0.8018 - 931ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8041 - val_loss: 0.4408 - val_accuracy: 0.7957 - 933ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "98/98 - 1s - loss: 0.4240 - accuracy: 0.8032 - val_loss: 0.4290 - val_accuracy: 0.8028 - 847ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8038 - val_loss: 0.4287 - val_accuracy: 0.8010 - 797ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "98/98 - 1s - loss: 0.4229 - accuracy: 0.8040 - val_loss: 0.4313 - val_accuracy: 0.8025 - 771ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8041 - val_loss: 0.4290 - val_accuracy: 0.8020 - 789ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "98/98 - 1s - loss: 0.4228 - accuracy: 0.8038 - val_loss: 0.4288 - val_accuracy: 0.8026 - 817ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "98/98 - 1s - loss: 0.4240 - accuracy: 0.8036 - val_loss: 0.4339 - val_accuracy: 0.7978 - 808ms/epoch - 8ms/step\n",
      "Epoch 50: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "98/98 - 2s - loss: 2.6034 - accuracy: 0.7592 - val_loss: 1.6515 - val_accuracy: 0.7620 - 2s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 1.1678 - accuracy: 0.7877 - val_loss: 0.8223 - val_accuracy: 0.8031 - 885ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.6560 - accuracy: 0.8019 - val_loss: 0.5483 - val_accuracy: 0.8041 - 744ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4927 - accuracy: 0.8031 - val_loss: 0.4638 - val_accuracy: 0.8012 - 772ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4465 - accuracy: 0.8038 - val_loss: 0.4416 - val_accuracy: 0.8009 - 794ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4353 - accuracy: 0.8006 - val_loss: 0.4353 - val_accuracy: 0.8026 - 803ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4297 - accuracy: 0.8026 - val_loss: 0.4351 - val_accuracy: 0.8007 - 834ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4287 - accuracy: 0.8025 - val_loss: 0.4319 - val_accuracy: 0.8017 - 964ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4269 - accuracy: 0.8030 - val_loss: 0.4342 - val_accuracy: 0.8026 - 1s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4265 - accuracy: 0.8037 - val_loss: 0.4339 - val_accuracy: 0.7988 - 1s/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4276 - accuracy: 0.8032 - val_loss: 0.4338 - val_accuracy: 0.8012 - 1s/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4260 - accuracy: 0.8030 - val_loss: 0.4380 - val_accuracy: 0.7937 - 955ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4263 - accuracy: 0.8045 - val_loss: 0.4301 - val_accuracy: 0.8033 - 1s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4261 - accuracy: 0.8031 - val_loss: 0.4371 - val_accuracy: 0.7957 - 1s/epoch - 15ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4256 - accuracy: 0.8024 - val_loss: 0.4303 - val_accuracy: 0.8028 - 817ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4248 - accuracy: 0.8043 - val_loss: 0.4327 - val_accuracy: 0.8005 - 876ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4271 - accuracy: 0.8013 - val_loss: 0.4307 - val_accuracy: 0.8025 - 1s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4255 - accuracy: 0.8033 - val_loss: 0.4309 - val_accuracy: 0.8026 - 927ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.8027 - val_loss: 0.4383 - val_accuracy: 0.7938 - 824ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4254 - accuracy: 0.8020 - val_loss: 0.4321 - val_accuracy: 0.8025 - 751ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4243 - accuracy: 0.8029 - val_loss: 0.4312 - val_accuracy: 0.7996 - 932ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4240 - accuracy: 0.8037 - val_loss: 0.4292 - val_accuracy: 0.8033 - 886ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4243 - accuracy: 0.8033 - val_loss: 0.4304 - val_accuracy: 0.8055 - 1s/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8032 - val_loss: 0.4332 - val_accuracy: 0.7959 - 859ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4243 - accuracy: 0.8034 - val_loss: 0.4304 - val_accuracy: 0.8002 - 943ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8033 - val_loss: 0.4297 - val_accuracy: 0.8025 - 952ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4252 - accuracy: 0.8020 - val_loss: 0.4285 - val_accuracy: 0.8031 - 900ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8036 - val_loss: 0.4376 - val_accuracy: 0.7973 - 855ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4257 - accuracy: 0.8017 - val_loss: 0.4288 - val_accuracy: 0.8044 - 921ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4246 - accuracy: 0.8014 - val_loss: 0.4285 - val_accuracy: 0.8033 - 1s/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4244 - accuracy: 0.8028 - val_loss: 0.4289 - val_accuracy: 0.8023 - 929ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8042 - val_loss: 0.4299 - val_accuracy: 0.8026 - 798ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4235 - accuracy: 0.8030 - val_loss: 0.4290 - val_accuracy: 0.8012 - 905ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8028 - val_loss: 0.4415 - val_accuracy: 0.7937 - 905ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4253 - accuracy: 0.8014 - val_loss: 0.4289 - val_accuracy: 0.8012 - 844ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4232 - accuracy: 0.8036 - val_loss: 0.4289 - val_accuracy: 0.8015 - 834ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4235 - accuracy: 0.8034 - val_loss: 0.4286 - val_accuracy: 0.8021 - 859ms/epoch - 9ms/step\n",
      "Epoch 37: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "98/98 - 3s - loss: 2.6383 - accuracy: 0.7540 - val_loss: 1.6910 - val_accuracy: 0.7620 - 3s/epoch - 27ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 1.2003 - accuracy: 0.7812 - val_loss: 0.8390 - val_accuracy: 0.8001 - 872ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.6643 - accuracy: 0.8018 - val_loss: 0.5497 - val_accuracy: 0.8020 - 796ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4941 - accuracy: 0.8038 - val_loss: 0.4659 - val_accuracy: 0.7993 - 761ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4464 - accuracy: 0.8029 - val_loss: 0.4422 - val_accuracy: 0.8017 - 750ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4333 - accuracy: 0.8029 - val_loss: 0.4356 - val_accuracy: 0.8026 - 939ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4303 - accuracy: 0.8032 - val_loss: 0.4377 - val_accuracy: 0.7999 - 775ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4285 - accuracy: 0.8041 - val_loss: 0.4332 - val_accuracy: 0.8018 - 804ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4283 - accuracy: 0.8035 - val_loss: 0.4315 - val_accuracy: 0.8021 - 796ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4271 - accuracy: 0.8038 - val_loss: 0.4355 - val_accuracy: 0.7999 - 848ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4264 - accuracy: 0.8040 - val_loss: 0.4324 - val_accuracy: 0.8057 - 842ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4264 - accuracy: 0.8029 - val_loss: 0.4344 - val_accuracy: 0.7997 - 768ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4261 - accuracy: 0.8030 - val_loss: 0.4346 - val_accuracy: 0.8020 - 781ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4271 - accuracy: 0.8021 - val_loss: 0.4310 - val_accuracy: 0.8029 - 766ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.8030 - val_loss: 0.4306 - val_accuracy: 0.8031 - 733ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4251 - accuracy: 0.8031 - val_loss: 0.4335 - val_accuracy: 0.8013 - 716ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4252 - accuracy: 0.8030 - val_loss: 0.4303 - val_accuracy: 0.8026 - 721ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4253 - accuracy: 0.8042 - val_loss: 0.4295 - val_accuracy: 0.8025 - 735ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4243 - accuracy: 0.8036 - val_loss: 0.4299 - val_accuracy: 0.8042 - 719ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4246 - accuracy: 0.8034 - val_loss: 0.4321 - val_accuracy: 0.7988 - 831ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4246 - accuracy: 0.8019 - val_loss: 0.4311 - val_accuracy: 0.8002 - 726ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4244 - accuracy: 0.8044 - val_loss: 0.4325 - val_accuracy: 0.8025 - 793ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4245 - accuracy: 0.8031 - val_loss: 0.4366 - val_accuracy: 0.7991 - 747ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4240 - accuracy: 0.8040 - val_loss: 0.4305 - val_accuracy: 0.8029 - 771ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4248 - accuracy: 0.8031 - val_loss: 0.4290 - val_accuracy: 0.8028 - 766ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4240 - accuracy: 0.8042 - val_loss: 0.4302 - val_accuracy: 0.8015 - 773ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4254 - accuracy: 0.8028 - val_loss: 0.4305 - val_accuracy: 0.8026 - 769ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8037 - val_loss: 0.4287 - val_accuracy: 0.8031 - 846ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8031 - val_loss: 0.4376 - val_accuracy: 0.7972 - 796ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4235 - accuracy: 0.8042 - val_loss: 0.4317 - val_accuracy: 0.7999 - 779ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8032 - val_loss: 0.4294 - val_accuracy: 0.8017 - 712ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4238 - accuracy: 0.8037 - val_loss: 0.4302 - val_accuracy: 0.8031 - 779ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8037 - val_loss: 0.4303 - val_accuracy: 0.8028 - 776ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8026 - val_loss: 0.4288 - val_accuracy: 0.8028 - 762ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8048 - val_loss: 0.4306 - val_accuracy: 0.8002 - 755ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8047 - val_loss: 0.4283 - val_accuracy: 0.8042 - 810ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4223 - accuracy: 0.8039 - val_loss: 0.4289 - val_accuracy: 0.8031 - 797ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4226 - accuracy: 0.8033 - val_loss: 0.4287 - val_accuracy: 0.8025 - 822ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4232 - accuracy: 0.8036 - val_loss: 0.4290 - val_accuracy: 0.8001 - 761ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8036 - val_loss: 0.4333 - val_accuracy: 0.7981 - 802ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.4226 - accuracy: 0.8042 - val_loss: 0.4300 - val_accuracy: 0.8005 - 778ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8029 - val_loss: 0.4290 - val_accuracy: 0.8031 - 746ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "98/98 - 1s - loss: 0.4228 - accuracy: 0.8032 - val_loss: 0.4303 - val_accuracy: 0.8025 - 883ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "98/98 - 1s - loss: 0.4223 - accuracy: 0.8051 - val_loss: 0.4291 - val_accuracy: 0.8049 - 756ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "98/98 - 1s - loss: 0.4234 - accuracy: 0.8044 - val_loss: 0.4306 - val_accuracy: 0.8009 - 827ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8018 - val_loss: 0.4285 - val_accuracy: 0.8042 - 778ms/epoch - 8ms/step\n",
      "Epoch 46: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "98/98 - 2s - loss: 2.5893 - accuracy: 0.7573 - val_loss: 1.6353 - val_accuracy: 0.7681 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 1.1498 - accuracy: 0.7944 - val_loss: 0.8076 - val_accuracy: 0.8033 - 764ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.6460 - accuracy: 0.8029 - val_loss: 0.5410 - val_accuracy: 0.8031 - 775ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4901 - accuracy: 0.8028 - val_loss: 0.4663 - val_accuracy: 0.8028 - 784ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4451 - accuracy: 0.8042 - val_loss: 0.4402 - val_accuracy: 0.8026 - 883ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4337 - accuracy: 0.8028 - val_loss: 0.4356 - val_accuracy: 0.8026 - 728ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4301 - accuracy: 0.8029 - val_loss: 0.4366 - val_accuracy: 0.8013 - 736ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4286 - accuracy: 0.8039 - val_loss: 0.4364 - val_accuracy: 0.8002 - 688ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4288 - accuracy: 0.8022 - val_loss: 0.4322 - val_accuracy: 0.8029 - 768ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4276 - accuracy: 0.8026 - val_loss: 0.4332 - val_accuracy: 0.8052 - 799ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4274 - accuracy: 0.8026 - val_loss: 0.4396 - val_accuracy: 0.7965 - 776ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4277 - accuracy: 0.8014 - val_loss: 0.4330 - val_accuracy: 0.8029 - 718ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4253 - accuracy: 0.8043 - val_loss: 0.4312 - val_accuracy: 0.8044 - 715ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4265 - accuracy: 0.8031 - val_loss: 0.4304 - val_accuracy: 0.8028 - 849ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4258 - accuracy: 0.8031 - val_loss: 0.4309 - val_accuracy: 0.8037 - 756ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4262 - accuracy: 0.8043 - val_loss: 0.4346 - val_accuracy: 0.7996 - 1s/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4263 - accuracy: 0.8025 - val_loss: 0.4309 - val_accuracy: 0.8031 - 975ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4268 - accuracy: 0.8039 - val_loss: 0.4309 - val_accuracy: 0.8023 - 994ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4247 - accuracy: 0.8025 - val_loss: 0.4298 - val_accuracy: 0.8029 - 1s/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4251 - accuracy: 0.8042 - val_loss: 0.4341 - val_accuracy: 0.8021 - 1s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4269 - accuracy: 0.8015 - val_loss: 0.4358 - val_accuracy: 0.7993 - 856ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.4344 - val_accuracy: 0.7981 - 1s/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4254 - accuracy: 0.8033 - val_loss: 0.4288 - val_accuracy: 0.8028 - 1s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.8025 - val_loss: 0.4445 - val_accuracy: 0.7922 - 1s/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4255 - accuracy: 0.8022 - val_loss: 0.4314 - val_accuracy: 0.7989 - 1s/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4248 - accuracy: 0.8033 - val_loss: 0.4324 - val_accuracy: 0.8009 - 798ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4255 - accuracy: 0.8021 - val_loss: 0.4301 - val_accuracy: 0.8025 - 690ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4247 - accuracy: 0.8032 - val_loss: 0.4298 - val_accuracy: 0.8029 - 944ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8026 - val_loss: 0.4322 - val_accuracy: 0.8012 - 1s/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4251 - accuracy: 0.8034 - val_loss: 0.4311 - val_accuracy: 0.8013 - 1s/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4244 - accuracy: 0.8041 - val_loss: 0.4290 - val_accuracy: 0.8026 - 1s/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4251 - accuracy: 0.8037 - val_loss: 0.4308 - val_accuracy: 0.8013 - 745ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8040 - val_loss: 0.4297 - val_accuracy: 0.8025 - 708ms/epoch - 7ms/step\n",
      "Epoch 33: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "98/98 - 3s - loss: 2.6131 - accuracy: 0.7273 - val_loss: 1.6506 - val_accuracy: 0.7620 - 3s/epoch - 34ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 1.1711 - accuracy: 0.7751 - val_loss: 0.8259 - val_accuracy: 0.7943 - 781ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.6583 - accuracy: 0.7994 - val_loss: 0.5501 - val_accuracy: 0.8028 - 766ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4947 - accuracy: 0.8033 - val_loss: 0.4652 - val_accuracy: 0.8021 - 734ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4473 - accuracy: 0.8039 - val_loss: 0.4436 - val_accuracy: 0.8021 - 781ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4346 - accuracy: 0.8032 - val_loss: 0.4364 - val_accuracy: 0.8018 - 859ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4302 - accuracy: 0.8035 - val_loss: 0.4347 - val_accuracy: 0.8029 - 750ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4293 - accuracy: 0.8031 - val_loss: 0.4337 - val_accuracy: 0.8029 - 703ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4278 - accuracy: 0.8034 - val_loss: 0.4322 - val_accuracy: 0.8033 - 722ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4280 - accuracy: 0.8040 - val_loss: 0.4314 - val_accuracy: 0.8025 - 766ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4265 - accuracy: 0.8042 - val_loss: 0.4319 - val_accuracy: 0.8036 - 750ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4269 - accuracy: 0.8034 - val_loss: 0.4319 - val_accuracy: 0.8025 - 766ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4257 - accuracy: 0.8043 - val_loss: 0.4314 - val_accuracy: 0.8012 - 797ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4267 - accuracy: 0.8025 - val_loss: 0.4308 - val_accuracy: 0.8033 - 708ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4260 - accuracy: 0.8028 - val_loss: 0.4299 - val_accuracy: 0.8025 - 781ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4260 - accuracy: 0.8032 - val_loss: 0.4326 - val_accuracy: 0.7994 - 703ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4252 - accuracy: 0.8030 - val_loss: 0.4311 - val_accuracy: 0.8015 - 781ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4245 - accuracy: 0.8041 - val_loss: 0.4329 - val_accuracy: 0.8009 - 750ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4249 - accuracy: 0.8030 - val_loss: 0.4313 - val_accuracy: 0.8012 - 703ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4251 - accuracy: 0.8028 - val_loss: 0.4331 - val_accuracy: 0.8018 - 797ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4241 - accuracy: 0.8030 - val_loss: 0.4405 - val_accuracy: 0.7957 - 750ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4242 - accuracy: 0.8050 - val_loss: 0.4298 - val_accuracy: 0.8028 - 766ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4252 - accuracy: 0.8030 - val_loss: 0.4297 - val_accuracy: 0.8034 - 734ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4246 - accuracy: 0.8036 - val_loss: 0.4304 - val_accuracy: 0.8034 - 750ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4247 - accuracy: 0.8030 - val_loss: 0.4302 - val_accuracy: 0.8036 - 750ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8043 - val_loss: 0.4293 - val_accuracy: 0.8025 - 769ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4241 - accuracy: 0.8037 - val_loss: 0.4299 - val_accuracy: 0.8031 - 803ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8038 - val_loss: 0.4319 - val_accuracy: 0.8007 - 779ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8022 - val_loss: 0.4291 - val_accuracy: 0.8028 - 750ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4243 - accuracy: 0.8024 - val_loss: 0.4293 - val_accuracy: 0.8028 - 796ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4232 - accuracy: 0.8041 - val_loss: 0.4293 - val_accuracy: 0.8026 - 734ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8041 - val_loss: 0.4292 - val_accuracy: 0.8023 - 812ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4247 - accuracy: 0.8037 - val_loss: 0.4285 - val_accuracy: 0.8028 - 713ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4225 - accuracy: 0.8035 - val_loss: 0.4280 - val_accuracy: 0.8033 - 737ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4241 - accuracy: 0.8043 - val_loss: 0.4310 - val_accuracy: 0.8002 - 789ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4241 - accuracy: 0.8026 - val_loss: 0.4286 - val_accuracy: 0.8029 - 753ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4229 - accuracy: 0.8042 - val_loss: 0.4288 - val_accuracy: 0.8018 - 750ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8034 - val_loss: 0.4281 - val_accuracy: 0.8033 - 797ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4235 - accuracy: 0.8036 - val_loss: 0.4290 - val_accuracy: 0.8033 - 750ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.4224 - accuracy: 0.8040 - val_loss: 0.4282 - val_accuracy: 0.8029 - 812ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.4224 - accuracy: 0.8038 - val_loss: 0.4290 - val_accuracy: 0.8037 - 819ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "98/98 - 1s - loss: 0.4222 - accuracy: 0.8029 - val_loss: 0.4305 - val_accuracy: 0.8015 - 794ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "98/98 - 1s - loss: 0.4224 - accuracy: 0.8038 - val_loss: 0.4330 - val_accuracy: 0.8012 - 766ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "98/98 - 1s - loss: 0.4221 - accuracy: 0.8036 - val_loss: 0.4275 - val_accuracy: 0.8031 - 797ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "98/98 - 1s - loss: 0.4238 - accuracy: 0.8028 - val_loss: 0.4283 - val_accuracy: 0.8025 - 781ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "98/98 - 1s - loss: 0.4216 - accuracy: 0.8045 - val_loss: 0.4294 - val_accuracy: 0.8029 - 766ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "98/98 - 1s - loss: 0.4215 - accuracy: 0.8037 - val_loss: 0.4321 - val_accuracy: 0.8025 - 719ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "98/98 - 1s - loss: 0.4232 - accuracy: 0.8032 - val_loss: 0.4347 - val_accuracy: 0.7961 - 734ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "98/98 - 1s - loss: 0.4226 - accuracy: 0.8040 - val_loss: 0.4281 - val_accuracy: 0.8025 - 735ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "98/98 - 1s - loss: 0.4223 - accuracy: 0.8027 - val_loss: 0.4277 - val_accuracy: 0.8021 - 766ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "98/98 - 1s - loss: 0.4220 - accuracy: 0.8037 - val_loss: 0.4295 - val_accuracy: 0.8029 - 771ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "98/98 - 1s - loss: 0.4228 - accuracy: 0.8025 - val_loss: 0.4305 - val_accuracy: 0.8013 - 750ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "98/98 - 1s - loss: 0.4224 - accuracy: 0.8040 - val_loss: 0.4279 - val_accuracy: 0.8029 - 823ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "98/98 - 1s - loss: 0.4222 - accuracy: 0.8047 - val_loss: 0.4294 - val_accuracy: 0.8010 - 797ms/epoch - 8ms/step\n",
      "Epoch 54: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "98/98 - 2s - loss: 2.5141 - accuracy: 0.7608 - val_loss: 1.5854 - val_accuracy: 0.7863 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 1.1259 - accuracy: 0.7952 - val_loss: 0.7986 - val_accuracy: 0.8015 - 797ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.6419 - accuracy: 0.8028 - val_loss: 0.5426 - val_accuracy: 0.8031 - 719ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4899 - accuracy: 0.8038 - val_loss: 0.4652 - val_accuracy: 0.7991 - 781ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4466 - accuracy: 0.8033 - val_loss: 0.4429 - val_accuracy: 0.8029 - 744ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4350 - accuracy: 0.8038 - val_loss: 0.4373 - val_accuracy: 0.8021 - 734ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4321 - accuracy: 0.8030 - val_loss: 0.4358 - val_accuracy: 0.8028 - 781ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4291 - accuracy: 0.8038 - val_loss: 0.4346 - val_accuracy: 0.8017 - 755ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4295 - accuracy: 0.8021 - val_loss: 0.4382 - val_accuracy: 0.7961 - 734ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4290 - accuracy: 0.8029 - val_loss: 0.4339 - val_accuracy: 0.8026 - 766ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4271 - accuracy: 0.8028 - val_loss: 0.4338 - val_accuracy: 0.8028 - 750ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4273 - accuracy: 0.8029 - val_loss: 0.4318 - val_accuracy: 0.8028 - 734ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4266 - accuracy: 0.8037 - val_loss: 0.4311 - val_accuracy: 0.8026 - 781ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4266 - accuracy: 0.8034 - val_loss: 0.4335 - val_accuracy: 0.8010 - 734ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4261 - accuracy: 0.8038 - val_loss: 0.4306 - val_accuracy: 0.8034 - 734ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4261 - accuracy: 0.8043 - val_loss: 0.4308 - val_accuracy: 0.8018 - 759ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4274 - accuracy: 0.8030 - val_loss: 0.4306 - val_accuracy: 0.8020 - 703ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4246 - accuracy: 0.8044 - val_loss: 0.4325 - val_accuracy: 0.8026 - 776ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4253 - accuracy: 0.8029 - val_loss: 0.4319 - val_accuracy: 0.8023 - 725ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4241 - accuracy: 0.8034 - val_loss: 0.4290 - val_accuracy: 0.8025 - 703ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4254 - accuracy: 0.8023 - val_loss: 0.4395 - val_accuracy: 0.7975 - 751ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4265 - accuracy: 0.8025 - val_loss: 0.4300 - val_accuracy: 0.8012 - 750ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4255 - accuracy: 0.8041 - val_loss: 0.4308 - val_accuracy: 0.8010 - 766ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4235 - accuracy: 0.8034 - val_loss: 0.4316 - val_accuracy: 0.8026 - 766ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4240 - accuracy: 0.8031 - val_loss: 0.4316 - val_accuracy: 0.8001 - 749ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4246 - accuracy: 0.8036 - val_loss: 0.4301 - val_accuracy: 0.8015 - 769ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8042 - val_loss: 0.4316 - val_accuracy: 0.8020 - 750ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8040 - val_loss: 0.4291 - val_accuracy: 0.8021 - 797ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4235 - accuracy: 0.8038 - val_loss: 0.4342 - val_accuracy: 0.7981 - 797ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4238 - accuracy: 0.8036 - val_loss: 0.4321 - val_accuracy: 0.8010 - 751ms/epoch - 8ms/step\n",
      "Epoch 30: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "98/98 - 2s - loss: 2.5984 - accuracy: 0.7521 - val_loss: 1.6419 - val_accuracy: 0.7620 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 1.1592 - accuracy: 0.7815 - val_loss: 0.8153 - val_accuracy: 0.8001 - 771ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.6515 - accuracy: 0.8018 - val_loss: 0.5435 - val_accuracy: 0.8013 - 797ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4910 - accuracy: 0.8035 - val_loss: 0.4657 - val_accuracy: 0.8001 - 750ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4452 - accuracy: 0.8034 - val_loss: 0.4416 - val_accuracy: 0.8018 - 781ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4338 - accuracy: 0.8028 - val_loss: 0.4348 - val_accuracy: 0.8026 - 750ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4312 - accuracy: 0.8034 - val_loss: 0.4337 - val_accuracy: 0.8021 - 734ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4280 - accuracy: 0.8027 - val_loss: 0.4343 - val_accuracy: 0.8023 - 741ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4276 - accuracy: 0.8044 - val_loss: 0.4314 - val_accuracy: 0.8026 - 844ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4280 - accuracy: 0.8037 - val_loss: 0.4374 - val_accuracy: 0.7989 - 771ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4268 - accuracy: 0.8022 - val_loss: 0.4329 - val_accuracy: 0.7999 - 750ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4264 - accuracy: 0.8029 - val_loss: 0.4304 - val_accuracy: 0.8025 - 781ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.8030 - val_loss: 0.4307 - val_accuracy: 0.8023 - 750ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4248 - accuracy: 0.8036 - val_loss: 0.4322 - val_accuracy: 0.8005 - 797ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4253 - accuracy: 0.8039 - val_loss: 0.4366 - val_accuracy: 0.7956 - 766ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4260 - accuracy: 0.8020 - val_loss: 0.4317 - val_accuracy: 0.8031 - 781ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4253 - accuracy: 0.8029 - val_loss: 0.4297 - val_accuracy: 0.8026 - 781ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4247 - accuracy: 0.8036 - val_loss: 0.4318 - val_accuracy: 0.8031 - 797ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4256 - accuracy: 0.8030 - val_loss: 0.4292 - val_accuracy: 0.8031 - 786ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4245 - accuracy: 0.8023 - val_loss: 0.4292 - val_accuracy: 0.8033 - 749ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4252 - accuracy: 0.8040 - val_loss: 0.4299 - val_accuracy: 0.8017 - 777ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4242 - accuracy: 0.8026 - val_loss: 0.4345 - val_accuracy: 0.8026 - 755ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4248 - accuracy: 0.8028 - val_loss: 0.4301 - val_accuracy: 0.8025 - 740ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8035 - val_loss: 0.4298 - val_accuracy: 0.8029 - 769ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8042 - val_loss: 0.4319 - val_accuracy: 0.8002 - 770ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8029 - val_loss: 0.4289 - val_accuracy: 0.8026 - 779ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8033 - val_loss: 0.4294 - val_accuracy: 0.8025 - 750ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4231 - accuracy: 0.8041 - val_loss: 0.4303 - val_accuracy: 0.8026 - 799ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4240 - accuracy: 0.8037 - val_loss: 0.4287 - val_accuracy: 0.8010 - 755ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4237 - accuracy: 0.8018 - val_loss: 0.4310 - val_accuracy: 0.8020 - 767ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4246 - accuracy: 0.8028 - val_loss: 0.4305 - val_accuracy: 0.8025 - 750ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4236 - accuracy: 0.8039 - val_loss: 0.4297 - val_accuracy: 0.8025 - 797ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4234 - accuracy: 0.8046 - val_loss: 0.4281 - val_accuracy: 0.8028 - 766ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4225 - accuracy: 0.8037 - val_loss: 0.4301 - val_accuracy: 0.8031 - 786ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8024 - val_loss: 0.4302 - val_accuracy: 0.8018 - 859ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4235 - accuracy: 0.8051 - val_loss: 0.4296 - val_accuracy: 0.8026 - 781ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4232 - accuracy: 0.8039 - val_loss: 0.4289 - val_accuracy: 0.8018 - 802ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4239 - accuracy: 0.8026 - val_loss: 0.4289 - val_accuracy: 0.8002 - 719ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4228 - accuracy: 0.8042 - val_loss: 0.4292 - val_accuracy: 0.8009 - 761ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.4223 - accuracy: 0.8046 - val_loss: 0.4299 - val_accuracy: 0.8017 - 781ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.4230 - accuracy: 0.8045 - val_loss: 0.4293 - val_accuracy: 0.8021 - 797ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "98/98 - 1s - loss: 0.4233 - accuracy: 0.8026 - val_loss: 0.4339 - val_accuracy: 0.8023 - 813ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "98/98 - 1s - loss: 0.4222 - accuracy: 0.8039 - val_loss: 0.4284 - val_accuracy: 0.8025 - 750ms/epoch - 8ms/step\n",
      "Epoch 43: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.4398371985478691\n",
      "epi entropy:  0.420116217913827\n",
      "\n",
      "dataset size:  0.9\n",
      "Epoch 1/100\n",
      "110/110 - 3s - loss: 2.5518 - accuracy: 0.7221 - val_loss: 1.5488 - val_accuracy: 0.7554 - 3s/epoch - 28ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 1.0630 - accuracy: 0.7797 - val_loss: 0.7460 - val_accuracy: 0.7850 - 836ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.5949 - accuracy: 0.8030 - val_loss: 0.5171 - val_accuracy: 0.7923 - 891ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4688 - accuracy: 0.8052 - val_loss: 0.4576 - val_accuracy: 0.7937 - 882ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4378 - accuracy: 0.8052 - val_loss: 0.4457 - val_accuracy: 0.7927 - 863ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4315 - accuracy: 0.8051 - val_loss: 0.4406 - val_accuracy: 0.7937 - 828ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4282 - accuracy: 0.8051 - val_loss: 0.4405 - val_accuracy: 0.7927 - 851ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4279 - accuracy: 0.8047 - val_loss: 0.4403 - val_accuracy: 0.7934 - 891ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4264 - accuracy: 0.8049 - val_loss: 0.4444 - val_accuracy: 0.7880 - 884ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4256 - accuracy: 0.8053 - val_loss: 0.4376 - val_accuracy: 0.7943 - 828ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4264 - accuracy: 0.8044 - val_loss: 0.4397 - val_accuracy: 0.7951 - 835ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4257 - accuracy: 0.8053 - val_loss: 0.4401 - val_accuracy: 0.7925 - 880ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4253 - accuracy: 0.8058 - val_loss: 0.4391 - val_accuracy: 0.7924 - 849ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4255 - accuracy: 0.8050 - val_loss: 0.4365 - val_accuracy: 0.7940 - 875ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4247 - accuracy: 0.8050 - val_loss: 0.4393 - val_accuracy: 0.7937 - 844ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4246 - accuracy: 0.8046 - val_loss: 0.4362 - val_accuracy: 0.7947 - 844ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4241 - accuracy: 0.8050 - val_loss: 0.4362 - val_accuracy: 0.7921 - 834ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4246 - accuracy: 0.8050 - val_loss: 0.4360 - val_accuracy: 0.7938 - 859ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4240 - accuracy: 0.8048 - val_loss: 0.4356 - val_accuracy: 0.7940 - 844ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4241 - accuracy: 0.8056 - val_loss: 0.4365 - val_accuracy: 0.7938 - 844ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4246 - accuracy: 0.8039 - val_loss: 0.4357 - val_accuracy: 0.7928 - 938ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4232 - accuracy: 0.8052 - val_loss: 0.4367 - val_accuracy: 0.7928 - 1s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8053 - val_loss: 0.4374 - val_accuracy: 0.7938 - 828ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4239 - accuracy: 0.8039 - val_loss: 0.4355 - val_accuracy: 0.7935 - 844ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8049 - val_loss: 0.4348 - val_accuracy: 0.7937 - 801ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4231 - accuracy: 0.8054 - val_loss: 0.4354 - val_accuracy: 0.7934 - 859ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4234 - accuracy: 0.8057 - val_loss: 0.4383 - val_accuracy: 0.7914 - 922ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4234 - accuracy: 0.8049 - val_loss: 0.4363 - val_accuracy: 0.7928 - 922ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4235 - accuracy: 0.8043 - val_loss: 0.4381 - val_accuracy: 0.7930 - 859ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4235 - accuracy: 0.8033 - val_loss: 0.4405 - val_accuracy: 0.7881 - 859ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4235 - accuracy: 0.8056 - val_loss: 0.4373 - val_accuracy: 0.7933 - 875ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8056 - val_loss: 0.4382 - val_accuracy: 0.7917 - 813ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8041 - val_loss: 0.4350 - val_accuracy: 0.7934 - 873ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4223 - accuracy: 0.8053 - val_loss: 0.4375 - val_accuracy: 0.7914 - 844ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8054 - val_loss: 0.4358 - val_accuracy: 0.7933 - 875ms/epoch - 8ms/step\n",
      "Epoch 35: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "110/110 - 3s - loss: 2.6195 - accuracy: 0.7164 - val_loss: 1.5982 - val_accuracy: 0.7554 - 3s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 1.1062 - accuracy: 0.7632 - val_loss: 0.7733 - val_accuracy: 0.7756 - 812ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.6122 - accuracy: 0.8003 - val_loss: 0.5245 - val_accuracy: 0.7918 - 869ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4732 - accuracy: 0.8052 - val_loss: 0.4616 - val_accuracy: 0.7923 - 836ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4399 - accuracy: 0.8061 - val_loss: 0.4453 - val_accuracy: 0.7927 - 927ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4335 - accuracy: 0.8046 - val_loss: 0.4462 - val_accuracy: 0.7918 - 844ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4294 - accuracy: 0.8066 - val_loss: 0.4461 - val_accuracy: 0.7911 - 859ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4285 - accuracy: 0.8057 - val_loss: 0.4402 - val_accuracy: 0.7937 - 891ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4265 - accuracy: 0.8058 - val_loss: 0.4389 - val_accuracy: 0.7934 - 844ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4258 - accuracy: 0.8053 - val_loss: 0.4394 - val_accuracy: 0.7928 - 922ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4256 - accuracy: 0.8056 - val_loss: 0.4411 - val_accuracy: 0.7935 - 844ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4250 - accuracy: 0.8049 - val_loss: 0.4367 - val_accuracy: 0.7940 - 834ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4253 - accuracy: 0.8060 - val_loss: 0.4391 - val_accuracy: 0.7921 - 859ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4245 - accuracy: 0.8052 - val_loss: 0.4358 - val_accuracy: 0.7935 - 875ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4250 - accuracy: 0.8053 - val_loss: 0.4367 - val_accuracy: 0.7945 - 898ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4248 - accuracy: 0.8048 - val_loss: 0.4370 - val_accuracy: 0.7934 - 859ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4236 - accuracy: 0.8053 - val_loss: 0.4375 - val_accuracy: 0.7934 - 844ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8052 - val_loss: 0.4357 - val_accuracy: 0.7968 - 859ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4238 - accuracy: 0.8053 - val_loss: 0.4386 - val_accuracy: 0.7931 - 865ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4239 - accuracy: 0.8051 - val_loss: 0.4356 - val_accuracy: 0.7938 - 891ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4231 - accuracy: 0.8051 - val_loss: 0.4368 - val_accuracy: 0.7931 - 844ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4229 - accuracy: 0.8057 - val_loss: 0.4358 - val_accuracy: 0.7933 - 880ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4228 - accuracy: 0.8057 - val_loss: 0.4356 - val_accuracy: 0.7933 - 843ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4233 - accuracy: 0.8056 - val_loss: 0.4376 - val_accuracy: 0.7931 - 839ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4229 - accuracy: 0.8050 - val_loss: 0.4369 - val_accuracy: 0.7934 - 828ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4240 - accuracy: 0.8057 - val_loss: 0.4348 - val_accuracy: 0.7930 - 797ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4226 - accuracy: 0.8058 - val_loss: 0.4348 - val_accuracy: 0.7961 - 868ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4217 - accuracy: 0.8057 - val_loss: 0.4344 - val_accuracy: 0.7935 - 864ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4232 - accuracy: 0.8046 - val_loss: 0.4348 - val_accuracy: 0.7930 - 900ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8047 - val_loss: 0.4347 - val_accuracy: 0.7938 - 849ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8059 - val_loss: 0.4349 - val_accuracy: 0.7938 - 813ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4218 - accuracy: 0.8061 - val_loss: 0.4341 - val_accuracy: 0.7924 - 770ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4222 - accuracy: 0.8059 - val_loss: 0.4347 - val_accuracy: 0.7935 - 797ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4214 - accuracy: 0.8064 - val_loss: 0.4338 - val_accuracy: 0.7931 - 812ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4228 - accuracy: 0.8069 - val_loss: 0.4351 - val_accuracy: 0.7938 - 812ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8052 - val_loss: 0.4371 - val_accuracy: 0.7933 - 788ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8048 - val_loss: 0.4378 - val_accuracy: 0.7931 - 907ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8051 - val_loss: 0.4347 - val_accuracy: 0.7934 - 898ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4223 - accuracy: 0.8059 - val_loss: 0.4372 - val_accuracy: 0.7933 - 897ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4214 - accuracy: 0.8066 - val_loss: 0.4335 - val_accuracy: 0.7933 - 857ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4213 - accuracy: 0.8063 - val_loss: 0.4343 - val_accuracy: 0.7934 - 855ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "110/110 - 1s - loss: 0.4224 - accuracy: 0.8050 - val_loss: 0.4350 - val_accuracy: 0.7930 - 859ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "110/110 - 1s - loss: 0.4213 - accuracy: 0.8060 - val_loss: 0.4337 - val_accuracy: 0.7945 - 813ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "110/110 - 1s - loss: 0.4216 - accuracy: 0.8058 - val_loss: 0.4346 - val_accuracy: 0.7927 - 834ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "110/110 - 1s - loss: 0.4213 - accuracy: 0.8049 - val_loss: 0.4336 - val_accuracy: 0.7945 - 812ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "110/110 - 1s - loss: 0.4211 - accuracy: 0.8059 - val_loss: 0.4350 - val_accuracy: 0.7938 - 828ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "110/110 - 1s - loss: 0.4222 - accuracy: 0.8051 - val_loss: 0.4369 - val_accuracy: 0.7930 - 899ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "110/110 - 1s - loss: 0.4212 - accuracy: 0.8058 - val_loss: 0.4351 - val_accuracy: 0.7950 - 859ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "110/110 - 1s - loss: 0.4216 - accuracy: 0.8056 - val_loss: 0.4361 - val_accuracy: 0.7930 - 844ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "110/110 - 1s - loss: 0.4208 - accuracy: 0.8058 - val_loss: 0.4367 - val_accuracy: 0.7921 - 828ms/epoch - 8ms/step\n",
      "Epoch 50: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "110/110 - 2s - loss: 2.5496 - accuracy: 0.7139 - val_loss: 1.5269 - val_accuracy: 0.7596 - 2s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 1.0472 - accuracy: 0.7897 - val_loss: 0.7365 - val_accuracy: 0.7877 - 859ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.5882 - accuracy: 0.8045 - val_loss: 0.5130 - val_accuracy: 0.7933 - 812ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4658 - accuracy: 0.8052 - val_loss: 0.4575 - val_accuracy: 0.7925 - 766ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4370 - accuracy: 0.8054 - val_loss: 0.4447 - val_accuracy: 0.7928 - 891ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4305 - accuracy: 0.8047 - val_loss: 0.4417 - val_accuracy: 0.7928 - 861ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4278 - accuracy: 0.8061 - val_loss: 0.4397 - val_accuracy: 0.7940 - 785ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8053 - val_loss: 0.4415 - val_accuracy: 0.7928 - 876ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4271 - accuracy: 0.8049 - val_loss: 0.4380 - val_accuracy: 0.7930 - 851ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4256 - accuracy: 0.8051 - val_loss: 0.4380 - val_accuracy: 0.7948 - 812ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4252 - accuracy: 0.8049 - val_loss: 0.4369 - val_accuracy: 0.7937 - 834ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4246 - accuracy: 0.8054 - val_loss: 0.4410 - val_accuracy: 0.7928 - 875ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4253 - accuracy: 0.8051 - val_loss: 0.4365 - val_accuracy: 0.7935 - 875ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4244 - accuracy: 0.8044 - val_loss: 0.4384 - val_accuracy: 0.7931 - 828ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4254 - accuracy: 0.8034 - val_loss: 0.4371 - val_accuracy: 0.7924 - 867ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4247 - accuracy: 0.8062 - val_loss: 0.4374 - val_accuracy: 0.7944 - 844ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8052 - val_loss: 0.4372 - val_accuracy: 0.7931 - 828ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4239 - accuracy: 0.8049 - val_loss: 0.4418 - val_accuracy: 0.7930 - 859ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8059 - val_loss: 0.4374 - val_accuracy: 0.7933 - 904ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4239 - accuracy: 0.8041 - val_loss: 0.4359 - val_accuracy: 0.7928 - 904ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4233 - accuracy: 0.8055 - val_loss: 0.4359 - val_accuracy: 0.7925 - 1s/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4228 - accuracy: 0.8055 - val_loss: 0.4381 - val_accuracy: 0.7925 - 1s/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4219 - accuracy: 0.8058 - val_loss: 0.4352 - val_accuracy: 0.7933 - 1s/epoch - 13ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4234 - accuracy: 0.8049 - val_loss: 0.4352 - val_accuracy: 0.7923 - 984ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4226 - accuracy: 0.8048 - val_loss: 0.4379 - val_accuracy: 0.7934 - 978ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8066 - val_loss: 0.4347 - val_accuracy: 0.7931 - 895ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4219 - accuracy: 0.8064 - val_loss: 0.4351 - val_accuracy: 0.7930 - 950ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4238 - accuracy: 0.8038 - val_loss: 0.4370 - val_accuracy: 0.7931 - 855ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8051 - val_loss: 0.4353 - val_accuracy: 0.7935 - 872ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4223 - accuracy: 0.8055 - val_loss: 0.4347 - val_accuracy: 0.7930 - 835ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4218 - accuracy: 0.8062 - val_loss: 0.4349 - val_accuracy: 0.7945 - 979ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4222 - accuracy: 0.8051 - val_loss: 0.4352 - val_accuracy: 0.7925 - 817ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4248 - accuracy: 0.8023 - val_loss: 0.4358 - val_accuracy: 0.7920 - 816ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4220 - accuracy: 0.8061 - val_loss: 0.4355 - val_accuracy: 0.7931 - 815ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4214 - accuracy: 0.8050 - val_loss: 0.4346 - val_accuracy: 0.7935 - 833ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4219 - accuracy: 0.8048 - val_loss: 0.4393 - val_accuracy: 0.7930 - 847ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4215 - accuracy: 0.8062 - val_loss: 0.4355 - val_accuracy: 0.7928 - 833ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4216 - accuracy: 0.8051 - val_loss: 0.4335 - val_accuracy: 0.7927 - 843ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4229 - accuracy: 0.8050 - val_loss: 0.4349 - val_accuracy: 0.7930 - 841ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4215 - accuracy: 0.8063 - val_loss: 0.4348 - val_accuracy: 0.7953 - 825ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4218 - accuracy: 0.8064 - val_loss: 0.4378 - val_accuracy: 0.7928 - 823ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8053 - val_loss: 0.4415 - val_accuracy: 0.7917 - 991ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "110/110 - 1s - loss: 0.4218 - accuracy: 0.8056 - val_loss: 0.4340 - val_accuracy: 0.7933 - 915ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "110/110 - 1s - loss: 0.4216 - accuracy: 0.8051 - val_loss: 0.4351 - val_accuracy: 0.7927 - 803ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8050 - val_loss: 0.4370 - val_accuracy: 0.7930 - 891ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "110/110 - 1s - loss: 0.4226 - accuracy: 0.8049 - val_loss: 0.4345 - val_accuracy: 0.7924 - 876ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "110/110 - 1s - loss: 0.4214 - accuracy: 0.8066 - val_loss: 0.4337 - val_accuracy: 0.7930 - 886ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "110/110 - 1s - loss: 0.4207 - accuracy: 0.8063 - val_loss: 0.4351 - val_accuracy: 0.7933 - 829ms/epoch - 8ms/step\n",
      "Epoch 48: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "110/110 - 2s - loss: 2.4852 - accuracy: 0.7498 - val_loss: 1.4955 - val_accuracy: 0.7573 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 1.0262 - accuracy: 0.7937 - val_loss: 0.7247 - val_accuracy: 0.7925 - 881ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.5822 - accuracy: 0.8053 - val_loss: 0.5105 - val_accuracy: 0.7923 - 852ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4646 - accuracy: 0.8057 - val_loss: 0.4571 - val_accuracy: 0.7947 - 814ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4377 - accuracy: 0.8043 - val_loss: 0.4467 - val_accuracy: 0.7927 - 812ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4308 - accuracy: 0.8057 - val_loss: 0.4419 - val_accuracy: 0.7931 - 853ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4282 - accuracy: 0.8054 - val_loss: 0.4401 - val_accuracy: 0.7925 - 835ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4271 - accuracy: 0.8053 - val_loss: 0.4418 - val_accuracy: 0.7918 - 819ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4270 - accuracy: 0.8044 - val_loss: 0.4379 - val_accuracy: 0.7945 - 868ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4267 - accuracy: 0.8046 - val_loss: 0.4381 - val_accuracy: 0.7925 - 849ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4256 - accuracy: 0.8050 - val_loss: 0.4371 - val_accuracy: 0.7953 - 858ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4265 - accuracy: 0.8053 - val_loss: 0.4363 - val_accuracy: 0.7928 - 820ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4244 - accuracy: 0.8053 - val_loss: 0.4380 - val_accuracy: 0.7938 - 818ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4245 - accuracy: 0.8062 - val_loss: 0.4368 - val_accuracy: 0.7937 - 814ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8058 - val_loss: 0.4374 - val_accuracy: 0.7933 - 876ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4243 - accuracy: 0.8039 - val_loss: 0.4397 - val_accuracy: 0.7927 - 861ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8057 - val_loss: 0.4363 - val_accuracy: 0.7943 - 868ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8038 - val_loss: 0.4368 - val_accuracy: 0.7937 - 830ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4239 - accuracy: 0.8060 - val_loss: 0.4419 - val_accuracy: 0.7893 - 821ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4248 - accuracy: 0.8033 - val_loss: 0.4364 - val_accuracy: 0.7930 - 835ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4240 - accuracy: 0.8055 - val_loss: 0.4398 - val_accuracy: 0.7890 - 821ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8056 - val_loss: 0.4392 - val_accuracy: 0.7930 - 840ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4235 - accuracy: 0.8045 - val_loss: 0.4368 - val_accuracy: 0.7924 - 835ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8052 - val_loss: 0.4345 - val_accuracy: 0.7934 - 887ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4223 - accuracy: 0.8056 - val_loss: 0.4354 - val_accuracy: 0.7943 - 978ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8045 - val_loss: 0.4382 - val_accuracy: 0.7900 - 849ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8054 - val_loss: 0.4343 - val_accuracy: 0.7940 - 936ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4235 - accuracy: 0.8045 - val_loss: 0.4381 - val_accuracy: 0.7910 - 810ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4233 - accuracy: 0.8040 - val_loss: 0.4357 - val_accuracy: 0.7935 - 797ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4224 - accuracy: 0.8066 - val_loss: 0.4359 - val_accuracy: 0.7930 - 1s/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8055 - val_loss: 0.4360 - val_accuracy: 0.7931 - 982ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4228 - accuracy: 0.8045 - val_loss: 0.4363 - val_accuracy: 0.7893 - 907ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8057 - val_loss: 0.4336 - val_accuracy: 0.7938 - 881ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8057 - val_loss: 0.4341 - val_accuracy: 0.7935 - 911ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4224 - accuracy: 0.8051 - val_loss: 0.4356 - val_accuracy: 0.7931 - 890ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8058 - val_loss: 0.4348 - val_accuracy: 0.7925 - 1s/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4212 - accuracy: 0.8055 - val_loss: 0.4362 - val_accuracy: 0.7924 - 1s/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4210 - accuracy: 0.8061 - val_loss: 0.4343 - val_accuracy: 0.7935 - 1s/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4213 - accuracy: 0.8059 - val_loss: 0.4350 - val_accuracy: 0.7941 - 797ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4215 - accuracy: 0.8059 - val_loss: 0.4368 - val_accuracy: 0.7937 - 1s/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4247 - accuracy: 0.8042 - val_loss: 0.4369 - val_accuracy: 0.7928 - 1s/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "110/110 - 1s - loss: 0.4213 - accuracy: 0.8052 - val_loss: 0.4379 - val_accuracy: 0.7918 - 928ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "110/110 - 1s - loss: 0.4212 - accuracy: 0.8056 - val_loss: 0.4347 - val_accuracy: 0.7934 - 975ms/epoch - 9ms/step\n",
      "Epoch 43: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "110/110 - 4s - loss: 2.4906 - accuracy: 0.7393 - val_loss: 1.5270 - val_accuracy: 0.7554 - 4s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 1.0629 - accuracy: 0.7700 - val_loss: 0.7440 - val_accuracy: 0.7837 - 961ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.5908 - accuracy: 0.8035 - val_loss: 0.5125 - val_accuracy: 0.7930 - 962ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4660 - accuracy: 0.8047 - val_loss: 0.4568 - val_accuracy: 0.7935 - 1s/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4372 - accuracy: 0.8049 - val_loss: 0.4447 - val_accuracy: 0.7933 - 1s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4299 - accuracy: 0.8052 - val_loss: 0.4410 - val_accuracy: 0.7941 - 1s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4282 - accuracy: 0.8055 - val_loss: 0.4398 - val_accuracy: 0.7920 - 871ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4271 - accuracy: 0.8055 - val_loss: 0.4425 - val_accuracy: 0.7930 - 1s/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4282 - accuracy: 0.8060 - val_loss: 0.4384 - val_accuracy: 0.7928 - 1s/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4254 - accuracy: 0.8062 - val_loss: 0.4374 - val_accuracy: 0.7953 - 974ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4254 - accuracy: 0.8062 - val_loss: 0.4394 - val_accuracy: 0.7937 - 983ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4255 - accuracy: 0.8058 - val_loss: 0.4366 - val_accuracy: 0.7933 - 927ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4241 - accuracy: 0.8048 - val_loss: 0.4367 - val_accuracy: 0.7931 - 1s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4275 - accuracy: 0.8025 - val_loss: 0.4382 - val_accuracy: 0.7921 - 1s/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 2s - loss: 0.4241 - accuracy: 0.8060 - val_loss: 0.4372 - val_accuracy: 0.7954 - 2s/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8057 - val_loss: 0.4363 - val_accuracy: 0.7931 - 966ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8052 - val_loss: 0.4353 - val_accuracy: 0.7924 - 1s/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4233 - accuracy: 0.8055 - val_loss: 0.4353 - val_accuracy: 0.7944 - 1s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4235 - accuracy: 0.8051 - val_loss: 0.4360 - val_accuracy: 0.7927 - 931ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8046 - val_loss: 0.4364 - val_accuracy: 0.7945 - 937ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8055 - val_loss: 0.4356 - val_accuracy: 0.7950 - 929ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4233 - accuracy: 0.8041 - val_loss: 0.4350 - val_accuracy: 0.7934 - 901ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8056 - val_loss: 0.4346 - val_accuracy: 0.7935 - 941ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8061 - val_loss: 0.4351 - val_accuracy: 0.7914 - 904ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4222 - accuracy: 0.8060 - val_loss: 0.4353 - val_accuracy: 0.7928 - 841ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4233 - accuracy: 0.8048 - val_loss: 0.4346 - val_accuracy: 0.7950 - 958ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4236 - accuracy: 0.8041 - val_loss: 0.4448 - val_accuracy: 0.7866 - 1s/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8062 - val_loss: 0.4341 - val_accuracy: 0.7933 - 960ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4232 - accuracy: 0.8057 - val_loss: 0.4355 - val_accuracy: 0.7937 - 891ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4220 - accuracy: 0.8061 - val_loss: 0.4347 - val_accuracy: 0.7931 - 953ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4224 - accuracy: 0.8055 - val_loss: 0.4350 - val_accuracy: 0.7938 - 912ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8050 - val_loss: 0.4374 - val_accuracy: 0.7923 - 874ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4218 - accuracy: 0.8061 - val_loss: 0.4355 - val_accuracy: 0.7935 - 837ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4220 - accuracy: 0.8066 - val_loss: 0.4354 - val_accuracy: 0.7933 - 860ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8055 - val_loss: 0.4380 - val_accuracy: 0.7931 - 839ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8054 - val_loss: 0.4419 - val_accuracy: 0.7879 - 897ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8064 - val_loss: 0.4373 - val_accuracy: 0.7916 - 900ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4222 - accuracy: 0.8055 - val_loss: 0.4399 - val_accuracy: 0.7930 - 970ms/epoch - 9ms/step\n",
      "Epoch 38: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "110/110 - 3s - loss: 2.4715 - accuracy: 0.7441 - val_loss: 1.5059 - val_accuracy: 0.7556 - 3s/epoch - 26ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 1.0438 - accuracy: 0.7840 - val_loss: 0.7396 - val_accuracy: 0.7917 - 862ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.5924 - accuracy: 0.8057 - val_loss: 0.5147 - val_accuracy: 0.7930 - 867ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4682 - accuracy: 0.8055 - val_loss: 0.4584 - val_accuracy: 0.7927 - 955ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4380 - accuracy: 0.8060 - val_loss: 0.4447 - val_accuracy: 0.7935 - 1s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4304 - accuracy: 0.8056 - val_loss: 0.4431 - val_accuracy: 0.7890 - 1s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4288 - accuracy: 0.8041 - val_loss: 0.4407 - val_accuracy: 0.7934 - 964ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4274 - accuracy: 0.8050 - val_loss: 0.4470 - val_accuracy: 0.7920 - 853ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4271 - accuracy: 0.8048 - val_loss: 0.4395 - val_accuracy: 0.7930 - 909ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4257 - accuracy: 0.8057 - val_loss: 0.4373 - val_accuracy: 0.7933 - 856ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4254 - accuracy: 0.8044 - val_loss: 0.4373 - val_accuracy: 0.7914 - 897ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4255 - accuracy: 0.8039 - val_loss: 0.4389 - val_accuracy: 0.7937 - 932ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4247 - accuracy: 0.8052 - val_loss: 0.4360 - val_accuracy: 0.7943 - 1s/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4246 - accuracy: 0.8057 - val_loss: 0.4365 - val_accuracy: 0.7927 - 932ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4236 - accuracy: 0.8054 - val_loss: 0.4381 - val_accuracy: 0.7934 - 834ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4251 - accuracy: 0.8052 - val_loss: 0.4357 - val_accuracy: 0.7934 - 916ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4232 - accuracy: 0.8061 - val_loss: 0.4374 - val_accuracy: 0.7928 - 851ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4233 - accuracy: 0.8061 - val_loss: 0.4363 - val_accuracy: 0.7928 - 877ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4236 - accuracy: 0.8048 - val_loss: 0.4351 - val_accuracy: 0.7931 - 838ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8056 - val_loss: 0.4347 - val_accuracy: 0.7943 - 841ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8057 - val_loss: 0.4366 - val_accuracy: 0.7933 - 868ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4229 - accuracy: 0.8062 - val_loss: 0.4354 - val_accuracy: 0.7935 - 865ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4236 - accuracy: 0.8045 - val_loss: 0.4349 - val_accuracy: 0.7935 - 897ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4224 - accuracy: 0.8056 - val_loss: 0.4362 - val_accuracy: 0.7940 - 840ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8056 - val_loss: 0.4354 - val_accuracy: 0.7918 - 870ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8052 - val_loss: 0.4362 - val_accuracy: 0.7937 - 919ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4223 - accuracy: 0.8057 - val_loss: 0.4348 - val_accuracy: 0.7938 - 880ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8060 - val_loss: 0.4339 - val_accuracy: 0.7935 - 977ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4222 - accuracy: 0.8059 - val_loss: 0.4356 - val_accuracy: 0.7934 - 875ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8059 - val_loss: 0.4351 - val_accuracy: 0.7931 - 876ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8061 - val_loss: 0.4364 - val_accuracy: 0.7930 - 901ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4216 - accuracy: 0.8059 - val_loss: 0.4345 - val_accuracy: 0.7928 - 1s/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4214 - accuracy: 0.8063 - val_loss: 0.4341 - val_accuracy: 0.7917 - 1s/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4217 - accuracy: 0.8053 - val_loss: 0.4341 - val_accuracy: 0.7940 - 1s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4209 - accuracy: 0.8056 - val_loss: 0.4375 - val_accuracy: 0.7933 - 1s/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4232 - accuracy: 0.8046 - val_loss: 0.4410 - val_accuracy: 0.7880 - 949ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4220 - accuracy: 0.8056 - val_loss: 0.4380 - val_accuracy: 0.7907 - 901ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4217 - accuracy: 0.8051 - val_loss: 0.4345 - val_accuracy: 0.7934 - 1s/epoch - 10ms/step\n",
      "Epoch 38: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "110/110 - 3s - loss: 2.4960 - accuracy: 0.7273 - val_loss: 1.5041 - val_accuracy: 0.7566 - 3s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 1.0324 - accuracy: 0.7934 - val_loss: 0.7265 - val_accuracy: 0.7923 - 866ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.5830 - accuracy: 0.8051 - val_loss: 0.5101 - val_accuracy: 0.7934 - 838ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4638 - accuracy: 0.8055 - val_loss: 0.4605 - val_accuracy: 0.7911 - 877ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4364 - accuracy: 0.8057 - val_loss: 0.4441 - val_accuracy: 0.7931 - 909ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4311 - accuracy: 0.8050 - val_loss: 0.4410 - val_accuracy: 0.7935 - 842ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4280 - accuracy: 0.8055 - val_loss: 0.4406 - val_accuracy: 0.7934 - 849ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4278 - accuracy: 0.8039 - val_loss: 0.4394 - val_accuracy: 0.7935 - 869ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4260 - accuracy: 0.8057 - val_loss: 0.4387 - val_accuracy: 0.7920 - 844ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4250 - accuracy: 0.8064 - val_loss: 0.4373 - val_accuracy: 0.7934 - 824ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4256 - accuracy: 0.8045 - val_loss: 0.4382 - val_accuracy: 0.7935 - 817ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4244 - accuracy: 0.8060 - val_loss: 0.4368 - val_accuracy: 0.7940 - 982ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4244 - accuracy: 0.8054 - val_loss: 0.4358 - val_accuracy: 0.7938 - 842ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4236 - accuracy: 0.8052 - val_loss: 0.4391 - val_accuracy: 0.7931 - 833ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4238 - accuracy: 0.8063 - val_loss: 0.4366 - val_accuracy: 0.7920 - 845ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4242 - accuracy: 0.8047 - val_loss: 0.4473 - val_accuracy: 0.7893 - 833ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4243 - accuracy: 0.8053 - val_loss: 0.4354 - val_accuracy: 0.7937 - 926ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4231 - accuracy: 0.8053 - val_loss: 0.4376 - val_accuracy: 0.7927 - 948ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4240 - accuracy: 0.8057 - val_loss: 0.4360 - val_accuracy: 0.7917 - 871ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4232 - accuracy: 0.8062 - val_loss: 0.4405 - val_accuracy: 0.7927 - 865ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8054 - val_loss: 0.4375 - val_accuracy: 0.7937 - 862ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4231 - accuracy: 0.8058 - val_loss: 0.4387 - val_accuracy: 0.7927 - 860ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4231 - accuracy: 0.8057 - val_loss: 0.4363 - val_accuracy: 0.7933 - 825ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8058 - val_loss: 0.4375 - val_accuracy: 0.7934 - 823ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8051 - val_loss: 0.4355 - val_accuracy: 0.7931 - 828ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4243 - accuracy: 0.8041 - val_loss: 0.4358 - val_accuracy: 0.7940 - 937ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4226 - accuracy: 0.8055 - val_loss: 0.4354 - val_accuracy: 0.7924 - 910ms/epoch - 8ms/step\n",
      "Epoch 27: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "110/110 - 2s - loss: 2.4371 - accuracy: 0.7564 - val_loss: 1.4764 - val_accuracy: 0.7554 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 1.0168 - accuracy: 0.7872 - val_loss: 0.7205 - val_accuracy: 0.7917 - 924ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.5799 - accuracy: 0.8057 - val_loss: 0.5098 - val_accuracy: 0.7933 - 967ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4635 - accuracy: 0.8057 - val_loss: 0.4574 - val_accuracy: 0.7933 - 951ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4362 - accuracy: 0.8050 - val_loss: 0.4474 - val_accuracy: 0.7927 - 970ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4303 - accuracy: 0.8055 - val_loss: 0.4404 - val_accuracy: 0.7924 - 871ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4293 - accuracy: 0.8055 - val_loss: 0.4391 - val_accuracy: 0.7924 - 923ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4269 - accuracy: 0.8056 - val_loss: 0.4456 - val_accuracy: 0.7927 - 954ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8068 - val_loss: 0.4402 - val_accuracy: 0.7928 - 958ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4257 - accuracy: 0.8059 - val_loss: 0.4385 - val_accuracy: 0.7938 - 971ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4258 - accuracy: 0.8046 - val_loss: 0.4387 - val_accuracy: 0.7923 - 1s/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4257 - accuracy: 0.8044 - val_loss: 0.4364 - val_accuracy: 0.7924 - 1s/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4249 - accuracy: 0.8053 - val_loss: 0.4363 - val_accuracy: 0.7945 - 1s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4254 - accuracy: 0.8054 - val_loss: 0.4370 - val_accuracy: 0.7941 - 960ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4252 - accuracy: 0.8044 - val_loss: 0.4375 - val_accuracy: 0.7930 - 1s/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4234 - accuracy: 0.8059 - val_loss: 0.4362 - val_accuracy: 0.7931 - 1s/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4233 - accuracy: 0.8062 - val_loss: 0.4354 - val_accuracy: 0.7940 - 1s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4229 - accuracy: 0.8064 - val_loss: 0.4353 - val_accuracy: 0.7930 - 979ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4233 - accuracy: 0.8061 - val_loss: 0.4353 - val_accuracy: 0.7928 - 944ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8057 - val_loss: 0.4362 - val_accuracy: 0.7928 - 956ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4226 - accuracy: 0.8066 - val_loss: 0.4346 - val_accuracy: 0.7937 - 853ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4235 - accuracy: 0.8057 - val_loss: 0.4374 - val_accuracy: 0.7927 - 849ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8061 - val_loss: 0.4391 - val_accuracy: 0.7927 - 974ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8057 - val_loss: 0.4353 - val_accuracy: 0.7930 - 918ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4234 - accuracy: 0.8064 - val_loss: 0.4410 - val_accuracy: 0.7927 - 1s/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4222 - accuracy: 0.8062 - val_loss: 0.4344 - val_accuracy: 0.7937 - 1s/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4224 - accuracy: 0.8046 - val_loss: 0.4353 - val_accuracy: 0.7931 - 913ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8058 - val_loss: 0.4387 - val_accuracy: 0.7934 - 939ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8066 - val_loss: 0.4375 - val_accuracy: 0.7933 - 876ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4239 - accuracy: 0.8046 - val_loss: 0.4358 - val_accuracy: 0.7934 - 860ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4220 - accuracy: 0.8069 - val_loss: 0.4346 - val_accuracy: 0.7928 - 890ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8058 - val_loss: 0.4351 - val_accuracy: 0.7930 - 879ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4219 - accuracy: 0.8062 - val_loss: 0.4347 - val_accuracy: 0.7938 - 900ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4211 - accuracy: 0.8063 - val_loss: 0.4349 - val_accuracy: 0.7921 - 944ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4212 - accuracy: 0.8060 - val_loss: 0.4359 - val_accuracy: 0.7930 - 932ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4214 - accuracy: 0.8057 - val_loss: 0.4345 - val_accuracy: 0.7934 - 965ms/epoch - 9ms/step\n",
      "Epoch 36: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "110/110 - 2s - loss: 2.5187 - accuracy: 0.7256 - val_loss: 1.5203 - val_accuracy: 0.7553 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 1.0481 - accuracy: 0.7905 - val_loss: 0.7413 - val_accuracy: 0.7911 - 1s/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.5933 - accuracy: 0.8049 - val_loss: 0.5152 - val_accuracy: 0.7934 - 1s/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4688 - accuracy: 0.8048 - val_loss: 0.4590 - val_accuracy: 0.7934 - 1s/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4381 - accuracy: 0.8051 - val_loss: 0.4446 - val_accuracy: 0.7935 - 999ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4309 - accuracy: 0.8061 - val_loss: 0.4434 - val_accuracy: 0.7930 - 861ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4282 - accuracy: 0.8050 - val_loss: 0.4438 - val_accuracy: 0.7925 - 904ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4273 - accuracy: 0.8056 - val_loss: 0.4390 - val_accuracy: 0.7933 - 912ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4261 - accuracy: 0.8055 - val_loss: 0.4387 - val_accuracy: 0.7925 - 915ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4257 - accuracy: 0.8058 - val_loss: 0.4389 - val_accuracy: 0.7931 - 925ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4251 - accuracy: 0.8060 - val_loss: 0.4415 - val_accuracy: 0.7930 - 934ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4250 - accuracy: 0.8057 - val_loss: 0.4429 - val_accuracy: 0.7927 - 1s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4260 - accuracy: 0.8050 - val_loss: 0.4408 - val_accuracy: 0.7927 - 1s/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4249 - accuracy: 0.8050 - val_loss: 0.4367 - val_accuracy: 0.7928 - 1s/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4241 - accuracy: 0.8060 - val_loss: 0.4364 - val_accuracy: 0.7925 - 1s/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4238 - accuracy: 0.8055 - val_loss: 0.4355 - val_accuracy: 0.7931 - 1s/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4231 - accuracy: 0.8062 - val_loss: 0.4354 - val_accuracy: 0.7925 - 1s/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4247 - accuracy: 0.8051 - val_loss: 0.4372 - val_accuracy: 0.7931 - 1s/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4238 - accuracy: 0.8054 - val_loss: 0.4380 - val_accuracy: 0.7930 - 1s/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4236 - accuracy: 0.8054 - val_loss: 0.4352 - val_accuracy: 0.7928 - 1s/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8059 - val_loss: 0.4348 - val_accuracy: 0.7925 - 1s/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4233 - accuracy: 0.8057 - val_loss: 0.4359 - val_accuracy: 0.7931 - 1s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8056 - val_loss: 0.4355 - val_accuracy: 0.7931 - 878ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8058 - val_loss: 0.4355 - val_accuracy: 0.7934 - 919ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8054 - val_loss: 0.4353 - val_accuracy: 0.7937 - 975ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4219 - accuracy: 0.8075 - val_loss: 0.4392 - val_accuracy: 0.7928 - 916ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4222 - accuracy: 0.8057 - val_loss: 0.4354 - val_accuracy: 0.7927 - 1s/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4217 - accuracy: 0.8060 - val_loss: 0.4373 - val_accuracy: 0.7924 - 917ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8053 - val_loss: 0.4354 - val_accuracy: 0.7930 - 890ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4226 - accuracy: 0.8061 - val_loss: 0.4351 - val_accuracy: 0.7931 - 842ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4215 - accuracy: 0.8062 - val_loss: 0.4340 - val_accuracy: 0.7918 - 844ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4216 - accuracy: 0.8071 - val_loss: 0.4385 - val_accuracy: 0.7930 - 915ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4220 - accuracy: 0.8066 - val_loss: 0.4378 - val_accuracy: 0.7937 - 898ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4223 - accuracy: 0.8058 - val_loss: 0.4374 - val_accuracy: 0.7933 - 948ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8048 - val_loss: 0.4340 - val_accuracy: 0.7931 - 907ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4215 - accuracy: 0.8057 - val_loss: 0.4372 - val_accuracy: 0.7930 - 888ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4231 - accuracy: 0.8048 - val_loss: 0.4399 - val_accuracy: 0.7913 - 832ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4229 - accuracy: 0.8045 - val_loss: 0.4341 - val_accuracy: 0.7921 - 859ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4213 - accuracy: 0.8055 - val_loss: 0.4338 - val_accuracy: 0.7928 - 885ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4211 - accuracy: 0.8061 - val_loss: 0.4344 - val_accuracy: 0.7916 - 898ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4212 - accuracy: 0.8060 - val_loss: 0.4344 - val_accuracy: 0.7925 - 909ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "110/110 - 1s - loss: 0.4215 - accuracy: 0.8058 - val_loss: 0.4348 - val_accuracy: 0.7924 - 872ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "110/110 - 1s - loss: 0.4210 - accuracy: 0.8070 - val_loss: 0.4339 - val_accuracy: 0.7924 - 849ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "110/110 - 1s - loss: 0.4206 - accuracy: 0.8062 - val_loss: 0.4349 - val_accuracy: 0.7918 - 865ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "110/110 - 1s - loss: 0.4217 - accuracy: 0.8054 - val_loss: 0.4389 - val_accuracy: 0.7930 - 912ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "110/110 - 1s - loss: 0.4209 - accuracy: 0.8060 - val_loss: 0.4345 - val_accuracy: 0.7918 - 931ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "110/110 - 1s - loss: 0.4211 - accuracy: 0.8055 - val_loss: 0.4358 - val_accuracy: 0.7931 - 985ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "110/110 - 1s - loss: 0.4209 - accuracy: 0.8057 - val_loss: 0.4340 - val_accuracy: 0.7930 - 869ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "110/110 - 1s - loss: 0.4209 - accuracy: 0.8064 - val_loss: 0.4406 - val_accuracy: 0.7931 - 889ms/epoch - 8ms/step\n",
      "Epoch 49: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "110/110 - 3s - loss: 2.5472 - accuracy: 0.7328 - val_loss: 1.5545 - val_accuracy: 0.7554 - 3s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 1.0674 - accuracy: 0.7857 - val_loss: 0.7474 - val_accuracy: 0.7927 - 962ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.5940 - accuracy: 0.8060 - val_loss: 0.5156 - val_accuracy: 0.7928 - 963ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4666 - accuracy: 0.8047 - val_loss: 0.4581 - val_accuracy: 0.7931 - 846ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4374 - accuracy: 0.8048 - val_loss: 0.4455 - val_accuracy: 0.7947 - 823ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4294 - accuracy: 0.8051 - val_loss: 0.4411 - val_accuracy: 0.7925 - 860ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4270 - accuracy: 0.8059 - val_loss: 0.4433 - val_accuracy: 0.7930 - 853ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4279 - accuracy: 0.8049 - val_loss: 0.4384 - val_accuracy: 0.7921 - 1s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4258 - accuracy: 0.8063 - val_loss: 0.4382 - val_accuracy: 0.7933 - 1s/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4260 - accuracy: 0.8039 - val_loss: 0.4372 - val_accuracy: 0.7934 - 971ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4245 - accuracy: 0.8055 - val_loss: 0.4377 - val_accuracy: 0.7941 - 979ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4259 - accuracy: 0.8046 - val_loss: 0.4379 - val_accuracy: 0.7947 - 1s/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4235 - accuracy: 0.8049 - val_loss: 0.4363 - val_accuracy: 0.7935 - 956ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4239 - accuracy: 0.8054 - val_loss: 0.4360 - val_accuracy: 0.7940 - 936ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4227 - accuracy: 0.8060 - val_loss: 0.4370 - val_accuracy: 0.7928 - 1s/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4230 - accuracy: 0.8047 - val_loss: 0.4365 - val_accuracy: 0.7931 - 1s/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4236 - accuracy: 0.8043 - val_loss: 0.4368 - val_accuracy: 0.7941 - 937ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4239 - accuracy: 0.8057 - val_loss: 0.4361 - val_accuracy: 0.7930 - 958ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4220 - accuracy: 0.8052 - val_loss: 0.4363 - val_accuracy: 0.7937 - 896ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8054 - val_loss: 0.4369 - val_accuracy: 0.7930 - 930ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4229 - accuracy: 0.8058 - val_loss: 0.4359 - val_accuracy: 0.7933 - 867ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8059 - val_loss: 0.4340 - val_accuracy: 0.7933 - 805ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4216 - accuracy: 0.8065 - val_loss: 0.4347 - val_accuracy: 0.7941 - 906ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4225 - accuracy: 0.8056 - val_loss: 0.4352 - val_accuracy: 0.7920 - 860ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8048 - val_loss: 0.4360 - val_accuracy: 0.7930 - 810ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4221 - accuracy: 0.8054 - val_loss: 0.4361 - val_accuracy: 0.7933 - 832ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4217 - accuracy: 0.8062 - val_loss: 0.4347 - val_accuracy: 0.7931 - 836ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4222 - accuracy: 0.8049 - val_loss: 0.4349 - val_accuracy: 0.7931 - 872ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4215 - accuracy: 0.8058 - val_loss: 0.4347 - val_accuracy: 0.7935 - 1s/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4220 - accuracy: 0.8053 - val_loss: 0.4342 - val_accuracy: 0.7934 - 1s/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 2s - loss: 0.4218 - accuracy: 0.8062 - val_loss: 0.4351 - val_accuracy: 0.7933 - 2s/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4210 - accuracy: 0.8058 - val_loss: 0.4358 - val_accuracy: 0.7927 - 1s/epoch - 12ms/step\n",
      "Epoch 32: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.43070281041683317\n",
      "epi entropy:  0.41019925791424244\n",
      "\n",
      "dataset size:  1.0\n",
      "Epoch 1/100\n",
      "123/123 - 4s - loss: 2.4875 - accuracy: 0.6943 - val_loss: 1.4094 - val_accuracy: 0.7680 - 4s/epoch - 34ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.9649 - accuracy: 0.7707 - val_loss: 0.6515 - val_accuracy: 0.8006 - 1s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.5478 - accuracy: 0.8007 - val_loss: 0.4711 - val_accuracy: 0.8077 - 973ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4557 - accuracy: 0.8023 - val_loss: 0.4355 - val_accuracy: 0.8078 - 930ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4379 - accuracy: 0.8016 - val_loss: 0.4283 - val_accuracy: 0.8061 - 977ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4340 - accuracy: 0.8010 - val_loss: 0.4258 - val_accuracy: 0.8083 - 965ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4320 - accuracy: 0.8017 - val_loss: 0.4266 - val_accuracy: 0.8081 - 1s/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.8023 - val_loss: 0.4253 - val_accuracy: 0.8036 - 1s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4304 - accuracy: 0.8017 - val_loss: 0.4230 - val_accuracy: 0.8074 - 1s/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4298 - accuracy: 0.8022 - val_loss: 0.4213 - val_accuracy: 0.8082 - 1s/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4292 - accuracy: 0.8017 - val_loss: 0.4232 - val_accuracy: 0.8064 - 1s/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4285 - accuracy: 0.8020 - val_loss: 0.4197 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4283 - accuracy: 0.8028 - val_loss: 0.4197 - val_accuracy: 0.8088 - 1s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4283 - accuracy: 0.8030 - val_loss: 0.4219 - val_accuracy: 0.8056 - 1s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4290 - accuracy: 0.8023 - val_loss: 0.4200 - val_accuracy: 0.8063 - 1s/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4274 - accuracy: 0.8023 - val_loss: 0.4200 - val_accuracy: 0.8083 - 1s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4285 - accuracy: 0.8015 - val_loss: 0.4186 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4276 - accuracy: 0.8012 - val_loss: 0.4182 - val_accuracy: 0.8065 - 1s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4279 - accuracy: 0.8024 - val_loss: 0.4187 - val_accuracy: 0.8077 - 986ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4270 - accuracy: 0.8022 - val_loss: 0.4195 - val_accuracy: 0.8081 - 1s/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.4197 - val_accuracy: 0.8083 - 1s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4273 - accuracy: 0.8018 - val_loss: 0.4195 - val_accuracy: 0.8063 - 1s/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.4193 - val_accuracy: 0.8083 - 1s/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4265 - accuracy: 0.8022 - val_loss: 0.4181 - val_accuracy: 0.8073 - 961ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.4192 - val_accuracy: 0.8083 - 975ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4265 - accuracy: 0.8013 - val_loss: 0.4174 - val_accuracy: 0.8078 - 986ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8025 - val_loss: 0.4249 - val_accuracy: 0.8017 - 928ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4264 - accuracy: 0.8013 - val_loss: 0.4195 - val_accuracy: 0.8061 - 917ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8019 - val_loss: 0.4191 - val_accuracy: 0.8083 - 999ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4275 - accuracy: 0.8007 - val_loss: 0.4170 - val_accuracy: 0.8084 - 1s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8027 - val_loss: 0.4184 - val_accuracy: 0.8064 - 1s/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8023 - val_loss: 0.4227 - val_accuracy: 0.8017 - 961ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4262 - accuracy: 0.8020 - val_loss: 0.4189 - val_accuracy: 0.8063 - 1s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8018 - val_loss: 0.4175 - val_accuracy: 0.8086 - 1s/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8023 - val_loss: 0.4182 - val_accuracy: 0.8082 - 964ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4262 - accuracy: 0.8016 - val_loss: 0.4199 - val_accuracy: 0.8044 - 904ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4263 - accuracy: 0.8017 - val_loss: 0.4204 - val_accuracy: 0.8023 - 895ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4256 - accuracy: 0.8013 - val_loss: 0.4183 - val_accuracy: 0.8081 - 1s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8025 - val_loss: 0.4190 - val_accuracy: 0.8063 - 1s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4253 - accuracy: 0.8017 - val_loss: 0.4183 - val_accuracy: 0.8081 - 898ms/epoch - 7ms/step\n",
      "Epoch 40: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "123/123 - 3s - loss: 2.3582 - accuracy: 0.7528 - val_loss: 1.3369 - val_accuracy: 0.7680 - 3s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.9202 - accuracy: 0.7662 - val_loss: 0.6306 - val_accuracy: 0.7950 - 921ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.5376 - accuracy: 0.7988 - val_loss: 0.4669 - val_accuracy: 0.8072 - 925ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4542 - accuracy: 0.8014 - val_loss: 0.4335 - val_accuracy: 0.8081 - 920ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4373 - accuracy: 0.8023 - val_loss: 0.4319 - val_accuracy: 0.8036 - 974ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4350 - accuracy: 0.8016 - val_loss: 0.4244 - val_accuracy: 0.8081 - 962ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4326 - accuracy: 0.8025 - val_loss: 0.4268 - val_accuracy: 0.8054 - 859ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4315 - accuracy: 0.8014 - val_loss: 0.4233 - val_accuracy: 0.8072 - 1s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.8023 - val_loss: 0.4202 - val_accuracy: 0.8088 - 1s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4301 - accuracy: 0.8017 - val_loss: 0.4215 - val_accuracy: 0.8084 - 918ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4292 - accuracy: 0.8023 - val_loss: 0.4197 - val_accuracy: 0.8073 - 879ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4290 - accuracy: 0.8021 - val_loss: 0.4201 - val_accuracy: 0.8065 - 906ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4299 - accuracy: 0.8013 - val_loss: 0.4208 - val_accuracy: 0.8087 - 942ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4282 - accuracy: 0.8019 - val_loss: 0.4189 - val_accuracy: 0.8074 - 1s/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4273 - accuracy: 0.8031 - val_loss: 0.4223 - val_accuracy: 0.8073 - 951ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4278 - accuracy: 0.8022 - val_loss: 0.4227 - val_accuracy: 0.8036 - 893ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4275 - accuracy: 0.8022 - val_loss: 0.4209 - val_accuracy: 0.8081 - 937ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8024 - val_loss: 0.4247 - val_accuracy: 0.8018 - 938ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8021 - val_loss: 0.4227 - val_accuracy: 0.8044 - 895ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4276 - accuracy: 0.8018 - val_loss: 0.4182 - val_accuracy: 0.8073 - 875ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4274 - accuracy: 0.8024 - val_loss: 0.4205 - val_accuracy: 0.8063 - 929ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8005 - val_loss: 0.4204 - val_accuracy: 0.8084 - 891ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4286 - accuracy: 0.8003 - val_loss: 0.4196 - val_accuracy: 0.8073 - 879ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4275 - accuracy: 0.8017 - val_loss: 0.4263 - val_accuracy: 0.8005 - 891ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4271 - accuracy: 0.8017 - val_loss: 0.4194 - val_accuracy: 0.8083 - 911ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4269 - accuracy: 0.8017 - val_loss: 0.4228 - val_accuracy: 0.8064 - 907ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4270 - accuracy: 0.8022 - val_loss: 0.4185 - val_accuracy: 0.8082 - 879ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4269 - accuracy: 0.8020 - val_loss: 0.4183 - val_accuracy: 0.8068 - 877ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.4239 - val_accuracy: 0.7983 - 943ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8025 - val_loss: 0.4176 - val_accuracy: 0.8086 - 947ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4270 - accuracy: 0.8022 - val_loss: 0.4183 - val_accuracy: 0.8082 - 913ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4256 - accuracy: 0.8015 - val_loss: 0.4193 - val_accuracy: 0.8075 - 903ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8025 - val_loss: 0.4178 - val_accuracy: 0.8077 - 917ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.4178 - val_accuracy: 0.8061 - 988ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8024 - val_loss: 0.4175 - val_accuracy: 0.8079 - 1s/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4255 - accuracy: 0.8025 - val_loss: 0.4182 - val_accuracy: 0.8074 - 1s/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8020 - val_loss: 0.4181 - val_accuracy: 0.8083 - 932ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8014 - val_loss: 0.4183 - val_accuracy: 0.8073 - 969ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4272 - accuracy: 0.8005 - val_loss: 0.4171 - val_accuracy: 0.8070 - 1s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4260 - accuracy: 0.8020 - val_loss: 0.4182 - val_accuracy: 0.8079 - 1s/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8021 - val_loss: 0.4208 - val_accuracy: 0.8068 - 949ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 1s - loss: 0.4255 - accuracy: 0.8027 - val_loss: 0.4188 - val_accuracy: 0.8059 - 1s/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8018 - val_loss: 0.4169 - val_accuracy: 0.8065 - 978ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8019 - val_loss: 0.4191 - val_accuracy: 0.8072 - 982ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4250 - accuracy: 0.8026 - val_loss: 0.4185 - val_accuracy: 0.8083 - 946ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.4169 - val_accuracy: 0.8075 - 1000ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8014 - val_loss: 0.4177 - val_accuracy: 0.8078 - 1s/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8030 - val_loss: 0.4173 - val_accuracy: 0.8081 - 1s/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "123/123 - 1s - loss: 0.4248 - accuracy: 0.8019 - val_loss: 0.4306 - val_accuracy: 0.7958 - 1s/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8019 - val_loss: 0.4166 - val_accuracy: 0.8083 - 1s/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "123/123 - 1s - loss: 0.4262 - accuracy: 0.8013 - val_loss: 0.4168 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8015 - val_loss: 0.4201 - val_accuracy: 0.8084 - 1s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "123/123 - 1s - loss: 0.4248 - accuracy: 0.8015 - val_loss: 0.4168 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8014 - val_loss: 0.4168 - val_accuracy: 0.8079 - 1s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "123/123 - 1s - loss: 0.4253 - accuracy: 0.8010 - val_loss: 0.4178 - val_accuracy: 0.8082 - 1s/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "123/123 - 1s - loss: 0.4253 - accuracy: 0.8024 - val_loss: 0.4211 - val_accuracy: 0.8024 - 1s/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "123/123 - 1s - loss: 0.4265 - accuracy: 0.8004 - val_loss: 0.4178 - val_accuracy: 0.8075 - 1s/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "123/123 - 1s - loss: 0.4245 - accuracy: 0.8019 - val_loss: 0.4188 - val_accuracy: 0.8054 - 1s/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "123/123 - 1s - loss: 0.4255 - accuracy: 0.8018 - val_loss: 0.4167 - val_accuracy: 0.8069 - 1s/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8018 - val_loss: 0.4166 - val_accuracy: 0.8072 - 1s/epoch - 8ms/step\n",
      "Epoch 60: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "123/123 - 3s - loss: 2.3984 - accuracy: 0.7324 - val_loss: 1.3780 - val_accuracy: 0.7680 - 3s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.9499 - accuracy: 0.7749 - val_loss: 0.6475 - val_accuracy: 0.8027 - 986ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.5437 - accuracy: 0.8006 - val_loss: 0.4682 - val_accuracy: 0.8078 - 978ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4532 - accuracy: 0.8022 - val_loss: 0.4328 - val_accuracy: 0.8081 - 927ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4376 - accuracy: 0.8017 - val_loss: 0.4245 - val_accuracy: 0.8087 - 923ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4333 - accuracy: 0.8014 - val_loss: 0.4261 - val_accuracy: 0.8081 - 934ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4313 - accuracy: 0.8020 - val_loss: 0.4225 - val_accuracy: 0.8079 - 914ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4298 - accuracy: 0.8022 - val_loss: 0.4243 - val_accuracy: 0.8047 - 1s/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.8003 - val_loss: 0.4208 - val_accuracy: 0.8081 - 1s/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4293 - accuracy: 0.8017 - val_loss: 0.4237 - val_accuracy: 0.8067 - 1s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4285 - accuracy: 0.8020 - val_loss: 0.4202 - val_accuracy: 0.8079 - 998ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4283 - accuracy: 0.8024 - val_loss: 0.4361 - val_accuracy: 0.7956 - 1s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4288 - accuracy: 0.8012 - val_loss: 0.4208 - val_accuracy: 0.8077 - 1s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4282 - accuracy: 0.8013 - val_loss: 0.4219 - val_accuracy: 0.8064 - 1s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4285 - accuracy: 0.8016 - val_loss: 0.4188 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4284 - accuracy: 0.8015 - val_loss: 0.4228 - val_accuracy: 0.7996 - 1s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4275 - accuracy: 0.8018 - val_loss: 0.4184 - val_accuracy: 0.8083 - 1s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8017 - val_loss: 0.4227 - val_accuracy: 0.8037 - 1s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8017 - val_loss: 0.4183 - val_accuracy: 0.8084 - 1s/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4284 - accuracy: 0.8016 - val_loss: 0.4188 - val_accuracy: 0.8081 - 1s/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4270 - accuracy: 0.8008 - val_loss: 0.4187 - val_accuracy: 0.8087 - 1s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8019 - val_loss: 0.4231 - val_accuracy: 0.8031 - 1s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4272 - accuracy: 0.8000 - val_loss: 0.4189 - val_accuracy: 0.8086 - 942ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4264 - accuracy: 0.8011 - val_loss: 0.4176 - val_accuracy: 0.8073 - 964ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8023 - val_loss: 0.4194 - val_accuracy: 0.8060 - 988ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.4239 - val_accuracy: 0.8005 - 970ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4269 - accuracy: 0.8007 - val_loss: 0.4178 - val_accuracy: 0.8059 - 976ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4263 - accuracy: 0.8010 - val_loss: 0.4277 - val_accuracy: 0.7959 - 1s/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4271 - accuracy: 0.8008 - val_loss: 0.4230 - val_accuracy: 0.8060 - 1s/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4269 - accuracy: 0.8007 - val_loss: 0.4195 - val_accuracy: 0.8051 - 1s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4263 - accuracy: 0.8012 - val_loss: 0.4176 - val_accuracy: 0.8078 - 1s/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4265 - accuracy: 0.8026 - val_loss: 0.4185 - val_accuracy: 0.8083 - 1s/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4265 - accuracy: 0.8020 - val_loss: 0.4185 - val_accuracy: 0.8067 - 1s/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8019 - val_loss: 0.4174 - val_accuracy: 0.8059 - 1s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8009 - val_loss: 0.4171 - val_accuracy: 0.8078 - 1s/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8027 - val_loss: 0.4181 - val_accuracy: 0.8070 - 1s/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8013 - val_loss: 0.4197 - val_accuracy: 0.8060 - 1s/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4260 - accuracy: 0.8023 - val_loss: 0.4179 - val_accuracy: 0.8078 - 1s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4253 - accuracy: 0.8004 - val_loss: 0.4191 - val_accuracy: 0.8064 - 1s/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4260 - accuracy: 0.8017 - val_loss: 0.4195 - val_accuracy: 0.8036 - 1s/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8016 - val_loss: 0.4179 - val_accuracy: 0.8083 - 1s/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 2s - loss: 0.4257 - accuracy: 0.8026 - val_loss: 0.4175 - val_accuracy: 0.8056 - 2s/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.4174 - val_accuracy: 0.8067 - 1s/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8024 - val_loss: 0.4194 - val_accuracy: 0.8058 - 974ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8022 - val_loss: 0.4173 - val_accuracy: 0.8079 - 1s/epoch - 10ms/step\n",
      "Epoch 45: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "123/123 - 2s - loss: 2.4155 - accuracy: 0.7360 - val_loss: 1.3668 - val_accuracy: 0.7882 - 2s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.9370 - accuracy: 0.7945 - val_loss: 0.6424 - val_accuracy: 0.8075 - 1s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.5433 - accuracy: 0.8009 - val_loss: 0.4676 - val_accuracy: 0.8087 - 1s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4544 - accuracy: 0.8023 - val_loss: 0.4326 - val_accuracy: 0.8074 - 1s/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4370 - accuracy: 0.8021 - val_loss: 0.4250 - val_accuracy: 0.8070 - 938ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4322 - accuracy: 0.8020 - val_loss: 0.4238 - val_accuracy: 0.8079 - 1s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4307 - accuracy: 0.8024 - val_loss: 0.4210 - val_accuracy: 0.8086 - 1s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4307 - accuracy: 0.8005 - val_loss: 0.4216 - val_accuracy: 0.8086 - 1s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4313 - accuracy: 0.8007 - val_loss: 0.4206 - val_accuracy: 0.8087 - 1s/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.8009 - val_loss: 0.4208 - val_accuracy: 0.8063 - 1s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4298 - accuracy: 0.8008 - val_loss: 0.4232 - val_accuracy: 0.8041 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4284 - accuracy: 0.8015 - val_loss: 0.4193 - val_accuracy: 0.8086 - 992ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4285 - accuracy: 0.8017 - val_loss: 0.4212 - val_accuracy: 0.8054 - 977ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4276 - accuracy: 0.8016 - val_loss: 0.4192 - val_accuracy: 0.8087 - 969ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4274 - accuracy: 0.8031 - val_loss: 0.4272 - val_accuracy: 0.7982 - 972ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4287 - accuracy: 0.8011 - val_loss: 0.4189 - val_accuracy: 0.8058 - 986ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4273 - accuracy: 0.8018 - val_loss: 0.4204 - val_accuracy: 0.8052 - 952ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4272 - accuracy: 0.8014 - val_loss: 0.4205 - val_accuracy: 0.8059 - 1s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4271 - accuracy: 0.8020 - val_loss: 0.4203 - val_accuracy: 0.8073 - 1s/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4263 - accuracy: 0.8021 - val_loss: 0.4179 - val_accuracy: 0.8069 - 1s/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8019 - val_loss: 0.4175 - val_accuracy: 0.8064 - 1s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.4194 - val_accuracy: 0.8083 - 1s/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8025 - val_loss: 0.4175 - val_accuracy: 0.8065 - 1s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8013 - val_loss: 0.4206 - val_accuracy: 0.8026 - 1s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8025 - val_loss: 0.4185 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4263 - accuracy: 0.8020 - val_loss: 0.4181 - val_accuracy: 0.8083 - 1s/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8017 - val_loss: 0.4172 - val_accuracy: 0.8083 - 970ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8009 - val_loss: 0.4177 - val_accuracy: 0.8068 - 979ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8017 - val_loss: 0.4175 - val_accuracy: 0.8073 - 1s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.7997 - val_loss: 0.4195 - val_accuracy: 0.8083 - 1s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4255 - accuracy: 0.8015 - val_loss: 0.4207 - val_accuracy: 0.8044 - 1s/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4264 - accuracy: 0.8020 - val_loss: 0.4177 - val_accuracy: 0.8073 - 1s/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8008 - val_loss: 0.4170 - val_accuracy: 0.8065 - 1s/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4256 - accuracy: 0.8017 - val_loss: 0.4192 - val_accuracy: 0.8073 - 1s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8017 - val_loss: 0.4178 - val_accuracy: 0.8065 - 1s/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8019 - val_loss: 0.4186 - val_accuracy: 0.8065 - 1s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8020 - val_loss: 0.4172 - val_accuracy: 0.8081 - 997ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8026 - val_loss: 0.4190 - val_accuracy: 0.8086 - 1s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8022 - val_loss: 0.4173 - val_accuracy: 0.8072 - 1s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4253 - accuracy: 0.8015 - val_loss: 0.4187 - val_accuracy: 0.8082 - 926ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.4167 - val_accuracy: 0.8070 - 995ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8011 - val_loss: 0.4175 - val_accuracy: 0.8077 - 965ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8024 - val_loss: 0.4171 - val_accuracy: 0.8064 - 930ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4246 - accuracy: 0.8032 - val_loss: 0.4172 - val_accuracy: 0.8082 - 945ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4253 - accuracy: 0.8017 - val_loss: 0.4192 - val_accuracy: 0.8078 - 985ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8028 - val_loss: 0.4169 - val_accuracy: 0.8068 - 982ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "123/123 - 1s - loss: 0.4253 - accuracy: 0.8014 - val_loss: 0.4203 - val_accuracy: 0.8064 - 917ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8010 - val_loss: 0.4186 - val_accuracy: 0.8056 - 932ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8017 - val_loss: 0.4177 - val_accuracy: 0.8082 - 1s/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "123/123 - 1s - loss: 0.4249 - accuracy: 0.8024 - val_loss: 0.4176 - val_accuracy: 0.8086 - 1s/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8006 - val_loss: 0.4169 - val_accuracy: 0.8070 - 919ms/epoch - 7ms/step\n",
      "Epoch 51: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "123/123 - 48s - loss: 2.5139 - accuracy: 0.7007 - val_loss: 1.4288 - val_accuracy: 0.7681 - 48s/epoch - 390ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.9740 - accuracy: 0.7866 - val_loss: 0.6609 - val_accuracy: 0.8070 - 1s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.5518 - accuracy: 0.8020 - val_loss: 0.4720 - val_accuracy: 0.8078 - 1s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4567 - accuracy: 0.8014 - val_loss: 0.4338 - val_accuracy: 0.8083 - 1s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4374 - accuracy: 0.8014 - val_loss: 0.4274 - val_accuracy: 0.8042 - 1s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4332 - accuracy: 0.8023 - val_loss: 0.4234 - val_accuracy: 0.8070 - 1s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.8016 - val_loss: 0.4251 - val_accuracy: 0.8064 - 1s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.8014 - val_loss: 0.4218 - val_accuracy: 0.8070 - 1s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4304 - accuracy: 0.8018 - val_loss: 0.4206 - val_accuracy: 0.8083 - 1s/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4299 - accuracy: 0.8015 - val_loss: 0.4214 - val_accuracy: 0.8081 - 1s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4313 - accuracy: 0.8014 - val_loss: 0.4200 - val_accuracy: 0.8079 - 967ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.8014 - val_loss: 0.4191 - val_accuracy: 0.8079 - 1s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4287 - accuracy: 0.8022 - val_loss: 0.4201 - val_accuracy: 0.8068 - 1s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4278 - accuracy: 0.8017 - val_loss: 0.4205 - val_accuracy: 0.8068 - 1s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8013 - val_loss: 0.4193 - val_accuracy: 0.8086 - 1s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8032 - val_loss: 0.4191 - val_accuracy: 0.8084 - 1s/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4282 - accuracy: 0.8012 - val_loss: 0.4187 - val_accuracy: 0.8075 - 1s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4274 - accuracy: 0.8026 - val_loss: 0.4209 - val_accuracy: 0.8060 - 1s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4273 - accuracy: 0.8016 - val_loss: 0.4193 - val_accuracy: 0.8078 - 1s/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4275 - accuracy: 0.8018 - val_loss: 0.4192 - val_accuracy: 0.8081 - 1s/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4273 - accuracy: 0.8023 - val_loss: 0.4180 - val_accuracy: 0.8079 - 1s/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4274 - accuracy: 0.8015 - val_loss: 0.4191 - val_accuracy: 0.8083 - 1s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8019 - val_loss: 0.4187 - val_accuracy: 0.8075 - 1s/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8011 - val_loss: 0.4192 - val_accuracy: 0.8079 - 1s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4260 - accuracy: 0.8019 - val_loss: 0.4203 - val_accuracy: 0.8063 - 1s/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8005 - val_loss: 0.4203 - val_accuracy: 0.8079 - 1s/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4274 - accuracy: 0.8025 - val_loss: 0.4241 - val_accuracy: 0.7985 - 1s/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4272 - accuracy: 0.8017 - val_loss: 0.4177 - val_accuracy: 0.8077 - 1s/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8026 - val_loss: 0.4208 - val_accuracy: 0.8067 - 1s/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8020 - val_loss: 0.4208 - val_accuracy: 0.8079 - 1s/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8010 - val_loss: 0.4175 - val_accuracy: 0.8074 - 1s/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.4176 - val_accuracy: 0.8078 - 1s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8011 - val_loss: 0.4192 - val_accuracy: 0.8044 - 1s/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8022 - val_loss: 0.4175 - val_accuracy: 0.8061 - 1s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4255 - accuracy: 0.8020 - val_loss: 0.4175 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4265 - accuracy: 0.7999 - val_loss: 0.4221 - val_accuracy: 0.8031 - 1s/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8007 - val_loss: 0.4224 - val_accuracy: 0.8046 - 1s/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4256 - accuracy: 0.8009 - val_loss: 0.4190 - val_accuracy: 0.8063 - 1s/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8023 - val_loss: 0.4181 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8018 - val_loss: 0.4188 - val_accuracy: 0.8069 - 1s/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8014 - val_loss: 0.4176 - val_accuracy: 0.8084 - 1s/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8022 - val_loss: 0.4193 - val_accuracy: 0.8056 - 1s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8014 - val_loss: 0.4172 - val_accuracy: 0.8070 - 1s/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8019 - val_loss: 0.4195 - val_accuracy: 0.8073 - 1s/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4260 - accuracy: 0.8024 - val_loss: 0.4175 - val_accuracy: 0.8064 - 1s/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "123/123 - 1s - loss: 0.4256 - accuracy: 0.8015 - val_loss: 0.4190 - val_accuracy: 0.8060 - 1s/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8026 - val_loss: 0.4196 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.7995 - val_loss: 0.4209 - val_accuracy: 0.8003 - 1s/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "123/123 - 1s - loss: 0.4260 - accuracy: 0.8013 - val_loss: 0.4171 - val_accuracy: 0.8079 - 1s/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8028 - val_loss: 0.4175 - val_accuracy: 0.8081 - 1s/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8030 - val_loss: 0.4180 - val_accuracy: 0.8083 - 1s/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "123/123 - 1s - loss: 0.4255 - accuracy: 0.8018 - val_loss: 0.4239 - val_accuracy: 0.8017 - 1s/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8009 - val_loss: 0.4178 - val_accuracy: 0.8067 - 1s/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8020 - val_loss: 0.4169 - val_accuracy: 0.8069 - 1s/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "123/123 - 1s - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.4187 - val_accuracy: 0.8077 - 1s/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8014 - val_loss: 0.4174 - val_accuracy: 0.8075 - 1s/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8023 - val_loss: 0.4196 - val_accuracy: 0.8058 - 1s/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "123/123 - 1s - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.4180 - val_accuracy: 0.8070 - 1s/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "123/123 - 1s - loss: 0.4245 - accuracy: 0.8009 - val_loss: 0.4166 - val_accuracy: 0.8077 - 1s/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8019 - val_loss: 0.4180 - val_accuracy: 0.8086 - 992ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "123/123 - 1s - loss: 0.4247 - accuracy: 0.8014 - val_loss: 0.4169 - val_accuracy: 0.8086 - 913ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8017 - val_loss: 0.4174 - val_accuracy: 0.8072 - 1s/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "123/123 - 1s - loss: 0.4245 - accuracy: 0.8031 - val_loss: 0.4170 - val_accuracy: 0.8067 - 1s/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "123/123 - 1s - loss: 0.4250 - accuracy: 0.8026 - val_loss: 0.4169 - val_accuracy: 0.8072 - 1s/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8030 - val_loss: 0.4181 - val_accuracy: 0.8084 - 1s/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8017 - val_loss: 0.4174 - val_accuracy: 0.8083 - 1s/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "123/123 - 1s - loss: 0.4253 - accuracy: 0.8027 - val_loss: 0.4208 - val_accuracy: 0.8035 - 1s/epoch - 8ms/step\n",
      "Epoch 68/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8019 - val_loss: 0.4183 - val_accuracy: 0.8055 - 1s/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "123/123 - 1s - loss: 0.4245 - accuracy: 0.8022 - val_loss: 0.4175 - val_accuracy: 0.8074 - 1s/epoch - 8ms/step\n",
      "Epoch 69: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "123/123 - 3s - loss: 2.3910 - accuracy: 0.7490 - val_loss: 1.3624 - val_accuracy: 0.7680 - 3s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.9383 - accuracy: 0.7687 - val_loss: 0.6422 - val_accuracy: 0.8042 - 1s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.5425 - accuracy: 0.8008 - val_loss: 0.4688 - val_accuracy: 0.8051 - 1s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4539 - accuracy: 0.8016 - val_loss: 0.4365 - val_accuracy: 0.8063 - 1s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4372 - accuracy: 0.8021 - val_loss: 0.4375 - val_accuracy: 0.7942 - 1s/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4336 - accuracy: 0.8002 - val_loss: 0.4248 - val_accuracy: 0.8082 - 995ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4318 - accuracy: 0.8020 - val_loss: 0.4237 - val_accuracy: 0.8063 - 980ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4299 - accuracy: 0.8022 - val_loss: 0.4212 - val_accuracy: 0.8067 - 985ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.4257 - val_accuracy: 0.8056 - 1s/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4297 - accuracy: 0.8017 - val_loss: 0.4261 - val_accuracy: 0.8033 - 1s/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4290 - accuracy: 0.8012 - val_loss: 0.4232 - val_accuracy: 0.8060 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4286 - accuracy: 0.8020 - val_loss: 0.4239 - val_accuracy: 0.8042 - 1s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4289 - accuracy: 0.8009 - val_loss: 0.4203 - val_accuracy: 0.8082 - 1s/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4281 - accuracy: 0.8014 - val_loss: 0.4226 - val_accuracy: 0.8033 - 1s/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4279 - accuracy: 0.8016 - val_loss: 0.4187 - val_accuracy: 0.8077 - 958ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4273 - accuracy: 0.8018 - val_loss: 0.4242 - val_accuracy: 0.8023 - 979ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4277 - accuracy: 0.8010 - val_loss: 0.4260 - val_accuracy: 0.8022 - 1s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4277 - accuracy: 0.8010 - val_loss: 0.4215 - val_accuracy: 0.8065 - 1s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4269 - accuracy: 0.8017 - val_loss: 0.4274 - val_accuracy: 0.7996 - 1s/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8025 - val_loss: 0.4229 - val_accuracy: 0.8051 - 1s/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8015 - val_loss: 0.4185 - val_accuracy: 0.8086 - 1s/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4278 - accuracy: 0.8014 - val_loss: 0.4170 - val_accuracy: 0.8092 - 980ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4263 - accuracy: 0.8016 - val_loss: 0.4177 - val_accuracy: 0.8074 - 945ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.4214 - val_accuracy: 0.8078 - 1s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4270 - accuracy: 0.8014 - val_loss: 0.4181 - val_accuracy: 0.8082 - 1s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8015 - val_loss: 0.4176 - val_accuracy: 0.8072 - 967ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4271 - accuracy: 0.8016 - val_loss: 0.4221 - val_accuracy: 0.8045 - 1s/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8009 - val_loss: 0.4194 - val_accuracy: 0.8063 - 1s/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8029 - val_loss: 0.4207 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8010 - val_loss: 0.4175 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4263 - accuracy: 0.8027 - val_loss: 0.4199 - val_accuracy: 0.8055 - 1s/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8012 - val_loss: 0.4172 - val_accuracy: 0.8074 - 1s/epoch - 9ms/step\n",
      "Epoch 32: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "123/123 - 2s - loss: 2.4116 - accuracy: 0.7611 - val_loss: 1.3587 - val_accuracy: 0.7886 - 2s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.9333 - accuracy: 0.7951 - val_loss: 0.6401 - val_accuracy: 0.8044 - 1s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.5414 - accuracy: 0.8008 - val_loss: 0.4676 - val_accuracy: 0.8072 - 1s/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4527 - accuracy: 0.8025 - val_loss: 0.4312 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4358 - accuracy: 0.8017 - val_loss: 0.4244 - val_accuracy: 0.8087 - 1s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4318 - accuracy: 0.8021 - val_loss: 0.4232 - val_accuracy: 0.8070 - 1s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4315 - accuracy: 0.8014 - val_loss: 0.4277 - val_accuracy: 0.8014 - 1s/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4301 - accuracy: 0.8011 - val_loss: 0.4203 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4313 - accuracy: 0.8005 - val_loss: 0.4208 - val_accuracy: 0.8084 - 1s/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4286 - accuracy: 0.8027 - val_loss: 0.4210 - val_accuracy: 0.8086 - 1s/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4293 - accuracy: 0.8017 - val_loss: 0.4194 - val_accuracy: 0.8081 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4278 - accuracy: 0.8019 - val_loss: 0.4194 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4284 - accuracy: 0.8010 - val_loss: 0.4198 - val_accuracy: 0.8075 - 1s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4291 - accuracy: 0.8012 - val_loss: 0.4216 - val_accuracy: 0.8046 - 1s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4278 - accuracy: 0.8011 - val_loss: 0.4186 - val_accuracy: 0.8075 - 1s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4271 - accuracy: 0.8016 - val_loss: 0.4185 - val_accuracy: 0.8067 - 1s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.4194 - val_accuracy: 0.8081 - 1s/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4274 - accuracy: 0.8024 - val_loss: 0.4205 - val_accuracy: 0.8078 - 1s/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8014 - val_loss: 0.4188 - val_accuracy: 0.8078 - 990ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8017 - val_loss: 0.4220 - val_accuracy: 0.8058 - 1s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4273 - accuracy: 0.8014 - val_loss: 0.4176 - val_accuracy: 0.8081 - 1s/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8018 - val_loss: 0.4184 - val_accuracy: 0.8084 - 1s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4263 - accuracy: 0.8032 - val_loss: 0.4178 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8023 - val_loss: 0.4192 - val_accuracy: 0.8058 - 1s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4272 - accuracy: 0.8009 - val_loss: 0.4185 - val_accuracy: 0.8083 - 1s/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4277 - accuracy: 0.8006 - val_loss: 0.4191 - val_accuracy: 0.8058 - 1s/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8017 - val_loss: 0.4235 - val_accuracy: 0.8042 - 1s/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8032 - val_loss: 0.4178 - val_accuracy: 0.8078 - 1s/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8029 - val_loss: 0.4185 - val_accuracy: 0.8081 - 1s/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4262 - accuracy: 0.8017 - val_loss: 0.4247 - val_accuracy: 0.8084 - 1s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8001 - val_loss: 0.4178 - val_accuracy: 0.8075 - 1s/epoch - 9ms/step\n",
      "Epoch 31: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "123/123 - 2s - loss: 2.3814 - accuracy: 0.7646 - val_loss: 1.3442 - val_accuracy: 0.7933 - 2s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.9246 - accuracy: 0.7975 - val_loss: 0.6350 - val_accuracy: 0.8058 - 1s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.5387 - accuracy: 0.8016 - val_loss: 0.4672 - val_accuracy: 0.8052 - 1s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4537 - accuracy: 0.8006 - val_loss: 0.4351 - val_accuracy: 0.8054 - 1s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4363 - accuracy: 0.8025 - val_loss: 0.4301 - val_accuracy: 0.8059 - 1s/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4343 - accuracy: 0.8010 - val_loss: 0.4308 - val_accuracy: 0.7981 - 1s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.8004 - val_loss: 0.4217 - val_accuracy: 0.8073 - 1s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4300 - accuracy: 0.8008 - val_loss: 0.4213 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4293 - accuracy: 0.8012 - val_loss: 0.4204 - val_accuracy: 0.8079 - 1s/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4287 - accuracy: 0.8018 - val_loss: 0.4237 - val_accuracy: 0.8065 - 1s/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4295 - accuracy: 0.8030 - val_loss: 0.4226 - val_accuracy: 0.8088 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4277 - accuracy: 0.8020 - val_loss: 0.4264 - val_accuracy: 0.8027 - 1s/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4290 - accuracy: 0.8008 - val_loss: 0.4218 - val_accuracy: 0.8072 - 1s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4291 - accuracy: 0.8013 - val_loss: 0.4194 - val_accuracy: 0.8084 - 1s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4275 - accuracy: 0.8016 - val_loss: 0.4194 - val_accuracy: 0.8083 - 1s/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4283 - accuracy: 0.8013 - val_loss: 0.4206 - val_accuracy: 0.8036 - 1s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4277 - accuracy: 0.8008 - val_loss: 0.4244 - val_accuracy: 0.8045 - 1s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8013 - val_loss: 0.4186 - val_accuracy: 0.8084 - 1s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4272 - accuracy: 0.8013 - val_loss: 0.4267 - val_accuracy: 0.8047 - 1s/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4269 - accuracy: 0.8029 - val_loss: 0.4192 - val_accuracy: 0.8084 - 1s/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4277 - accuracy: 0.8009 - val_loss: 0.4185 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4271 - accuracy: 0.8012 - val_loss: 0.4197 - val_accuracy: 0.8083 - 1s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8017 - val_loss: 0.4186 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4290 - accuracy: 0.8011 - val_loss: 0.4247 - val_accuracy: 0.8023 - 1s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8017 - val_loss: 0.4178 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4272 - accuracy: 0.8009 - val_loss: 0.4192 - val_accuracy: 0.8049 - 1s/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8008 - val_loss: 0.4188 - val_accuracy: 0.8083 - 1s/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4266 - accuracy: 0.8016 - val_loss: 0.4209 - val_accuracy: 0.8079 - 1s/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8027 - val_loss: 0.4189 - val_accuracy: 0.8093 - 1s/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4264 - accuracy: 0.8024 - val_loss: 0.4180 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8015 - val_loss: 0.4187 - val_accuracy: 0.8065 - 997ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8017 - val_loss: 0.4208 - val_accuracy: 0.8026 - 958ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8012 - val_loss: 0.4180 - val_accuracy: 0.8070 - 1s/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8032 - val_loss: 0.4222 - val_accuracy: 0.8045 - 1s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4264 - accuracy: 0.8013 - val_loss: 0.4174 - val_accuracy: 0.8086 - 1s/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4256 - accuracy: 0.8019 - val_loss: 0.4182 - val_accuracy: 0.8081 - 1s/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4270 - accuracy: 0.8015 - val_loss: 0.4181 - val_accuracy: 0.8074 - 1s/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4265 - accuracy: 0.8019 - val_loss: 0.4245 - val_accuracy: 0.8018 - 1s/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4276 - accuracy: 0.7999 - val_loss: 0.4195 - val_accuracy: 0.8060 - 1s/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8025 - val_loss: 0.4181 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8031 - val_loss: 0.4172 - val_accuracy: 0.8078 - 1s/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8013 - val_loss: 0.4202 - val_accuracy: 0.8074 - 1s/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8018 - val_loss: 0.4179 - val_accuracy: 0.8084 - 1s/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8016 - val_loss: 0.4186 - val_accuracy: 0.8067 - 1s/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4252 - accuracy: 0.8018 - val_loss: 0.4184 - val_accuracy: 0.8068 - 1s/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "123/123 - 1s - loss: 0.4251 - accuracy: 0.8017 - val_loss: 0.4197 - val_accuracy: 0.8052 - 1s/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "123/123 - 1s - loss: 0.4249 - accuracy: 0.8028 - val_loss: 0.4189 - val_accuracy: 0.8074 - 1s/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8006 - val_loss: 0.4190 - val_accuracy: 0.8068 - 1s/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "123/123 - 1s - loss: 0.4256 - accuracy: 0.8014 - val_loss: 0.4183 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "123/123 - 1s - loss: 0.4248 - accuracy: 0.8027 - val_loss: 0.4182 - val_accuracy: 0.8064 - 1s/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "123/123 - 1s - loss: 0.4254 - accuracy: 0.8028 - val_loss: 0.4175 - val_accuracy: 0.8073 - 1s/epoch - 9ms/step\n",
      "Epoch 51: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "123/123 - 2s - loss: 2.4720 - accuracy: 0.7475 - val_loss: 1.3913 - val_accuracy: 0.7687 - 2s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.9451 - accuracy: 0.7913 - val_loss: 0.6434 - val_accuracy: 0.8061 - 996ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.5425 - accuracy: 0.8018 - val_loss: 0.4690 - val_accuracy: 0.8063 - 1s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4541 - accuracy: 0.8016 - val_loss: 0.4322 - val_accuracy: 0.8087 - 1s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4362 - accuracy: 0.8021 - val_loss: 0.4265 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4328 - accuracy: 0.8022 - val_loss: 0.4237 - val_accuracy: 0.8075 - 1s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4319 - accuracy: 0.8015 - val_loss: 0.4340 - val_accuracy: 0.7997 - 1s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.4221 - val_accuracy: 0.8078 - 1s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4314 - accuracy: 0.8019 - val_loss: 0.4227 - val_accuracy: 0.8072 - 1s/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4296 - accuracy: 0.8022 - val_loss: 0.4210 - val_accuracy: 0.8090 - 1s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4293 - accuracy: 0.8021 - val_loss: 0.4202 - val_accuracy: 0.8075 - 942ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4290 - accuracy: 0.8022 - val_loss: 0.4247 - val_accuracy: 0.8063 - 987ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4285 - accuracy: 0.8019 - val_loss: 0.4239 - val_accuracy: 0.8038 - 1s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4288 - accuracy: 0.8013 - val_loss: 0.4209 - val_accuracy: 0.8063 - 1s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4283 - accuracy: 0.8023 - val_loss: 0.4198 - val_accuracy: 0.8083 - 1s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4286 - accuracy: 0.8017 - val_loss: 0.4263 - val_accuracy: 0.8044 - 1s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4278 - accuracy: 0.8013 - val_loss: 0.4185 - val_accuracy: 0.8072 - 1s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8021 - val_loss: 0.4196 - val_accuracy: 0.8065 - 1s/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8011 - val_loss: 0.4197 - val_accuracy: 0.8041 - 995ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4271 - accuracy: 0.8015 - val_loss: 0.4212 - val_accuracy: 0.8059 - 1s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4271 - accuracy: 0.8027 - val_loss: 0.4198 - val_accuracy: 0.8074 - 1s/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8023 - val_loss: 0.4192 - val_accuracy: 0.8090 - 1s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8018 - val_loss: 0.4173 - val_accuracy: 0.8070 - 1s/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8018 - val_loss: 0.4176 - val_accuracy: 0.8073 - 1s/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4265 - accuracy: 0.8022 - val_loss: 0.4179 - val_accuracy: 0.8061 - 1s/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4264 - accuracy: 0.8019 - val_loss: 0.4178 - val_accuracy: 0.8088 - 955ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4260 - accuracy: 0.8011 - val_loss: 0.4181 - val_accuracy: 0.8079 - 957ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4265 - accuracy: 0.8012 - val_loss: 0.4390 - val_accuracy: 0.7965 - 1s/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4275 - accuracy: 0.8017 - val_loss: 0.4181 - val_accuracy: 0.8078 - 1s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4271 - accuracy: 0.8007 - val_loss: 0.4195 - val_accuracy: 0.8074 - 957ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4260 - accuracy: 0.8022 - val_loss: 0.4237 - val_accuracy: 0.8055 - 978ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4277 - accuracy: 0.8010 - val_loss: 0.4199 - val_accuracy: 0.8058 - 1s/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4255 - accuracy: 0.8028 - val_loss: 0.4189 - val_accuracy: 0.8079 - 1s/epoch - 10ms/step\n",
      "Epoch 33: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "123/123 - 2s - loss: 2.3918 - accuracy: 0.7584 - val_loss: 1.3517 - val_accuracy: 0.7680 - 2s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.9316 - accuracy: 0.7739 - val_loss: 0.6389 - val_accuracy: 0.8019 - 1s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.5411 - accuracy: 0.8006 - val_loss: 0.4668 - val_accuracy: 0.8079 - 1s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4534 - accuracy: 0.8023 - val_loss: 0.4318 - val_accuracy: 0.8081 - 1s/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4362 - accuracy: 0.8025 - val_loss: 0.4251 - val_accuracy: 0.8075 - 1s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4322 - accuracy: 0.8016 - val_loss: 0.4219 - val_accuracy: 0.8091 - 1s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4311 - accuracy: 0.8019 - val_loss: 0.4227 - val_accuracy: 0.8077 - 1s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.8021 - val_loss: 0.4237 - val_accuracy: 0.8052 - 1s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.8011 - val_loss: 0.4200 - val_accuracy: 0.8082 - 1s/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.8011 - val_loss: 0.4278 - val_accuracy: 0.7963 - 1s/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4289 - accuracy: 0.8021 - val_loss: 0.4197 - val_accuracy: 0.8067 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.4238 - val_accuracy: 0.8036 - 1s/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4292 - accuracy: 0.7999 - val_loss: 0.4247 - val_accuracy: 0.8042 - 1s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4284 - accuracy: 0.8007 - val_loss: 0.4192 - val_accuracy: 0.8075 - 1s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4274 - accuracy: 0.8019 - val_loss: 0.4224 - val_accuracy: 0.8083 - 1s/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4280 - accuracy: 0.8017 - val_loss: 0.4188 - val_accuracy: 0.8072 - 1s/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8014 - val_loss: 0.4178 - val_accuracy: 0.8070 - 1s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8022 - val_loss: 0.4187 - val_accuracy: 0.8075 - 1s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4269 - accuracy: 0.8020 - val_loss: 0.4184 - val_accuracy: 0.8081 - 1s/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.4182 - val_accuracy: 0.8069 - 1s/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4264 - accuracy: 0.8023 - val_loss: 0.4190 - val_accuracy: 0.8064 - 1s/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4264 - accuracy: 0.8014 - val_loss: 0.4181 - val_accuracy: 0.8078 - 1s/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8017 - val_loss: 0.4184 - val_accuracy: 0.8063 - 1s/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4262 - accuracy: 0.8019 - val_loss: 0.4172 - val_accuracy: 0.8072 - 1s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4267 - accuracy: 0.8013 - val_loss: 0.4189 - val_accuracy: 0.8086 - 1s/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8016 - val_loss: 0.4183 - val_accuracy: 0.8077 - 985ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4262 - accuracy: 0.8020 - val_loss: 0.4202 - val_accuracy: 0.8059 - 922ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4268 - accuracy: 0.8019 - val_loss: 0.4187 - val_accuracy: 0.8067 - 891ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4259 - accuracy: 0.8026 - val_loss: 0.4178 - val_accuracy: 0.8086 - 888ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8017 - val_loss: 0.4176 - val_accuracy: 0.8061 - 961ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4257 - accuracy: 0.8031 - val_loss: 0.4184 - val_accuracy: 0.8058 - 844ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4264 - accuracy: 0.8008 - val_loss: 0.4189 - val_accuracy: 0.8082 - 877ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4258 - accuracy: 0.8015 - val_loss: 0.4175 - val_accuracy: 0.8079 - 910ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4261 - accuracy: 0.8021 - val_loss: 0.4215 - val_accuracy: 0.8042 - 871ms/epoch - 7ms/step\n",
      "Epoch 34: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.43234153019020116\n",
      "epi entropy:  0.41379853230391017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train ensemble model for dataset size 0.1 to 1.0\n",
    "ale_entropy_ensemble = []\n",
    "epi_entropy_ensemble = []\n",
    "pred_prob_ensemble = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print('dataset size: ', np.round((i * 0.1 + 0.1),1))\n",
    "    pred, ale_entropy, epi_entropy = train_ensemble_model(train_sets[dataset_frac[i]].features, train_sets[dataset_frac[i]].labels.ravel(), dataset_orig_test.features, ensemble_size=10)\n",
    "    print('ale entropy: ', np.mean(ale_entropy))\n",
    "    print('epi entropy: ', np.mean(epi_entropy))\n",
    "\n",
    "    # save ale and epi entropy\n",
    "    ale_entropy_ensemble.append(ale_entropy)\n",
    "    epi_entropy_ensemble.append(epi_entropy)\n",
    "    pred_prob_ensemble.append(pred)\n",
    "\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal opportunity difference for dataset of size 0.10 = 0.449348\n",
      "Equal opportunity difference for dataset of size 0.20 = 0.454865\n",
      "Equal opportunity difference for dataset of size 0.30 = 0.448847\n",
      "Equal opportunity difference for dataset of size 0.40 = 0.448345\n",
      "Equal opportunity difference for dataset of size 0.50 = 0.450351\n",
      "Equal opportunity difference for dataset of size 0.60 = 0.497994\n",
      "Equal opportunity difference for dataset of size 0.70 = 0.459378\n",
      "Equal opportunity difference for dataset of size 0.80 = 0.455868\n",
      "Equal opportunity difference for dataset of size 0.90 = 0.445838\n",
      "Equal opportunity difference for dataset of size 1.00 = 0.459378\n"
     ]
    }
   ],
   "source": [
    "Equal_opp_diffs_ensemble = equal_opportunity_difference(dataset_orig_test, pred_prob_ensemble, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  0.1\n",
      "ale entropy:  0.4406959585333589\n",
      "epi entropy:  0.412198451034542\n",
      "\n",
      "dataset size:  0.2\n",
      "ale entropy:  0.4410759826015914\n",
      "epi entropy:  0.4158793373031786\n",
      "\n",
      "dataset size:  0.3\n",
      "ale entropy:  0.4365954841937596\n",
      "epi entropy:  0.41067587444711534\n",
      "\n",
      "dataset size:  0.4\n",
      "ale entropy:  0.43761980942708745\n",
      "epi entropy:  0.41189464333236436\n",
      "\n",
      "dataset size:  0.5\n",
      "ale entropy:  0.45362373209834017\n",
      "epi entropy:  0.4280003503733929\n",
      "\n",
      "dataset size:  0.6\n",
      "ale entropy:  0.44274364391730997\n",
      "epi entropy:  0.4185807097705979\n",
      "\n",
      "dataset size:  0.7\n",
      "ale entropy:  0.4335625447171057\n",
      "epi entropy:  0.41136076525460186\n",
      "\n",
      "dataset size:  0.8\n",
      "ale entropy:  0.4398371985478691\n",
      "epi entropy:  0.420116217913827\n",
      "\n",
      "dataset size:  0.9\n",
      "ale entropy:  0.43070281041683317\n",
      "epi entropy:  0.41019925791424244\n",
      "\n",
      "dataset size:  1.0\n",
      "ale entropy:  0.43234153019020116\n",
      "epi entropy:  0.41379853230391017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mean of each entropy in epi_entropy_ensemble\n",
    "for i in range(0, 10):\n",
    "    print('dataset size: ', np.round((i * 0.1 + 0.1),1))\n",
    "    print('ale entropy: ', np.mean(ale_entropy_ensemble[i]))\n",
    "    print('epi entropy: ', np.mean(epi_entropy_ensemble[i]))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sketch graph for mean epistemic entropy of ensemble model\n",
    "plt.plot(dataset_frac, np.mean(epi_entropy_ensemble, axis=1), label='ensemble model')\n",
    "plt.xlabel('dataset size') # dataset size\n",
    "plt.ylabel('Mean Epistemic Entropy')\n",
    "plt.title('Mean Epistemic Uncertainty of Ensemble Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sketch graph of mean equal opportunity difference for ensemble model\n",
    "plt.plot(dataset_frac, Equal_opp_diffs_ensemble, label='ensemble model')\n",
    "plt.xlabel('dataset size') # dataset size\n",
    "plt.ylabel('Mean Equal Opportunity Difference')\n",
    "plt.title('Mean Equal Opportunity Difference of Ensemble Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAHHCAYAAAC1Nz73AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB0W0lEQVR4nO3dd1gUV9sG8HuXtiBVaaIIihUbioLYMEoENVgTjVFB7F1jNGo+e3xjjNGY2DX22GJJbLHFqLFrVGKNEQQrxUazobvn+8N392XcRQGBZdz7d1176Z45M/ucKTsPs2fOKIQQAkREREREJkZp7ACIiIiIiIyBiTARERERmSQmwkRERERkkpgIExEREZFJYiJMRERERCaJiTARERERmSQmwkRERERkkpgIExEREZFJYiJMRERERCaJiXA+UigUmDhxorHDyLXu3bvD29vb2GEQyUJ8fDwUCgWWL19u7FDeWU2aNEGTJk2MHYZBhr4vMzIy0KtXL7i7u0OhUGDYsGEAgKSkJHz44YcoUaIEFAoFZs2aVejxylF269MUeXt744MPPnhjvQMHDkChUODAgQMFH1QBe5vj39vbG927d8/VPLlKhJcvXw6FQgGFQoHDhw/rTRdCwNPTEwqFIkcbzpi8vb11bXn1FRYWVmhxrFmz5p36cuzevXu261WlUuVpmfPmzWPS8RraxEyhUGDKlCkG63Tp0gUKhQK2traFHF3uFMT+Y2w3btxAv3794O3tDSsrK7i6uqJt27Y4cuSIsUPLsUuXLmHixImIj483yuffuXMHEydORHR0dL4ud+LEiZJ9zMbGBmXKlEF4eDiWLVuGZ8+e5Wg5X331FZYvX47+/ftj1apV6NatGwDg008/xe7duzFmzBisWrWqUM8tcpbd+jSkqJzL3zXv0nnlTczzMpNKpcKaNWvQsGFDSfnBgwdx69YtWFlZ5UtwBc3Pzw+fffaZXrmHh0eelvfkyROYm+dula5ZswYXLlww6l+8ixcvhkajybflWVlZ4ccff9QrNzMzy9Py5s2bB2dn51z/lWdqVCoV1q5di7Fjx0rKHz16hC1btsgmkczv/ceYjhw5gpYtWwIAevXqBV9fXyQmJmL58uVo1KgRvv/+ewwePNjIUb7ZpUuXMGnSJDRp0qRQfj3as2eP5P2dO3cwadIkeHt7w8/PL98/b/78+bC1tcWzZ89w+/Zt7N69Gz169MCsWbOwfft2eHp66uoa+r78448/UK9ePUyYMEGvvE2bNhgxYkS+x/wuy259Zie/z+X0P+/KeeV18pQIt2zZEhs2bMAPP/wgSfzWrFkDf39/3Lt3L98CLEilSpVC165d8215ct0hLCws8nV55ubm+bpec+PRo0coVqyYUT7b2Fq2bInNmzfj77//Rs2aNXXlW7ZsQWZmJsLCwvDHH38YMcKcMeb+k58ePnyIDz/8ENbW1jhy5Ah8fHx004YPH47Q0FAMGzYM/v7+qF+/vhEjzd7Tp09haWlZ6J9b2J/54YcfwtnZWfd+/PjxWL16NSIiIvDRRx/h+PHjummGvi+Tk5Ph6+trsNzR0THf4nzx4gU0Go1Rtklhym59Zie/z+X0P+/KeeV18tRHuHPnzrh//z727t2rK8vMzMTGjRvxySefGJxHo9Fg1qxZqFq1KlQqFdzc3NC3b188fPhQUm/Lli1o1aoVPDw8YGVlBR8fH3z55ZdQq9WSek2aNEG1atVw6dIlvPfee7CxsUGpUqXwzTff5KVJ2erevTtsbW1x7do1hIaGolixYvDw8MDkyZMhhJDUfbWPcHp6OoYNGyb5SfT999/HmTNndG3YsWMHrl+/rvsJIuvVlmfPnmHChAkoX748rKys4Onpic8//1zv5zqFQoFBgwZhw4YN8PX1hbW1NYKCgnD+/HkAwMKFC1G+fHmoVCo0adJE7+dNQ33eNBoNvv/+e1SvXh0qlQouLi4ICwvDX3/99XYr9L+03WyOHDmC4cOHw8XFBcWKFUO7du1w9+5dXT1vb29cvHgRBw8e1K0jbd8h7TIOHjyIAQMGwNXVFaVLl9bNO2/ePFStWhVWVlbw8PDAwIEDkZKSIolDux+dPn0a9evXh7W1NcqWLYsFCxbo6mRkZKBYsWIYOnSoXjtu3boFMzMzTJ061WA7nz9/juLFiyMqKkpvWlpaGlQqleRq0ezZs1G1alXY2NjAyckJderUwZo1a3K0ToOCglC2bFm9+qtXr0ZYWBiKFy9ucL6dO3eiUaNGKFasGOzs7NCqVStcvHhRUufcuXPo3r07ypUrB5VKBXd3d/To0QP379+X1NP+1BwTE4Pu3bvD0dERDg4OiIqKwuPHj3PUjpy6ePEimjZtCmtra5QuXRpTpkzB0qVLoVAoJPt4dn33X+1L9uDBA4wYMQLVq1eHra0t7O3t0aJFC/z99995im/hwoVITEzE9OnTJUkwAFhbW2PFihVQKBSYPHmyrly7T//555/o27cvSpQoAXt7e0REROh9V2r7Du7Zswd+fn5QqVTw9fXF5s2b9WK5du0aPvroIxQvXhw2NjaoV68eduzYIamj7WO4bt06jB07FqVKlYKNjQ1++OEHfPTRRwCA9957T3ccavsi5nT95vSYB6R9BA8cOIC6desCAKKionSfv3z5ckyYMAEWFhZ68wNAnz594OjoiKdPn+pNy4kuXbqgV69eOHHihORcl/X7UrvO4uLisGPHDklsCoUCQgjMnTtXV66VkpKCYcOGwdPTE1ZWVihfvjymTZsmudKs/Wn622+/xaxZs+Dj4wMrKytcunQJAPDPP//gww8/RPHixaFSqVCnTh1s3bpV0obcrHPg5XdBcHAw7OzsYG9vj7p16+p9n5w4cQJhYWFwcHCAjY0NgoODc9zNJzk5GT179oSbmxtUKhVq1qyJFStW6KZntz7zo0uO9lx++/ZttG3bFra2tnBxccGIESP08ot169bB399ftx6qV6+O77//XlInt9tw7ty5KFeuHGxsbNC8eXPcvHkTQgh8+eWXKF26NKytrdGmTRs8ePDAYPw5Oc4NeZvtBeT9vJKT8y8ALFq0CD4+PrC2tkZAQAAOHTpkcHk5zYfyROTCsmXLBABx6tQpUb9+fdGtWzfdtF9//VUolUpx+/Zt4eXlJVq1aiWZt1evXsLc3Fz07t1bLFiwQIwaNUoUK1ZM1K1bV2RmZurqtW3bVnTs2FFMnz5dzJ8/X3z00UcCgBgxYoRkecHBwcLDw0N4enqKoUOHinnz5ommTZsKAOK33357Y1u8vLxE8+bNxd27d/Vejx8/1tWLjIwUKpVKVKhQQXTr1k3MmTNHfPDBBwKAGDdunGSZAMSECRN07z/55BNhaWkphg8fLn788Ucxbdo0ER4eLn766SchhBB79uwRfn5+wtnZWaxatUqsWrVK/PLLL0IIIdRqtWjevLmwsbERw4YNEwsXLhSDBg0S5ubmok2bNnqfW6NGDeHp6Sm+/vpr8fXXXwsHBwdRpkwZMWfOHOHr6ytmzJghxo4dKywtLcV7770nmT8yMlJ4eXlJyrp37y4AiBYtWohZs2aJb7/9VrRp00bMnj37tes1MjJSFCtWzOB6TU1N1dXT7ku1atUSTZs2FbNnzxafffaZMDMzEx07dtTV++WXX0Tp0qVF5cqVdetoz549kmX4+vqK4OBgMXv2bPH1118LIYSYMGGCACBCQkLE7NmzxaBBg4SZmZne/qbdj1xdXcWgQYPEDz/8IBo2bCgAiCVLlujqdenSRbi5uYkXL15I2vvNN98IhUIhrl+/nu066dGjh3B0dBTPnj2TlK9YsUJ3PAkhxKJFiwQA8eGHH4qFCxeK77//XvTs2VMMGTLktes8Li5OABDTp08XX3zxhShTpozQaDRCCCHu3r0rzM3Nxdq1a3XbJquVK1cKhUIhwsLCxOzZs8W0adOEt7e3cHR0FHFxcbp63377rWjUqJGYPHmyWLRokRg6dKiwtrYWAQEBus/Kut5r1aol2rdvL+bNmyd69eolAIjPP//8te0QIuf7T0JCgnBxcRFOTk5i4sSJYvr06aJChQqiRo0aAoAk9lePSy0vLy8RGRmpe3/q1Cnh4+MjRo8eLRYuXCgmT54sSpUqJRwcHMTt27f11veyZcte25b69esLlUolnj59mm2d4OBgYWFhofvO0e7T1atXF40aNRI//PCDGDhwoFAqlaJx48aSde3l5SUqVqwoHB0dxejRo8XMmTNF9erVhVKp1B0jQgiRmJgo3NzchJ2dnfi///s/MXPmTFGzZk2hVCrF5s2bdfX279+vO578/PzEzJkzxdSpU8XFixfFkCFDBADxxRdf6I7DxMTEXK3fnB7z2vUSHBysi3/y5MkCgOjTp4/u82NjY8XVq1cFAL3vpWfPngknJyfRo0eP124j7f569+5dg9MPHTqkd/7J+n2ZmJgoVq1aJZydnYWfn58utgsXLohVq1YJAOL999/XlQshxKNHj0SNGjVEiRIlxBdffCEWLFggIiIihEKhEEOHDtV9jnY/8/X1FeXKlRNff/21+O6778T169fFhQsXhIODg/D19RXTpk0Tc+bMEY0bNxYKhUKyTXOzzpctWyYUCoWoVq2a+M9//iPmzp0revXqJTnP79u3T1haWoqgoCAxY8YM8d1334kaNWoIS0tLceLEideu68ePH4sqVaoICwsL8emnn4offvhBNGrUSAAQs2bNeu36zMjIyHa5uT2XV61aVfTo0UPMnz9fdOjQQQAQ8+bN09Xbs2ePACCaNWsm5s6dK+bOnSsGDRokPvroI12d3G5DPz8/4evrK2bOnKk7D9erV0988cUXon79+uKHH34QQ4YMEQqFQkRFRem1LyfHufb43b9/f75sr7c5r+T0/Pvjjz8KALp1MGzYMOHo6CjKlSunO/6FyF0+9Or3Tk7kORGeM2eOsLOz0+1oH330kS7BejUR1n6ZrF69WrK8Xbt26ZVn3XG1+vbtK2xsbCQnlODgYAFArFy5Ulf27Nkz4e7uLjp06PDGtnh5eQkABl9Tp07V1YuMjBQAxODBg3VlGo1GtGrVSlhaWkq+QF89ITg4OIiBAwe+No5WrVrpJaFCCLFq1SqhVCrFoUOHJOULFiwQAMSRI0ckn2tlZSU5+S9cuFAAEO7u7iItLU1XPmbMGL1E4dVE+I8//hAADCZgWU/EhmjXl6FXaGiorp52XwoJCZEs89NPPxVmZmYiJSVFV1a1alXJQfHqMho2bChJUJOTk4WlpaVo3ry5UKvVuvI5c+YIAGLp0qW6Mu1+NGPGDF3Zs2fPhJ+fn3B1ddUdtLt37xYAxM6dOyUx1KhRw2BsWWnn3bZtm6S8ZcuWoly5crr3bdq0EVWrVn3tsgzJ+oV14cIFAUC338ydO1fY2tqKR48e6X1hpaenC0dHR9G7d2/J8hITE4WDg4Ok3NBxuXbtWgFA/Pnnn7oy7RfgqwlIu3btRIkSJd7YlpzuP8OGDRMAJF/mycnJwsHBIc+J8NOnTyX7ixAv162VlZWYPHmypCwnibCjo6OoWbPma+toE8xz584JIf63T/v7+0tOGN98840AILZs2SKJH4DYtGmTriw1NVWULFlS1KpVS1emXVdZv0vS09NF2bJlhbe3t67N2hNpuXLl9Lb3hg0b9E6yWrlNhHNyzGdNhIV4+UdKdus8KChIBAYGSso2b96cbbxZvSkRfvjwoQAg2rVrpyszdOHA0MUfIV6um1fPAV9++aUoVqyY+PfffyXlo0ePFmZmZuLGjRtCiP/tZ/b29iI5OVlSt1mzZqJ69eqSc6JGoxH169cXFSpU0JXldJ2npKQIOzs7ERgYKJ48eSL5LO18Go1GVKhQQYSGhkqW9fjxY1G2bFnx/vvv67U/q1mzZgkAugtBQgiRmZkpgoKChK2treQ8ld36NCS35/Ksx7IQQtSqVUv4+/vr3g8dOlTY29vrXfTIKrfb0MXFRbJ/a8/DNWvWFM+fP9eVd+7cWVhaWkq2a06P81cT4bfdXnk9r+T0/JuZmSlcXV2Fn5+f5CKR9oJQ1uM/N/lQXhLhPA+f1rFjRzx58gTbt29Heno6tm/fnm23iA0bNsDBwQHvv/8+7t27p3v5+/vD1tYW+/fv19W1trbW/T89PR337t1Do0aN8PjxY/zzzz+S5dra2kr6BVlaWiIgIADXrl3LURsCAwOxd+9evVfnzp316g4aNEj3f21XhMzMTPz+++/ZLt/R0REnTpzAnTt3chRPVhs2bECVKlVQuXJlyTpr2rQpAEjWGQA0a9ZM0r0hMDAQANChQwfY2dnplb9uHW3atAkKhcLgjQpZf97LjkqlMrhev/76a726ffr0kSyzUaNGUKvVuH79+hs/R6t3796SG6l+//13ZGZmYtiwYVAqlZJ69vb2ej8Jm5ubo2/fvrr3lpaW6Nu3L5KTk3H69GkAQEhICDw8PLB69WpdvQsXLuDcuXNv7JvWtGlTODs7Y/369bqyhw8fYu/evejUqZOuzNHREbdu3cKpU6dy3PZXVa1aFTVq1MDatWsBvOy336ZNG9jY2OjV3bt3L1JSUtC5c2fJPmZmZobAwMBsj8unT5/i3r17qFevHgDouvpk1a9fP8n7Ro0a4f79+0hLS3tjG3Ky//z222+oV68eAgICdGUuLi7o0qXLG5efHSsrK93+olarcf/+fdja2qJSpUoG2/gm6enpkmPPEO30V9dLnz59JH1R+/fvD3Nzc/z222+Seh4eHmjXrp3uvbYbxdmzZ5GYmAjg5boKCAiQ3Nxsa2uLPn36ID4+XvdTu1ZkZKRke+e3/Djms4qIiMCJEycQGxurK1u9ejU8PT0RHBz8VrFq74ZPT09/q+VktWHDBjRq1AhOTk6S4y4kJARqtRp//vmnpH6HDh3g4uKie//gwQP88ccf6Nixo+4cee/ePdy/fx+hoaG4evUqbt++LVnGm9b53r17kZ6ejtGjR+vd66KdLzo6GlevXsUnn3yC+/fv6z730aNHaNasGf7888/X3nT922+/wd3dXXJ+tbCwwJAhQ5CRkYGDBw/mck3+T27O5Ya+m7KeDx0dHfHo0SNJd5hX5XYbfvTRR3BwcJDECwBdu3aV3GcVGBiIzMxMve2Xk+P8VW+7vbLKzXklp+ffv/76C8nJyejXr5+kz3v37t0l6wrIfT6UW3m6WQ54edIJCQnBmjVr8PjxY6jVanz44YcG6169ehWpqalwdXU1OD05OVn3/4sXL2Ls2LH4448/9E4OqampkvelS5fWS8ycnJxw7ty5HLXB2dkZISEhb6ynVCpRrlw5SVnFihUB4LV9l7755htERkbC09MT/v7+aNmyJSIiIvSWZcjVq1dx+fJlyRdgVlnXGQCUKVNG8l67I2W92zlr+av9DbOKjY2Fh4dHtn1/3sTMzCxH6xXQj9vJyemN8b2qbNmykvfaL/dKlSpJyi0tLVGuXDm9E66Hh4feDXZZt2+9evWgVCrRpUsXzJ8/H48fP4aNjQ1Wr14NlUql6z+ZHXNzc3To0AFr1qzBs2fPYGVlhc2bN+P58+eSRHjUqFH4/fffERAQgPLly6N58+b45JNP0KBBgxyvCwD45JNPMGPGDHz66ac4evQovvjiC4P1rl69CgC6L5NX2dvb6/7/4MEDTJo0CevWrdPb9149LoHXb9esyzUkJ/vP9evXdSeTrF7d5rmh7Rc/b948xMXFSfoNlihRItfLs7Oze2MCpZ3+asJcoUIFyXtbW1uULFlS7/umfPnyet+BWfddd3f3bNdVlSpVALxcl9WqVdOVv3o85bf8OOaz6tSpE4YNG4bVq1dj/PjxSE1Nxfbt2/Hpp5/m6A/318nIyACgv33extWrV3Hu3Lkcf7e/uj1iYmIghMC4ceMwbty4bJdRqlQp3fs3rXPtHxFZ9wNDcQMv/1DKTmpqqm7Zr7p+/ToqVKggSY4A6X6YVzk9l2vvd8nKyclJsu8NGDAAP//8M1q0aIFSpUqhefPm6Nixo2Qottxuw7c9P+fkOH/V226vV+X0vJLT86/231e/6ywsLPRypNzmQ7mV50QYeLlievfujcTERLRo0SLbu2M1Gg1cXV0lV9Oy0jYuJSUFwcHBsLe3x+TJk+Hj4wOVSoUzZ85g1KhRen+9ZDecknjlJjZj6dixIxo1aoRffvkFe/bswfTp0zFt2jRs3rwZLVq0eO28Go0G1atXx8yZMw1Of/UAym5dFPV1lB/xFeTVq6wiIiIwffp0/Prrr+jcuTPWrFmDDz74QO+vV0M+/vhjLFy4EDt37kTbtm3x888/o3LlypK7cKtUqYIrV65g+/bt2LVrFzZt2oR58+Zh/PjxmDRpUo7j7Ny5M8aMGYPevXujRIkSaN68ucF62uNp1apVBr9Is16p6NixI44ePYqRI0fCz88Ptra20Gg0CAsLM3hVoajvdwD0bpD56quvMG7cOPTo0QNffvklihcvDqVSiWHDhuVpeMEqVarg7Nmzuj9+DDl37hwsLCz0TgbGlF/H06vrVyu/9w0nJyd88MEHukR448aNePbsWb6MInDhwgUALxOR/KLRaPD+++/j888/Nzhdm+Bovbo9tPviiBEjEBoaanAZr8abH+tc+7nTp0/Pdgi7oj6ebE6GYHR1dUV0dDR2796NnTt3YufOnVi2bBkiIiJ0N/bldhsa4/yc39srp+eVgpDbfCi33ioRbteuHfr27Yvjx49LfvZ9lY+PD37//Xc0aNDgtV+yBw4cwP3797F582Y0btxYVx4XF/c2Yb41jUaDa9euSXbuf//9FwDeOKZmyZIlMWDAAAwYMADJycmoXbs2/vOf/+gS4eyuWPj4+ODvv/9Gs2bN3vqqRm75+Phg9+7dePDgQZ6vCuen3Lbfy8sLAHDlyhXJX5aZmZmIi4vTu3Jw584dvWHXDG3fatWqoVatWli9ejVKly6NGzduYPbs2TmKqXHjxihZsiTWr1+Phg0b4o8//sD//d//6dUrVqwYOnXqhE6dOiEzMxPt27fHf/7zH4wZMybHw/OVKVMGDRo0wIEDB3Q/qRuiHcnA1dX1tVdTHj58iH379mHSpEkYP368rlx7xcEYvLy8DH7+lStX9MqcnJz07lbOzMxEQkKCpGzjxo147733sGTJEkl5SkqKZGitnPrggw9w7NgxbNiwwWBSFh8fj0OHDiEkJETve/Hq1at47733dO8zMjKQkJCgG5NYS3t1MOsx8uq+6+XlZXC9aLuaaY+X13ndMZjT9fs23vQdEBERgTZt2uDUqVNYvXo1atWqhapVq771565atQoAsk0488LHxwcZGRk5/tXsVdrvNAsLizwvw1BMwMvEP7ukX1vH3t4+T5/r5eWFc+fOQaPRSK4K52Y/LCyWlpYIDw9HeHg4NBoNBgwYgIULF2LcuHEoX778W2/D3MrJcf6qt91er8rpeSWn519tvatXr0p+lXz+/Dni4uIkF4kKOh96q0cs29raYv78+Zg4cSLCw8OzrdexY0eo1Wp8+eWXetNevHih+xLV/nWU9a+hzMxMzJs3723CzBdz5szR/V8IgTlz5sDCwgLNmjUzWF+tVuv9ZOzq6goPDw/JcB/FihUz+NNyx44dcfv2bSxevFhv2pMnT/Do0aO8NuWNOnToACGEwauQxriiV6xYMYPDrmQnJCQElpaW+OGHHyTxLlmyBKmpqWjVqpWk/osXL7Bw4ULd+8zMTCxcuBAuLi7w9/eX1O3WrRv27NmDWbNmoUSJEm+8sq+lVCrx4YcfYtu2bVi1ahVevHgh6RYBQG8oMktLS/j6+kIIgefPn+foc7SmTJmCCRMmvPZhDaGhobC3t8dXX31lcPna4ZUMHZcAjPpExJYtW+L48eM4efKkruzu3bsGf3Xy8fHR67O3aNEivSuWZmZmem3csGGDXn+9nOrbty9cXV0xcuRIvT75T58+RVRUFIQQkj8ussaXdZvMnz8fL1680Nvf7ty5g19++UX3Pi0tDStXroSfn5/uKn/Lli1x8uRJHDt2TFfv0aNHWLRoEby9vXM0Xqv2j0RDx2FO1+/beN3nA0CLFi3g7OyMadOm4eDBg/lyNXjNmjX48ccfERQUlO33fF507NgRx44dw+7du/WmpaSk4MWLF6+d39XVFU2aNMHChQsN/rFhaFi0N2nevDns7OwwdepUveHmtMeEv78/fHx88O233+q6jOTmc1u2bInExETJRbMXL15g9uzZsLW1fev+3Pnl1e9hpVKJGjVqAIDu3P222zC3cnKcv+ptt5chOTmv5PT8W6dOHbi4uGDBggXIzMzU1Vu+fLnecV7Q+dBbXREGXt//RCs4OBh9+/bF1KlTER0djebNm8PCwgJXr17Fhg0b8P333+PDDz9E/fr14eTkhMjISAwZMgQKhQKrVq0qsOTr9u3b+Omnn/TKbW1t0bZtW917lUqFXbt2ITIyEoGBgdi5cyd27NiBL774Its+K+np6ShdujQ+/PBD1KxZE7a2tvj9999x6tQpzJgxQ1fP398f69evx/Dhw1G3bl3Y2toiPDwc3bp1w88//4x+/fph//79aNCgAdRqNf755x/8/PPP2L17N+rUqZPv6wR4OVZot27d8MMPP+Dq1au6n78PHTqE9957T3LjoCEvXrwwuF6Bl78i5PaBF/7+/pg/fz6mTJmC8uXLw9XVNdt+rcDLrjZjxozBpEmTEBYWhtatW+PKlSuYN28e6tatq3eS9PDwwLRp0xAfH4+KFSti/fr1iI6OxqJFi/QGz//kk0/w+eef45dffkH//v1z9TCSTp06Yfbs2ZgwYQKqV6+u6xun1bx5c7i7u6NBgwZwc3PD5cuXMWfOHLRq1SrXfRSDg4PfeGKxt7fH/Pnz0a1bN9SuXRsff/wxXFxccOPGDezYsQMNGjTAnDlzYG9vj8aNG+Obb77B8+fPUapUKezZs6fAfqnJyf7z+eef6x5ZO3ToUBQrVgyLFi3SXXXKqlevXujXrx86dOiA999/H3///Td2796td5X3gw8+wOTJkxEVFYX69evj/PnzWL16dY769BtSokQJbNy4Ea1atULt2rX1niwXExOD77//3uDDNDIzM9GsWTN07NhRt+82bNgQrVu3ltSrWLEievbsiVOnTsHNzQ1Lly5FUlISli1bpqszevRorF27Fi1atMCQIUNQvHhxrFixAnFxcdi0aZNen01D/Pz8YGZmhmnTpiE1NRVWVlZo2rQpXF1dc7x+34aPjw8cHR2xYMEC2NnZoVixYggMDNT1n7WwsMDHH3+MOXPmwMzMzOBNUq+zceNG2Nra6m5U2r17N44cOYKaNWtiw4YN+dYOABg5ciS2bt2KDz74AN27d4e/vz8ePXqE8+fPY+PGjYiPj3/jups7dy4aNmyI6tWro3fv3ihXrhySkpJw7Ngx3Lp1K9djX9vb2+O7775Dr169ULduXXzyySdwcnLC33//jcePH2PFihVQKpX48ccf0aJFC1StWhVRUVEoVaoUbt++jf3798Pe3h7btm3L9jP69OmDhQsXonv37jh9+jS8vb2xceNGHDlyBLNmzXqrftg5PZfnRK9evfDgwQM0bdoUpUuXxvXr1zF79mz4+fnpvrPzYxvmRk6O81e97fYyJCfnlZyefy0sLDBlyhT07dsXTZs2RadOnRAXF4dly5bpfecWeD6UmyEmsg6f9jrZDX2yaNEi4e/vL6ytrYWdnZ2oXr26+Pzzz8WdO3d0dY4cOSLq1asnrK2thYeHh/j88891w09lHQonODjY4FBThoa2yS5GZDPkStb5tUODxMbG6saxc3NzExMmTNAbaglZhhF69uyZGDlypKhZs6aws7MTxYoVEzVr1pSMVyiEEBkZGeKTTz4Rjo6Oep+dmZkppk2bJqpWrSqsrKyEk5OT8Pf3F5MmTZKMqQoDQ/RkHfokK+0QKxs2bHjtOnvx4oWYPn26qFy5srC0tBQuLi6iRYsW4vTp069dr68b/gpZhrXKbl8yNBZiYmKiaNWqlbCzs5MMq/Km/XHOnDmicuXKwsLCQri5uYn+/fuLhw8fSupo96O//vpLBAUFCZVKJby8vMScOXOybWPLli0FAHH06NHXrotXaTQa4enpKQCIKVOm6E1fuHChaNy4sShRooSwsrISPj4+YuTIkZJtbUh22/pVhsZ7FOLlOg8NDRUODg5CpVIJHx8f0b17d/HXX3/p6ty6dUu0a9dOODo6CgcHB/HRRx+JO3fu6A2dld1wVNptlXVYs+xizMn+I4QQ586dE8HBwUKlUolSpUqJL7/8UixZskSvnlqtFqNGjRLOzs7CxsZGhIaGipiYGIPDp3322WeiZMmSwtraWjRo0EAcO3ZMbyivnA6flrV+7969RZkyZYSFhYVwdnYWrVu31hsKKOt6OnjwoOjTp49wcnIStra2okuXLuL+/fuSutrv2d27d4saNWoIKysrUblyZcmxrRUbGys+/PBD4ejoKFQqlQgICBDbt2+X1DH03ZDV4sWLRbly5YSZmZnkGM3p+s3NMf/qOhdCiC1btghfX19hbm5ucP2fPHlSABDNmzc3GL8h2v1V+1KpVKJ06dLigw8+EEuXLjU4BvTbDp8mxMvh68aMGSPKly8vLC0thbOzs6hfv7749ttvdcPmvem4jo2NFREREcLd3V1YWFiIUqVKiQ8++EBs3LhRVyc361wIIbZu3Srq168vrK2thb29vQgICBBr166V1Dl79qxo37697nvKy8tLdOzYUezbt89gnFklJSWJqKgo4ezsLCwtLUX16tUNHkf5NXyaoXP5q7T7gNbGjRtF8+bNhaurq7C0tBRlypQRffv2FQkJCZL53mYbZnesGdpeOT3Os9umed1eb3teycn5Vwgh5s2bJ8qWLSusrKxEnTp1xJ9//mnw+M9pPpSX4dMUQhShu1eKoO7du2Pjxo0Gf1og+WvSpAnu3bunuykmJ9q1a4fz588jJiamACOjvFi+fDmioqIQFxf3xv77RZE2/lOnTr3xCoe3tzeqVauG7du3F1J0Rdvff/8NPz8/rFy5Et26dTN2OEQkE2/VR5jI1CQkJGDHjh080RIVMYsXL4atrS3at29v7FCISEbeuo8wkSmIi4vDkSNH8OOPP8LCwkLyAA4iMp5t27bh0qVLWLRoEQYNGpTrexCIyLQxESbKgYMHDyIqKgplypTBihUrsr1Tl4gK1+DBg5GUlISWLVvmarxtIiIAYB9hIiIiIjJJ7CNMRERERCaJiTARERERmST2ES7iNBoN7ty5Azs7u0J/1DIRERHljRAC6enp8PDwyNGDa8hIcjXqsAmYM2eO8PLyElZWViIgIECcOHEi27rawa+zvqysrCR1NBqNGDdunHB3dxcqlUo0a9ZM/PvvvzmO5+bNm699wABffPHFF1988VV0Xzdv3sxzTkIFj1eEs9A+6njBggUIDAzErFmzEBoaiitXrsDV1dXgPPb29rhy5Yru/atXbb/55hv88MMPWLFiBcqWLYtx48YhNDQUly5dgkqlemNM2sdO3rx5E/b29m/ROiIiIiosaWlp8PT0fKvHR1PB46gRWQQGBqJu3bqYM2cOgJfdEjw9PTF48GCMHj1ar/7y5csxbNgwpKSkGFyeEAIeHh747LPPMGLECABAamoq3NzcsHz5cnz88cdvjCktLQ0ODg5ITU1lIkxERCQTPH/LAzut/FdmZiZOnz6NkJAQXZlSqURISAiOHTuW7XwZGRnw8vKCp6cn2rRpg4sXL+qmxcXFITExUbJMBwcHBAYGZrvMZ8+eIS0tTfIiIiIiovzHRPi/7t27B7VaDTc3N0m5m5sbEhMTDc5TqVIlLF26FFu2bMFPP/0EjUaD+vXr49atWwCgmy83y5w6dSocHBx0L09Pz7dtGhEREREZwET4LQQFBSEiIgJ+fn4IDg7G5s2b4eLigoULF+Z5mWPGjEFqaqrudfPmzXyMmIiIiIi0mAj/l7OzM8zMzJCUlCQpT0pKyvHjdC0sLFCrVi3ExMQAgG6+3CzTysoK9vb2khcRERER5T8mwv9laWkJf39/7Nu3T1em0Wiwb98+BAUF5WgZarUa58+fR8mSJQEAZcuWhbu7u2SZaWlpOHHiRI6XSUREREQFg8OnZTF8+HBERkaiTp06CAgIwKxZs/Do0SNERUUBACIiIlCqVClMnToVADB58mTUq1cP5cuXR0pKCqZPn47r16+jV69eAF4OpTZs2DBMmTIFFSpU0A2f5uHhgbZt2xqrmUREREQEJsISnTp1wt27dzF+/HgkJibCz88Pu3bt0t3sduPGDcnTYR4+fIjevXsjMTERTk5O8Pf3x9GjR+Hr66ur8/nnn+PRo0fo06cPUlJS0LBhQ+zatStHYwgTERERUcHhOMJFHMchJCIikh+ev+WBfYSJiIiIyCSxawQR0VtSawROxj1AcvpTuNqpEFC2OMyUijfPSERERsVEmIjoLey6kIBJ2y4hIfWprqykgwoTwn0RVq2kESMjIqI3YdcIIqI82nUhAf1/OiNJggEgMfUp+v90BrsuJBgpMiIiygkmwkREeaDWCEzadgmG7jbWlk3adglqDe9HJiIqqpgIExHlwcm4B3pXgrMSABJSn+Jk3IPCC4qIiHKFiTARUR4kp2efBOelHhERFT4mwkREeeBql7OH4uS0HhERFT4mwkREeRBQtjhKOqiQ3SBpCrwcPSKgbPHCDIuIiHKBiTARUR6YKRWYEP7yceqvJsPa9xPCfTmeMBFREcZEmIgoj8KqlcT8rrXh7iDt/uDuoML8rrU5jjARURHHB2oQEb2FsGol8b6vO58sR0QkQ0yEiYjekplSgSCfEsYOg4iIcoldI4iIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMkmyT4RjY2MxduxYdO7cGcnJyQCAnTt34uLFi7le1ty5c+Ht7Q2VSoXAwECcPHkyR/OtW7cOCoUCbdu2lZQnJSWhe/fu8PDwgI2NDcLCwnD16tVcx0VERERE+U/WifDBgwdRvXp1nDhxAps3b0ZGRgYA4O+//8aECRNytaz169dj+PDhmDBhAs6cOYOaNWsiNDRUl1xnJz4+HiNGjECjRo0k5UIItG3bFteuXcOWLVtw9uxZeHl5ISQkBI8ePcpdQ4mIiIgo38k6ER49ejSmTJmCvXv3wtLSUlfetGlTHD9+PFfLmjlzJnr37o2oqCj4+vpiwYIFsLGxwdKlS7OdR61Wo0uXLpg0aRLKlSsnmXb16lUcP34c8+fPR926dVGpUiXMnz8fT548wdq1a3PXUCIiIiLKd7JOhM+fP4927drplbu6uuLevXs5Xk5mZiZOnz6NkJAQXZlSqURISAiOHTuW7XyTJ0+Gq6srevbsqTft2bNnAACVSiVZppWVFQ4fPpztMp89e4a0tDTJi4iIiIjyn6wTYUdHRyQkJOiVnz17FqVKlcrxcu7duwe1Wg03NzdJuZubGxITEw3Oc/jwYSxZsgSLFy82OL1y5cooU6YMxowZg4cPHyIzMxPTpk3DrVu3DMasNXXqVDg4OOhenp6eOW4HEREREeWcrBPhjz/+GKNGjUJiYiIUCgU0Gg2OHDmCESNGICIiosA+Nz09Hd26dcPixYvh7OxssI6FhQU2b96Mf//9F8WLF4eNjQ3279+PFi1aQKnMfrWPGTMGqamputfNmzcLqhlEREREJs3c2AG8ja+++goDBw6Ep6cn1Go1fH19oVar8cknn2Ds2LE5Xo6zszPMzMyQlJQkKU9KSoK7u7te/djYWMTHxyM8PFxXptFoAADm5ua4cuUKfHx84O/vj+joaKSmpiIzMxMuLi4IDAxEnTp1so3FysoKVlZWOY6diIiIiPJGIYQQxg7ibd28eRPnz59HRkYGatWqhQoVKuR6GYGBgQgICMDs2bMBvExsy5Qpg0GDBmH06NGSuk+fPkVMTIykbOzYsUhPT8f333+PihUrSm7e07p69SoqV66MnTt3onnz5jmKKy0tDQ4ODkhNTYW9vX2u20VERESFj+dveZD1FWEtT0/Pt+5LO3z4cERGRqJOnToICAjArFmz8OjRI0RFRQEAIiIiUKpUKUydOhUqlQrVqlWTzO/o6AgAkvINGzbAxcUFZcqUwfnz5zF06FC0bds2x0kwERERERUcWSfCHTp0QEBAAEaNGiUp/+abb3Dq1Cls2LAhx8vq1KkT7t69i/HjxyMxMRF+fn7YtWuX7ga6GzduvLZvryEJCQkYPnw4kpKSULJkSURERGDcuHG5WgYRERERFQxZd41wcXHBH3/8gerVq0vKz58/j5CQEL0+v3LEn1aIiIjkh+dveZD1qBEZGRkG++JaWFhw/F0iIiIiei1ZJ8LVq1fH+vXr9crXrVsHX19fI0RERERERHIh6z7C48aNQ/v27REbG4umTZsCAPbt24e1a9fmqn8wEREREZkeWSfC4eHh+PXXX/HVV19h48aNsLa2Ro0aNfD7778jODjY2OERERERUREm65vlTAE72xMREckPz9/yIOsrwlqZmZlITk7WPd1Nq0yZMkaKiIiIiIiKOlknwlevXkWPHj1w9OhRSbkQAgqFAmq12kiREREREVFRJ+tEuHv37jA3N8f27dtRsmRJKBQKY4dERERERDIh60Q4Ojoap0+fRuXKlY0dChERERHJjKzHEfb19cW9e/eMHQYRERERyZCsE+Fp06bh888/x4EDB3D//n2kpaVJXkRERERE2ZH18GlK5cs8/tW+we/SzXIcfoWIiEh+eP6WB1n3Ed6/f7+xQyAiIiIimZJ1IsynxxERERFRXsm6jzAAHDp0CF27dkX9+vVx+/ZtAMCqVatw+PBhI0dGREREREWZrBPhTZs2ITQ0FNbW1jhz5gyePXsGAEhNTcVXX31l5OiIiIiIqCiTdSI8ZcoULFiwAIsXL4aFhYWuvEGDBjhz5owRIyMiIiKiok7WifCVK1fQuHFjvXIHBwekpKQUfkBEREREJBuyToTd3d0RExOjV3748GGUK1fOCBERERERkVzIOhHu3bs3hg4dihMnTkChUODOnTtYvXo1RowYgf79+xs7PCIiIiIqwmQ9fNro0aOh0WjQrFkzPH78GI0bN4aVlRVGjBiBwYMHGzs8IiIiIirCZPtkObVajSNHjqBGjRqwsbFBTEwMMjIy4OvrC1tbW2OHl2/4ZBoiIiL54flbHmR7RdjMzAzNmzfH5cuX4ejoCF9fX2OHREREREQyIus+wtWqVcO1a9eMHQYRERERyZCsE+EpU6ZgxIgR2L59OxISEpCWliZ5ERERERFlR7Z9hAFAqfxfHq9QKHT/F0JAoVBArVYbI6x8xT5GRERE8sPztzzIto8wAOzfv9/YIRARERGRTMk6EQ4ODjZ2CEREREQkU7LuIwwAhw4dQteuXVG/fn3cvn0bALBq1SocPnzYyJERERERUVEm60R406ZNCA0NhbW1Nc6cOYNnz54BAFJTU/HVV18ZOToiIiIiKspknQhPmTIFCxYswOLFi2FhYaErb9CgAc6cOWPEyIiIiIioqJN1InzlyhU0btxYr9zBwQEpKSmFHxARERERyYasE2F3d3fExMTolR8+fBjlypUzQkREREREJBeyToR79+6NoUOH4sSJE1AoFLhz5w5Wr16NESNGoH///sYOj4iIiIiKMFkPnzZ69GhoNBo0a9YMjx8/RuPGjWFlZYURI0Zg8ODBxg6PiIiIiIow2T1Z7ty5c6hWrZrkqXKZmZmIiYlBRkYGfH19YWtra8QI8xefTENERCQ/PH/Lg+y6RtSqVQv37t0DAJQrVw7379+HpaUlfH19ERAQ8E4lwURERERUcGSXCDs6OiIuLg4AEB8fD41GY+SIiIiIiEiOZNdHuEOHDggODkbJkiWhUChQp04dmJmZGax77dq1Qo6OiIiIiORCdonwokWL0L59e8TExGDIkCHo3bs37OzsjB0WEREREcmM7BLhc+fOoXnz5ggLC8Pp06cxdOhQJsJERERElGuy6yOc9Wa5gwcPIjMz08gREREREZEcyS4R5s1yRERERJQfZNc1gjfLEREREVF+kF0izJvliIiIiCg/yC4RBoCwsDAA4M1yRERERJRnskyEtZYtW2bsEIiIiIhIpmSXCLdv3x7Lly+Hvb092rdv/9q6mzdvLqSoiIiIiEhuZJcIOzg4QKFQ6P5PRERERJQXCiGEMHYQlL20tDQ4ODggNTUV9vb2xg6HiIiIcoDnb3mQ3RXhV927dw/x8fFQKBTw9vZGiRIljB0SEREREcmA7B6ooXXx4kU0btwYbm5uCAwMREBAAFxdXdG0aVP8888/xg6PiIiIiIo4WV4RTkxMRHBwMFxcXDBz5kxUrlwZQghcunQJixcvRuPGjXHhwgW4uroaO1QiIiIiKqJk2Ud41KhR+P3333HkyBGoVCrJtCdPnqBhw4Zo3rw5pk6daqQI8w/7GBEREckPz9/yIMuuEXv37sWoUaP0kmAAsLa2xsiRI7F79+5cL3fu3Lnw9vaGSqVCYGAgTp48maP51q1bB4VCgbZt20rKMzIyMGjQIJQuXRrW1tbw9fXFggULch0XEREREeU/WSbC165dQ+3atbOdXqdOHVy7di1Xy1y/fj2GDx+OCRMm4MyZM6hZsyZCQ0ORnJz82vni4+MxYsQINGrUSG/a8OHDsWvXLvz000+4fPkyhg0bhkGDBmHr1q25io2IiIiI8p8sE+H09PTX/sxgZ2eHjIyMXC1z5syZ6N27N6KionRXbm1sbLB06dJs51Gr1ejSpQsmTZqEcuXK6U0/evQoIiMj0aRJE3h7e6NPnz6oWbNmjq80ExEREVHBkWUiDLxMhtPS0rJ95abrc2ZmJk6fPo2QkBBdmVKpREhICI4dO5btfJMnT4arqyt69uxpcHr9+vWxdetW3L59G0II7N+/H//++y+aN2+e7TKfPXum1xYiIiIiyn+yHDVCCIGKFSu+drr26XM5ce/ePajVari5uUnK3dzcsh2K7fDhw1iyZAmio6OzXe7s2bPRp08flC5dGubm5lAqlbpRLbIzdepUTJo0KcexExEREVHeyDIR3r9/v1E/Pz09Hd26dcPixYvh7Oycbb3Zs2fj+PHj2Lp1K7y8vPDnn39i4MCB8PDwkFx9zmrMmDEYPny47n1aWho8PT3zvQ1EREREpk6WiXBwcHC+Ls/Z2RlmZmZISkqSlCclJcHd3V2vfmxsLOLj4xEeHq4r02g0AABzc3NcuXIFHh4e+OKLL/DLL7+gVatWAIAaNWogOjoa3377bbaJsJWVFaysrPKraURERESUDdn2Ec5PlpaW8Pf3x759+3RlGo0G+/btQ1BQkF79ypUr4/z584iOjta9Wrdujffeew/R0dHw9PTE8+fP8fz5cyiV0lVsZmamS5qJiIiIyHhkeUW4IAwfPhyRkZGoU6cOAgICMGvWLDx69AhRUVEAgIiICJQqVQpTp06FSqVCtWrVJPM7OjoCgK7c0tISwcHBGDlyJKytreHl5YWDBw9i5cqVmDlzZqG2jYiIiIj0MRH+r06dOuHu3bsYP348EhMT4efnh127duluoLtx44be1d03WbduHcaMGYMuXbrgwYMH8PLywn/+8x/069evIJpARERERLkgy0csmxI+opGIiEh+eP6WB1n3EV62bBkeP35s7DCIiIiISIZknQiPHj0a7u7u6NmzJ44ePWrscIiIiIhIRmSdCN++fRsrVqzAvXv30KRJE1SuXBnTpk1DYmKisUMjIiIioiJO1omwubk52rVrhy1btuDmzZvo3bs3Vq9ejTJlyqB169bYsmULhyojIiIiIoNknQhn5ebmhoYNGyIoKAhKpRLnz59HZGQkfHx8cODAAWOHR0RERERFjOwT4aSkJHz77beoWrUqmjRpgrS0NGzfvh1xcXG4ffs2OnbsiMjISGOHSURERERFjKyHTwsPD8fu3btRsWJF9OrVCxEREShevLikTnJyMtzd3WXbRYLDrxAREckPz9/yIOsHari6uuLgwYMGH4Os5eLigri4uEKMioiIiIjkQNZdI4KDg1G7dm298szMTKxcuRIAoFAo4OXlVdihEREREVERJ+uuEWZmZkhISICrq6uk/P79+3B1dYVarTZSZPmHP60QERHJD8/f8iDrK8JCCCgUCr3yW7duwcHBwQgREREREZFcyLKPcK1ataBQKKBQKNCsWTOYm/+vGWq1GnFxcQgLCzNihERERERU1MkyEW7bti0AIDo6GqGhobC1tdVNs7S0hLe3Nzp06GCk6IiIiIhIDmSZCE+YMAEA4O3tjU6dOkGlUhk5IiIiIiKSG1kmwlp8UAYRERER5ZXsEuHixYvj33//hbOzM5ycnAzeLKf14MGDQoyMiIiIiOREdonwd999Bzs7OwDArFmzjBsMEREREcmWrMcRNgUch5CIiEh+eP6WB9ldEX6VRqNBTEwMkpOTodFoJNMaN25spKiIiIiIqKiTdSJ8/PhxfPLJJ7h+/TpevbCtUCjeiSfLEREREVHBkHUi3K9fP9SpUwc7duxAyZIlX3vjHBERERFRVrJOhK9evYqNGzeifPnyxg6FiIiIiGRGaewA3kZgYCBiYmKMHQYRERERyZCsrwgPHjwYn332GRITE1G9enVYWFhIpteoUcNIkRERERFRUSfr4dOUSv0L2gqFAkKId+ZmOQ6/QkREJD88f8uDrK8Ix8XFGTsEIiIiIpIpWSfCXl5exg6BiIiIiGRK1onwypUrXzs9IiKikCIhIiIiIrmRdR9hJycnyfvnz5/j8ePHsLS0hI2NDR48eGCkyPIP+xgRERHJD8/f8iDr4dMePnwoeWVkZODKlSto2LAh1q5da+zwiIiIiKgIk3UibEiFChXw9ddfY+jQocYOhYiIiIiKsHcuEQYAc3Nz3Llzx9hhEBEREVERJuub5bZu3Sp5L4RAQkIC5syZgwYNGhgpKiIiIiKSA1knwm3btpW8VygUcHFxQdOmTTFjxgzjBEVEREREsiDrRFij0Rg7BCIiIiKSKVn3EZ48eTIeP36sV/7kyRNMnjzZCBERERERkVzIehxhMzMzJCQkwNXVVVJ+//59uLq6Qq1WGymy/MNxCImIiOSH5295kPUVYSEEFAqFXvnff/+N4sWLGyEiIiIiIpILWfYRdnJygkKhgEKhQMWKFSXJsFqtRkZGBvr162fECImIiIioqJNlIjxr1iwIIdCjRw9MmjQJDg4OummWlpbw9vZGUFCQESMkIiIioqJOlolwZGQkXrx4AYVCgaZNm8LT09PYIRERERGRzMi2j7C5uTn69+/PIdSIiIiIKE9kmwgDQEBAAM6ePWvsMIiIiIhIhmTZNUJrwIAB+Oyzz3Dr1i34+/ujWLFikuk1atQwUmREREREVNTJehxhpVL/grZCodANq8ZxhImIiMgYeP6WB1lfEY6LizN2CEREREQkU7JOhL28vIwdAhERERHJlKwTYQCIjY3FrFmzcPnyZQCAr68vhg4dCh8fHyNHRkRERERFmaxHjdi9ezd8fX1x8uRJ1KhRAzVq1MCJEydQtWpV7N2719jhEREREVERJuub5WrVqoXQ0FB8/fXXkvLRo0djz549OHPmjJEiyz/sbE9ERCQ/PH/Lg6yvCF++fBk9e/bUK+/RowcuXbpkhIiIiIiISC5knQi7uLggOjparzw6Ohqurq6FHxARERERyYasb5br3bs3+vTpg2vXrqF+/foAgCNHjmDatGkYPny4kaMjIiIioqJM1leEx40bh/Hjx2P27NkIDg5GcHAw5syZg4kTJ2Ls2LF5WubcuXPh7e0NlUqFwMBAnDx5MkfzrVu3DgqFAm3btpWUKxQKg6/p06fnKT4iIiIiyh+yvlkuq/T0dACAnZ1dnpexfv16REREYMGCBQgMDMSsWbOwYcMGXLly5bVdLeLj49GwYUOUK1cOxYsXx6+//qqblpiYKKm7c+dO9OzZEzExMShXrtwbY2JneyIiIvnh+Vse3olEODk5GVeuXAEAVK5cGS4uLnlaTmBgIOrWrYs5c+YAADQaDTw9PTF48GCMHj3a4DxqtRqNGzdGjx49cOjQIaSkpEgS4Ve1bdsW6enp2LdvX45i4oFEREQkPzx/y4Osu0akp6ejW7du8PDw0HWN8PDwQNeuXZGampqrZWVmZuL06dMICQnRlSmVSoSEhODYsWPZzjd58mS4uroaHL3iVUlJSdixY8dr6z579gxpaWmSFxERERHlP1knwr169cKJEyewY8cOpKSkICUlBdu3b8dff/2Fvn375mpZ9+7dg1qthpubm6Tczc1Nr3uD1uHDh7FkyRIsXrw4R5+xYsUK2NnZoX379tnWmTp1KhwcHHQvT0/PnDeCiIiIiHJM1onw9u3bsXTpUoSGhsLe3h729vYIDQ3F4sWLsW3btgL9bO3V6MWLF8PZ2TlH8yxduhRdunSBSqXKts6YMWOQmpqqe928eTO/QiYiIiKiLGQ9fFqJEiXg4OCgV+7g4AAnJ6dcLcvZ2RlmZmZISkqSlCclJcHd3V2vfmxsLOLj4xEeHq4r02g0AABzc3NcuXIFPj4+ummHDh3ClStXsH79+tfGYWVlBSsrq1zFTkRERES5J+srwmPHjsXw4cMlXRcSExMxcuRIjBs3LlfLsrS0hL+/v+QmNo1Gg3379iEoKEivfuXKlXH+/HlER0frXq1bt8Z7772H6OhovS4NS5Ysgb+/P2rWrJnLVhIRERFRQZD1FeH58+cjJiYGZcqUQZkyZQAAN27cgJWVFe7evYuFCxfq6p45c+aNyxs+fDgiIyNRp04dBAQEYNasWXj06BGioqIAABEREShVqhSmTp0KlUqFatWqSeZ3dHQEAL3ytLQ0bNiwATNmzHib5hIRERFRPpJ1IvzqwyveVqdOnXD37l2MHz8eiYmJ8PPzw65du3Q30N24cQNKZe4voq9btw5CCHTu3Dlf4yUiIiKivHsnxhF+l3EcQiIiIvnh+VseZH1FWOuvv/7C5cuXAQC+vr7w9/c3ckREREREVNTJOhG+desWOnfujCNHjuj656akpKB+/fpYt24dSpcubdwAiYiIiKjIkvWoEb169cLz589x+fJlPHjwAA8ePMDly5eh0WjQq1cvY4dHREREREWYrPsIW1tb4+jRo6hVq5ak/PTp02jUqBEeP35spMjyD/sYERERyQ/P3/Ig6yvCnp6eeP78uV65Wq2Gh4eHESIiIiIiIrmQdSI8ffp0DB48GH/99Zeu7K+//sLQoUPx7bffGjEyIiIiIirqZN01wsnJCY8fP8aLFy9gbv7yvj/t/4sVKyap++DBA2OE+Nb40woREZH88PwtD7IeNWLWrFnGDoGIiIiIZErWiXBkZKSxQyAiIiIimZJ1Inz79m1s2rQJ//77LwCgUqVKaN++PUqVKmXkyIiIiIioqJNtIjxv3jwMHz4cmZmZur43aWlpGDlyJGbOnIkBAwYYOUIiIiIiKspkOWrEjh07MGTIEAwaNAi3b99GSkoKUlJScPv2bQwYMABDhw7Fb7/9ZuwwiYiIiKgIk+WoEU2aNEHDhg0xZcoUg9PHjh2Lw4cP48CBA4UbWAHgXadERETyw/O3PMjyivCZM2fQrVu3bKd369YNZ86cKcSIiIiIiEhuZJkIq9VqWFhYZDvdwsICarW6ECMiIiIiIrmRZSJctWpVbNmyJdvpv/76K6pWrVqIERERERGR3Mhy1IiBAweif//+sLKyQp8+fSRPlVu4cCHGjh2LefPmGTlKIiIiIirKZJkIR0ZG4vz58xg0aBDGjBkDHx8fCCFw7do1ZGRkYMiQIejevbuxwyQiIiKiIkyWo0ZoHT9+HGvXrsXVq1cBABUrVsTHH3+MevXqGTmy/MO7TomIiOSH5295kOUVYa169eq9U0kvERERERUeWd4sR0RERET0tpgIExEREZFJYiJMRERERCaJiTARERERmSQmwkRERERkkmQ3akStWrWgUChyVPfMmTMFHA0RERERyZXsEuG2bdsaOwQiIiIiegfI+oEapoADchMREckPz9/ywD7CRERERGSSZNc1Iiu1Wo3vvvsOP//8M27cuIHMzEzJ9AcPHhgpMiIiIiIq6mR9RXjSpEmYOXMmOnXqhNTUVAwfPhzt27eHUqnExIkTjR0eERERERVhsk6EV69ejcWLF+Ozzz6Dubk5OnfujB9//BHjx4/H8ePHjR0eERERERVhsk6EExMTUb16dQCAra0tUlNTAQAffPABduzYYczQiIiIiKiIk3UiXLp0aSQkJAAAfHx8sGfPHgDAqVOnYGVlZczQiIiIiKiIk3Ui3K5dO+zbtw8AMHjwYIwbNw4VKlRAREQEevToYeToiIiIiKgoe6fGET527BiOHTuGChUqIDw83Njh5AuOQ0hERCQ/PH/Lg6yHT3tVUFAQgoKCjB0GEREREcmArBPhlStXvnZ6REREIUVCRERERHIj664RTk5OkvfPnz/H48ePYWlpCRsbm3figRr8aYWIiEh+eP6WB1nfLPfw4UPJKyMjA1euXEHDhg2xdu1aY4dHREREREWYrBNhQypUqICvv/4aQ4cONXYoRERERFSEvXOJMACYm5vjzp07xg6DiIiIiIowWd8st3XrVsl7IQQSEhIwZ84cNGjQwEhREREREZEcyDoRbtu2reS9QqGAi4sLmjZtihkzZhgnKCIiIiKSBVknwhqNxtghEBEREZFMvZN9hImIiIiI3kTWV4SHDx+e47ozZ84swEiIiIiISG5knQifPXsWZ8+exfPnz1GpUiUAwL///gszMzPUrl1bV0+hUBgrRCIiIiIqomSdCIeHh8POzg4rVqzQPWXu4cOHiIqKQqNGjfDZZ58ZOUIiIiIiKqpk/YjlUqVKYc+ePahataqk/MKFC2jevPk7MZYwH9FIREQkPzx/y4Osb5ZLS0vD3bt39crv3r2L9PR0I0RERERERHIh60S4Xbt2iIqKwubNm3Hr1i3cunULmzZtQs+ePdG+fXtjh0dERERERZis+wgvWLAAI0aMwCeffILnz58DePl45Z49e2L69OlGjo6IiIiIijJZXxG2sbHBvHnzcP/+fd0IEg8ePMC8efNQrFixXC9v7ty58Pb2hkqlQmBgIE6ePJmj+datWweFQqH3pDsAuHz5Mlq3bg0HBwcUK1YMdevWxY0bN3IdGxERERHlL1knwlrFihVDjRo1UKNGDV0CnJycnKtlrF+/HsOHD8eECRNw5swZ1KxZE6GhoW9cTnx8PEaMGIFGjRrpTYuNjUXDhg1RuXJlHDhwAOfOncO4ceOgUqlyFRsRERER5T9ZjhphY2OD69evw8XFBQDQqlUr/PjjjyhZsiQAICkpCR4eHlCr1TleZmBgIOrWrYs5c+YAePn4Zk9PTwwePBijR482OI9arUbjxo3Ro0cPHDp0CCkpKfj111910z/++GNYWFhg1apVeWwp7zolIiKSI56/5UGWV4SfPn2KrPn7n3/+iSdPnkjq5Ca/z8zMxOnTpxESEqIrUyqVCAkJwbFjx7Kdb/LkyXB1dUXPnj31pmk0GuzYsQMVK1ZEaGgoXF1dERgYKEmUiYiIiMh4ZJkI50RuniZ37949qNVquLm5Scrd3NyQmJhocJ7Dhw9jyZIlWLx4scHpycnJyMjIwNdff42wsDDs2bMH7dq1Q/v27XHw4MFsY3n27BnS0tIkr3eFWiNwLPY+tkTfxrHY+1BrZPdjRJ6YaruJiIiKOlmPGmEs6enp6NatGxYvXgxnZ2eDdTQaDQCgTZs2+PTTTwEAfn5+OHr0KBYsWIDg4GCD802dOhWTJk0qmMCNaNeFBEzadgkJqU91ZSUdVJgQ7ouwaiWNGFnBMtV2ExERyYEsrwgrFArJFd9X3+eWs7MzzMzMkJSUJClPSkqCu7u7Xv3Y2FjEx8cjPDwc5ubmMDc3x8qVK7F161aYm5sjNjYWzs7OMDc3h6+vr2TeKlWqvHbUiDFjxiA1NVX3unnzZp7bVVTsupCA/j+dkSSDAJCY+hT9fzqDXRcSjBRZwTLVdhMREcmFLK8ICyFQsWJFXfKbkZGBWrVqQalU6qbnhqWlJfz9/bFv3z7dEGgajQb79u3DoEGD9OpXrlwZ58+fl5SNHTsW6enp+P777+Hp6QlLS0vUrVsXV65ckdT7999/4eXllW0sVlZWsLKyylX8RZlaIzBp2yUY2iICgALApG2X8L6vO8yUef9jpqgx1XYTERHJiSwT4WXLluX7MocPH47IyEjUqVMHAQEBmDVrFh49eoSoqCgAQEREBEqVKoWpU6dCpVKhWrVqkvkdHR0BQFI+cuRIdOrUCY0bN8Z7772HXbt2Ydu2bThw4EC+x19UnYx7oHdFNCsBICH1KU7GPUCQT4nCC6yAmWq7iYiI5ESWiXBkZGS+L7NTp064e/cuxo8fj8TERPj5+WHXrl26G+hu3Lihu+KcU+3atcOCBQswdepUDBkyBJUqVcKmTZvQsGHDfI+/qEpOzz4ZzEs9uTDVdhMREcmJLMcRNiVyH4fwWOx9dF58/I311vau905dGTXVdhMR0UtyP3+bClneLEfyEVC2OEo6qJBdL1gFXo6iEFC2eGGGVeBMtd1ERERywkSYCpSZUoEJ4S9Hzng1KdS+nxDu+87dMGaq7SYiIpITJsJU4MKqlcT8rrXh7qCSlLs7qDC/a+13djxdU203ERGRXLCPcBH3LvUxUmsETsY9QHL6U7javewWYApXRE213UREpuxdOn+/y2Q5aoSWWq3G8uXLsW/fPiQnJ+ue5qb1xx9/GCkyMsRMqTDJG8NMtd1ERERFnawT4aFDh2L58uVo1aoVqlWr9lZPlyMiIiIi0yLrRHjdunX4+eef0bJlS2OHQkREREQyI+ub5SwtLVG+fHljh0FEREREMiTrRPizzz7D999/D97vR0RERES5JeuuEYcPH8b+/fuxc+dOVK1aFRYWFpLpmzdvNlJkRERERFTUyToRdnR0RLt27YwdBhERERHJkKwT4WXLlhk7BCIiIiKSKVn3ESYiIiIiyitZXxEGgI0bN+Lnn3/GjRs3kJmZKZl25swZI0VFREREREWdrK8I//DDD4iKioKbmxvOnj2LgIAAlChRAteuXUOLFi2MHR4RERERFWGyToTnzZuHRYsWYfbs2bC0tMTnn3+OvXv3YsiQIUhNTTV2eERERqfWCByLvY8t0bdxLPY+1BoON0lEpCXrrhE3btxA/fr1AQDW1tZIT08HAHTr1g316tXDnDlzjBkeEZFR7bqQgEnbLiEh9amurKSDChPCfRFWraQRIyMiKhpkfUXY3d0dDx48AACUKVMGx48fBwDExcXxIRtEZNJ2XUhA/5/OSJJgAEhMfYr+P53BrgsJRoqMiKjokHUi3LRpU2zduhUAEBUVhU8//RTvv/8+OnXqxPGFichkqTUCk7ZdgqHLAdqySdsusZsEEZk8WXeNWLRoETQaDQBg4MCBKFGiBI4ePYrWrVujb9++Ro6OiMg4TsY90LsSnJUAkJD6FCfjHiDIp0ThBUZEVMTIOhFWKpVQKv93Ufvjjz/Gxx9/bMSIiIiMLzk9+yQ4L/WIiN5Vsu4aAQCHDh1C165dERQUhNu3bwMAVq1ahcOHDxs5MiIi43C1U+VrPSKid5WsE+FNmzYhNDQU1tbWOHv2LJ49ewYASE1NxVdffWXk6IjeTRyOq+gLKFscJR1UUGQzXYGXo0cElC1emGERERU5sk6Ep0yZggULFmDx4sWwsLDQlTdo0IBPlSMqALsuJKDhtD/QefFxDF0Xjc6Lj6PhtD84AkERY6ZUYEK4LwDoJcPa9xPCfWGmzC5VJiIyDbJOhK9cuYLGjRvrlTs4OCAlJaXwAyJ6h3E4LnkJq1YS87vWhruDtPuDu4MK87vW5jjCRESQ+c1y7u7uiImJgbe3t6T88OHDKFeunHGCInoHvWk4LgVeDsf1vq87rzIWIWHVSuJ9X3ecjHuA5PSncLV72R2C24iI6CVZJ8K9e/fG0KFDsXTpUigUCty5cwfHjh3DiBEjMG7cOGOHR/TO4HBc8mWmVHCbEBFlQ9aJ8OjRo6HRaNCsWTM8fvwYjRs3hpWVFUaMGIHBgwcbOzyidwaH4yIioneRrBNhhUKB//u//8PIkSMRExODjIwM+Pr6wtbW1tihEb1TOBwXERG9i2SdCGtZWlrC19fX2GEQvbO0w3Elpj412E9YgZc3YXE4LiIikhNZJsI9evTIUb2lS5cWcCREpkE7HFf/n85AAUiSYQ7HRUREciXLRHj58uXw8vJCrVq1IAQH8ycqDNrhuCZtuyS5cc7dQYUJ4b4cjouIiGRHlolw//79sXbtWsTFxSEqKgpdu3ZF8eL8SZaooHE4LiIiepcohEwvqT579gybN2/G0qVLcfToUbRq1Qo9e/ZE8+bNoVC8OyfltLQ0ODg4IDU1Ffb29sYOh4iIiHKA5295kG0inNX169exfPlyrFy5Ei9evMDFixffmZEjeCARERHJD8/f8iDrRyxrKZVKKBQKCCGgVquNHQ4RERERyYBsE+Fnz55h7dq1eP/991GxYkWcP38ec+bMwY0bN96Zq8FEREREVHBkebPcgAEDsG7dOnh6eqJHjx5Yu3YtnJ2djR0WEREREcmILPsIK5VKlClTBrVq1XrtjXGbN28uxKgKBvsYERERyQ/P3/IgyyvCERER79TIEERERERU+GSZCC9fvtzYIRARERGRzMn2ZjkiIiIiorfBRJiIiIiITBITYSIiIiIySUyEiYiIiMgkMREmIiIiIpPERJiIiIiITBITYSIiIiIySUyEiYiIiMgkMREmIiIiIpPERJiIiIiITJIsH7FMRERE9LbUGoGTcQ+QnP4UrnYqBJQtDjOlwthhUSFiIkxEREQmZ9eFBEzadgkJqU91ZSUdVJgQ7ouwaiWNGBkVJnaNICIiIpOy60IC+v90RpIEA0Bi6lP0/+kMdl1IMFJkVNiYCL9i7ty58Pb2hkqlQmBgIE6ePJmj+datWweFQoG2bdtKyrt37w6FQiF5hYWFFUDkRERE9CZqjcCkbZcgDEzTlk3adglqjaEa9K5hIpzF+vXrMXz4cEyYMAFnzpxBzZo1ERoaiuTk5NfOFx8fjxEjRqBRo0YGp4eFhSEhIUH3Wrt2bUGET0RERG9wMu6B3pXgrASAhNSnOBn3oPCCIqNhIpzFzJkz0bt3b0RFRcHX1xcLFiyAjY0Nli5dmu08arUaXbp0waRJk1CuXDmDdaysrODu7q57OTk5FVQTiIiI6DWS07NPgvNSj+SNifB/ZWZm4vTp0wgJCdGVKZVKhISE4NixY9nON3nyZLi6uqJnz57Z1jlw4ABcXV1RqVIl9O/fH/fv38+27rNnz5CWliZ5UfbUGoFjsfexJfo2jsXe509ZRET0Wq52qnytR/LGUSP+6969e1Cr1XBzc5OUu7m54Z9//jE4z+HDh7FkyRJER0dnu9ywsDC0b98eZcuWRWxsLL744gu0aNECx44dg5mZmV79qVOnYtKkSW/VFlPBO36JiCi3AsoWR0kHFRJTnxrsJ6wA4O7wcig1evfxinAepaeno1u3bli8eDGcnZ2zrffxxx+jdevWqF69Otq2bYvt27fj1KlTOHDggMH6Y8aMQWpqqu518+bNAmqBvPGOXyIiygszpQITwn0BvEx6s9K+nxDuy/GETQQT4f9ydnaGmZkZkpKSJOVJSUlwd3fXqx8bG4v4+HiEh4fD3Nwc5ubmWLlyJbZu3Qpzc3PExsYa/Jxy5crB2dkZMTExBqdbWVnB3t5e8iIp3vFLRERvI6xaSczvWhvuDtLuD+4OKszvWpu/KpoQdo34L0tLS/j7+2Pfvn26IdA0Gg327duHQYMG6dWvXLkyzp8/LykbO3Ys0tPT8f3338PT09Pg59y6dQv3799HyZLyOsiK0tN3cnPHb5BPicILjIiIZCOsWkm87+teZM5tZBxMhLMYPnw4IiMjUadOHQQEBGDWrFl49OgRoqKiAAAREREoVaoUpk6dCpVKhWrVqknmd3R0BABdeUZGBiZNmoQOHTrA3d0dsbGx+Pzzz1G+fHmEhoYWatveRlHri8s7fomIKD+YKRW8YGLimAhn0alTJ9y9exfjx49HYmIi/Pz8sGvXLt0NdDdu3IBSmfPeJGZmZjh37hxWrFiBlJQUeHh4oHnz5vjyyy9hZWVVUM3IV9q+uK92MtD2xTXGT0i845eIiIjyg0IIwY6URVhaWhocHByQmppa6P2F1RqBhtP+yLYbgvbO2sOjmhboT0mvdsvw93JC8PT9b7zjt6DjIiIiyo4xz9+Uc7wiTNkqCn1xs+uW0bpmSSz6Mw4KQJIM845fIiIiyimOGkHZMnZf3NcNkbbozzj0aVyWd/wSERFRnvGKMGXLmH1x3zREmgLA1r8TcHDkezh9/SHv+CUiIqJcYyJM2TLm03dy2i3j9PWHvOOXiIiI8oRdIyhbxnz6jrG7ZRAREdG7j4kwvZaxnr7DIdKIiIiooLFrBL2RMZ6+Y8xuGURERGQamAhTjhT203e03TL6/3SGQ6QRERFRgWDXCCqyjNUtg4iIiEwDrwhTkWaMbhlERERkGpgIU5FX2N0yiIiIyDSwawQRERERmSQmwkRERERkkpgIExEREZFJYiJMRERERCaJN8uZKLVGcCQGIiIiMmlMhE3QrgsJmLTtEhJSn+rKSjqoMCHcl2PzEhERkclg1wgTs+tCAvr/dEaSBANAYupT9P/pDHZdSDBSZERERESFi4mwCVFrBCZtuyR5XLGWtmzStktQawzVICIiInq3MBE2ISfjHuhdCc5KAEhIfYqTcQ8KLygiIiIiI2EibEKS07NPgvNSj4iIiEjOmAibEFc7Vb7WIyIiIpIzJsImJKBscZR0UCG7QdIUeDl6REDZ4oUZFhEREZFRMBE2IWZKBSaE+wKAXjKsfT8h3JfjCRMREZFJYCJsYsKqlcT8rrXh7iDt/uDuoML8rrU5jjARERGZDD5QwwSFVSuJ933d+WQ5IiIiMmlMhE2UmVKBIJ8Sxg6DiIiIyGjYNYKIiIiITBITYSIiIiIySUyEiYiIiMgkMREmIiIiIpPERJiIiIiITBITYSIiIiIySUyEiYiIiMgkMREmIiIiIpPERJiIiIiITBKfLFfECSEAAGlpaUaOhIiIiHJKe97WnsepaGIiXMSlp6cDADw9PY0cCREREeVWeno6HBwcjB0GZUMh+KdKkabRaHDnzh3Y2dlBoVDkeTlpaWnw9PTEzZs3YW9vn48RFn1su2m2HTDt9rPtptl2wLTbX5TaLoRAeno6PDw8oFSyJ2pRxSvCRZxSqUTp0qXzbXn29vZG/3IwFrbdNNsOmHb72XbTbDtg2u0vKm3nleCij3+iEBEREZFJYiJMRERERCaJibCJsLKywoQJE2BlZWXsUAod226abQdMu/1su2m2HTDt9pty2ylveLMcEREREZkkXhEmIiIiIpPERJiIiIiITBITYSIiIiIySUyEiYiIiMgkMREugubOnQtvb2+oVCoEBgbi5MmTOZpv3bp1UCgUaNu2raR88+bNaN68OUqUKAGFQoHo6Gi9eZ8+fYqBAweiRIkSsLW1RYcOHZCUlCSpc+PGDbRq1Qo2NjZwdXXFyJEj8eLFi7w2M1uF3f4HDx5g8ODBqFSpEqytrVGmTBkMGTIEqampknoKhULvtW7durdpqh5jbPsmTZrotatfv36SOoWx7Qu77fHx8Qa3qUKhwIYNG3T1CmO7A/nb/ufPn2PUqFGoXr06ihUrBg8PD0RERODOnTuSeR88eIAuXbrA3t4ejo6O6NmzJzIyMiR1zp07h0aNGkGlUsHT0xPffPPNW7f1VYXd9vj4ePTs2RNly5aFtbU1fHx8MGHCBGRmZkrqGNr2x48fz7d2A8bZ7t7e3nrt+vrrryV1CmO7A4Xf/gMHDmR73J86dQpA4W17KiIEFSnr1q0TlpaWYunSpeLixYuid+/ewtHRUSQlJb12vri4OFGqVCnRqFEj0aZNG8m0lStXikmTJonFixcLAOLs2bN68/fr1094enqKffv2ib/++kvUq1dP1K9fXzf9xYsXolq1aiIkJEScPXtW/Pbbb8LZ2VmMGTMmP5qtY4z2nz9/XrRv315s3bpVxMTEiH379okKFSqIDh06SOoBEMuWLRMJCQm615MnT/Kj2UII42374OBg0bt3b0m7UlNTddMLY9sbo+0vXryQtDkhIUFMmjRJ2NraivT0dF29gt7uQuR/+1NSUkRISIhYv369+Oeff8SxY8dEQECA8Pf3l8wfFhYmatasKY4fPy4OHTokypcvLzp37qybnpqaKtzc3ESXLl3EhQsXxNq1a4W1tbVYuHChrNu+c+dO0b17d7F7924RGxsrtmzZIlxdXcVnn30mWT4A8fvvv0u2fWZmpqzbLoQQXl5eYvLkyZJ2ZWRk6KYXxnY3VvufPXumd9z36tVLlC1bVmg0Gt3yC3rbU9HBRLiICQgIEAMHDtS9V6vVwsPDQ0ydOjXbeV68eCHq168vfvzxRxEZGamXEGhpD+5XE4KUlBRhYWEhNmzYoCu7fPmyACCOHTsmhBDit99+E0qlUiQmJurqzJ8/X9jb24tnz57loaWGGaP9hvz888/C0tJSPH/+XFcGQPzyyy85bUquGavtwcHBYujQodl+RmFs+6Ky3f38/ESPHj0kZQW93YUo2PZrnTx5UgAQ169fF0IIcenSJQFAnDp1Sldn586dQqFQiNu3bwshhJg3b55wcnKSbOdRo0aJSpUq5aWZBhmj7YZ88803omzZsrr3udlv8spYbffy8hLfffddtvMUxnYXomhs+8zMTOHi4iImT56sKyuMbU9FB7tGFCGZmZk4ffo0QkJCdGVKpRIhISE4duxYtvNNnjwZrq6u6NmzZ54+9/Tp03j+/LnkcytXrowyZcroPvfYsWOoXr063NzcdHVCQ0ORlpaGixcv5ulzX2Ws9huSmpoKe3t7mJubS8oHDhwIZ2dnBAQEYOnSpRD5NAy3sdu+evVqODs7o1q1ahgzZgweP36sm1bQ297Ybdc6ffo0oqOjDS6voLY7UHjtT01NhUKhgKOjI4CX29XR0RF16tTR1QkJCYFSqcSJEyd0dRo3bgxLS0tdndDQUFy5cgUPHz7MTTMNMlbbs6tTvHhxvfLWrVvD1dUVDRs2xNatW3P0eTlh7LZ//fXXKFGiBGrVqoXp06dLujoV9HYHjN9+ra1bt+L+/fuIiorSm1ZQ256KFvM3V6HCcu/ePajVaknCAQBubm74559/DM5z+PBhLFmyxGDfz5xKTEyEpaWl3heFm5sbEhMTdXUMxaWdlh+M1X5DcXz55Zfo06ePpHzy5Mlo2rQpbGxssGfPHgwYMAAZGRkYMmRIvnymsdr+ySefwMvLCx4eHjh37hxGjRqFK1euYPPmzQAKftsXle2+ZMkSVKlSBfXr15eUF+R2Bwqn/U+fPsWoUaPQuXNn2NvbA3i57VxdXSX1zM3NUbx4cclxX7ZsWb24tNOcnJxy9PnZMVbbXxUTE4PZs2fj22+/1ZXZ2tpixowZaNCgAZRKJTZt2oS2bdvi119/RevWrXPWwNcwZtuHDBmC2rVro3jx4jh69CjGjBmDhIQEzJw5E0DBb3eg6Gz7JUuWIDQ0FKVLl9aVFfS2p6KFibCMpaeno1u3bli8eDGcnZ2NHU6hK4j2p6WloVWrVvD19cXEiRMl08aNG6f7f61atfDo0SNMnz493xKi3MjPtmdN+KtXr46SJUuiWbNmiI2NhY+Pz9uGmu8KYrs/efIEa9askWxjraK03YHct//58+fo2LEjhBCYP39+IURYcAqi7bdv30ZYWBg++ugj9O7dW1fu7OyM4cOH697XrVsXd+7cwfTp042SDOVn27O2q0aNGrC0tETfvn0xderUIvto4oLY9rdu3cLu3bvx888/S8qL2rangsVEuAhxdnaGmZmZ3mgNSUlJcHd316sfGxuL+Ph4hIeH68o0Gg2Al1d2rly5kqNExt3dHZmZmUhJSZFcFc76ue7u7np382rjNBRbXhir/Vrp6ekICwuDnZ0dfvnlF1hYWLy2fmBgIL788ks8e/bsrU8exm57VoGBgQBeXiXz8fEp8G1fFNq+ceNGPH78GBEREW+sm5/bHSjY9muTgevXr+OPP/6QXBVzd3dHcnKyZNkvXrzAgwcPJMe9obi0096WsdqudefOHbz33nuoX78+Fi1a9MZ4AwMDsXfv3ly1MTvGbntWgYGBePHiBeLj41GpUqUC3+5A0Wj/smXLUKJEiRwlt/m57aloYR/hIsTS0hL+/v7Yt2+frkyj0WDfvn0ICgrSq1+5cmWcP38e0dHRulfr1q3x3nvvITo6Gp6enjn6XH9/f1hYWEg+98qVK7hx44buc4OCgnD+/HnJiXPv3r2wt7eHr69vXpssYaz2Ay+vBDdv3hyWlpbYunUrVCrVG+eJjo6Gk5NTviRDxmz7q7Q/O5YsWRJAwW/7otD2JUuWoHXr1nBxcXlj3fzc7kDBtV+bDFy9ehW///47SpQoIVlOUFAQUlJScPr0aV3ZH3/8AY1Go/tjKCgoCH/++SeeP3+uq7N3715UqlQpX34eN1bbgZdXgps0aQJ/f38sW7YMSuWbT4fR0dG64+JtGbPthtqlVCp1XWUKersDxm+/EALLli1DRETEGy96APm77amIMeKNemTAunXrhJWVlVi+fLm4dOmS6NOnj3B0dNTdsd+tWzcxevTobOc3dBft/fv3xdmzZ8WOHTsEALFu3Tpx9uxZkZCQoKvTr18/UaZMGfHHH3+Iv/76SwQFBYmgoCDddO0QWs2bNxfR0dFi165dwsXFpUCGTyvs9qemporAwEBRvXp1ERMTIxku58WLF0IIIbZu3SoWL14szp8/L65evSrmzZsnbGxsxPjx42Xd9piYGDF58mTx119/ibi4OLFlyxZRrlw50bhxY90yCmPbG2u/F0KIq1evCoVCIXbu3Km33MLY7kLkf/szMzNF69atRenSpUV0dLRkn846EkBYWJioVauWOHHihDh8+LCoUKGCZPi0lJQU4ebmJrp16yYuXLgg1q1bJ2xsbPJ9+LTCbvutW7dE+fLlRbNmzcStW7ckdbSWL18u1qxZIy5fviwuX74s/vOf/wilUimWLl0q67YfPXpUfPfddyI6OlrExsaKn376Sbi4uIiIiAjdcgpjuxur/Vq///67ACAuX76st9zC2PZUdDARLoJmz54typQpIywtLUVAQIA4fvy4blpwcLCIjIzMdl5DCcGyZcsEAL3XhAkTdHWePHkiBgwYIJycnISNjY1o166dXsIQHx8vWrRoIaytrYWzs7P47LPPJMOL5ZfCbv/+/fsNTgcg4uLihBAvh5Xy8/MTtra2olixYqJmzZpiwYIFQq1Wy7rtN27cEI0bNxbFixcXVlZWonz58mLkyJGScYSFKJxtb4z9XgghxowZIzw9PQ1uy8La7kLkb/u1wz8Zeu3fv19X7/79+6Jz587C1tZW2Nvbi6ioKMkYykII8ffff4uGDRsKKysrUapUKfH111/nV5N1Crvt2e0bWa8NLV++XFSpUkXY2NgIe3t7ERAQIBliMr8UdttPnz4tAgMDhYODg1CpVKJKlSriq6++Ek+fPpUsuzC2uxDG2e+FEKJz586SsfKzKqxtT0WDQoh8HAeIiIiIiEgm2EeYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiIiIiKTxESYiIiIiEwSE2EiIiIiMklMhImIiIjIJDERJiJ6A29vb8yaNcvYYehZvnw5HB0djR0GEZFsMREmolzr3r07FAoF+vXrpzdt4MCBUCgU6N69e+EH9orly5dDoVDovVQqVa6Wc+rUKfTp0ydHdQszae7UqRP+/fffPM+fX+tHoVDg119/zXMcRETGYm7sAIhInjw9PbFu3Tp89913sLa2BgA8ffoUa9asQZkyZYwc3f/Y29vjypUrkjKFQpGrZbi4uORnSPnG2tpat+7zKj/WT05kZmbC0tIy35dLRPQ2eEWYiPKkdu3a8PT0xObNm3VlmzdvRpkyZVCrVi1JXY1Gg6lTp6Js2bKwtrZGzZo1sXHjRt10tVqNnj176qZXqlQJ33//vWQZ3bt3R9u2bfHtt9+iZMmSKFGiBAYOHIjnz5+/Nk6FQgF3d3fJy83NTTe9SZMmGDRoEAYNGgQHBwc4Oztj3LhxyPr0+axXeYUQmDhxIsqUKQMrKyt4eHhgyJAhumVdv34dn376qe7qqtbhw4fRqFEjWFtbw9PTE0OGDMGjR48knzFlyhRERETA1tYWXl5e2Lp1K+7evYs2bdrA1tYWNWrUwF9//aWbx1DXiG3btqFu3bpQqVRwdnZGu3bt3nr9DBkyBJ9//jmKFy8Od3d3TJw4URI3ALRr1w4KhUL3fuLEifDz88OPP/6IsmXL6q4y37hxQ9cee3t7dOzYEUlJSbrlaedbuHAhPD09YWNjg44dOyI1NRUA8Oeff8LCwgKJiYmSdgwbNgyNGjV6bVuJiF7FRJiI8qxHjx5YtmyZ7v3SpUsRFRWlV2/q1KlYuXIlFixYgIsXL+LTTz9F165dcfDgQQAvE+XSpUtjw4YNuHTpEsaPH48vvvgCP//8s2Q5+/fvR2xsLPbv348VK1Zg+fLlWL58+Vu3Y8WKFTA3N8fJkyfx/fffY+bMmfjxxx8N1t20aRO+++47LFy4EFevXsWvv/6K6tWrA3j5h0Dp0qUxefJkJCQkICEhAQAQGxuLsLAwdOjQAefOncP69etx+PBhDBo0SLLs7777Dg0aNMDZs2fRqlUrdOvWDREREejatSvOnDkDHx8fRERESJL0rHbs2IF27dqhZcuWOHv2LPbt24eAgIB8WT/FihXDiRMn8M0332Dy5MnYu3cvgJfdRgBg2bJlSEhI0L0HgJiYGGzatAmbN29GdHQ0NBoN2rRpgwcPHuDgwYPYu3cvrl27hk6dOkk+LyYmBj///DO2bduGXbt24ezZsxgwYAAAoHHjxihXrhxWrVqlq//8+XOsXr0aPXr0eOu2EpGJEUREuRQZGSnatGkjkpOThZWVlYiPjxfx8fFCpVKJu3fvijZt2ojIyEghhBBPnz4VNjY24ujRo5Jl9OzZU3Tu3Dnbzxg4cKDo0KGD5DO9vLzEixcvdGUfffSR6NSpU7bLWLZsmQAgihUrJnmFhYXp6gQHB4sqVaoIjUajKxs1apSoUqWK7r2Xl5f47rvvhBBCzJgxQ1SsWFFkZmYa/MysdbO2tU+fPpKyQ4cOCaVSKZ48eaKbr2vXrrrpCQkJAoAYN26cruzYsWMCgEhISNC1z8HBQTc9KChIdOnSJdv18aqcrp+GDRtK5qtbt64YNWqU7j0A8csvv0jqTJgwQVhYWIjk5GRd2Z49e4SZmZm4ceOGruzixYsCgDh58qRuPjMzM3Hr1i1dnZ07dwqlUqlr97Rp0yTbZ9OmTcLW1lZkZGTkuO1EREIIwT7CRJRnLi4uaNWqFZYvXw4hBFq1agVnZ2dJnZiYGDx+/Bjvv/++pDwzM1PShWLu3LlYunQpbty4gSdPniAzMxN+fn6SeapWrQozMzPd+5IlS+L8+fOvjdHOzg5nzpyRlL3ar7ZevXqSbgxBQUGYMWMG1Gq15PMA4KOPPsKsWbNQrlw5hIWFoWXLlggPD4e5efZfp3///TfOnTuH1atX68qEENBoNIiLi0OVKlUAADVq1NBN13ZP0F5tzlqWnJwMd3d3vc+Jjo5G7969s43DkJysn6xxAS/Xe3Jy8huX7eXlJelfffnyZXh6esLT01NX5uvrC0dHR1y+fBl169YFAJQpUwalSpXS1QkKCoJGo8GVK1fg7u6O7t27Y+zYsTh+/Djq1auH5cuXo2PHjihWrFjOG05EBN4sR0RvqUePHrqf+OfOnas3PSMjA8DLn+2zJjcAYGVlBQBYt24dRowYgRkzZiAoKAh2dnaYPn06Tpw4IalvYWEhea9QKKDRaF4bn1KpRPny5XPXqNfw9PTElStX8Pvvv2Pv3r0YMGAApk+fjoMHD+rFp5WRkYG+ffvq+hJnlfXGwqzzaxNzQ2XZtTkvN87lZP3kZb0DKLDE1NXVFeHh4Vi2bBnKli2LnTt34sCBAwXyWUT0bmMiTERvJSwsDJmZmVAoFAgNDdWb7uvrCysrK9y4cQPBwcEGl3HkyBHUr19f1w8UeNmvtrC8mnAfP34cFSpU0LsarGVtbY3w8HCEh4dj4MCBqFy5Ms6fP4/atWvD0tISarVaUr927dq4dOlSvibkhtSoUQP79u0z2E+7IFlYWOi12ZAqVarg5s2buHnzpu6q8KVLl5CSkgJfX19dvRs3buDOnTvw8PAA8HJ7KJVKVKpUSVenV69e6Ny5M0qXLg0fHx80aNAgn1tFRKaAiTARvRUzMzNcvnxZ9/9X2dnZYcSIEfj000+h0WjQsGFDpKam4siRI7C3t0dkZCQqVKiAlStXYvfu3ShbtixWrVqFU6dOoWzZsm8dnxBCb4QB4OVVRaXy5f3CN27cwPDhw9G3b1+cOXMGs2fPxowZMwwub/ny5VCr1QgMDISNjQ1++uknWFtbw8vLC8DLURT+/PNPfPzxx7CysoKzszNGjRqFevXqYdCgQejVqxeKFSuGS5cuYe/evZgzZ85bt1FrwoQJaNasGXx8fPDxxx/jxYsX+O233zBq1Khs58nJ+nkTb29v7Nu3Dw0aNICVlRWcnJwM1gsJCUH16tXRpUsXzJo1Cy9evMCAAQMQHByMOnXq6OqpVCpERkbi22+/RVpaGoYMGYKOHTtKuoOEhobC3t4eU6ZMweTJk3MUJxHRqzhqBBG9NXt7e9jb22c7/csvv8S4ceMwdepUVKlSBWFhYdixY4cu0e3bty/at2+PTp06ITAwEPfv35dcHX4baWlpKFmypN4rax/XiIgIPHnyBAEBARg4cCCGDh2a7QM0HB0dsXjxYjRo0AA1atTA77//jm3btqFEiRIAgMmTJyM+Ph4+Pj66/rE1atTAwYMH8e+//6JRo0aoVasWxo8fr7vimV+aNGmCDRs2YOvWrfDz80PTpk1x8uTJ186Tk/XzJjNmzMDevXvh6empN3ReVgqFAlu2bIGTkxMaN26MkJAQlCtXDuvXr5fUK1++PNq3b4+WLVuiefPmqFGjBubNmyepo1Qq0b17d6jVakREROQ4ViKirBRCZDMODxGRCWjSpAn8/PyK5COUTdHEiRPx66+/Ijo6+o11e/bsibt372Lr1q0FHxgRvZPYNYKIiGQlNTUV58+fx5o1a5gEE9FbYSJMRESy0qZNG5w8eRL9+vXTG5aPiCg32DWCiIiIiEwSb5YjIiIiIpPERJiIiIiITBITYSIiIiIySUyEiYiIiMgkMREmIiIiIpPERJiIiIiITBITYSIiIiIySUyEiYiIiMgkMREmIiIiIpP0/w6MmYrA8DPeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot epistemic entropy as x-axis and equal opportunity difference as y-axis for ensemble model\n",
    "plt.scatter(np.mean(epi_entropy_ensemble, axis=1), Equal_opp_diffs_ensemble)\n",
    "plt.xlabel('Mean Epistemic Entropy')\n",
    "plt.ylabel('Mean Equal Opportunity Difference')\n",
    "plt.title('Mean Epistemic Entropy vs Mean Equal Opportunity Difference of Ensemble Model')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ale_entropy_ensemble to dict\n",
    "ale_entropy_ensemble_dict = {}\n",
    "for i in range(0, 10):\n",
    "    ale_entropy_ensemble_dict[dataset_frac[i]] = ale_entropy_ensemble[i]\n",
    "    \n",
    "#epi_entropy_ensemble to dict\n",
    "epi_entropy_ensemble_dict = {}\n",
    "for i in range(0, 10):\n",
    "    epi_entropy_ensemble_dict[dataset_frac[i]] = epi_entropy_ensemble[i]\n",
    "\n",
    "#save to pickle file\n",
    "import pickle\n",
    "\n",
    "with open('adult_results/ale_entropy_ensemble_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(ale_entropy_ensemble_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('adult_results/epi_entropy_ensemble_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(epi_entropy_ensemble_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('adult_results/Equal_opp_diffs_ensemble.pickle', 'wb') as handle:\n",
    "    pickle.dump(Equal_opp_diffs_ensemble, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROP OUT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZOHAIR~1\\AppData\\Local\\Temp\\__autograph_generated_filecl8ut8_0.py:54: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  ag__.if_stmt(ag__.ld(self).variance_type is 'linear_variance', if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "C:\\Users\\ZOHAIR~1\\AppData\\Local\\Temp\\__autograph_generated_filecl8ut8_0.py:55: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  ag__.if_stmt(ag__.ld(self).variance_type is 'logit', if_body_1, else_body_1, get_state_1, set_state_1, ('do_return', 'retval_'), 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 19s - loss: 0.6836 - accuracy: 0.5510 - val_loss: 0.6503 - val_accuracy: 0.6253 - 19s/epoch - 1s/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6232 - accuracy: 0.6925 - val_loss: 0.5892 - val_accuracy: 0.7417 - 459ms/epoch - 35ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 1s - loss: 0.5886 - accuracy: 0.7418 - val_loss: 0.5738 - val_accuracy: 0.7481 - 563ms/epoch - 43ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5714 - accuracy: 0.7558 - val_loss: 0.5482 - val_accuracy: 0.7506 - 280ms/epoch - 22ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5520 - accuracy: 0.7613 - val_loss: 0.5545 - val_accuracy: 0.7558 - 187ms/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5417 - accuracy: 0.7616 - val_loss: 0.5367 - val_accuracy: 0.7519 - 207ms/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5292 - accuracy: 0.7638 - val_loss: 0.5163 - val_accuracy: 0.7519 - 196ms/epoch - 15ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5213 - accuracy: 0.7626 - val_loss: 0.5331 - val_accuracy: 0.7558 - 201ms/epoch - 15ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.5115 - accuracy: 0.7638 - val_loss: 0.5253 - val_accuracy: 0.7570 - 195ms/epoch - 15ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.5078 - accuracy: 0.7632 - val_loss: 0.5225 - val_accuracy: 0.7545 - 194ms/epoch - 15ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 15s - loss: 0.5048 - accuracy: 0.7638 - val_loss: 0.5115 - val_accuracy: 0.7570 - 15s/epoch - 1s/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.4845 - accuracy: 0.7654 - val_loss: 0.4915 - val_accuracy: 0.7583 - 187ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.4896 - accuracy: 0.7648 - val_loss: 0.4995 - val_accuracy: 0.7609 - 185ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4795 - accuracy: 0.7645 - val_loss: 0.4948 - val_accuracy: 0.7609 - 191ms/epoch - 15ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4769 - accuracy: 0.7651 - val_loss: 0.5017 - val_accuracy: 0.7545 - 185ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4789 - accuracy: 0.7667 - val_loss: 0.4814 - val_accuracy: 0.7545 - 182ms/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4763 - accuracy: 0.7638 - val_loss: 0.4965 - val_accuracy: 0.7570 - 179ms/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4694 - accuracy: 0.7642 - val_loss: 0.4767 - val_accuracy: 0.7596 - 175ms/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4615 - accuracy: 0.7670 - val_loss: 0.4842 - val_accuracy: 0.7519 - 202ms/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4667 - accuracy: 0.7731 - val_loss: 0.4723 - val_accuracy: 0.7621 - 207ms/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4676 - accuracy: 0.7686 - val_loss: 0.4691 - val_accuracy: 0.7685 - 199ms/epoch - 15ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4639 - accuracy: 0.7709 - val_loss: 0.4744 - val_accuracy: 0.7621 - 216ms/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4640 - accuracy: 0.7798 - val_loss: 0.4889 - val_accuracy: 0.7685 - 188ms/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4578 - accuracy: 0.7792 - val_loss: 0.4814 - val_accuracy: 0.7762 - 174ms/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.4605 - accuracy: 0.7712 - val_loss: 0.4838 - val_accuracy: 0.7583 - 162ms/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4652 - accuracy: 0.7741 - val_loss: 0.4846 - val_accuracy: 0.7737 - 190ms/epoch - 15ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4565 - accuracy: 0.7827 - val_loss: 0.4754 - val_accuracy: 0.7826 - 176ms/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4576 - accuracy: 0.7850 - val_loss: 0.4771 - val_accuracy: 0.7762 - 169ms/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4584 - accuracy: 0.7853 - val_loss: 0.4856 - val_accuracy: 0.7673 - 168ms/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4789 - val_accuracy: 0.7749 - 181ms/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4567 - accuracy: 0.7821 - val_loss: 0.4875 - val_accuracy: 0.7724 - 199ms/epoch - 15ms/step\n",
      "Epoch 31: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ale entropy:  0.455959305852733\n",
      "epi entropy:  0.471214965836654\n",
      "\n",
      "dataset size:  0.2\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6383 - accuracy: 0.6513 - val_loss: 0.5777 - val_accuracy: 0.7249 - 2s/epoch - 73ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.5682 - accuracy: 0.7472 - val_loss: 0.5445 - val_accuracy: 0.7588 - 379ms/epoch - 15ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5420 - accuracy: 0.7580 - val_loss: 0.5195 - val_accuracy: 0.7607 - 308ms/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5203 - accuracy: 0.7618 - val_loss: 0.5151 - val_accuracy: 0.7658 - 307ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.5124 - accuracy: 0.7578 - val_loss: 0.5018 - val_accuracy: 0.7626 - 280ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.4980 - accuracy: 0.7663 - val_loss: 0.4963 - val_accuracy: 0.7639 - 255ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4875 - accuracy: 0.7672 - val_loss: 0.4877 - val_accuracy: 0.7793 - 303ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4831 - accuracy: 0.7714 - val_loss: 0.4809 - val_accuracy: 0.7748 - 328ms/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4796 - accuracy: 0.7711 - val_loss: 0.4771 - val_accuracy: 0.7658 - 283ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4770 - accuracy: 0.7807 - val_loss: 0.4679 - val_accuracy: 0.7844 - 314ms/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4732 - accuracy: 0.7778 - val_loss: 0.4686 - val_accuracy: 0.7825 - 318ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.4670 - accuracy: 0.7850 - val_loss: 0.4682 - val_accuracy: 0.7844 - 357ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4663 - accuracy: 0.7732 - val_loss: 0.4811 - val_accuracy: 0.7799 - 324ms/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4597 - accuracy: 0.7876 - val_loss: 0.4725 - val_accuracy: 0.7837 - 322ms/epoch - 13ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4581 - accuracy: 0.7797 - val_loss: 0.4756 - val_accuracy: 0.7671 - 303ms/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4585 - accuracy: 0.7869 - val_loss: 0.4679 - val_accuracy: 0.7914 - 316ms/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4606 - accuracy: 0.7848 - val_loss: 0.4662 - val_accuracy: 0.7754 - 340ms/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4554 - accuracy: 0.7855 - val_loss: 0.4653 - val_accuracy: 0.7812 - 308ms/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4571 - accuracy: 0.7847 - val_loss: 0.4667 - val_accuracy: 0.7869 - 302ms/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4527 - accuracy: 0.7887 - val_loss: 0.4620 - val_accuracy: 0.7882 - 270ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4513 - accuracy: 0.7866 - val_loss: 0.4587 - val_accuracy: 0.7882 - 284ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4517 - accuracy: 0.7866 - val_loss: 0.4564 - val_accuracy: 0.7850 - 274ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4464 - accuracy: 0.7903 - val_loss: 0.4496 - val_accuracy: 0.7825 - 285ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4481 - accuracy: 0.7874 - val_loss: 0.4611 - val_accuracy: 0.7889 - 292ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4506 - accuracy: 0.7941 - val_loss: 0.4475 - val_accuracy: 0.7933 - 276ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4511 - accuracy: 0.7872 - val_loss: 0.4519 - val_accuracy: 0.7901 - 291ms/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4449 - accuracy: 0.7893 - val_loss: 0.4627 - val_accuracy: 0.7767 - 283ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4485 - accuracy: 0.7893 - val_loss: 0.4642 - val_accuracy: 0.7837 - 273ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4463 - accuracy: 0.7943 - val_loss: 0.4594 - val_accuracy: 0.7786 - 271ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4444 - accuracy: 0.7874 - val_loss: 0.4521 - val_accuracy: 0.7876 - 278ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4414 - accuracy: 0.7999 - val_loss: 0.4500 - val_accuracy: 0.7863 - 268ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4426 - accuracy: 0.7965 - val_loss: 0.4463 - val_accuracy: 0.7946 - 280ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4452 - accuracy: 0.7919 - val_loss: 0.4502 - val_accuracy: 0.7882 - 269ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4446 - accuracy: 0.7912 - val_loss: 0.4559 - val_accuracy: 0.7863 - 281ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4399 - accuracy: 0.7938 - val_loss: 0.4493 - val_accuracy: 0.7933 - 281ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4443 - accuracy: 0.7938 - val_loss: 0.4469 - val_accuracy: 0.7908 - 265ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4438 - accuracy: 0.7927 - val_loss: 0.4483 - val_accuracy: 0.7889 - 288ms/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4401 - accuracy: 0.7964 - val_loss: 0.4510 - val_accuracy: 0.7850 - 285ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4384 - accuracy: 0.7940 - val_loss: 0.4432 - val_accuracy: 0.7965 - 284ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4391 - accuracy: 0.7965 - val_loss: 0.4433 - val_accuracy: 0.7940 - 287ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4418 - accuracy: 0.7935 - val_loss: 0.4530 - val_accuracy: 0.7876 - 279ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4399 - accuracy: 0.7964 - val_loss: 0.4440 - val_accuracy: 0.7895 - 271ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4431 - accuracy: 0.7901 - val_loss: 0.4491 - val_accuracy: 0.7997 - 276ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4420 - accuracy: 0.7967 - val_loss: 0.4473 - val_accuracy: 0.7895 - 264ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4403 - accuracy: 0.7946 - val_loss: 0.4500 - val_accuracy: 0.7889 - 290ms/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4385 - accuracy: 0.7972 - val_loss: 0.4447 - val_accuracy: 0.7869 - 415ms/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4409 - accuracy: 0.7948 - val_loss: 0.4492 - val_accuracy: 0.7882 - 411ms/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4412 - accuracy: 0.7970 - val_loss: 0.4401 - val_accuracy: 0.7997 - 326ms/epoch - 13ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4417 - accuracy: 0.7996 - val_loss: 0.4448 - val_accuracy: 0.7946 - 337ms/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4408 - accuracy: 0.7948 - val_loss: 0.4385 - val_accuracy: 0.7991 - 276ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 0s - loss: 0.4382 - accuracy: 0.7936 - val_loss: 0.4399 - val_accuracy: 0.7972 - 265ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 0s - loss: 0.4403 - accuracy: 0.7944 - val_loss: 0.4424 - val_accuracy: 0.7895 - 271ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 0s - loss: 0.4333 - accuracy: 0.7976 - val_loss: 0.4467 - val_accuracy: 0.7927 - 275ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 0s - loss: 0.4366 - accuracy: 0.7988 - val_loss: 0.4516 - val_accuracy: 0.7921 - 278ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 0s - loss: 0.4378 - accuracy: 0.7965 - val_loss: 0.4496 - val_accuracy: 0.7940 - 266ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 0s - loss: 0.4363 - accuracy: 0.7936 - val_loss: 0.4419 - val_accuracy: 0.7876 - 264ms/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 0s - loss: 0.4369 - accuracy: 0.7968 - val_loss: 0.4473 - val_accuracy: 0.7869 - 269ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 0s - loss: 0.4375 - accuracy: 0.7984 - val_loss: 0.4422 - val_accuracy: 0.7978 - 274ms/epoch - 11ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 0s - loss: 0.4399 - accuracy: 0.7919 - val_loss: 0.4464 - val_accuracy: 0.7953 - 269ms/epoch - 11ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 0s - loss: 0.4353 - accuracy: 0.7943 - val_loss: 0.4416 - val_accuracy: 0.7965 - 271ms/epoch - 11ms/step\n",
      "Epoch 60: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ale entropy:  0.4005118098994138\n",
      "epi entropy:  0.3788619388901892\n",
      "\n",
      "dataset size:  0.3\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 0.6204 - accuracy: 0.7102 - val_loss: 0.5960 - val_accuracy: 0.7369 - 2s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5540 - accuracy: 0.7625 - val_loss: 0.5633 - val_accuracy: 0.7493 - 360ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.5275 - accuracy: 0.7661 - val_loss: 0.5321 - val_accuracy: 0.7561 - 358ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.5052 - accuracy: 0.7698 - val_loss: 0.5086 - val_accuracy: 0.7595 - 368ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.4895 - accuracy: 0.7718 - val_loss: 0.5104 - val_accuracy: 0.7612 - 425ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4789 - accuracy: 0.7784 - val_loss: 0.4970 - val_accuracy: 0.7612 - 388ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4700 - accuracy: 0.7768 - val_loss: 0.4978 - val_accuracy: 0.7620 - 370ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4610 - accuracy: 0.7844 - val_loss: 0.4886 - val_accuracy: 0.7608 - 375ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4578 - accuracy: 0.7804 - val_loss: 0.4860 - val_accuracy: 0.7684 - 381ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4544 - accuracy: 0.7880 - val_loss: 0.4895 - val_accuracy: 0.7650 - 380ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 1s - loss: 0.4517 - accuracy: 0.7858 - val_loss: 0.4732 - val_accuracy: 0.7697 - 593ms/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4475 - accuracy: 0.7848 - val_loss: 0.4621 - val_accuracy: 0.7804 - 399ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 1s - loss: 0.4461 - accuracy: 0.7938 - val_loss: 0.4755 - val_accuracy: 0.7770 - 526ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 1s - loss: 0.4427 - accuracy: 0.7875 - val_loss: 0.4723 - val_accuracy: 0.7753 - 569ms/epoch - 15ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 1s - loss: 0.4472 - accuracy: 0.7913 - val_loss: 0.4642 - val_accuracy: 0.7791 - 535ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 1s - loss: 0.4403 - accuracy: 0.7895 - val_loss: 0.4721 - val_accuracy: 0.7761 - 623ms/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 1s - loss: 0.4423 - accuracy: 0.7906 - val_loss: 0.4748 - val_accuracy: 0.7778 - 685ms/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 1s - loss: 0.4424 - accuracy: 0.7963 - val_loss: 0.4685 - val_accuracy: 0.7817 - 667ms/epoch - 18ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4394 - accuracy: 0.7916 - val_loss: 0.4605 - val_accuracy: 0.7817 - 409ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4402 - accuracy: 0.7930 - val_loss: 0.4599 - val_accuracy: 0.7842 - 393ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4332 - accuracy: 0.7952 - val_loss: 0.4551 - val_accuracy: 0.7829 - 405ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4403 - accuracy: 0.7936 - val_loss: 0.4659 - val_accuracy: 0.7791 - 386ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4374 - accuracy: 0.7992 - val_loss: 0.4591 - val_accuracy: 0.7872 - 427ms/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4336 - accuracy: 0.7961 - val_loss: 0.4587 - val_accuracy: 0.7906 - 434ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4356 - accuracy: 0.7975 - val_loss: 0.4550 - val_accuracy: 0.7855 - 438ms/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4314 - accuracy: 0.7990 - val_loss: 0.4565 - val_accuracy: 0.7855 - 475ms/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4355 - accuracy: 0.7948 - val_loss: 0.4637 - val_accuracy: 0.7778 - 454ms/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4361 - accuracy: 0.7937 - val_loss: 0.4589 - val_accuracy: 0.7872 - 481ms/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4345 - accuracy: 0.7992 - val_loss: 0.4644 - val_accuracy: 0.7842 - 385ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4319 - accuracy: 0.7992 - val_loss: 0.4591 - val_accuracy: 0.7915 - 498ms/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.4558 - val_accuracy: 0.7842 - 474ms/epoch - 13ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4311 - accuracy: 0.7945 - val_loss: 0.4654 - val_accuracy: 0.7778 - 431ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4292 - accuracy: 0.8007 - val_loss: 0.4581 - val_accuracy: 0.7821 - 442ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4313 - accuracy: 0.7996 - val_loss: 0.4546 - val_accuracy: 0.7851 - 463ms/epoch - 13ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 1s - loss: 0.4341 - accuracy: 0.8007 - val_loss: 0.4583 - val_accuracy: 0.7898 - 573ms/epoch - 15ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4305 - accuracy: 0.8003 - val_loss: 0.4539 - val_accuracy: 0.7876 - 490ms/epoch - 13ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4313 - accuracy: 0.8002 - val_loss: 0.4572 - val_accuracy: 0.7893 - 402ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4294 - accuracy: 0.8029 - val_loss: 0.4566 - val_accuracy: 0.7876 - 402ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4298 - accuracy: 0.8000 - val_loss: 0.4522 - val_accuracy: 0.7932 - 391ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4283 - accuracy: 0.7993 - val_loss: 0.4623 - val_accuracy: 0.7859 - 389ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4290 - accuracy: 0.8011 - val_loss: 0.4625 - val_accuracy: 0.7838 - 417ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4297 - accuracy: 0.8004 - val_loss: 0.4596 - val_accuracy: 0.7881 - 401ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 0s - loss: 0.4298 - accuracy: 0.8041 - val_loss: 0.4531 - val_accuracy: 0.7872 - 398ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 0s - loss: 0.4297 - accuracy: 0.8004 - val_loss: 0.4578 - val_accuracy: 0.7876 - 389ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 0s - loss: 0.4296 - accuracy: 0.8024 - val_loss: 0.4489 - val_accuracy: 0.7910 - 391ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 0s - loss: 0.4325 - accuracy: 0.7971 - val_loss: 0.4565 - val_accuracy: 0.7910 - 391ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 0s - loss: 0.4290 - accuracy: 0.7996 - val_loss: 0.4568 - val_accuracy: 0.7932 - 376ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "37/37 - 0s - loss: 0.4305 - accuracy: 0.8020 - val_loss: 0.4555 - val_accuracy: 0.7885 - 400ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "37/37 - 0s - loss: 0.4296 - accuracy: 0.8029 - val_loss: 0.4551 - val_accuracy: 0.7838 - 388ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "37/37 - 0s - loss: 0.4259 - accuracy: 0.8027 - val_loss: 0.4569 - val_accuracy: 0.7936 - 392ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "37/37 - 0s - loss: 0.4293 - accuracy: 0.8012 - val_loss: 0.4552 - val_accuracy: 0.7846 - 408ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "37/37 - 0s - loss: 0.4293 - accuracy: 0.8034 - val_loss: 0.4556 - val_accuracy: 0.7855 - 400ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "37/37 - 0s - loss: 0.4319 - accuracy: 0.8023 - val_loss: 0.4515 - val_accuracy: 0.7940 - 415ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "37/37 - 0s - loss: 0.4295 - accuracy: 0.8030 - val_loss: 0.4523 - val_accuracy: 0.7902 - 387ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "37/37 - 0s - loss: 0.4291 - accuracy: 0.8008 - val_loss: 0.4524 - val_accuracy: 0.7919 - 372ms/epoch - 10ms/step\n",
      "Epoch 55: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ale entropy:  0.36696283066095975\n",
      "epi entropy:  0.33401131145808877\n",
      "\n",
      "dataset size:  0.4\n",
      "Epoch 1/100\n",
      "49/49 - 4s - loss: 0.6287 - accuracy: 0.6688 - val_loss: 0.5732 - val_accuracy: 0.7367 - 4s/epoch - 71ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5449 - accuracy: 0.7494 - val_loss: 0.5331 - val_accuracy: 0.7486 - 468ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.5139 - accuracy: 0.7589 - val_loss: 0.5109 - val_accuracy: 0.7556 - 496ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 1s - loss: 0.4941 - accuracy: 0.7653 - val_loss: 0.4933 - val_accuracy: 0.7601 - 519ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4783 - accuracy: 0.7775 - val_loss: 0.4675 - val_accuracy: 0.7735 - 487ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4761 - accuracy: 0.7750 - val_loss: 0.4724 - val_accuracy: 0.7703 - 486ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4697 - accuracy: 0.7744 - val_loss: 0.4692 - val_accuracy: 0.7790 - 472ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 1s - loss: 0.4654 - accuracy: 0.7773 - val_loss: 0.4644 - val_accuracy: 0.7796 - 675ms/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 1s - loss: 0.4600 - accuracy: 0.7803 - val_loss: 0.4559 - val_accuracy: 0.7825 - 558ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 1s - loss: 0.4522 - accuracy: 0.7845 - val_loss: 0.4567 - val_accuracy: 0.7885 - 531ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 1s - loss: 0.4542 - accuracy: 0.7833 - val_loss: 0.4555 - val_accuracy: 0.7764 - 525ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4512 - accuracy: 0.7871 - val_loss: 0.4493 - val_accuracy: 0.7879 - 486ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 1s - loss: 0.4488 - accuracy: 0.7853 - val_loss: 0.4377 - val_accuracy: 0.7921 - 508ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4483 - accuracy: 0.7891 - val_loss: 0.4414 - val_accuracy: 0.7962 - 481ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4459 - accuracy: 0.7913 - val_loss: 0.4449 - val_accuracy: 0.7898 - 468ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 1s - loss: 0.4451 - accuracy: 0.7885 - val_loss: 0.4407 - val_accuracy: 0.7914 - 504ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4436 - accuracy: 0.7905 - val_loss: 0.4481 - val_accuracy: 0.7885 - 492ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 1s - loss: 0.4435 - accuracy: 0.7901 - val_loss: 0.4474 - val_accuracy: 0.7863 - 562ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 1s - loss: 0.4432 - accuracy: 0.7928 - val_loss: 0.4438 - val_accuracy: 0.7863 - 561ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 1s - loss: 0.4440 - accuracy: 0.7924 - val_loss: 0.4400 - val_accuracy: 0.7943 - 526ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 1s - loss: 0.4428 - accuracy: 0.7886 - val_loss: 0.4427 - val_accuracy: 0.7937 - 511ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4392 - accuracy: 0.7909 - val_loss: 0.4443 - val_accuracy: 0.7994 - 498ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4421 - accuracy: 0.7948 - val_loss: 0.4387 - val_accuracy: 0.7914 - 486ms/epoch - 10ms/step\n",
      "Epoch 23: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ale entropy:  0.3856984846129245\n",
      "epi entropy:  0.37521895978154945\n",
      "\n",
      "dataset size:  0.5\n",
      "Epoch 1/100\n",
      "62/62 - 3s - loss: 0.6138 - accuracy: 0.6879 - val_loss: 0.5506 - val_accuracy: 0.7659 - 3s/epoch - 52ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 0.5287 - accuracy: 0.7609 - val_loss: 0.4973 - val_accuracy: 0.7694 - 592ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 0.4944 - accuracy: 0.7662 - val_loss: 0.4735 - val_accuracy: 0.7789 - 702ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 1s - loss: 0.4762 - accuracy: 0.7718 - val_loss: 0.4542 - val_accuracy: 0.7802 - 623ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 1s - loss: 0.4608 - accuracy: 0.7782 - val_loss: 0.4492 - val_accuracy: 0.7858 - 642ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.4553 - accuracy: 0.7779 - val_loss: 0.4454 - val_accuracy: 0.7828 - 634ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 1s - loss: 0.4537 - accuracy: 0.7813 - val_loss: 0.4397 - val_accuracy: 0.7915 - 680ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 1s - loss: 0.4514 - accuracy: 0.7829 - val_loss: 0.4353 - val_accuracy: 0.7902 - 619ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4468 - accuracy: 0.7885 - val_loss: 0.4369 - val_accuracy: 0.7874 - 763ms/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4485 - accuracy: 0.7886 - val_loss: 0.4268 - val_accuracy: 0.7930 - 816ms/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4441 - accuracy: 0.7883 - val_loss: 0.4341 - val_accuracy: 0.7953 - 652ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4431 - accuracy: 0.7876 - val_loss: 0.4295 - val_accuracy: 0.7909 - 658ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4397 - accuracy: 0.7895 - val_loss: 0.4289 - val_accuracy: 0.7904 - 915ms/epoch - 15ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4386 - accuracy: 0.7901 - val_loss: 0.4277 - val_accuracy: 0.7984 - 692ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4398 - accuracy: 0.7908 - val_loss: 0.4214 - val_accuracy: 0.7935 - 601ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 1s - loss: 0.4389 - accuracy: 0.7920 - val_loss: 0.4270 - val_accuracy: 0.7955 - 630ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4378 - accuracy: 0.7913 - val_loss: 0.4304 - val_accuracy: 0.7948 - 740ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4377 - accuracy: 0.7923 - val_loss: 0.4250 - val_accuracy: 0.8009 - 659ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4386 - accuracy: 0.7945 - val_loss: 0.4240 - val_accuracy: 0.7966 - 641ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4359 - accuracy: 0.7905 - val_loss: 0.4275 - val_accuracy: 0.7991 - 667ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4365 - accuracy: 0.7947 - val_loss: 0.4219 - val_accuracy: 0.8012 - 654ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4386 - accuracy: 0.7933 - val_loss: 0.4267 - val_accuracy: 0.7984 - 711ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 1s - loss: 0.4344 - accuracy: 0.7972 - val_loss: 0.4195 - val_accuracy: 0.8053 - 889ms/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4353 - accuracy: 0.7960 - val_loss: 0.4226 - val_accuracy: 0.8058 - 711ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4353 - accuracy: 0.7929 - val_loss: 0.4233 - val_accuracy: 0.8076 - 633ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4361 - accuracy: 0.7965 - val_loss: 0.4255 - val_accuracy: 0.8017 - 662ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4347 - accuracy: 0.7963 - val_loss: 0.4227 - val_accuracy: 0.8017 - 718ms/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 1s - loss: 0.4336 - accuracy: 0.7968 - val_loss: 0.4217 - val_accuracy: 0.8002 - 730ms/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4336 - accuracy: 0.7954 - val_loss: 0.4199 - val_accuracy: 0.8063 - 700ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4354 - accuracy: 0.7981 - val_loss: 0.4188 - val_accuracy: 0.8089 - 680ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 1s - loss: 0.4356 - accuracy: 0.7943 - val_loss: 0.4263 - val_accuracy: 0.7981 - 702ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4334 - accuracy: 0.7975 - val_loss: 0.4183 - val_accuracy: 0.8025 - 769ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4341 - accuracy: 0.7989 - val_loss: 0.4206 - val_accuracy: 0.8060 - 801ms/epoch - 13ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 1s - loss: 0.4337 - accuracy: 0.7981 - val_loss: 0.4250 - val_accuracy: 0.7994 - 702ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4336 - accuracy: 0.7975 - val_loss: 0.4213 - val_accuracy: 0.8071 - 750ms/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 1s - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.4205 - val_accuracy: 0.8089 - 674ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 1s - loss: 0.4352 - accuracy: 0.7956 - val_loss: 0.4213 - val_accuracy: 0.8007 - 604ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 1s - loss: 0.4314 - accuracy: 0.7981 - val_loss: 0.4225 - val_accuracy: 0.8053 - 697ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 1s - loss: 0.4321 - accuracy: 0.7980 - val_loss: 0.4222 - val_accuracy: 0.8042 - 693ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 1s - loss: 0.4349 - accuracy: 0.7977 - val_loss: 0.4216 - val_accuracy: 0.8068 - 751ms/epoch - 12ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 1s - loss: 0.4313 - accuracy: 0.7994 - val_loss: 0.4205 - val_accuracy: 0.8004 - 770ms/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 1s - loss: 0.4320 - accuracy: 0.7970 - val_loss: 0.4224 - val_accuracy: 0.8045 - 724ms/epoch - 12ms/step\n",
      "Epoch 42: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ale entropy:  0.3838133554819818\n",
      "epi entropy:  0.3778529557886042\n",
      "\n",
      "dataset size:  0.6\n",
      "Epoch 1/100\n",
      "74/74 - 3s - loss: 0.5910 - accuracy: 0.6874 - val_loss: 0.5103 - val_accuracy: 0.7592 - 3s/epoch - 41ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 0.4919 - accuracy: 0.7617 - val_loss: 0.4791 - val_accuracy: 0.7701 - 764ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.4663 - accuracy: 0.7736 - val_loss: 0.4654 - val_accuracy: 0.7750 - 808ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.4596 - accuracy: 0.7780 - val_loss: 0.4649 - val_accuracy: 0.7801 - 662ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4518 - accuracy: 0.7811 - val_loss: 0.4670 - val_accuracy: 0.7816 - 671ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4520 - accuracy: 0.7816 - val_loss: 0.4594 - val_accuracy: 0.7876 - 665ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4475 - accuracy: 0.7833 - val_loss: 0.4580 - val_accuracy: 0.7910 - 703ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4458 - accuracy: 0.7869 - val_loss: 0.4572 - val_accuracy: 0.7959 - 707ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4418 - accuracy: 0.7876 - val_loss: 0.4500 - val_accuracy: 0.7936 - 666ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4389 - accuracy: 0.7891 - val_loss: 0.4512 - val_accuracy: 0.7844 - 712ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4412 - accuracy: 0.7893 - val_loss: 0.4476 - val_accuracy: 0.7951 - 893ms/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4388 - accuracy: 0.7927 - val_loss: 0.4478 - val_accuracy: 0.7955 - 679ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4362 - accuracy: 0.7915 - val_loss: 0.4490 - val_accuracy: 0.7936 - 688ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4400 - accuracy: 0.7898 - val_loss: 0.4497 - val_accuracy: 0.7946 - 662ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4374 - accuracy: 0.7897 - val_loss: 0.4460 - val_accuracy: 0.7959 - 664ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4348 - accuracy: 0.7907 - val_loss: 0.4473 - val_accuracy: 0.7936 - 645ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4350 - accuracy: 0.7930 - val_loss: 0.4440 - val_accuracy: 0.7955 - 680ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4341 - accuracy: 0.7923 - val_loss: 0.4458 - val_accuracy: 0.7925 - 723ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4340 - accuracy: 0.7941 - val_loss: 0.4396 - val_accuracy: 0.7970 - 697ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4347 - accuracy: 0.7917 - val_loss: 0.4430 - val_accuracy: 0.7959 - 786ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4336 - accuracy: 0.7942 - val_loss: 0.4430 - val_accuracy: 0.7916 - 905ms/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4331 - accuracy: 0.7919 - val_loss: 0.4416 - val_accuracy: 0.7944 - 674ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4317 - accuracy: 0.7927 - val_loss: 0.4418 - val_accuracy: 0.7955 - 659ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4316 - accuracy: 0.7938 - val_loss: 0.4402 - val_accuracy: 0.7946 - 715ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4315 - accuracy: 0.7934 - val_loss: 0.4436 - val_accuracy: 0.7997 - 669ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4325 - accuracy: 0.7939 - val_loss: 0.4438 - val_accuracy: 0.7953 - 671ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4315 - accuracy: 0.7957 - val_loss: 0.4426 - val_accuracy: 0.7968 - 750ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.4454 - val_accuracy: 0.7957 - 696ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4310 - accuracy: 0.7935 - val_loss: 0.4427 - val_accuracy: 0.7974 - 660ms/epoch - 9ms/step\n",
      "Epoch 29: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ale entropy:  0.39351933899372427\n",
      "epi entropy:  0.3789817402517221\n",
      "\n",
      "dataset size:  0.7\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 0.5840 - accuracy: 0.7144 - val_loss: 0.5097 - val_accuracy: 0.7644 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.4878 - accuracy: 0.7702 - val_loss: 0.4703 - val_accuracy: 0.7827 - 798ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4664 - accuracy: 0.7822 - val_loss: 0.4713 - val_accuracy: 0.7765 - 830ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4569 - accuracy: 0.7857 - val_loss: 0.4560 - val_accuracy: 0.7889 - 799ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4522 - accuracy: 0.7868 - val_loss: 0.4533 - val_accuracy: 0.7854 - 730ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4478 - accuracy: 0.7902 - val_loss: 0.4563 - val_accuracy: 0.7825 - 812ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4439 - accuracy: 0.7895 - val_loss: 0.4454 - val_accuracy: 0.7854 - 891ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4423 - accuracy: 0.7904 - val_loss: 0.4450 - val_accuracy: 0.7874 - 801ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4389 - accuracy: 0.7953 - val_loss: 0.4453 - val_accuracy: 0.7882 - 808ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4393 - accuracy: 0.7916 - val_loss: 0.4408 - val_accuracy: 0.7891 - 801ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4354 - accuracy: 0.7947 - val_loss: 0.4406 - val_accuracy: 0.7887 - 866ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4341 - accuracy: 0.7945 - val_loss: 0.4415 - val_accuracy: 0.7947 - 761ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4340 - accuracy: 0.7949 - val_loss: 0.4404 - val_accuracy: 0.7907 - 759ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4357 - accuracy: 0.7946 - val_loss: 0.4404 - val_accuracy: 0.7951 - 766ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4343 - accuracy: 0.7971 - val_loss: 0.4445 - val_accuracy: 0.7889 - 772ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4316 - accuracy: 0.7993 - val_loss: 0.4389 - val_accuracy: 0.7940 - 770ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4315 - accuracy: 0.7957 - val_loss: 0.4375 - val_accuracy: 0.7894 - 774ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4335 - accuracy: 0.7984 - val_loss: 0.4369 - val_accuracy: 0.7975 - 755ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4330 - accuracy: 0.7989 - val_loss: 0.4357 - val_accuracy: 0.7944 - 768ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4311 - accuracy: 0.7970 - val_loss: 0.4317 - val_accuracy: 0.7938 - 795ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4305 - accuracy: 0.7989 - val_loss: 0.4338 - val_accuracy: 0.7975 - 784ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4308 - accuracy: 0.7989 - val_loss: 0.4335 - val_accuracy: 0.7967 - 762ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4298 - accuracy: 0.7997 - val_loss: 0.4403 - val_accuracy: 0.7922 - 751ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4318 - accuracy: 0.7994 - val_loss: 0.4377 - val_accuracy: 0.7935 - 758ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4293 - accuracy: 0.8005 - val_loss: 0.4368 - val_accuracy: 0.7966 - 750ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4292 - accuracy: 0.8008 - val_loss: 0.4327 - val_accuracy: 0.7991 - 763ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4285 - accuracy: 0.7998 - val_loss: 0.4347 - val_accuracy: 0.7977 - 769ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4279 - accuracy: 0.8000 - val_loss: 0.4355 - val_accuracy: 0.7995 - 779ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4275 - accuracy: 0.8005 - val_loss: 0.4345 - val_accuracy: 0.7947 - 798ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4281 - accuracy: 0.8006 - val_loss: 0.4349 - val_accuracy: 0.7958 - 777ms/epoch - 9ms/step\n",
      "Epoch 30: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ale entropy:  0.3818363881637925\n",
      "epi entropy:  0.35891444396540834\n",
      "\n",
      "dataset size:  0.8\n",
      "Epoch 1/100\n",
      "98/98 - 2s - loss: 0.5574 - accuracy: 0.7499 - val_loss: 0.5107 - val_accuracy: 0.7618 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.4834 - accuracy: 0.7725 - val_loss: 0.4717 - val_accuracy: 0.7758 - 885ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4591 - accuracy: 0.7793 - val_loss: 0.4640 - val_accuracy: 0.7782 - 847ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4516 - accuracy: 0.7832 - val_loss: 0.4557 - val_accuracy: 0.7869 - 869ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4479 - accuracy: 0.7891 - val_loss: 0.4465 - val_accuracy: 0.7863 - 874ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4437 - val_accuracy: 0.7913 - 869ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4410 - accuracy: 0.7911 - val_loss: 0.4457 - val_accuracy: 0.7937 - 864ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4392 - accuracy: 0.7928 - val_loss: 0.4440 - val_accuracy: 0.7925 - 882ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4389 - accuracy: 0.7916 - val_loss: 0.4451 - val_accuracy: 0.7938 - 892ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4347 - accuracy: 0.7939 - val_loss: 0.4413 - val_accuracy: 0.7921 - 851ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4342 - accuracy: 0.7930 - val_loss: 0.4417 - val_accuracy: 0.7938 - 887ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4345 - accuracy: 0.7968 - val_loss: 0.4390 - val_accuracy: 0.7945 - 893ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4332 - accuracy: 0.7976 - val_loss: 0.4369 - val_accuracy: 0.7977 - 913ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4335 - accuracy: 0.7948 - val_loss: 0.4365 - val_accuracy: 0.7993 - 872ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4331 - accuracy: 0.7983 - val_loss: 0.4365 - val_accuracy: 0.7957 - 859ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4331 - accuracy: 0.7978 - val_loss: 0.4383 - val_accuracy: 0.7956 - 901ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4316 - accuracy: 0.7976 - val_loss: 0.4390 - val_accuracy: 0.7969 - 853ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4335 - accuracy: 0.7998 - val_loss: 0.4368 - val_accuracy: 0.7972 - 874ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4314 - accuracy: 0.8006 - val_loss: 0.4386 - val_accuracy: 0.7981 - 850ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4317 - accuracy: 0.7995 - val_loss: 0.4402 - val_accuracy: 0.7983 - 888ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4298 - accuracy: 0.7996 - val_loss: 0.4371 - val_accuracy: 0.7965 - 859ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4304 - accuracy: 0.7992 - val_loss: 0.4395 - val_accuracy: 0.7929 - 861ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4304 - accuracy: 0.7974 - val_loss: 0.4375 - val_accuracy: 0.7993 - 881ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4306 - accuracy: 0.7984 - val_loss: 0.4413 - val_accuracy: 0.7986 - 878ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4301 - accuracy: 0.7982 - val_loss: 0.4419 - val_accuracy: 0.7962 - 875ms/epoch - 9ms/step\n",
      "Epoch 25: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ale entropy:  0.38552789334494914\n",
      "epi entropy:  0.3672160027990948\n",
      "\n",
      "dataset size:  0.9\n",
      "Epoch 1/100\n",
      "110/110 - 2s - loss: 0.5544 - accuracy: 0.7385 - val_loss: 0.5057 - val_accuracy: 0.7607 - 2s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4749 - accuracy: 0.7750 - val_loss: 0.4781 - val_accuracy: 0.7672 - 992ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4602 - accuracy: 0.7819 - val_loss: 0.4711 - val_accuracy: 0.7745 - 983ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4508 - accuracy: 0.7867 - val_loss: 0.4589 - val_accuracy: 0.7809 - 995ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4477 - accuracy: 0.7884 - val_loss: 0.4570 - val_accuracy: 0.7807 - 989ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4429 - accuracy: 0.7922 - val_loss: 0.4575 - val_accuracy: 0.7839 - 991ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4407 - accuracy: 0.7916 - val_loss: 0.4566 - val_accuracy: 0.7805 - 1s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4406 - accuracy: 0.7931 - val_loss: 0.4496 - val_accuracy: 0.7880 - 1s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.4512 - val_accuracy: 0.7880 - 976ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4358 - accuracy: 0.7943 - val_loss: 0.4487 - val_accuracy: 0.7843 - 1s/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4373 - accuracy: 0.7941 - val_loss: 0.4490 - val_accuracy: 0.7850 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4360 - accuracy: 0.7965 - val_loss: 0.4469 - val_accuracy: 0.7859 - 986ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4345 - accuracy: 0.7961 - val_loss: 0.4480 - val_accuracy: 0.7826 - 984ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4343 - accuracy: 0.7978 - val_loss: 0.4429 - val_accuracy: 0.7914 - 992ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4321 - accuracy: 0.8014 - val_loss: 0.4435 - val_accuracy: 0.7853 - 973ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.4452 - val_accuracy: 0.7834 - 963ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4300 - accuracy: 0.7982 - val_loss: 0.4449 - val_accuracy: 0.7869 - 994ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4297 - accuracy: 0.8011 - val_loss: 0.4402 - val_accuracy: 0.7879 - 991ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4330 - accuracy: 0.7972 - val_loss: 0.4436 - val_accuracy: 0.7879 - 967ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.8001 - val_loss: 0.4424 - val_accuracy: 0.7898 - 1s/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4298 - accuracy: 0.7981 - val_loss: 0.4452 - val_accuracy: 0.7871 - 1s/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4289 - accuracy: 0.8005 - val_loss: 0.4404 - val_accuracy: 0.7904 - 957ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4293 - accuracy: 0.8017 - val_loss: 0.4417 - val_accuracy: 0.7891 - 1s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4294 - accuracy: 0.8004 - val_loss: 0.4423 - val_accuracy: 0.7856 - 1s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4296 - accuracy: 0.7996 - val_loss: 0.4455 - val_accuracy: 0.7864 - 974ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4270 - accuracy: 0.8025 - val_loss: 0.4452 - val_accuracy: 0.7894 - 968ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4292 - accuracy: 0.8000 - val_loss: 0.4433 - val_accuracy: 0.7856 - 993ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4268 - accuracy: 0.8004 - val_loss: 0.4405 - val_accuracy: 0.7900 - 973ms/epoch - 9ms/step\n",
      "Epoch 28: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ale entropy:  0.3926533410461557\n",
      "epi entropy:  0.37095153611735643\n",
      "\n",
      "dataset size:  1.0\n",
      "Epoch 1/100\n",
      "123/123 - 3s - loss: 0.5631 - accuracy: 0.7235 - val_loss: 0.4923 - val_accuracy: 0.7694 - 3s/epoch - 26ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4788 - accuracy: 0.7761 - val_loss: 0.4609 - val_accuracy: 0.7839 - 1s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4614 - accuracy: 0.7808 - val_loss: 0.4443 - val_accuracy: 0.7901 - 1s/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4587 - accuracy: 0.7807 - val_loss: 0.4502 - val_accuracy: 0.7904 - 1s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4510 - accuracy: 0.7862 - val_loss: 0.4393 - val_accuracy: 0.7922 - 1s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4494 - accuracy: 0.7883 - val_loss: 0.4395 - val_accuracy: 0.7977 - 1s/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4440 - accuracy: 0.7918 - val_loss: 0.4376 - val_accuracy: 0.7951 - 1s/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4416 - accuracy: 0.7909 - val_loss: 0.4302 - val_accuracy: 0.7994 - 1s/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4413 - accuracy: 0.7929 - val_loss: 0.4301 - val_accuracy: 0.8015 - 1s/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4383 - accuracy: 0.7925 - val_loss: 0.4292 - val_accuracy: 0.8027 - 1s/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4394 - accuracy: 0.7946 - val_loss: 0.4334 - val_accuracy: 0.7946 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4378 - accuracy: 0.7950 - val_loss: 0.4300 - val_accuracy: 0.8013 - 1s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4377 - accuracy: 0.7946 - val_loss: 0.4292 - val_accuracy: 0.7985 - 1s/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4375 - accuracy: 0.7950 - val_loss: 0.4288 - val_accuracy: 0.7985 - 1s/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4361 - accuracy: 0.7950 - val_loss: 0.4270 - val_accuracy: 0.7995 - 1s/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4339 - accuracy: 0.7958 - val_loss: 0.4283 - val_accuracy: 0.8010 - 1s/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4345 - accuracy: 0.7962 - val_loss: 0.4264 - val_accuracy: 0.8019 - 1s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4338 - accuracy: 0.7966 - val_loss: 0.4250 - val_accuracy: 0.7992 - 1s/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4337 - accuracy: 0.7962 - val_loss: 0.4281 - val_accuracy: 0.8009 - 1s/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4340 - accuracy: 0.7958 - val_loss: 0.4262 - val_accuracy: 0.8037 - 1s/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4325 - accuracy: 0.7977 - val_loss: 0.4280 - val_accuracy: 0.8018 - 1s/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4319 - accuracy: 0.7971 - val_loss: 0.4276 - val_accuracy: 0.8046 - 1s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4341 - accuracy: 0.7968 - val_loss: 0.4273 - val_accuracy: 0.7981 - 1s/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4322 - accuracy: 0.7982 - val_loss: 0.4253 - val_accuracy: 0.8001 - 1s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4325 - accuracy: 0.7982 - val_loss: 0.4239 - val_accuracy: 0.7992 - 1s/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4333 - accuracy: 0.7981 - val_loss: 0.4254 - val_accuracy: 0.8018 - 1s/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4319 - accuracy: 0.7967 - val_loss: 0.4268 - val_accuracy: 0.8010 - 1s/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.7967 - val_loss: 0.4266 - val_accuracy: 0.7983 - 1s/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4324 - accuracy: 0.7988 - val_loss: 0.4267 - val_accuracy: 0.7991 - 1s/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 2s - loss: 0.4315 - accuracy: 0.7968 - val_loss: 0.4256 - val_accuracy: 0.8010 - 2s/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.7962 - val_loss: 0.4244 - val_accuracy: 0.8036 - 1s/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4307 - accuracy: 0.7985 - val_loss: 0.4261 - val_accuracy: 0.8050 - 1s/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.7980 - val_loss: 0.4241 - val_accuracy: 0.8028 - 1s/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.7993 - val_loss: 0.4234 - val_accuracy: 0.7988 - 1s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.7976 - val_loss: 0.4235 - val_accuracy: 0.8028 - 1s/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.7973 - val_loss: 0.4243 - val_accuracy: 0.8028 - 1s/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4298 - accuracy: 0.7976 - val_loss: 0.4252 - val_accuracy: 0.7988 - 1s/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7973 - val_loss: 0.4248 - val_accuracy: 0.8026 - 1s/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4302 - accuracy: 0.7984 - val_loss: 0.4228 - val_accuracy: 0.8065 - 1s/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7990 - val_loss: 0.4238 - val_accuracy: 0.8015 - 1s/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4307 - accuracy: 0.7998 - val_loss: 0.4242 - val_accuracy: 0.8026 - 1s/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 1s - loss: 0.4291 - accuracy: 0.7997 - val_loss: 0.4227 - val_accuracy: 0.8051 - 1s/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4304 - accuracy: 0.7995 - val_loss: 0.4237 - val_accuracy: 0.8026 - 1s/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.7976 - val_loss: 0.4243 - val_accuracy: 0.8038 - 1s/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7977 - val_loss: 0.4245 - val_accuracy: 0.8069 - 1s/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "123/123 - 1s - loss: 0.4295 - accuracy: 0.8005 - val_loss: 0.4234 - val_accuracy: 0.8046 - 1s/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "123/123 - 1s - loss: 0.4299 - accuracy: 0.7988 - val_loss: 0.4245 - val_accuracy: 0.8047 - 1s/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "123/123 - 1s - loss: 0.4302 - accuracy: 0.7980 - val_loss: 0.4252 - val_accuracy: 0.8052 - 1s/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "123/123 - 1s - loss: 0.4291 - accuracy: 0.7994 - val_loss: 0.4252 - val_accuracy: 0.8033 - 1s/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "123/123 - 1s - loss: 0.4290 - accuracy: 0.7988 - val_loss: 0.4238 - val_accuracy: 0.8009 - 1s/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.4236 - val_accuracy: 0.8037 - 1s/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "123/123 - 1s - loss: 0.4300 - accuracy: 0.7993 - val_loss: 0.4244 - val_accuracy: 0.8033 - 1s/epoch - 12ms/step\n",
      "Epoch 52: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ale entropy:  0.39177567559698473\n",
      "epi entropy:  0.3526230720138184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train dropout model for dataset size 0.1 to 1.0\n",
    "ale_entropy_dropout = []\n",
    "epi_entropy_dropout = []\n",
    "pred_prob = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print('dataset size: ', np.round((i * 0.1 + 0.1),1))\n",
    "    pred, ale_entropy, epi_entropy = train_dropout_model(train_sets[dataset_frac[i]].features, train_sets[dataset_frac[i]].labels.ravel(), dataset_orig_test.features, prob=0.5)\n",
    "    print('ale entropy: ', np.mean(ale_entropy))\n",
    "    print('epi entropy: ', np.mean(epi_entropy))\n",
    "\n",
    "    # save ale and epi entropy\n",
    "    pred_prob.append(pred)\n",
    "    ale_entropy_dropout.append(ale_entropy)\n",
    "    epi_entropy_dropout.append(epi_entropy)\n",
    "\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal opportunity difference for dataset of size 0.10 = 0.271314\n",
      "Equal opportunity difference for dataset of size 0.20 = 0.444750\n",
      "Equal opportunity difference for dataset of size 0.30 = 0.483952\n",
      "Equal opportunity difference for dataset of size 0.40 = 0.470453\n",
      "Equal opportunity difference for dataset of size 0.50 = 0.484955\n",
      "Equal opportunity difference for dataset of size 0.60 = 0.466441\n",
      "Equal opportunity difference for dataset of size 0.70 = 0.473420\n",
      "Equal opportunity difference for dataset of size 0.80 = 0.473795\n",
      "Equal opportunity difference for dataset of size 0.90 = 0.478435\n",
      "Equal opportunity difference for dataset of size 1.00 = 0.467402\n"
     ]
    }
   ],
   "source": [
    "Equal_opp_diffs_dropout = equal_opportunity_difference(dataset_orig_test, pred_prob, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  0.1\n",
      "ale entropy:  0.455959305852733\n",
      "epi entropy:  0.471214965836654\n",
      "\n",
      "dataset size:  0.2\n",
      "ale entropy:  0.4005118098994138\n",
      "epi entropy:  0.3788619388901892\n",
      "\n",
      "dataset size:  0.3\n",
      "ale entropy:  0.36696283066095975\n",
      "epi entropy:  0.33401131145808877\n",
      "\n",
      "dataset size:  0.4\n",
      "ale entropy:  0.3856984846129245\n",
      "epi entropy:  0.37521895978154945\n",
      "\n",
      "dataset size:  0.5\n",
      "ale entropy:  0.3838133554819818\n",
      "epi entropy:  0.3778529557886042\n",
      "\n",
      "dataset size:  0.6\n",
      "ale entropy:  0.39351933899372427\n",
      "epi entropy:  0.3789817402517221\n",
      "\n",
      "dataset size:  0.7\n",
      "ale entropy:  0.3818363881637925\n",
      "epi entropy:  0.35891444396540834\n",
      "\n",
      "dataset size:  0.8\n",
      "ale entropy:  0.38552789334494914\n",
      "epi entropy:  0.3672160027990948\n",
      "\n",
      "dataset size:  0.9\n",
      "ale entropy:  0.3926533410461557\n",
      "epi entropy:  0.37095153611735643\n",
      "\n",
      "dataset size:  1.0\n",
      "ale entropy:  0.39177567559698473\n",
      "epi entropy:  0.3526230720138184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mean of each entropy in ale and epi_entropy_dropout\n",
    "for i in range(0, 10):\n",
    "    print('dataset size: ', np.round((i * 0.1 + 0.1),1))\n",
    "    print('ale entropy: ', np.mean(ale_entropy_dropout[i]))\n",
    "    print('epi entropy: ', np.mean(epi_entropy_dropout[i]))\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB5CElEQVR4nO3dd1xV9f8H8Ne9wL2XPWXKUExxswS3qRiONDVzhoirstRE7adfS00rmmalae4yV5qZmamJkgsn4khFZTtYyt7ce35/IDevgHIRuMB9PR+P+yjP+Zxz3+ce7r3v+5kiQRAEEBEREWkRsaYDICIiIqprTICIiIhI6zABIiIiIq3DBIiIiIi0DhMgIiIi0jpMgIiIiEjrMAEiIiIircMEiIiIiLQOEyAiIiLSOkyAiJ5CJBJh8eLFmg5DbRMmTICLi4umw2hUGurfAgAkJydjxIgRsLS0hEgkwvLlyzUdEqkpLCwMIpEIYWFhah+7adMmiEQixMXF1XhcDRkTIC1X9sYQiUQ4ceJEuf2CIMDR0REikQgvv/yyBiKsOhcXF+W1PPno379/ncWxdevWRvUF8+KLL6Jdu3YV7ktLS2sQiYGm78knn3yCPXv2aOz5Z82ahYMHD2L+/PnYvHnzU98Pj79vdHV1YWFhAS8vL8ycORPXrl2rw6jrxqlTp7B48WJkZGRUqfyECRMgEolgYmKC/Pz8cvtv3bqlfP2+/PLLGo6WapKupgOg+kEmk2Hr1q3o3r27yvZ//vkHd+7cgVQq1VBk6nF3d8fs2bPLbbe3t6/W+fLz86Grq97bZOvWrbh69Srefffdaj1nTVi7di0UCoXGnr++qYl7Up2/hTKffPIJRowYgaFDh1b7+Z/HkSNH8Morr2DOnDlVKt+vXz+MHz8egiAgMzMTly5dwo8//ojvv/8en332GYKDg2s54rpz6tQpfPjhh5gwYQLMzMyqdIyuri7y8vLwxx9/YOTIkSr7tmzZAplMhoKCglqIlmoSEyACAAwcOBA7d+7Et99+q/Ihv3XrVnh5eSEtLU2D0VWdg4MDXn/99Ro7n0wmq7Fz1SU9PT1Nh1Av5ObmwtDQsEbO1VD/FgAgJSWlyl/uANCyZcty76NPP/0UgwcPxuzZs+Hm5oaBAwdWenxBQQEkEgnE4sbZyCCVStGtWzds27atXAK0detWDBo0CL/++quGoqOqapx/naS2MWPG4MGDB/j777+V24qKirBr1y6MHTu2wmMUCgWWL1+Otm3bQiaTwcbGBm+88QbS09NVyv3+++8YNGgQ7O3tIZVK4erqiqVLl0Iul6uUK2tquXbtGnr37g0DAwM4ODjg888/r9FrnTBhAoyMjBATEwN/f38YGhrC3t4eS5YsgSAIKmWfbN7Jzs7Gu+++CxcXF0ilUlhbW6Nfv36IiIhQXsOff/6J+Ph4ZTX4431xCgsLsWjRIrRo0QJSqRSOjo547733UFhYWO5533nnHezcuRNt2rSBvr4+unTpgitXrgAAfvjhB7Ro0QIymQwvvvhiubb9ivoAKRQKfPPNN2jfvj1kMhmaNGmC/v374/z588/3gj5h8eLFEIlEuH37tvJXtampKYKCgpCXl1eu/M8//wwfHx8YGBjA3NwcPXv2xKFDh1TK/PXXX+jRowcMDQ1hbGyMQYMG4d9//y13zUZGRoiOjsbAgQNhbGyMcePGPfWeFBUVYeHChfDy8oKpqSkMDQ3Ro0cPHD16tFycT/4tVPU6RSIRcnNz8eOPPyqff8KECTh69ChEIhF+++23cs+1detWiEQihIeHP/W1jomJwWuvvQYLCwsYGBigc+fO+PPPP5X7y5q4BUHAypUrlc9fHZaWlti+fTt0dXXx8ccfK7eX9U3Zvn073n//fTg4OMDAwABZWVkAgJ07d8LLywv6+vqwsrLC66+/jrt376qcW533ZG5uLmbPng1HR0dIpVK0atUKX375pUq5uLg4iEQibNq0qdx1PH4fFy9ejLlz5wIAmjVrpnx9qtJXZuzYsfjrr79Ums7OnTuHW7duVfqZ+az7VebOnTsYOnQoDA0NYW1tjVmzZpX7jChz5swZ9O/fH6ampjAwMECvXr1w8uTJZ8ZPrAGiR1xcXNClSxds27YNAwYMAFD6pZOZmYnRo0fj22+/LXfMG2+8gU2bNiEoKAgzZsxAbGwsVqxYgYsXL+LkyZPKWohNmzbByMgIwcHBMDIywpEjR7Bw4UJkZWXhiy++UDlneno6+vfvj+HDh2PkyJHYtWsX/u///g/t27dXxvU0xcXFFdZWGRoaQl9fX/lvuVyO/v37o3Pnzvj8889x4MABLFq0CCUlJViyZEml53/zzTexa9cuvPPOO2jTpg0ePHiAEydO4Pr16/D09MSCBQuQmZmJO3fu4OuvvwYAGBkZAShNQIYMGYITJ05g6tSpaN26Na5cuYKvv/4aN2/eLNdH5Pjx49i7dy/efvttAEBISAhefvllvPfee/j+++8xbdo0pKen4/PPP8fEiRNx5MiRp742kyZNwqZNmzBgwABMnjwZJSUlOH78OE6fPg1vb+9nvrbqGjlyJJo1a4aQkBBERERg3bp1sLa2xmeffaYs8+GHH2Lx4sXo2rUrlixZAolEgjNnzuDIkSN46aWXAACbN29GYGAg/P398dlnnyEvLw+rVq1C9+7dcfHiRZVEr6SkBP7+/ujevTu+/PJLGBgYwNbWttJ7kpWVhXXr1mHMmDGYMmUKsrOzsX79evj7++Ps2bNwd3d/7uvcvHkzJk+eDB8fH0ydOhUA4Orqis6dO8PR0RFbtmzBsGHDVM65ZcsWuLq6okuXLpU+b3JyMrp27Yq8vDzMmDEDlpaW+PHHHzFkyBDs2rULw4YNQ8+ePbF582YEBAQom7Weh5OTE3r16oWjR48iKysLJiYmyn1Lly6FRCLBnDlzUFhYCIlEovx86NSpE0JCQpCcnIxvvvkGJ0+exMWLF1VqparynhQEAUOGDMHRo0cxadIkuLu74+DBg5g7dy7u3r2rvL9VNXz4cNy8eRPbtm3D119/DSsrKwBAkyZNqnTsm2++id27d2PixIkAShNXNzc3eHp6litflfsFlDa19u3bFwkJCZgxYwbs7e2xefPmCt/fR44cwYABA+Dl5YVFixZBLBZj48aN6NOnD44fPw4fHx+1Xg+tI5BW27hxowBAOHfunLBixQrB2NhYyMvLEwRBEF577TWhd+/egiAIgrOzszBo0CDlccePHxcACFu2bFE534EDB8ptLzvf49544w3BwMBAKCgoUG7r1auXAED46aeflNsKCwsFW1tb4dVXX33mtTg7OwsAKnyEhIQoywUGBgoAhOnTpyu3KRQKYdCgQYJEIhFSU1OV2wEIixYtUv7b1NRUePvtt58ax6BBgwRnZ+dy2zdv3iyIxWLh+PHjKttXr14tABBOnjyp8rxSqVSIjY1Vbvvhhx8EAIKtra2QlZWl3D5//nwBgErZwMBAlRiOHDkiABBmzJhRLi6FQvHU6+nVq5fQtm3bCvelpqaWe40WLVokABAmTpyoUnbYsGGCpaWl8t+3bt0SxGKxMGzYMEEul1cYU3Z2tmBmZiZMmTJFZX9SUpJgamqqsr3svs6bN69cnJXdk5KSEqGwsFBlW3p6umBjY1Mu/upepyAIgqGhoRAYGFju+efPny9IpVIhIyNDuS0lJUXQ1dVVea6KvPvuuwIAlb+n7OxsoVmzZoKLi4vKawrgmX+3VS07c+ZMAYBw6dIlQRAE4ejRowIAoXnz5irv9aKiIsHa2lpo166dkJ+fr9y+b98+AYCwcOFC5baqvif37NkjABA++ugjlZhGjBghiEQi4fbt24IgCEJsbKwAQNi4cWOF1/f4a/vFF1+Ue/88TWBgoGBoaKh83r59+wqCIAhyuVywtbUVPvzwQ+Xzf/HFF8rjqnq/li9fLgAQfvnlF2W53NxcoUWLFgIA4ejRo8rX54UXXhD8/f1V3sN5eXlCs2bNhH79+im3lX3OV/UatQWbwEhp5MiRyM/Px759+5CdnY19+/ZVWpW7c+dOmJqaol+/fkhLS1M+vLy8YGRkpNKE8HjNS3Z2NtLS0tCjRw/k5eXhxo0bKuc1MjJS6XsgkUjg4+ODmJiYKl2Dr68v/v7773KPMWPGlCv7zjvvKP+/rMmpqKgIhw8frvT8ZmZmOHPmDO7du1eleB63c+dOtG7dGm5ubiqvWZ8+fQCgXLNL3759VWo3fH19AQCvvvoqjI2Ny21/2mv066+/QiQSYdGiReX2VbdJ5FnefPNNlX/36NEDDx48UDaN7NmzBwqFAgsXLizXV6Qspr///hsZGRkYM2aMymumo6MDX1/fCpuq3nrrrSrHqKOjA4lEAqC0hu7hw4coKSmBt7e3slnzea/zacaPH4/CwkLs2rVLuW3Hjh0oKSl5Zl+2/fv3w8fHR2XggpGREaZOnYq4uLhaG7FVVnuWnZ2tsj0wMFDlvX7+/HmkpKRg2rRpKv2nBg0aBDc3twqbfp71nty/fz90dHQwY8YMleNmz54NQRDw119/Pf8FqmHs2LEICwtDUlISjhw5gqSkpEo/M6t6v/bv3w87OzuMGDFCWc7AwEBZe1gmMjJS2dz24MED5XsjNzcXffv2xbFjxzgQ4hnYBEZKTZo0gZ+fH7Zu3Yq8vDzI5XKVN+Hjbt26hczMTFhbW1e4PyUlRfn///77L95//30cOXKk3JdCZmamyr+bNm1a7gvZ3Nwcly9frtI1WFlZwc/P75nlxGIxmjdvrrKtZcuWAPDU9v/PP/8cgYGBcHR0hJeXFwYOHIjx48eXO1dFbt26hevXr1davf74awaUNjc8ztTUFADg6OhY4fYn+149Ljo6Gvb29rCwsHhmnNVRURL1ZPzm5uYASuM0MTFBdHQ0xGIx2rRpU+l5b926BQDKJPFJjzfBAKWjc5o2bapW7D/++CO++uor3LhxA8XFxcrtzZo1q9Lxz7rOp3Fzc0OnTp2wZcsWTJo0CUBp81fnzp3RokWLpx4bHx+vTH4f17p1a+X+yqYveB45OTkAoJKEA+Vfr/j4eABAq1atyp3Dzc2t3LQbVXlPxsfHw97evtxzP37Ndamsr9mOHTsQGRmJTp06oUWLFhV+hlT1fsXHx6NFixbl3lNPvo5l743AwMBK48vMzFT+PVJ5TIBIxdixYzFlyhQkJSVhwIABlY4cUSgUsLa2xpYtWyrcX/Yln5GRgV69esHExARLliyBq6srZDIZIiIi8H//93/lfqHo6OhUeD7hiY6QmjJy5Ej06NEDv/32Gw4dOoQvvvgCn332GXbv3v3MPkoKhQLt27fHsmXLKtz/ZGJT2WtR16+RTCarcL4TAMrOvhWNkKqJOMv+PjZv3gxbW9ty+58cli6VStUaefTzzz9jwoQJGDp0KObOnQtra2vo6OggJCQE0dHRVTrH817n+PHjMXPmTNy5cweFhYU4ffo0VqxYUeVrqGtXr16Fjo5OuYTn8dofTausVvPJgRfPSyqVYvjw4fjxxx8RExNTp/Nhlb03vvjii0r7qpXV1lHFmACRimHDhuGNN97A6dOnsWPHjkrLubq64vDhw+jWrdtTP/jCwsLw4MED7N69Gz179lRuj42NrdG41aVQKBATE6P8hQkAN2/eBIBnzqBsZ2eHadOmYdq0aUhJSYGnpyc+/vhjZQJU2Yevq6srLl26hL59+9Zas1NlXF1dcfDgQTx8+FDtWiBnZ2ccOXIE+fn55e51VFSUskx1YlIoFLh27VqlH+Curq4AAGtr6yrV7FWmstd7165daN68OXbv3q1SpqKmwufxtPs9evRoBAcHY9u2bcjPz4eenh5GjRr1zHM6OzsrX//HlTUrV+eePEtCQgL++ecfdOnSpVwtTEXxAaV/I0/W4EVFRZWLryrvSWdnZxw+fBjZ2dkqz//kNZfVejw5uWFFNUTP+14cO3YsNmzYALFYjNGjR1darqr3y9nZGVevXoUgCCqxPXls2XvDxMTkud4b2ox9gEiFkZERVq1ahcWLF2Pw4MGVlhs5ciTkcjmWLl1abl9JSYnyg6fs1/Hjv4aLiorw/fff12zg1fD4r2xBELBixQro6emhb9++FZaXy+Xlmuysra1hb2+vMkTV0NCwXDmg9DW7e/cu1q5dW25ffn4+cnNzq3spz/Tqq69CEAR8+OGH5fY9q6Zi4MCBKC4uxg8//KCyXaFQYNWqVZBIJJW+Zk8zdOhQiMViLFmypFxNYFlM/v7+MDExwSeffKLSPFUmNTW1Ss9V2T2p6O/zzJkzzxx+ri5DQ8NKZxq2srLCgAED8PPPP2PLli3o37+/cjTS0wwcOBBnz55ViTU3Nxdr1qyBi4vLU5sWq+Phw4cYM2YM5HI5FixY8Mzy3t7esLa2xurVq1XeH3/99ReuX7+OQYMGlTvmWe/JgQMHQi6Xl6sh+/rrryESiZQ/QkxMTGBlZYVjx46plKvoc6dsnqiqzgT9pN69e2Pp0qVYsWJFhbWUZap6vwYOHIh79+6p9AvLy8vDmjVrVM7n5eUFV1dXfPnll8pmycdV9b2hzVgDROU8rU25TK9evfDGG28gJCQEkZGReOmll6Cnp4dbt25h586d+OabbzBixAh07doV5ubmCAwMxIwZMyASibB58+Zaa665e/cufv7553LbjYyMVGbhlclkOHDgAAIDA+Hr64u//voLf/75J/73v/9V2kcnOzsbTZs2xYgRI9CxY0cYGRnh8OHDOHfuHL766itlOS8vL+zYsQPBwcHo1KkTjIyMMHjwYAQEBOCXX37Bm2++iaNHj6Jbt26Qy+W4ceMGfvnlFxw8eLBWhqMDpR/SAQEB+Pbbb3Hr1i30798fCoUCx48fR+/evVU6nz5p8ODBeOmllzBr1iycPXtWOZR37969OHnyJD766KMqDRt+UosWLbBgwQIsXboUPXr0wPDhwyGVSnHu3DnY29sjJCQEJiYmWLVqFQICAuDp6YnRo0ejSZMmSEhIwJ9//olu3bpVqbmosnvy8ssvY/fu3Rg2bBgGDRqE2NhYrF69Gm3atKnwS6W6vLy8cPjwYSxbtgz29vZo1qyZSn+Q8ePHK/vbVfSjoiLz5s1TTlsxY8YMWFhY4Mcff0RsbCx+/fXX55qE8ObNm/j5558hCAKysrJw6dIl7Ny5Ezk5OVi2bFmVlpbR09PDZ599hqCgIPTq1QtjxoxRDoN3cXHBrFmzVMpX5T05ePBg9O7dGwsWLEBcXBw6duyIQ4cO4ffff8e7776rrBUBgMmTJ+PTTz/F5MmT4e3tjWPHjilrlB7n5eUFAFiwYAFGjx4NPT09DB48uMoTaIrFYrz//vvPLFfV+zVlyhSsWLEC48ePx4ULF2BnZ4fNmzfDwMCg3POuW7cOAwYMQNu2bREUFAQHBwfcvXsXR48ehYmJCf74448qXYPW0sDIM6pHHh8G/zRPDoMvs2bNGsHLy0vQ19cXjI2Nhfbt2wvvvfeecO/ePWWZkydPCp07dxb09fUFe3t74b333hMOHjyoMqRTECofbv3kkO6nxYhKhsE/fnzZMNbo6GjhpZdeEgwMDAQbGxth0aJF5YZj47Ehs4WFhcLcuXOFjh07CsbGxoKhoaHQsWNH4fvvv1c5JicnRxg7dqxgZmZW7rmLioqEzz77TGjbtq0glUoFc3NzwcvLS/jwww+FzMxMled9cihyRUNrBeG/Ycg7d+586mtWUlIifPHFF4Kbm5sgkUiEJk2aCAMGDBAuXLjwzNe2oKBAWLx4seDm5iZIpVLB0NBQ6Ny5s/Dzzz+XK1s2PPzx6QQEofKhuBs2bBA8PDyUr0evXr2Ev//+u9w1+vv7C6ampoJMJhNcXV2FCRMmCOfPn1e55rLhyU+q7J4oFArhk08+EZydnQWpVCp4eHgI+/btq/D1e/xvQd3rvHHjhtCzZ09BX19fAFBuSHxhYaFgbm4umJqaqgwZf5bo6GhhxIgRgpmZmSCTyQQfHx9h37595cpV9PdUmcffN2KxWDAzMxM8PDyEmTNnCv/++2+58hX9/T1ux44dyvtrYWEhjBs3Trhz545KGXXek9nZ2cKsWbMEe3t7QU9PT3jhhReEL774otx0Dnl5ecKkSZMEU1NTwdjYWBg5cqSQkpJS7j4KgiAsXbpUcHBwEMRi8TOHiz/t76xMZe/Vqt6v+Ph4YciQIYKBgYFgZWUlzJw5UznFyOOfmYIgCBcvXhSGDx8uWFpaClKpVHB2dhZGjhwphIaGKstwGHzFRIJQT3qXEtWRCRMmYNeuXTX6C5/oeZSUlMDe3h6DBw/G+vXrNR1OneN7kjSBfYCIiDRsz549SE1Nfe6Zmomo6tgHiIhIQ86cOYPLly9j6dKl8PDwQK9evTQdEpHWYA0QEZGGrFq1Cm+99Rasra3x008/aTocIq3CPkBERESkdVgDRERERFqHCRARERFpHXaCroBCocC9e/dgbGxc50sWEBERUfUIgoDs7GzY29s/czJQJkAVuHfvXrmFKYmIiKhhSExMRNOmTZ9ahglQBcoW2UtMTISJiYmGoyEiIqKqyMrKgqOj4zMX6wWYAFWorNnLxMSECRAREVEDU5XuK+wETURERFqHCRARERFpHSZAREREpHWYABEREZHWYQJEREREWocJEBEREWkdJkBERESkdZgAERERkdZhAkRERERahwkQERERaR0mQERERKR1mAARERGR1mECVIcEQUDCgzzczcjXdChERERajQlQHfr4z+vo+cVR/HgqTtOhEBERaTUmQHWotZ0JACAiPl3DkRAREWk3JkB1yNPZHABw+W4mikoUGo6GiIhIezEBqkMulgYwN9BDUYkC1+5naTocIiIircUEqA6JRCJ4OJXWAl1MYDMYERGRpjABqmOeTmYAgIiEDI3GQUREpM2YANWxshogdoQmIiLSHCZAdayjoxnEIuBuRj5Ssgo0HQ4REZFWYgJUx4ykumhpYwyAzWBERESawgRIA8qGw7MjNBERkWYwAdIAD0czAEAEEyAiIiKNYAKkAcoJEe9koljOCRGJiIjqGhMgDWhuZQhTfT0UlihwnRMiEhER1TkmQBpQOiGiGQAOhyciItIEJkAa4lk2I3RihmYDISIi0kJMgDSkLAFiR2giIqK6xwRIQzo6mkIkAhIf5iM1u1DT4RAREWkVJkAaYizTQ0vr0gkROR8QERFR3WICpEGezmYAOCM0ERFRXWMCpEEe7AdERESkEUyANMjz0VD4y3cyOCEiERFRHWICpEHNrYxgItNFQbECUUnZmg6HiIhIazAB0iCxWMRmMCIiIg1gAqRhnBGaiIio7mk8AVq5ciVcXFwgk8ng6+uLs2fPVum47du3QyQSYejQoeX2Xb9+HUOGDIGpqSkMDQ3RqVMnJCQk1HDkNYMzQhMREdU9jSZAO3bsQHBwMBYtWoSIiAh07NgR/v7+SElJeepxcXFxmDNnDnr06FFuX3R0NLp37w43NzeEhYXh8uXL+OCDDyCTyWrrMp6Lu5MZRCIg/kEe0nI4ISIREVFdEAmCIGjqyX19fdGpUyesWLECAKBQKODo6Ijp06dj3rx5FR4jl8vRs2dPTJw4EcePH0dGRgb27Nmj3D969Gjo6elh8+bN1Y4rKysLpqamyMzMhImJSbXPU1Uvff0PbibnYO14b/RrY1Prz0dERNQYqfP9rbEaoKKiIly4cAF+fn7/BSMWw8/PD+Hh4ZUet2TJElhbW2PSpEnl9ikUCvz5559o2bIl/P39YW1tDV9fX5UEqSKFhYXIyspSedQlD0d2hCYiIqpLGkuA0tLSIJfLYWOjWuNhY2ODpKSkCo85ceIE1q9fj7Vr11a4PyUlBTk5Ofj000/Rv39/HDp0CMOGDcPw4cPxzz//VBpLSEgITE1NlQ9HR8fqX1g1lM0IzSUxiIiI6obGO0FXVXZ2NgICArB27VpYWVlVWEahKJ1M8JVXXsGsWbPg7u6OefPm4eWXX8bq1asrPff8+fORmZmpfCQmJtbKNVSmrCP0pcRMlHBCRCIiolqnq6kntrKygo6ODpKTk1W2Jycnw9bWtlz56OhoxMXFYfDgwcptZQmPrq4uoqKi4OjoCF1dXbRp00bl2NatW+PEiROVxiKVSiGVSp/ncp6LaxMjGMt0kV1QghtJ2WjnYKqxWIiIiLSBxmqAJBIJvLy8EBoaqtymUCgQGhqKLl26lCvv5uaGK1euIDIyUvkYMmQIevfujcjISDg6OkIikaBTp06IiopSOfbmzZtwdnau9WuqLrFYBHdHMwAcDk9ERFQXNFYDBADBwcEIDAyEt7c3fHx8sHz5cuTm5iIoKAgAMH78eDg4OCAkJAQymQzt2rVTOd7MzAwAVLbPnTsXo0aNQs+ePdG7d28cOHAAf/zxB8LCwurqsqrF08kcx2+l4WJ8OgI6199kjYiIqDHQaAI0atQopKamYuHChUhKSoK7uzsOHDig7BidkJAAsVi9Sqphw4Zh9erVCAkJwYwZM9CqVSv8+uuv6N69e21cQo3xdOZIMCIiorqi0XmA6qu6ngcIADLzitFxySEAwIX3/WBppLk+SURERA1Rg5gHiFSZGuihhbURACCS/YCIiIhqFROgesSzbGFUNoMRERHVKiZA9YjHo/mAIuIzNBsIERFRI8cEqB5RToh4JwNyBbtmERER1RYmQPXIC9ZGMJbqIq9IjqikbE2HQ0RE1GgxAapHxGIROj6aEJH9gIiIiGoPE6B6hh2hiYiIah8ToHrG49GEiJEJGZoNhIiIqBFjAlTPeDxqAotJy0V6bpFmgyEiImqkmADVM2YGEjRvYggAuJjIZjAiIqLawASoHiobDn+RzWBERES1gglQPVSWALEjNBERUe1gAlQPeTwaCRaZwAkRiYiIagMToHqopY0xjKS6yC2S42YyJ0QkIiKqaUyA6iEdsQgdHU0BsB8QERFRbWACVE+xHxAREVHtYQJUT3lwRmgiIqJawwSonvJwLK0BiknNRUYeJ0QkIiKqSUyA6ilzQwmaW5VNiJih2WCIiIgaGSZA9Zj7o2awi/FsBiMiIqpJTIDqsf86QmdoNhAiIqJGhglQPVaWAEUmckJEIiKimsQEqB5rZWsMA4kOcgpLcDslR9PhEBERNRpMgOoxHbEIHZuaAeBweCIioprEBKie83Q2AwBcZAJERERUY5gA1XPsCE1ERFTzmADVc+6OZgCA2yk5yMwr1mwwREREjQQToHrO0kgKF0sDAMDFRDaDERER1QQmQA1AWTMYV4YnIiKqGUyAGgAujEpERFSzmAA1AB6PTYio4ISIREREz40JUAPg9mhCxOyCEkSnckJEIiKi58UEqAHQ1RGjQ1NTAGwGIyIiqglMgBqIsmawiPgMzQZCRETUCDABaiD+mxCRNUBERETPiwlQA1E2EuxWSg4y8zkhIhER0fNgAtRAWBlJ4WRROiHipcQMzQZDRETUwDEBakA8OR8QERFRjagXCdDKlSvh4uICmUwGX19fnD17tkrHbd++HSKRCEOHDq20zJtvvgmRSITly5fXTLAa5OnMGaGJiIhqgsYToB07diA4OBiLFi1CREQEOnbsCH9/f6SkpDz1uLi4OMyZMwc9evSotMxvv/2G06dPw97evqbD1oj/lsRI54SIREREz0HjCdCyZcswZcoUBAUFoU2bNli9ejUMDAywYcOGSo+Ry+UYN24cPvzwQzRv3rzCMnfv3sX06dOxZcsW6Onp1Vb4daqVrTFkemJkFZQgJo0TIhIREVWXRhOgoqIiXLhwAX5+fsptYrEYfn5+CA8Pr/S4JUuWwNraGpMmTapwv0KhQEBAAObOnYu2bds+M47CwkJkZWWpPOojPR0xOjQ1A8D5gIiIiJ6HRhOgtLQ0yOVy2NjYqGy3sbFBUlJShcecOHEC69evx9q1ays972effQZdXV3MmDGjSnGEhITA1NRU+XB0dKz6RdQxZTNYIjtCExERVZfGm8DUkZ2djYCAAKxduxZWVlYVlrlw4QK++eYbbNq0CSKRqErnnT9/PjIzM5WPxMTEmgy7RilXhmcNEBERUbXpavLJraysoKOjg+TkZJXtycnJsLW1LVc+OjoacXFxGDx4sHKbQqEAAOjq6iIqKgrHjx9HSkoKnJyclGXkcjlmz56N5cuXIy4urtx5pVIppFJpDV1V7SqrAbqZko2sgmKYyBpH/yYiIqK6pNEaIIlEAi8vL4SGhiq3KRQKhIaGokuXLuXKu7m54cqVK4iMjFQ+hgwZgt69eyMyMhKOjo4ICAjA5cuXVcrY29tj7ty5OHjwYF1eXq1oYiyFo4U+BAG4nJip6XCIiIgaJI3WAAFAcHAwAgMD4e3tDR8fHyxfvhy5ubkICgoCAIwfPx4ODg4ICQmBTCZDu3btVI43MzMDAOV2S0tLWFpaqpTR09ODra0tWrVqVfsXVAc8HM2R+DAfEQnp6P5CxU2BREREVDmNJ0CjRo1CamoqFi5ciKSkJLi7u+PAgQPKjtEJCQkQixtUV6Va5+lkhr2X7nFGaCIiomoSCYLAGfWekJWVBVNTU2RmZsLExETT4ZRz+U4Ghqw4CVN9PVz8oB/E4qp19iYiImrM1Pn+ZtVKA9TazgRSXTEy84sR+yBX0+EQERE1OEyAGqDSCRFNAQAR8WwGIyIiUpfaCVCvXr3w008/IT8/vzbioSoqGw4fwYVRiYiI1KZ2AuTh4YE5c+bA1tYWU6ZMwenTp2sjLnoGj8cWRiUiIiL1qJ0ALV++HPfu3cPGjRuRkpKCnj17ok2bNvjyyy/LTWhItcfz0YzQN5OzkVNYotlgiIiIGphq9QHS1dXF8OHD8fvvv+POnTsYO3YsPvjgAzg6OmLo0KE4cuRITcdJT7A2kcHBTB8KAbiUmKHpcIiIiBqU5+oEffbsWSxatAhfffUVrK2tMX/+fFhZWeHll1/GnDlzaipGqoSn86N+QOwITUREpBa1E6CUlBR89dVXaNeuHXr06IHU1FRs27YNcXFx+PDDD7Fu3TocOnQIq1evro146TFlzWAXWQNERESkFrVngm7atClcXV0xceJETJgwAU2aNClXpkOHDujUqVONBEiVe7wjtCAIEIk4ISIREVFVqJ0AhYaGokePHk8tY2JigqNHj1Y7KKqaNo8mREzPK0ZsWi6aNzHSdEhEREQNgtpNYGXJT0pKCo4fP47jx48jJSWlxgOjZ5PoitHeoXRCxIucD4iIiKjK1E6AsrOzERAQAAcHB/Tq1Qu9evWCg4MDXn/9dWRmZtZGjPQUHo/6AXFhVCIioqpTOwGaPHkyzpw5g3379iEjIwMZGRnYt28fzp8/jzfeeKM2YqSn4IzQRERE6lO7D9C+fftw8OBBdO/eXbnN398fa9euRf/+/Ws0OHq2sqHwUUlZyCksgZFU7VtKRESkddSuAbK0tISpqWm57aampjA3N6+RoKjqbB6bEPHynQxNh0NERNQgqJ0Avf/++wgODkZSUpJyW1JSEubOnYsPPvigRoOjqnEvmw+IzWBERERVonZ7yapVq3D79m04OTnByckJAJCQkACpVIrU1FT88MMPyrIRERE1FylVytPJHH9evs8ZoYmIiKpI7QRo6NChtRAGPY/HZ4TmhIhERETPpnYCtGjRotqIg55DG3sTSHTEeJhbhPgHeXCxMtR0SERERPVatYcMXbhwAdevXwcAtG3bFh4eHjUWFKlHqquDdg4miEjIQERCOhMgIiKiZ1A7AUpJScHo0aMRFhYGMzMzAEBGRgZ69+6N7du3V7g2GNU+TydzZQI03LOppsMhIiKq19QeBTZ9+nRkZ2fj33//xcOHD/Hw4UNcvXoVWVlZmDFjRm3ESFXw38KoGZoNhIiIqAFQuwbowIEDOHz4MFq3bq3c1qZNG6xcuRIvvfRSjQZHVefpbAYAuJGUjbyiEhhIOCEiERFRZdSuAVIoFNDT0yu3XU9PDwqFokaCIvXZmerDzlQGuULApUSuyUZERPQ0aidAffr0wcyZM3Hv3j3ltrt372LWrFno27dvjQZH6ilbF+xiIucDIiIiehq1E6AVK1YgKysLLi4ucHV1haurK5o1a4asrCx89913tREjVZFyZfj4DI3GQUREVN+p3VHE0dEREREROHz4MG7cuAEAaN26Nfz8/Go8OFLPfx2h0zkhIhER0VOolQAVFxdDX18fkZGR6NevH/r161dbcVE1tHMonRDxQW4REh/mw8nSQNMhERER1UtqNYHp6enByckJcrm8tuKh5yDV1UEbexMAQEQC+wERERFVRu0+QAsWLMD//vc/PHz4sDbioedU1hGaCRAREVHl1O4DtGLFCty+fRv29vZwdnaGoaHqsgtcAV6zPJ3NsOEkEyAiIqKnUTsBeuWVV9i5th4rqwG6fj8b+UVy6Et0NBwRERFR/aN2ArR48eJaCINqip2pDDYmUiRnFeLynQz4NrfUdEhERET1jtp9gJo3b44HDx6U256RkYHmzZvXSFBUfSKR6LF+QBmaDYaIiKieUjsBiouLq3AUWGFhIe7cuVMjQdHz8XxsPiAiIiIqr8pNYHv37lX+/8GDB2Fqaqr8t1wuR2hoKJo1a1az0VG1KGeETsjghIhEREQVqHICNHToUAClTSyBgYEq+/T09ODi4oKvvvqqRoOj6mnnYAo9HRHScgpxJz0fjhacEJGIiOhxVU6AylZ6b9asGc6dOwcrK6taC4qej0xPB23sTXEpMQMRCelMgIiIiJ6gdh+g2NjYGk9+Vq5cCRcXF8hkMvj6+uLs2bNVOm779u0QiUTK2imgdLmO//u//0P79u1haGgIe3t7jB8/XmX1em3g4WgGALjIjtBERETlqD0MHgBCQ0MRGhqKlJQUZc1QmQ0bNqh1rh07diA4OBirV6+Gr68vli9fDn9/f0RFRcHa2rrS4+Li4jBnzhz06NFDZXteXh4iIiLwwQcfoGPHjkhPT8fMmTMxZMgQnD9/Xq3YGjJPZ3NsOhXHCRGJiIgqIBIEQVDngA8//BBLliyBt7c37OzsynWw/e2339QKwNfXF506dcKKFSsAlDa1OTo6Yvr06Zg3b16Fx8jlcvTs2RMTJ07E8ePHkZGRgT179lT6HOfOnYOPjw/i4+Ph5OT0zJiysrJgamqKzMxMmJiYqHU99cWd9Dx0/+wodMUiXP3QHzI9TohIRESNmzrf32rXAK1evRqbNm1CQEBAtQMsU1RUhAsXLmD+/PnKbWKxGH5+fggPD6/0uCVLlsDa2hqTJk3C8ePHn/k8mZmZEIlEMDMzq3B/YWEhCgsLlf/Oysqq+kXUUw5m+rA2liIluxBX7maik4uFpkMiIiKqN9TuA1RUVISuXbvWyJOnpaVBLpfDxsZGZbuNjQ2SkpIqPObEiRNYv3491q5dW6XnKCgowP/93/9hzJgxlWaDISEhMDU1VT4cHR3Vu5B6SCQS/TccPp7NYERERI9TOwGaPHkytm7dWhuxPFN2djYCAgKwdu3aKnXELi4uxsiRIyEIAlatWlVpufnz5yMzM1P5SExMrMmwNYYrwxMREVVM7SawgoICrFmzBocPH0aHDh2gp6ensn/ZsmVVPpeVlRV0dHSQnJyssj05ORm2trblykdHRyMuLg6DBw9WbivrhK2rq4uoqCi4uroC+C/5iY+Px5EjR57aFiiVSiGVSqscd0Ph6fzfkhicEJGIiOg/aidAly9fhru7OwDg6tWrKvvU/YKVSCTw8vJCaGiocii7QqFAaGgo3nnnnXLl3dzccOXKFZVt77//PrKzs/HNN98om67Kkp9bt27h6NGjsLTUzgVB2zuYQlcsQmp2Ie5m5KOpOecDIiIiAqqRAB09erRGAwgODkZgYCC8vb3h4+OD5cuXIzc3F0FBQQCA8ePHw8HBASEhIZDJZGjXrp3K8WUdm8u2FxcXY8SIEYiIiMC+ffsgl8uV/YksLCwgkUhqNP76rHRCRBNcvpOJiIQMJkBERESPVGseoMqkpKQ8de6eiowaNQqpqalYuHAhkpKS4O7ujgMHDig7RickJEAsrnpXpbt37yrXLSurqSpz9OhRvPjii2rF19B5OpmXJkDx6RjS0V7T4RAREdULVZ4HyMDAAPHx8WjSpAkAYNCgQVi3bh3s7OwAlPbbsbe3r3Cl+IamMcwDVOb3yLuYuT0SHR3N8Pvb3TQdDhERUa1R5/u7ylUrBQUFeDxXOnbsGPLz81XKqDmnItWBspFg1+5loqC44SenRERENUHtYfBPw1FG9U9Tc31YGUlRLBdw9W6mpsMhIiKqF2o0AaL6RyQSwbNsQkTOB0RERARAjQRIJBKp1PA8+W+qvzweNYNxZXgiIqJSVR4FJggCWrZsqUx6cnJy4OHhoRyhxf4/9dfjNUCcEJGIiEiNBGjjxo21GQfVog5NzaArFiE5qxD3MgvgYKav6ZCIiIg0qsoJUGBgYG3GQbVIX6KD1nYmuHI3ExcT0pkAERGR1mMnaC3x38rwGRqNg4iIqD5gAqQluDI8ERHRf5gAaYmyBOhfTohIRETEBEhbOFrow9JQgmK5gH/vZWk6HCIiIo1iAqQlRCLRY/MBsRmMiIi0m9oJ0KuvvorPPvus3PbPP/8cr732Wo0ERbXD09kMAPsBERERqZ0AHTt2DAMHDiy3fcCAATh27FiNBEW1w8ORM0ITEREB1UiAcnJyIJFIym3X09NDVhb7ltRnHR1NoSMW4X5mAe5n5ms6HCIiIo1ROwFq3749duzYUW779u3b0aZNmxoJimqHgUQXbrbGADgfEBERabcqzwRd5oMPPsDw4cMRHR2NPn36AABCQ0Oxbds27Ny5s8YDpJrl6WSOf+9lISIhHYM62Gk6HCIiIo1QuwZo8ODB2LNnD27fvo1p06Zh9uzZuHPnDg4fPoyhQ4fWQohUk8pmhOZIMCIi0mZq1wABwKBBgzBo0KCajoXqQNmEiFfvZqGwRA6pro6GIyIiIqp7nAdIyzhbGsDCUIIiuYITIhIRkdaqUgJkYWGBtLQ0AIC5uTksLCwqfVD9JhKJ4OFoBoDD4YmISHtVqQns66+/hrFx6eih5cuX12Y8VAc8nc0ReiMFEQnpmIRmmg6HiIiozlUpAQoMDKzw/6lhUnaEjmdHaCIi0k7V6gQNACkpKUhJSYFCoVDZ3qFDh+cOimpXx6ZmEIuAe5kFSMosgK2pTNMhERER1Sm1E6ALFy4gMDAQ169fhyAIKvtEIhHkcnmNBUe1w1Cqi1a2Jrh+PwsXE9IxoD3nAyIiIu2idgI0ceJEtGzZEuvXr4eNjQ1EIlFtxEW1zNPJDNfvl06IyASIiIi0jdoJUExMDH799Ve0aNGiNuKhOuLpZI4tZxIQwZFgRESkhdSeB6hv3764dOlSbcRCdaisI/SVu5koKlE8vTAREVEjo3YN0Lp16xAYGIirV6+iXbt20NPTU9k/ZMiQGguOak8zK0OYG+ghPa8Y1+5nwf3R3EBERETaQO0EKDw8HCdPnsRff/1Vbh87QTccIpEIHk7mOHIjBRHx6UyAiIhIq6jdBDZ9+nS8/vrruH//PhQKhcqDyU/D4vmoGSyCC6MSEZGWUTsBevDgAWbNmgUbG5vaiIfqkMejhVG5JAYREWkbtROg4cOH4+jRo7URC9Wxjo6lEyLezchHSlaBpsMhIiKqM2r3AWrZsiXmz5+PEydOoH379uU6Qc+YMaPGgqPaZSTVRUsbY9xIykZEQjr6t+N8QEREpB1EwpPTOT9Ds2aVL54pEokQExPz3EFpWlZWFkxNTZGZmQkTExNNh1Or5u++gm1nE/BGz+aYP7C1psMhIiKqNnW+v9WuAYqNja12YFT/eDqZYdvZBHaEJiIiraJ2H6AyRUVFiIqKQklJSU3GQ3XM07m0I/TlO5wQkYiItIfaCVBeXh4mTZoEAwMDtG3bFgkJCQBKh8d/+umnNR4g1a5mloYw1ddDYYkC1+9naTocIiKiOqF2AjR//nxcunQJYWFhkMlkyu1+fn7YsWNHtYJYuXIlXFxcIJPJ4Ovri7Nnz1bpuO3bt0MkEmHo0KEq2wVBwMKFC2FnZwd9fX34+fnh1q1b1YqtsROLRcplMS6yGYyIiLSE2gnQnj17sGLFCnTv3l1lJfi2bdsiOjpa7QB27NiB4OBgLFq0CBEREejYsSP8/f2RkpLy1OPi4uIwZ84c9OjRo9y+zz//HN9++y1Wr16NM2fOwNDQEP7+/igo4FDving+mg+IC6MSEZG2UDsBSk1NhbW1dbntubm5KglRVS1btgxTpkxBUFAQ2rRpg9WrV8PAwAAbNmyo9Bi5XI5x48bhww8/RPPmzVX2CYKA5cuX4/3338crr7yCDh064KeffsK9e/ewZ88etePTBv8lQKwBIiIi7aB2AuTt7Y0///xT+e+ypGfdunXo0qWLWucqKirChQsX4Ofn919AYjH8/PwQHh5e6XFLliyBtbU1Jk2aVG5fbGwskpKSVM5pamoKX1/fSs9ZWFiIrKwslYc26ehoCpEIuJOej5Rs1pIREVHjp/Yw+E8++QQDBgzAtWvXUFJSgm+++QbXrl3DqVOn8M8//6h1rrS0NMjl8nLLatjY2ODGjRsVHnPixAmsX78ekZGRFe5PSkpSnuPJc5bte1JISAg+/PBDtWJvTIxlemhpbYyo5GxcTMiAf1tbTYdERERUq9SuAerevTsiIyNRUlKC9u3b49ChQ7C2tkZ4eDi8vLxqI0al7OxsBAQEYO3atbCysqqx886fPx+ZmZnKR2JiYo2du6HwdDYDwGYwIiLSDmrXAAGAq6sr1q5d+9xPbmVlBR0dHSQnJ6tsT05Ohq1t+VqI6OhoxMXFYfDgwcptCkXp3DW6urqIiopSHpecnAw7u/+WdkhOToa7u3uFcUilUkil0ue9nAbNw9Ec284m4mJ8hqZDISIiqnVq1wDp6OhUOELrwYMH0NHRUetcEokEXl5eCA0NVW5TKBQIDQ2tsD+Rm5sbrly5gsjISOVjyJAh6N27NyIjI+Ho6IhmzZrB1tZW5ZxZWVk4c+aM2n2UtElZDdDluxkolnNCRCIiatzUrgGqbOmwwsJCSCQStQMIDg5GYGAgvL294ePjg+XLlyM3NxdBQUEAgPHjx8PBwQEhISGQyWRo166dyvFmZmYAoLL93XffxUcffYQXXngBzZo1wwcffAB7e/ty8wXRf5pbGcFEpousghLcuJ+N9k1NNR0SERFRralyAvTtt98CKB31tW7dOhgZGSn3yeVyHDt2DG5ubmoHMGrUKKSmpmLhwoVISkqCu7s7Dhw4oOzEnJCQALFYvYqq9957D7m5uZg6dSoyMjLQvXt3HDhwQGXiRlJVOiGiOf65mYqIhHQmQERE1KhVeTX4slXg4+Pj0bRpU5XmLolEAhcXFyxZsgS+vr61E2kd0qbV4B+3/PBNLD98C0Pd7bF8tIemwyEiIlJLrawGX7YKfO/evbF7926Ym5s/X5RU73BGaCIi0hZqd4I+evSoSvIjl8sRGRmJ9HQOn27o3J3MIBIBCQ/zkJZTqOlwiIiIao3aCdC7776L9evXAyhNfnr27AlPT084OjoiLCyspuOjOmQi00OLJqV9uyLimdASEVHjpXYCtHPnTnTs2BEA8McffyAuLg43btzArFmzsGDBghoPkOpWWTPYxcQMzQZCRERUi9ROgB48eKCcbHD//v147bXX0LJlS0ycOBFXrlyp8QCpbilnhGYNEBERNWJqJ0A2Nja4du0a5HI5Dhw4gH79+gEA8vLy1J4Ikeofj0c1QJfvZKKEEyISEVEjpXYCFBQUhJEjR6Jdu3YQiUTKVdfPnDlTrXmAqH5p0cQIxjJd5BfLcSMpW9PhEBER1Qq1Z4JevHgx2rVrh8TERLz22mvKNbR0dHQwb968Gg+Q6pZYLIK7oxmO30rDxYR0tHPghIhERNT4VGsx1BEjRpTbFhgY+NzBUP3g6WSO47fSEJGQgQAun0ZERI1QlRKgb7/9FlOnToVMJlMuiVGZGTNm1EhgpDkeTmYAgIgEdoQmIqLGqUpLYTRr1gznz5+HpaWlckmMCk8mEiEmJqZGA9QEbV0Ko0xmXjE6LjkEALjwvh8sjaQajoiIiOjZanwpjLJlMJ78f2qcTA300MLaCLdTcnAxIQN+bWw0HRIREVGNUnsU2OMEQUAV11KlBsbD0QwAm8GIiKhxqlYCtH79erRr1w4ymQwymQzt2rXDunXrajo20iBP50czQnNhVCIiaoTUHgW2cOFCLFu2DNOnT0eXLqVDhMLDwzFr1iwkJCRgyZIlNR4k1b2yJTEu3clAiVwBXZ3nqiwkIiKqV9ROgFatWoW1a9dizJgxym1DhgxBhw4dMH36dCZAjcQL1kYwluoiu7AEUcnZaGvP+YCIiKjxUPtnfXFxMby9vctt9/LyQklJSY0ERZonFovQUdkPKEOjsRAREdU0tROggIAArFq1qtz2NWvWYNy4cTUSFNUPno/mA7rIjtBERNTIVGsm6PXr1+PQoUPo3LkzgNJ1wBISEjB+/HgEBwcryy1btqxmoiSN8GBHaCIiaqTUToCuXr0KT09PAEB0dDQAwMrKClZWVrh69aqynEgkqqEQSVPKhsLHpuXiYW4RLAwlmg2IiIiohqidAB09erQ24qB6yMxAguZNDBGTmovIxHT0ceOEiERE1DjU6NjmlJSUmjwd1QNlw+Ej4jM0GwgREVENqnICZGBggNTUVOW/Bw0ahPv37yv/nZycDDs7u5qNjjROmQCxIzQRETUiVU6ACgoKVJa9OHbsGPLz81XKcFmMxqdsZfhLiRmQK3h/iYiocajRJjB2fG58WtoYw0iqi9wiOW4mZ2s6HCIiohrB9Q3oqXTEInR0LJ0Fms1gRETUWFQ5ARKJRCo1PE/+mxovD0d2hCYiosalysPgBUFAy5YtlUlPTk4OPDw8IBaLlfupcfJ0NgMAXExkDRARETUOVU6ANm7cWJtxUD1WVgMUk5qLjLwimBlwQkQiImrYqpwABQYG1mYcVI+ZG0rQzMoQsWm5uJiQgd5u1poOiYiI6LmwEzRViQcXRiUiokaECRBVyX8TImZoNhAiIqIawASIqqQsAYrkhIhERNQIMAGiKmlpYwQDiQ5yCktwK4UTIhIRUcPGBIiqRFdHjI5NzQAAF9kMRkREDVyVR4GVkcvl2LRpE0JDQ5GSkgKFQqGy/8iRIzUWHNUvns5mCI95gIj4dIzxcdJ0OERERNWmdgI0c+ZMbNq0CYMGDUK7du04G7QWUc4IzZFgRETUwKmdAG3fvh2//PILBg4cWBvxUD1WNhQ+OjUXmXnFMDXQ02xARERE1aR2HyCJRIIWLVrUWAArV66Ei4sLZDIZfH19cfbs2UrL7t69G97e3jAzM4OhoSHc3d2xefNmlTI5OTl455130LRpU+jr66NNmzZYvXp1jcWrzSyNpHCxNADAZTGIiKhhUzsBmj17Nr755psaWftrx44dCA4OxqJFixAREYGOHTvC398fKSkpFZa3sLDAggULEB4ejsuXLyMoKAhBQUE4ePCgskxwcDAOHDiAn3/+GdevX8e7776Ld955B3v37n3ueInzARERUeMgEtTMZIYNG4ajR4/CwsICbdu2hZ6eajPI7t27q3wuX19fdOrUCStWrAAAKBQKODo6Yvr06Zg3b16VzuHp6YlBgwZh6dKlAIB27dph1KhR+OCDD5RlvLy8MGDAAHz00UdVOmdWVhZMTU2RmZkJExOTKl+PNtgcHocPfv8XPV6wwuZJvpoOh4iISEmd72+1a4DMzMwwbNgw9OrVC1ZWVjA1NVV5VFVRUREuXLgAPz+//4IRi+Hn54fw8PBnHi8IAkJDQxEVFYWePXsqt3ft2hV79+7F3bt3IQgCjh49ips3b+Kll16q9FyFhYXIyspSeVDFPMomREzIgIITIhIRUQOldifomloVPi0tDXK5HDY2NirbbWxscOPGjUqPy8zMhIODAwoLC6Gjo4Pvv/8e/fr1U+7/7rvvMHXqVDRt2hS6uroQi8VYu3atSpL0pJCQEHz44YfPf1FawM3WGPp6OsguLMHt1By0tDHWdEhERERqa3ATIRobGyMyMhLnzp3Dxx9/jODgYISFhSn3f/fddzh9+jT27t2LCxcu4KuvvsLbb7+Nw4cPV3rO+fPnIzMzU/lITEysgytpmHR1xOjQtLSmLyKeHaGJAEChEJBdUIz7mfm4lZyNiIR0pOUUajosInoKtWuAAGDXrl345ZdfkJCQgKKiIpV9ERERVTqHlZUVdHR0kJycrLI9OTkZtra2lR4nFouVo9Dc3d1x/fp1hISE4MUXX0R+fj7+97//4bfffsOgQYMAAB06dEBkZCS+/PJLlea2x0mlUkil0irFTYCnsznOxD7E+fh0jOaEiNSAyRUCcgpLSh8FJcgpLEZ2wX//zi4oQfZj+3IKS8rtLzv+SRIdMVa97om+rW0qeGYi0jS1E6Bvv/0WCxYswIQJE/D7778jKCgI0dHROHfuHN5+++0qn0cikcDLywuhoaEYOnQogNJO0KGhoXjnnXeqfB6FQoHCwtJfWsXFxSguLoZYrFqxpaOjU27Gaqq+7i2ssCosGn9duY8PXm4DU33OB0R1q0SuQG6hHFkFxSoJjEqyUlCCrILHk5uy/cXKbblF8hqNS1csgrFMFzpiEdJyivDmzxewYqwn/NtW/qOOiDRD7QTo+++/x5o1azBmzBhs2rQJ7733Hpo3b46FCxfi4cOHap0rODgYgYGB8Pb2ho+PD5YvX47c3FwEBQUBAMaPHw8HBweEhIQAKO2r4+3tDVdXVxQWFmL//v3YvHkzVq1aBQAwMTFBr169MHfuXOjr68PZ2Rn//PMPfvrpJyxbtkzdS6VKdHW1RCsbY0QlZ2PrmQS89aKrpkOiBiynsAR30vOQ+DAfiQ/z8DC3CDmFJaXJzWM1LI8nOPnFNZu46OmIYCzTg7FMF0bS0ofy/2W6MJKW7nt8v5FMF8ZSvUf7S/dJdcUQiUQolivw7o5I/Hn5Pt7eEoFvx3hgYHu7Go2ZiJ6P2glQQkICunbtCgDQ19dHdnbpyuABAQHo3Lmzckh7VYwaNQqpqalYuHAhkpKS4O7ujgMHDig7RickJKjU5uTm5mLatGm4c+cO9PX14ebmhp9//hmjRo1Sltm+fTvmz5+PcePG4eHDh3B2dsbHH3+MN998U91LpUqIRCJM7tEMc3ddxsaTsZjY3QVSXR1Nh0X1VGGJHHfT85GYXprgJKbn4c7DfCSm5yHxYR7S84qrfW6prviJREW3NJF57N+liUrFCUvZ/pr++9XTEeObUe7QFYvwe+Q9TN92EXKFgMEd7Wv0eYio+tSeB6h58+b49ddf4eHhAW9vb0yZMgVvvPEGDh06hNGjR6tdC1QfcR6gZysqUaDH50eQnFWIL0Z0wGvejpoOiTRErhCQlFVQmtw8zENiej7uPEp0Eh/mIzm7AM/6lDHV14OjhT4czQ1gbSyFsayCROVRsmIi04ORVBeGUl1IdOv3OA65QsB7uy7j14g7EIuAr0Z2xDCPppoOi6jRUuf7W+0aoD59+mDv3r3w8PBAUFAQZs2ahV27duH8+fMYPnx4tYOmhkWiK0ZQt2b49K8bWHs8BiO8mnJh3EZKEAQ8yC1SJjeJD/P+a7JKz8O9jHwUy5+e4ejr6SgTHEcLAzQ110dTc4PSbRYGMJE1zn5kOmIRvhjRAbpiEXacT0TwL5dQIhf4g4GoHlC7BkihUEChUEBXtzR32r59O06dOoUXXngBb7zxBiQSSa0EWpdYA1Q1WQXF6BpyBDmFJdg4oRN6u1lrOiSqpqyCYpVmqTuPNVclPsx/Zp8bXbEIDuZlCU5ZcmMAR/PSBMfSUKLVCbJCIeCD369iy5kEiERAyLD2HEFJVAvU+f5WOwHSBkyAqu6jfdew7kQsOje3wPapXTQdDlWioFhemtSk5z1qnlJNcDLzn94PRyQCbE1kcDR/VHvzWHLjaGEAWxMZdMTam+BUhSAIWLz3X/wYHg8AWDq0HQI6O2s4KqLGpVabwADg+PHj+OGHHxAdHY1du3bBwcEBmzdvRrNmzdC9e/dqBU0N08TuzbDpVBxOxzzE5TsZ6NDUTNMhaSW5QsC9jPxyHYzLEp2U7GdPymdhKIGjMrkxUGmysjeTsaP7cxKJRFg8pC10dcRYfyIWH+y5CrlcgQndmmk6NCKtpHYC9OuvvyIgIADjxo3DxYsXlXPwZGZm4pNPPsH+/ftrPEiqv+zN9DG4oz1+u3gXa47FYMVYT02HpHUe5BRi8HcncC+z4KnlDCU6j/rfqCY3ZU1WRtJq/R4iNYhEIrw/qDV0dUT44Z8YLP7jGkoUAib3aK7p0Ii0jtqfeB999BFWr16N8ePHY/v27crt3bp1q/Jq69S4TOnRHL9dvIv9V+4j8WEeHC0MNB2SVllzPAb3MgugpyMqbaJ6vHnqsWTHzEBPq/vh1BcikQjz+rtBTyzGiqO38dGf11EsFzifFlEdUzsBenL19TKmpqbIyMioiZiogWljb4IeL1jh+K00rD8Ri8VD2mo6JK3xMLcImx/1KVn9uheXXWggRCIRZr/UEro6Iiw/fAufHbiBErkC0/u+oOnQiLSG2pNo2Nra4vbt2+W2nzhxAs2bsxpXW03tWXrvd5xLRHpu0TNKU01ZezwGeUVytHcwRR+OwmtQRCIR3vVriTkvtQQAfPX3TXz9901wXApR3VA7AZoyZQpmzpyJM2fOQCQS4d69e9iyZQvmzJmDt956qzZipAagewsrtLEzQX6xHFvOxGs6HK2QnluEn07FAQBm9H2BzVsN1Dt9XsC8AW4AgG9Cb+HLQ1FMgojqgNpNYPPmzYNCoUDfvn2Rl5eHnj17QiqVYs6cOZg+fXptxEgNgEgkwtSezfHujkhsOhWPyT2aQ6bHUUO1ad2JGOQWydHW3gR+rVn705C92csVumIRPvrzOlYejUaJXMC8AW5Maolqkdo1QCKRCAsWLMDDhw9x9epVnD59GqmpqVi6dGltxEcNyKAOdrA3lSEtpxC/Xbyr6XAatfTcImw6GQeAtT+NxeQezbF4cBsAwA/HYrB033XWBBHVomovpCORSNCmTRv4+PjAyMioJmOiBkpPR4yJ3UvnNFl7PAYKBT+8a8v6E7HILZKjtZ0JXmrDjs+NxYRuzfDR0HYAgA0nY7F4779MgohqSZWbwCZOnFilchs2bKh2MNTwjfZxwjehtxCTmovQGynoxy/nGpeRV4RNj/r+zOzbgrU/jczrnZ2hKxZh/m9X8GN4PIoVAj56pR3EnGmbqEZVOQHatGkTnJ2d4eHhwV8kVCkjqS7G+Tpj9T/RWHMsmglQLdhwIhY5hSVwszXGS21sNR0O1YLRPk7Q1RFj7q5L2HomAXK5gJDh7ZkEEdWgKidAb731FrZt24bY2FgEBQXh9ddfh4WFRW3GRg1UUDcXrD8Rg3Nx6YhISIenk7mmQ2o0MvOKsfGxvj/8Qmy8Rng1ha5YhOBfIrHjfCKKFQp8MaIj11zTQg9zi3D9fhau389CYYkCozs5wtJIqumwGjy1FkMtLCzE7t27sWHDBpw6dQqDBg3CpEmT8NJLLzWqanguhvr85u68hJ0X7qB/W1usDvDSdDiNxtd/38Q3obfQysYYf83swQRIC/xx6R7e3REJuULAK+72+Oq1jtDVqXb3TarHSuQKxKbl4tr9LFy/n43r97NwIykLyVmqa/m5WBrgx4k+cLY01FCk9VedrAYfHx+PTZs24aeffkJJSQn+/fffRtMZmgnQ87uZnI2Xvj4GkQg4MvtFNLPiG/V5ZeYXo/tnR5BdUIKVYz0xqIOdpkOiOvLXlfuYvu0iShQCBnWww/JR7tBjEtSgZeQV4dr9LNx4lOhcT8rCzeQcFJUoKizvbGmA1rYmuHI3E3cz8mFlJMHGCT5o39S0jiOv32p9NXgAEIvFEIlEEAQBcrm8uqehRqqljTF6t2qCo1GpWH8iBh8Nba/pkBq8TSfjkF1QgpY2RhjQjn1/tMmA9nb4XizC21sj8Ofl+5DLBXw7xgMSXSZB9Z1cISA2LVfZhHUjqTThuV/J4sUGEh242RqjtZ3Jo4cxWtmaKBcrTskqwISN53DtfhZGrwnHqte90LNlk7q8pEaj2k1gJ06cwMsvv4ygoCD0798fYnHjeSOyBqhmhEc/wJi1pyHVFePUvD5ss34OWQXF6P7pEWQVlOC7MR4Y3NFe0yGRBoReT8ZbP0egSK6AX2sbrBznAakuJxytLzLzi3HjUaJz/X42ridlISopG4WV1Oo4WujDzbY00WljV5r0OJobPLNpO7ugGG/+fAEnbz+ArliEL17rgGEeTWvjkhqcWmkCmzZtGrZv3w5HR0dMnDgR48aNg5WVVY0EXN8wAaoZgiDglZUncflOJmb2fQGz+rXUdEgN1neht/DV3zfRwtoIB9/tyY6wWiwsKgVTN19AUYkCvVs1warXvTjreh2TKwTEP8jF9fvZuJH0X8JzNyO/wvL6ejpopazVKf1vK1tjmMj0qh1DUYkCc3Zewt5L9wAA8wa44Y2ezRtVf9zqqJUESCwWw8nJCR4eHk99gXfv3q1etPUQE6Ca88ele5i+7SLMDfRwal5f6Ev4Qa2u7IJidP/sKDLzi/HNaHe84u6g6ZBIw07cSsPkn86hoFiBHi9YYe14byZBtSS7oFjZbFWW6EQlZSO/uOKuHw5m+sokp7WdCdxsjeFsaVgrP1oUCgEhf13H2uOxAEpH4H4wqI1WD46olT5A48eP1/rMktQ3oJ0tmprr4056PnZF3EFAZ2dNh9Tg/HgqDpn5xXBtYoiXO7Dpi4DuL1hh4wQfTNx0DsdvpWHSj+ewbnwn/sB4DgqFgISHebiRlIVr9/9LeO6kV1yrI9UVw83W+FETVmnC42ZnAlP96tfqqEssFmHBoDawMZHhoz+vY+PJOKRkF2LZyI5sGq2Cao8Ca8xYA1SzNp2MxeI/rsHZ0gBHZr/I5hs15BSWoPtnR5CRV4zlo9wx1IO1P/Sfs7EPEbTxLHKL5PBtZoENEzrBUFrtsS1aI6ewBFGPEp2yPjtRSdnILaq4VsfOVKZsvirrs9PMqnZqdarr98i7mLPzEorlAjo3t8Ca8d7P1cTWUNXJMPjGjAlQzcorKkHXT0u/xFeN88SA9hy+XVUrj97GFwej0NzKEH8H96pXH7hUP1yIf4jADeeQU1iCTi7m2BjkoxwxRKUu38nAkRspylFY8Q/yKiwn0RWjpY0RWj9KctzsjNHa1gTmhpI6jrh6Tt5OwxubLyhnit8U5ANbU5mmw6pTTICeExOgmvfVoSh8d+Q23B3N8Nu0rmxOrYLcR7U/6XnFWDayI4Z7cpQHVSwyMQMB688gu6AEHk5m+HGij1b++n9cbmEJ9l66hy1n4nH1bla5/TYm0kd9dEprdto8qtVp6JNM/nsvExM2nkNqdiEczPTx48ROaGFtrOmw6gwToOfEBKjmpWYXottnR1BUosDON7ugkwuXUXmWVWHR+OzADbhYGuBwcK8G/8FMtevKnUy8vv4MMvOL0bGpKX6a6AtTA+1Lgq7fz8LWMwn47eJd5BSWAAAkOmL0a2MDDyczZedkiwZSq1MdiQ/zELjhLGLScmFmoIf1gd7wctaOz1wmQM+JCVDtmL/7MradTYRfaxusC/TWdDj1Wm5hCXp8fhQPc4vw1Wsd8aoXa3/o2f69l4nX151Bel4x2jmYYPNE3wbTfPM8Corl2H/lPracScCF+HTldhdLA4z1dcIIL8dGnfBU5GFuESZuOofIxAxIdcVYMdZTKxanZgL0nJgA1Y7o1Bz4LfsHggAcDu6FFtaNY+mU2vDDP9EI+Yu1P6S+G0lZGLf2DB7kFqG1nQl+nuTTaCchjU7NwdYzCdh14Q4y84sBALpiEfq1scE4X2d0dbXU6iHheUUleGfrRRy5kQKxCPhoaHuM9XXSdFi1Sp3vb36qUp1xbWIEv9alv0DWHY/RcDT1V15RCdYcK3193u7dgskPqcXN1gTbp3aGlZEU1+9nYezaM0jLKXz2gQ1EUYkC+y7fw5g1p9H3q3+w/kQsMvOL4WCmjzkvtcSpeX2w6nUvdH/BSquTHwAwkOhiTYAXRno3hUIA/vfbFXz9902w3qMUa4AqwBqg2nMu7iFeWx0OiY4YJ+b1hrWxdo1QqIq1x2Lw8f7rcLIwwJHZrP2h6rmdkoOxa08jJbsQLayNsHWyL6xNGu77LfFhHradTcAv5xORllMEABCJgD6trDGusxN6tbTmKMlKCIKAr/++iW+P3AYAjPFxxNJX2jXKz5Y6WQyVqDq8nc3h4WSGiwkZ+OlUPOb4t9J0SPVKfpEcPxyLBgC8w9ofeg4trI2w440uGLv2NG6n5GD0mtPYOqVzgxoWXSJX4GhUKracicc/N1NR9nPd2liKUZ0cMaqTI5qaG2g2yAZAJBIh+KVWsDaRYeHvV7HtbCJSswvx3RhPrZ48kzVAFWANUO06cPU+3vw5Aqb6ejg1rw8nbnvMuuMx+OjP63C00MeR2S9CjwkQPaeEB3kYs/Y07mbkw9nSANumdIa9mb6mw3qqpMwCbD+XgO1nE5GU9d+q6T1esMI4Xyf0bW3D90Y1Hfw3CTO2XURhiQIeTmZYH9ipUXUQZx8gqtf6tbGFi6UBMvOL8cv5RE2HU2/kF8mx+p9HfX9ebMEPeKoRTpYG2D61Mxwt9BH/IA+j1oQj8WHFEwFqkkIh4J+bqZj603l0++wIlh++haSsApgb6OGNns0RNudFbJ7ki/7t7PjeeA7+bW2xZbIvTPX1cDEhAyNWn6qXfw91gX9FVOd0xCJM6tEcALD+RCxK5AoNR1Q/bD2bgLSc0snLOOkh1SRHCwPsmNoFzpYGSHyYj9FrTiOhktmQ61paTiFWhUXjxS/DELjhLA5dS4ZcIcCnmQW+Ge2O0//ri/kDW8PFylDToTYa3i4W2PVmF9ibyhCTmotXV53CtXvlJ4ts7NgEVgE2gdW+gmI5un56BA9zi/DdGA8M7qjdi3wWFMvR4/OjSM0uxCfDGv9QVdKMpMwCjF17GjFpubAzlWHrlM5opoHEQhAEnIl9iC1nEnDg6n0Uy0u/hoxlunjVsynG+TrhBRvtmb1YU5IyCxC44SyikrNhLNXFDwFe6NrCStNhPRc2gVG9J9PTwfgupSvDrzkWo/XDMredTVBOXT+Ckx5SLbE1lWH71M5oYW2E+5kFGPVDOKJTc+rs+TPyirD+RCz8lv2D0WtO449L91AsF9DR0Qyfj+iAs//zw+IhbZn81BFbUxl+ebMLfJpZILuwBIEbz2LvpXuaDqvOsAaoAqwBqhsPc4vQ9dNQFBQrsHWKL7q6NuxfHtVVUCxHry+OIjmrEB8Pa4dxvs6aDokaudTsQry+7gyikrNhZSTFtim+tZZ0CIKAi4kZ2HI6Afsu30NhSWmTt4FEB6+4O2CcrxPaOZjWynNT1RQUyxH8SyT2X0kCAHzwchtM6t5Mw1FVD4fBU4NgYSjBa16O2Hw6HmuOxWhtArTjXCKSswphbyrDa16Omg6HtEATYym2TvHFuHVncCMpG6PXnMaWKb5ws625H3w5hSXYc/EutpxJwPX7//UvcbM1xuudnfGKuz2MtXzB1vpCpqeD78Z4oonRv/gxPB5L911DclYB5vV3a9STSWq8CWzlypVwcXGBTCaDr68vzp49W2nZ3bt3w9vbG2ZmZjA0NIS7uzs2b95crtz169cxZMgQmJqawtDQEJ06dUJCQkJtXgZV06TuzSASAWFRqYhKytZ0OHWusESOVWGl8/681bsFJLoaf0uSlrA0kmLblM5oa2+CB7lFGLPmNP69l/nc5716NxP/++0KfD8+jPf3XMX1+1mQ6orxqmdT7J7WFX/N7IHXOzsz+alndMQiLB7SFu/1L52bbc2xGAT/EomiksY7SEWjn7Y7duxAcHAwFi1ahIiICHTs2BH+/v5ISUmpsLyFhQUWLFiA8PBwXL58GUFBQQgKCsLBgweVZaKjo9G9e3e4ubkhLCwMly9fxgcffACZrOFM/qVNXKwM0b+tLQBgrRYuj/HLudJ5TuxMZRjpzb4/VLfMDSXYOrkzOjY1RXpeMcauPYMrd9RPgvKL5PjlfCJeWXkSL393AlvPJCC3SA7XJob44OU2OPO/vvhqZEd4OplDJGq8NQoNnUgkwrQXW+Cr1zpCVyzCnsh7mLjpHHIKSzQdWq3QaB8gX19fdOrUCStWrAAAKBQKODo6Yvr06Zg3b16VzuHp6YlBgwZh6dKlAIDRo0dDT0+vwpqhqmIfoLp1MSEdw74/BT0dEY6/16dBzVT7PApL5HjxizDczyzAklfaYnwXF02HRFoqq6AYgRvO4mJCBoxlutg8yRfujmbPPO5Wcja2nEnArxF3kF1Q+iWppyNC/3Z2GOfrBN9mFkx4GqiwqBRM2xKBvCI52tqbYGNQpwaxdFGDGAVWVFSECxcuwM/P779gxGL4+fkhPDz8mccLgoDQ0FBERUWhZ8+eAEoTqD///BMtW7aEv78/rK2t4evriz179jz1XIWFhcjKylJ5UN3xcDKHj4sFiuUCNp6K1XQ4dWbn+Tu4n1kAGxMpRnqz7w9pjolMDz9N9IG3szmyC0oQsO4MLsSnV1i2sESO3yPvYuQP4ej39TFsOhWH7IISOFro4//6uyF8fl98N8YDnZtbMvlpwF5sZY3tUzvD0lCCf+9l4dVVpxCblqvpsGqUxhKgtLQ0yOVy2NjYqGy3sbFBUlJSpcdlZmbCyMgIEokEgwYNwnfffYd+/foBAFJSUpCTk4NPP/0U/fv3x6FDhzBs2DAMHz4c//zzT6XnDAkJgampqfLh6Mgvo7o2pWfpxIhbTycgu6BYw9HUvqISBb4/Wrow4Vu9XCHT0971eKh+MJbp4ceJPvB9NCR6/PozOBv7ULk/Li0XIfuvo0vIEczcHomzsQ+hIxbhpTY2+HGiD/6Z0xtvvegKKyOpBq+CalKHpmb49a2ucLIonUDz1VWnEJmYoemwakyDGwVmbGyMyMhI5OTkIDQ0FMHBwWjevDlefPFFKBSlnbVeeeUVzJo1CwDg7u6OU6dOYfXq1ejVq1eF55w/fz6Cg4OV/87KymISVMf6ulnDtYkholNzseNcIiY/mim6sdp5IRH3MgtgbSzFaB9Oekj1g6FUFxuDOmHyj+dxKvoBAjecxeyXWuKfm6k4fitNWc7WRIbRPqWLkdqZ1u91xej5uFgZ4te3umLipnO4cjcTY9acxvfjPNHbzVrToT03jdUAWVlZQUdHB8nJySrbk5OTYWtrW+lxYrEYLVq0gLu7O2bPno0RI0YgJCREeU5dXV20adNG5ZjWrVs/dRSYVCqFiYmJyoPqllgswpRHSc+GE7EobsTLY5TW/pSO/HqTtT9UzxhIdLFhQif0eMEK+cVyfPTndRy/lQaRCHixVROsHe+NE//XG+/6tWTyoyWaGEuxfWpn9GzZBPnFckz+6XyjWMdRYwmQRCKBl5cXQkNDldsUCgVCQ0PRpUuXKp9HoVCgsLBQec5OnTohKipKpczNmzfh7MzJ5eq7oR4OsDKS4l5mAfZdbryzkf4acQd3M/LRxFjKJS+oXpLp6WDteG8M6mAHe1MZpr3oimNze2NTkA/6tbGBLhcj1TqGUl2sD/TGcA8HyBUC3tt1GSuO3GrQs/hrtAksODgYgYGB8Pb2ho+PD5YvX47c3FwEBQUBAMaPHw8HBwdlDU9ISAi8vb3h6uqKwsJC7N+/H5s3b8aqVauU55w7dy5GjRqFnj17onfv3jhw4AD++OMPhIWFaeISSQ0yPR0EdXPBFwej8MM/MRjq7tDoOlEWyxVY+ajvD2t/qD6T6elg5VhPTYdB9YiejhhfjewIaxMZVv8TjS8P3URyViEWD2kLnQY4YaJGE6BRo0YhNTUVCxcuRFJSEtzd3XHgwAFlx+iEhASIxf/90sjNzcW0adNw584d6Ovrw83NDT///DNGjRqlLDNs2DCsXr0aISEhmDFjBlq1aoVff/0V3bt3r/PrI/WN83XCyqO3cSMpG8dvpaFnyyaaDqlG7Y64gzvp+bAykmIca3+IqIERiUSYN8ANtiZSfLjvGjafjkdqdiGWj3ZvcD/ouBZYBTgPkGYt3vsvNp2KQ48XrLB5kq+mw6kxxXIF+nwVhsSH+Xh/UOtG39GbiBq3Py/fx6wdkSiSK9DJxRzrxneCqYFmZ/huEPMAEVVmUvdm0BGLcPxWWo1MzV9f/HbxLhIf5sPKSMIFT4mowRvUwQ4/TvSBsVQX5+LS8doPp3AvI1/TYVUZEyCqdxwtDDCwvR0AYO2xxrE8RsljfX+m9mwOfUnDqiomIqpIF1dL/PJmF9iYSHEzOQfDvz/VYNZ1ZAJE9dLUR81Df1y+j7sN6BdFZfZE3kP8gzxYGkrwemfW/hBR49HazgS7p3VDC2sjJGUV4LXVp3Am5oGmw3omJkBUL7VvaoouzS0hVwjYeKJhL49RIldgxZFbAEpnvDaQNLj5R4mInsrBTB+73uwCL2dzZBWUIGDDWfx15b6mw3oqJkBUb03tVVoLtO1sAjLzG+7yGHsv3UPcgzxYGEoQwNofImqkzAwk2DLZF/3a2KCoRIFpWyPwU3icpsOqFBMgqrdebNkErWyMkVskx9Yzlc/kXZ+VyBX47khp35/JPZrBUMraHyJqvGR6Olg1zhNjfZ0gCMDC3//FFwdv1MsJE5kAUb0lEomUi6RuPBmLwhK5hiNS3x+X7yE2LRdmBnoY38VF0+EQEdU6XR0xPh7aDsH9WgIAVh6Nxtxdl+vdEkdMgKheG9LRHjYmUqRkF2JvZMNaHkOuEJS1P1N6NIcRa3+ISEuIRCLM6PsCPh3eHmIRsOvCHUz56Tzyiko0HZoSEyCq1yS6YgR1awYAWHs8pl5Wo1Zm3+V7iEktrf0J7Oqi6XCIiOrcaB8nrAnwhkxPjLCoVIxZcxoPcgo1HRYAJkDUAIz1dYKRVBc3k3MQFpWq6XCqRK4Q8G1o6civyd2bsfaHiLSWXxsbbJ3SGeYGerh0JxOvrjqFhAd5mg6LCRDVfyYyPYzxcQQA/HAsWsPRVM2fV+4jOjUXpvqs/SEi8nQyx663usLBTB9xD/IwfNVJXLmj2Zn+mQBRgxDUrRl0xSKcjnmIy3cyNB3OUykUAr57VPszqXszGMs0uzYOEVF94NrECL9N64rWdiZIyynC92G3NRoPEyBqEOzN9DG4oz0AYE09Xx5j/9X7uJWSAxOZLiZ0c9F0OERE9Ya1iQw73uiMCV1d8OVrHTUaCxMgajCmPFoeY/+V+0h8qPn244ooHuv7M7F7M5iw9oeISIWJTA+Lh7TV+LxoTICowWhjb4IeL1hBIQDr6+nyGAf+TcLN5BwYy3SVo9eIiKj+YQJEDcrURxMj7jiXiPTcIg1Ho+rx2p+gbs1gqs/aHyKi+ooJEDUo3VtYoY2dCfKL5dhyJl7T4ag4+G8SbiRlw1iqi0ms/SEiqteYAFGDIhKJlLVAm07Fo6C4fiyPoVAI+OZR7c+Ebi4wNWDtDxFRfcYEiBqcQR3sYG8qQ1pOIX67eFfT4QAADl1Lxo2kbBhJdTGpO2t/iIjqOyZA1ODo6Ygxsft/y2MoFJpdHkMQ/uv7M6GrC8wMJBqNh4iIno0JEDVIo32cYCzTRUxqLg5fT9ZoLH9fS8a1+1kwlOiw9oeIqIFgAkQNkpFUF+N8nQGU1gJpiiD81/cnsKsLzA1Z+0NE1BAwAaIGK6ibC/R0RDgXl46IhHSNxBB6PQX/3suCgUQHkx9N1EhERPUfEyBqsGxMZBjq7gAAWPNP3dcCPV77M76LCyxY+0NE1GAwAaIGbcqjIfEHryUhNi23Tp/7aFQKrtzNhL6eDqb0YN8fIqKGhAkQNWgtbYzRu1UTCAKw/kTd1QIJgoBvDpfV/jjD0khaZ89NRETPjwkQNXhTe7oCAHaev4MHOYV18pxhN1Nx6c6j2p+e7PtDRNTQMAGiBq9zcwt0aGqKwhIFfgqv/eUxBEHA8ke1P693doIVa3+IiBocJkDU4D2+PMZP4XHIL6rd5TH+uZmKS4kZkOmJlbVPRETUsDABokahf1tbNDXXR3peMXZdSKy153l85Nfrvs5oYszaHyKihogJEDUKujpiTH40C/O6E7GQ19LyGMdvpeFiQgakumJM7cW+P0REDRUTIGo0RnZyhJmBHuIf5OHQv0k1fv7Ha3/G+TrD2lhW489BRER1gwkQNRoGEl0EdC5dHuOHYzEQhJqtBTp5+wEuxKdDqivGm6z9ISJq0JgAUaMyvosLJLpiRCZm4FxczS2PUVr7cxMAMMbHCdYmrP0hImrImABRo9LEWIpXPR8tj3Gs5iZGDI9+gHNx6ZDoivHWixz5RUTU0DEBokZnco/mEImAw9eTcTslp0bOufxR358xnRxhw9ofIqIGjwkQNTquTYzg19oGALDu+PPXAoVHP8DZ2IeQ6IjxJmt/iIgaBSZA1Ci98WhixN0Rd5GSXfBc5yrr+zOqkyPsTPWfOzYiItK8epEArVy5Ei4uLpDJZPD19cXZs2crLbt79254e3vDzMwMhoaGcHd3x+bNmyst/+abb0IkEmH58uW1EDnVV17O5vBwMkORXIGfTlV/eYzTMQ9wOqa09od9f4iIGg+NJ0A7duxAcHAwFi1ahIiICHTs2BH+/v5ISUmpsLyFhQUWLFiA8PBwXL58GUFBQQgKCsLBgwfLlf3tt99w+vRp2Nvb1/ZlUD0jEomUtUCbT8cjt7CkWucpW/F9ZKemsDdj7Q8RUWOh8QRo2bJlmDJlCoKCgtCmTRusXr0aBgYG2LBhQ4XlX3zxRQwbNgytW7eGq6srZs6ciQ4dOuDEiRMq5e7evYvp06djy5Yt0NPTq4tLoXqmXxtbuFgaIDO/GL+cV395jLOxDxEe8wB6OiK89WKLWoiQiIg0RaMJUFFRES5cuAA/Pz/lNrFYDD8/P4SHhz/zeEEQEBoaiqioKPTs2VO5XaFQICAgAHPnzkXbtm2feZ7CwkJkZWWpPKjh0xGLMLlHaS3Q+hOxKJEr1Dq+rO/Pa96OcGDtDxFRo6LRBCgtLQ1yuRw2NjYq221sbJCUVPlSBpmZmTAyMoJEIsGgQYPw3XffoV+/fsr9n332GXR1dTFjxowqxRESEgJTU1Plw9HRsXoXRPXOCK+msDCU4E56PvZfrfryGOfjHuLk7dLan2ns+0NE1OhovAmsOoyNjREZGYlz587h448/RnBwMMLCwgAAFy5cwDfffINNmzZBJBJV6Xzz589HZmam8pGYWHuriVPdkunpYHyX0uUx1hyLrvLyGGVrfo3waoqm5ga1Fh8REWmGRhMgKysr6OjoIDk5WWV7cnIybG1tKz1OLBajRYsWcHd3x+zZszFixAiEhIQAAI4fP46UlBQ4OTlBV1cXurq6iI+Px+zZs+Hi4lLh+aRSKUxMTFQe1HiM7+ICmZ4YV+9mITzmwTPLX4hPx/FbadAVizCNfX+IiBoljSZAEokEXl5eCA0NVW5TKBQIDQ1Fly5dqnwehUKBwsJCAEBAQAAuX76MyMhI5cPe3h5z586tcKQYNX4WhhK85lXarFmV5THKan9e9WwKRwvW/hARNUa6mg4gODgYgYGB8Pb2ho+PD5YvX47c3FwEBQUBAMaPHw8HBwdlDU9ISAi8vb3h6uqKwsJC7N+/H5s3b8aqVasAAJaWlrC0tFR5Dj09Pdja2qJVq1Z1e3FUb0zq3gw/n4lHWFQqopKy0crWuMJyFxPScexmKnTEIrzdm7U/RESNlcYToFGjRiE1NRULFy5EUlIS3N3dceDAAWXH6ISEBIjF/1VU5ebmYtq0abhz5w709fXh5uaGn3/+GaNGjdLUJVAD4GJliP5tbfHX1SSsPR6DL1/rWGG5stqf4R4OcLJk7Q8RUWMlEqraK1SLZGVlwdTUFJmZmewP1IhcTEjHsO9PQU9HhOPv9YGtqeqippGJGRi68iR0xCIcmd0LzpaGGoqUiIiqQ53v7wY5CoyoOjyczOHjYoFiuYCNp2LL7f/mcOm8P8M8HJj8EBE1ckyASKtMfbQ8xtbTCcguKFZuv5SYgaNRpX1/3mHfHyKiRo8JEGmVPm7WcG1iiOzCEmw/+998T98+6vvzirs9XKxY+0NE1NgxASKtIhaLMOXR8hgbTsaiWK7AlTuZCL2RArEImN7nBQ1HSEREdYEJEGmdoR4OsDKS4n5mAfZdvqcc+fWKuwOasfaHiEgrMAEirSPT00FQNxcAwOcHonD4ejLEIuCdPuz7Q0SkLZgAkVYa5+sEA4kO7mcWAAAGd7SHaxMjDUdFRER1hQkQaSUzAwlGepcujyESAdNZ+0NEpFU0PhM0kaa82csVp2MeoLebNVpYV7w0BhERNU5MgEhr2ZrKcODdnpoOg4iINIBNYERERKR1mAARERGR1mECRERERFqHCRARERFpHSZAREREpHWYABEREZHWYQJEREREWocJEBEREWkdJkBERESkdZgAERERkdZhAkRERERahwkQERERaR0mQERERKR1mAARERGR1tHVdAD1kSAIAICsrCwNR0JERERVVfa9XfY9/jRMgCqQnZ0NAHB0dNRwJERERKSu7OxsmJqaPrWMSKhKmqRlFAoF7t27B2NjY4hEIk2HUy9lZWXB0dERiYmJMDEx0XQ4Wo/3o37h/ahfeD/ql9q8H4IgIDs7G/b29hCLn97LhzVAFRCLxWjatKmmw2gQTExM+IFSj/B+1C+8H/UL70f9Ulv341k1P2XYCZqIiIi0DhMgIiIi0jpMgKhapFIpFi1aBKlUqulQCLwf9Q3vR/3C+1G/1Jf7wU7QREREpHVYA0RERERahwkQERERaR0mQERERKR1mAARERGR1mECRJVauXIlXFxcIJPJ4Ovri7Nnz1Zadu3atejRowfMzc1hbm4OPz+/p5Yn9alzPx63fft2iEQiDB06tHYD1DLq3o+MjAy8/fbbsLOzg1QqRcuWLbF///46irbxU/d+LF++HK1atYK+vj4cHR0xa9YsFBQU1FG0jduxY8cwePBg2NvbQyQSYc+ePc88JiwsDJ6enpBKpWjRogU2bdpU63FCIKrA9u3bBYlEImzYsEH4999/hSlTpghmZmZCcnJyheXHjh0rrFy5Urh48aJw/fp1YcKECYKpqalw586dOo68cVL3fpSJjY0VHBwchB49egivvPJK3QSrBdS9H4WFhYK3t7cwcOBA4cSJE0JsbKwQFhYmREZG1nHkjZO692PLli2CVCoVtmzZIsTGxgoHDx4U7OzshFmzZtVx5I3T/v37hQULFgi7d+8WAAi//fbbU8vHxMQIBgYGQnBwsHDt2jXhu+++E3R0dIQDBw7UapxMgKhCPj4+wttvv638t1wuF+zt7YWQkJAqHV9SUiIYGxsLP/74Y22FqFWqcz9KSkqErl27CuvWrRMCAwOZANUgde/HqlWrhObNmwtFRUV1FaJWUfd+vP3220KfPn1UtgUHBwvdunWr1Ti1UVUSoPfee09o27atyrZRo0YJ/v7+tRiZILAJjMopKirChQsX4Ofnp9wmFovh5+eH8PDwKp0jLy8PxcXFsLCwqK0wtUZ178eSJUtgbW2NSZMm1UWYWqM692Pv3r3o0qUL3n77bdjY2KBdu3b45JNPIJfL6yrsRqs696Nr1664cOGCspksJiYG+/fvx8CBA+skZlIVHh6ucv8AwN/fv8rfN9XFxVCpnLS0NMjlctjY2Khst7GxwY0bN6p0jv/7v/+Dvb19uT9qUl917seJEyewfv16REZG1kGE2qU69yMmJgZHjhzBuHHjsH//fty+fRvTpk1DcXExFi1aVBdhN1rVuR9jx45FWloaunfvDkEQUFJSgjfffBP/+9//6iJkekJSUlKF9y8rKwv5+fnQ19evledlDRDVuE8//RTbt2/Hb7/9BplMpulwtE52djYCAgKwdu1aWFlZaTocAqBQKGBtbY01a9bAy8sLo0aNwoIFC7B69WpNh6aVwsLC8Mknn+D7779HREQEdu/ejT///BNLly7VdGhUh1gDROVYWVlBR0cHycnJKtuTk5Nha2v71GO//PJLfPrppzh8+DA6dOhQm2FqDXXvR3R0NOLi4jB48GDlNoVCAQDQ1dVFVFQUXF1dazfoRqw67w87Ozvo6elBR0dHua1169ZISkpCUVERJBJJrcbcmFXnfnzwwQcICAjA5MmTAQDt27dHbm4upk6digULFkAsZt1AXbK1ta3w/pmYmNRa7Q/AGiCqgEQigZeXF0JDQ5XbFAoFQkND0aVLl0qP+/zzz7F06VIcOHAA3t7edRGqVlD3fri5ueHKlSuIjIxUPoYMGYLevXsjMjISjo6OdRl+o1Od90e3bt1w+/ZtZSIKADdv3oSdnR2Tn+dUnfuRl5dXLskpS04FLo9Z57p06aJy/wDg77//fur3TY2o1S7W1GBt375dkEqlwqZNm4Rr164JU6dOFczMzISkpCRBEAQhICBAmDdvnrL8p59+KkgkEmHXrl3C/fv3lY/s7GxNXUKjou79eBJHgdUsde9HQkKCYGxsLLzzzjtCVFSUsG/fPsHa2lr46KOPNHUJjYq692PRokWCsbGxsG3bNiEmJkY4dOiQ4OrqKowcOVJTl9CoZGdnCxcvXhQuXrwoABCWLVsmXLx4UYiPjxcEQRDmzZsnBAQEKMuXDYOfO3eucP36dWHlypUcBk+a9d133wlOTk6CRCIRfHx8hNOnTyv39erVSwgMDFT+29nZWQBQ7rFo0aK6D7yRUud+PIkJUM1T936cOnVK8PX1FaRSqdC8eXPh448/FkpKSuo46sZLnftRXFwsLF68WHB1dRVkMpng6OgoTJs2TUhPT6/7wBuho0ePVvh9UHYPAgMDhV69epU7xt3dXZBIJELz5s2FjRs31nqcIkFgfR8RERFpF/YBIiIiIq3DBIiIiIi0DhMgIiIi0jpMgIiIiEjrMAEiIiIircMEiIiIiLQOEyAiIiLSOkyAiKjWvfjii3j33Xc1HUadWLx4Mdzd3TUdBhE9AxMgIqp3wsLCIBKJkJGRUafPWxPJy5w5c8qta0RE9Q9XgyciqkFGRkYwMjLSdBhE9AysASKiGpWbm4vx48fDyMgIdnZ2+Oqrr8qV2bx5M7y9vWFsbAxbW1uMHTsWKSkpAIC4uDj07t0bAGBubg6RSIQJEyYAAA4cOIDu3bvDzMwMlpaWePnllxEdHa08b1FREd555x3Y2dlBJpPB2dkZISEhyv0ZGRmYPHkymjRpAhMTE/Tp0weXLl0CAGzatAkffvghLl26BJFIBJFIhE2bNlV4jWFhYfDx8YGhoSHMzMzQrVs3xMfHAyhfi1R2rscfLi4uyv1Xr17FgAEDYGRkBBsbGwQEBCAtLU3t152I1MMEiIhq1Ny5c/HPP//g999/x6FDhxAWFoaIiAiVMsXFxVi6dCkuXbqEPXv2IC4uTpnkODo64tdffwUAREVF4f79+/jmm28AlCZXwcHBOH/+PEJDQyEWizFs2DAoFAoAwLfffou9e/fil19+QVRUFLZs2aKSbLz22mtISUnBX3/9hQsXLsDT0xN9+/bFw4cPMWrUKMyePRtt27bF/fv3cf/+fYwaNarc9ZWUlGDo0KHo1asXLl++jPDwcEydOhUikajC16PsXPfv38ft27fRokUL9OzZE0BpQtanTx94eHjg/PnzOHDgAJKTkzFy5MjnugdEVAW1vtwqEWmN7OxsQSKRCL/88oty24MHDwR9fX1h5syZlR537tw5AYCQnZ0tCMJ/q0k/a3Xu1NRUAYBw5coVQRAEYfr06UKfPn0EhUJRruzx48cFExMToaCgQGW7q6ur8MMPPwiCIAiLFi0SOnbs+NTnfPDggQBACAsLq3B/ZedQKBTCsGHDBC8vLyEvL08QBEFYunSp8NJLL6mUS0xMFAAIUVFRT42DiJ4Pa4CIqMZER0ejqKgIvr6+ym0WFhZo1aqVSrkLFy5g8ODBcHJygrGxMXr16gUASEhIeOr5b926hTFjxqB58+YwMTFR1u6UHTdhwgRERkaiVatWmDFjBg4dOqQ89tKlS8jJyYGlpaWyn46RkRFiY2NVmtGexcLCAhMmTIC/vz8GDx6Mb775Bvfv33/mcf/73/8QHh6O33//Hfr6+sqYjh49qhKPm5sbAKgVExGpj52giahO5ebmwt/fH/7+/tiyZQuaNGmChIQE+Pv7o6io6KnHDh48GM7Ozli7di3s7e2hUCjQrl075XGenp6IjY3FX3/9hcOHD2PkyJHw8/PDrl27kJOTAzs7O4SFhZU7r5mZmVrXsHHjRsyYMQMHDhzAjh078P777+Pvv/9G586dKyz/888/4+uvv0ZYWBgcHByU23NycjB48GB89tln5Y6xs7NTKyYiUg8TICKqMa6urtDT08OZM2fg5OQEAEhPT8fNmzeVtTw3btzAgwcP8Omnn8LR0REAcP78eZXzSCQSAIBcLldue/DgAaKiorB27Vr06NEDAHDixIlyMZiYmGDUqFEYNWoURowYgf79++Phw4fw9PREUlISdHV1VfoFPfm8jz/n03h4eMDDwwPz589Hly5dsHXr1goToPDwcEyePBk//PBDuf2enp749ddf4eLiAl1dfhwT1SU2gRFRjTEyMsKkSZMwd+5cHDlyBFevXsWECRMgFv/3UePk5ASJRILvvvsOMTEx2Lt3L5YuXapyHmdnZ4hEIuzbtw+pqanIycmBubk5LC0tsWbNGty+fRtHjhxBcHCwynHLli3Dtm3bcOPGDdy8eRM7d+6Era0tzMzM4Ofnhy5dumDo0KE4dOgQ4uLicOrUKSxYsECZgLm4uCA2NhaRkZFIS0tDYWFhuWuMjY3F/PnzER4ejvj4eBw6dAi3bt1C69aty5VNSkrCsGHDMHr0aPj7+yMpKQlJSUlITU0FALz99tt4+PAhxowZg3PnziE6OhoHDx5EUFBQlRMxIqomTXdCIqLGJTs7W3j99dcFAwMDwcbGRvj888+FXr16qXSC3rp1q+Di4iJIpVKhS5cuwt69ewUAwsWLF5VllixZItja2goikUgIDAwUBEEQ/v77b6F169aCVCoVOnToIISFhQkAhN9++00QBEFYs2aN4O7uLhgaGgomJiZC3759hYiICOU5s7KyhOnTpwv29vaCnp6e4OjoKIwbN05ISEgQBEEQCgoKhFdffVUwMzMTAAgbN24sd31JSUnC0KFDBTs7O0EikQjOzs7CwoULBblcLgiCaifoss7cTz6cnZ2V57t586YwbNgwwczMTNDX1xfc3NyEd999t8KO3ERUc0SCIAiaS7+IiIiI6h6bwIiIiEjrMAEiIiIircMEiIiIiLQOEyAiIiLSOkyAiIiISOswASIiIiKtwwSIiIiItA4TICIiItI6TICIiIhI6zABIiIiIq3DBIiIiIi0DhMgIiIi0jr/D4jl3rRET82cAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sketch graph of mean epistemic entropy for dropout model\n",
    "plt.plot(dataset_frac, [np.mean(epi_entropy_dropout[i]) for i in range(0, 10)])\n",
    "plt.xlabel('dataset size')\n",
    "plt.ylabel('Mean Epistemic Entropy')\n",
    "plt.title('Mean Epistemic Uncertainty of Dropout Model')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sketch graph of mean equal opportunity difference for dropout model\n",
    "plt.plot(dataset_frac, Equal_opp_diffs_dropout)\n",
    "plt.xlabel('Dataset Size')\n",
    "plt.ylabel('Mean Equal Opportunity Difference')\n",
    "plt.title('Mean Equal Opportunity Difference of Dropout Model')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot epistemic entropy as x-axis and equal opportunity difference as y-axis for dropout model\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter([np.mean(epi_entropy_dropout[i]) for i in range(0, 10)], Equal_opp_diffs_dropout)\n",
    "plt.xlabel('Mean Epistemic Entropy')\n",
    "plt.ylabel('Mean Equal Opportunity Difference')\n",
    "plt.title('Mean Equal Opportunity Difference vs Mean Epistemic Entropy of Dropout Model')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ale_entropy_dropout to dict\n",
    "ale_entropy_dropout_dict = {}\n",
    "for i in range(0, 10):\n",
    "    ale_entropy_dropout_dict[dataset_frac[i]] = ale_entropy_dropout[i]\n",
    "\n",
    "#epi_entropy_dropout to dict\n",
    "epi_entropy_dropout_dict = {}\n",
    "for i in range(0, 10):\n",
    "    epi_entropy_dropout_dict[dataset_frac[i]] = epi_entropy_dropout[i]\n",
    "    \n",
    "#save to pickle file\n",
    "import pickle\n",
    "\n",
    "with open('adult_results/ale_entropy_dropout_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(ale_entropy_dropout_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('adult_results/epi_entropy_dropout_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(epi_entropy_dropout_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('adult_results/Equal_opp_diffs_dropout.pickle', 'wb') as handle:\n",
    "    pickle.dump(Equal_opp_diffs_dropout, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLE DROP OUT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  0.1\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 0.6819 - accuracy: 0.5626 - val_loss: 0.6392 - val_accuracy: 0.6445 - 2s/epoch - 187ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6185 - accuracy: 0.6973 - val_loss: 0.5978 - val_accuracy: 0.7136 - 138ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.5831 - accuracy: 0.7405 - val_loss: 0.5738 - val_accuracy: 0.7468 - 144ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5633 - accuracy: 0.7555 - val_loss: 0.5565 - val_accuracy: 0.7468 - 136ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5571 - accuracy: 0.7568 - val_loss: 0.5295 - val_accuracy: 0.7583 - 139ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5364 - accuracy: 0.7651 - val_loss: 0.5197 - val_accuracy: 0.7583 - 202ms/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5168 - accuracy: 0.7632 - val_loss: 0.5218 - val_accuracy: 0.7481 - 134ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5099 - accuracy: 0.7658 - val_loss: 0.5012 - val_accuracy: 0.7532 - 169ms/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.4998 - accuracy: 0.7683 - val_loss: 0.5016 - val_accuracy: 0.7621 - 139ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.4963 - accuracy: 0.7670 - val_loss: 0.4829 - val_accuracy: 0.7698 - 122ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.4896 - accuracy: 0.7750 - val_loss: 0.4962 - val_accuracy: 0.7762 - 126ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.4823 - accuracy: 0.7744 - val_loss: 0.5093 - val_accuracy: 0.7621 - 130ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.4821 - accuracy: 0.7754 - val_loss: 0.4737 - val_accuracy: 0.7775 - 132ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4749 - accuracy: 0.7837 - val_loss: 0.4903 - val_accuracy: 0.7749 - 132ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4786 - accuracy: 0.7818 - val_loss: 0.4767 - val_accuracy: 0.7839 - 118ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4706 - accuracy: 0.7747 - val_loss: 0.4839 - val_accuracy: 0.7724 - 128ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4732 - accuracy: 0.7824 - val_loss: 0.4767 - val_accuracy: 0.7839 - 127ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4684 - accuracy: 0.7782 - val_loss: 0.4987 - val_accuracy: 0.7724 - 134ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4660 - accuracy: 0.7754 - val_loss: 0.4717 - val_accuracy: 0.7839 - 131ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4622 - accuracy: 0.7891 - val_loss: 0.4773 - val_accuracy: 0.7788 - 139ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4559 - accuracy: 0.7770 - val_loss: 0.4823 - val_accuracy: 0.7749 - 133ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4756 - val_accuracy: 0.7928 - 121ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4607 - accuracy: 0.7853 - val_loss: 0.4866 - val_accuracy: 0.7801 - 130ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4582 - accuracy: 0.7878 - val_loss: 0.4712 - val_accuracy: 0.7877 - 124ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.4578 - accuracy: 0.7808 - val_loss: 0.4719 - val_accuracy: 0.7928 - 120ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4588 - accuracy: 0.7837 - val_loss: 0.4894 - val_accuracy: 0.7864 - 134ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4564 - accuracy: 0.7859 - val_loss: 0.5034 - val_accuracy: 0.7826 - 134ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4611 - accuracy: 0.7843 - val_loss: 0.4810 - val_accuracy: 0.7954 - 141ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4581 - accuracy: 0.7894 - val_loss: 0.4664 - val_accuracy: 0.7801 - 140ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4702 - val_accuracy: 0.7788 - 134ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4530 - accuracy: 0.7840 - val_loss: 0.4619 - val_accuracy: 0.7813 - 140ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4503 - accuracy: 0.7862 - val_loss: 0.4738 - val_accuracy: 0.7826 - 135ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.4818 - val_accuracy: 0.7826 - 134ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4523 - accuracy: 0.7904 - val_loss: 0.4820 - val_accuracy: 0.7788 - 139ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4477 - accuracy: 0.7878 - val_loss: 0.4628 - val_accuracy: 0.7826 - 136ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4544 - accuracy: 0.7907 - val_loss: 0.4722 - val_accuracy: 0.7839 - 193ms/epoch - 15ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4515 - accuracy: 0.7888 - val_loss: 0.4567 - val_accuracy: 0.7980 - 143ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4460 - accuracy: 0.7914 - val_loss: 0.4595 - val_accuracy: 0.7864 - 134ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4452 - accuracy: 0.7885 - val_loss: 0.4795 - val_accuracy: 0.7775 - 161ms/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4450 - accuracy: 0.7898 - val_loss: 0.4751 - val_accuracy: 0.7775 - 179ms/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4459 - accuracy: 0.7965 - val_loss: 0.4664 - val_accuracy: 0.7992 - 173ms/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4495 - accuracy: 0.7907 - val_loss: 0.4799 - val_accuracy: 0.7826 - 169ms/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4428 - accuracy: 0.7930 - val_loss: 0.4659 - val_accuracy: 0.7941 - 206ms/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4511 - accuracy: 0.7891 - val_loss: 0.4576 - val_accuracy: 0.8031 - 174ms/epoch - 13ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4484 - accuracy: 0.7933 - val_loss: 0.4804 - val_accuracy: 0.7890 - 170ms/epoch - 13ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4455 - accuracy: 0.7898 - val_loss: 0.4706 - val_accuracy: 0.7967 - 180ms/epoch - 14ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4451 - accuracy: 0.7862 - val_loss: 0.4681 - val_accuracy: 0.7980 - 189ms/epoch - 15ms/step\n",
      "Epoch 47: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 0.7206 - accuracy: 0.5136 - val_loss: 0.6542 - val_accuracy: 0.6240 - 2s/epoch - 152ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6384 - accuracy: 0.6592 - val_loss: 0.6063 - val_accuracy: 0.7238 - 222ms/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.5800 - accuracy: 0.7389 - val_loss: 0.5717 - val_accuracy: 0.7583 - 135ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5626 - accuracy: 0.7555 - val_loss: 0.5529 - val_accuracy: 0.7481 - 132ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5418 - accuracy: 0.7587 - val_loss: 0.5468 - val_accuracy: 0.7506 - 163ms/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5328 - accuracy: 0.7686 - val_loss: 0.5259 - val_accuracy: 0.7570 - 165ms/epoch - 13ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5235 - accuracy: 0.7619 - val_loss: 0.5166 - val_accuracy: 0.7494 - 179ms/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5083 - accuracy: 0.7654 - val_loss: 0.5001 - val_accuracy: 0.7647 - 145ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.4944 - accuracy: 0.7670 - val_loss: 0.5008 - val_accuracy: 0.7647 - 147ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.4985 - accuracy: 0.7702 - val_loss: 0.4909 - val_accuracy: 0.7660 - 192ms/epoch - 15ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.4818 - accuracy: 0.7706 - val_loss: 0.4991 - val_accuracy: 0.7737 - 158ms/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.4778 - accuracy: 0.7757 - val_loss: 0.5015 - val_accuracy: 0.7749 - 140ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.4750 - accuracy: 0.7773 - val_loss: 0.4786 - val_accuracy: 0.7737 - 138ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4686 - accuracy: 0.7789 - val_loss: 0.4666 - val_accuracy: 0.7826 - 156ms/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4719 - accuracy: 0.7827 - val_loss: 0.4702 - val_accuracy: 0.7916 - 134ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4678 - accuracy: 0.7734 - val_loss: 0.4937 - val_accuracy: 0.7737 - 130ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4711 - accuracy: 0.7843 - val_loss: 0.4802 - val_accuracy: 0.7954 - 115ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4644 - accuracy: 0.7846 - val_loss: 0.4997 - val_accuracy: 0.7839 - 141ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4600 - accuracy: 0.7843 - val_loss: 0.4810 - val_accuracy: 0.7813 - 138ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4673 - accuracy: 0.7782 - val_loss: 0.4850 - val_accuracy: 0.7749 - 122ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4535 - accuracy: 0.7894 - val_loss: 0.4912 - val_accuracy: 0.7839 - 116ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4558 - accuracy: 0.7901 - val_loss: 0.4861 - val_accuracy: 0.7762 - 165ms/epoch - 13ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4553 - accuracy: 0.7923 - val_loss: 0.4743 - val_accuracy: 0.7980 - 109ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4527 - accuracy: 0.7914 - val_loss: 0.4741 - val_accuracy: 0.7852 - 113ms/epoch - 9ms/step\n",
      "Epoch 24: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 0.7005 - accuracy: 0.5450 - val_loss: 0.6505 - val_accuracy: 0.6535 - 2s/epoch - 175ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6154 - accuracy: 0.6854 - val_loss: 0.5880 - val_accuracy: 0.7276 - 246ms/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.5799 - accuracy: 0.7440 - val_loss: 0.5673 - val_accuracy: 0.7404 - 135ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5617 - accuracy: 0.7552 - val_loss: 0.5568 - val_accuracy: 0.7455 - 134ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5487 - accuracy: 0.7565 - val_loss: 0.5443 - val_accuracy: 0.7545 - 164ms/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5329 - accuracy: 0.7622 - val_loss: 0.5342 - val_accuracy: 0.7506 - 100ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5406 - accuracy: 0.7635 - val_loss: 0.5343 - val_accuracy: 0.7494 - 131ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5193 - accuracy: 0.7661 - val_loss: 0.5043 - val_accuracy: 0.7532 - 119ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.5084 - accuracy: 0.7651 - val_loss: 0.5004 - val_accuracy: 0.7558 - 123ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.5098 - accuracy: 0.7654 - val_loss: 0.5101 - val_accuracy: 0.7609 - 115ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.4974 - accuracy: 0.7654 - val_loss: 0.4988 - val_accuracy: 0.7583 - 107ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.4835 - accuracy: 0.7734 - val_loss: 0.4973 - val_accuracy: 0.7660 - 163ms/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.4909 - accuracy: 0.7693 - val_loss: 0.5018 - val_accuracy: 0.7749 - 102ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4779 - accuracy: 0.7722 - val_loss: 0.4842 - val_accuracy: 0.7698 - 152ms/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4787 - accuracy: 0.7715 - val_loss: 0.4894 - val_accuracy: 0.7813 - 131ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4775 - accuracy: 0.7722 - val_loss: 0.4858 - val_accuracy: 0.7852 - 119ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4784 - accuracy: 0.7706 - val_loss: 0.4827 - val_accuracy: 0.7749 - 115ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4723 - accuracy: 0.7779 - val_loss: 0.4898 - val_accuracy: 0.7660 - 117ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4703 - accuracy: 0.7757 - val_loss: 0.4765 - val_accuracy: 0.7890 - 109ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4669 - accuracy: 0.7827 - val_loss: 0.4805 - val_accuracy: 0.7685 - 125ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4607 - accuracy: 0.7798 - val_loss: 0.4817 - val_accuracy: 0.7852 - 141ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4658 - accuracy: 0.7792 - val_loss: 0.4681 - val_accuracy: 0.7813 - 130ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4568 - accuracy: 0.7792 - val_loss: 0.4705 - val_accuracy: 0.7813 - 186ms/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4783 - val_accuracy: 0.7826 - 119ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.4594 - accuracy: 0.7834 - val_loss: 0.4772 - val_accuracy: 0.7647 - 149ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4656 - accuracy: 0.7843 - val_loss: 0.4828 - val_accuracy: 0.7813 - 123ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4625 - accuracy: 0.7856 - val_loss: 0.4807 - val_accuracy: 0.7839 - 136ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4597 - accuracy: 0.7821 - val_loss: 0.4635 - val_accuracy: 0.7992 - 134ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4537 - accuracy: 0.7805 - val_loss: 0.4768 - val_accuracy: 0.7801 - 131ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4703 - accuracy: 0.7766 - val_loss: 0.4621 - val_accuracy: 0.7801 - 113ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4553 - accuracy: 0.7891 - val_loss: 0.4756 - val_accuracy: 0.7877 - 197ms/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4544 - accuracy: 0.7856 - val_loss: 0.4706 - val_accuracy: 0.7788 - 119ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4500 - accuracy: 0.7837 - val_loss: 0.4651 - val_accuracy: 0.7852 - 116ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4592 - accuracy: 0.7850 - val_loss: 0.4649 - val_accuracy: 0.7839 - 117ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4430 - accuracy: 0.7862 - val_loss: 0.4814 - val_accuracy: 0.7673 - 137ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4510 - accuracy: 0.7878 - val_loss: 0.4934 - val_accuracy: 0.7801 - 127ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4444 - accuracy: 0.7894 - val_loss: 0.4687 - val_accuracy: 0.7852 - 124ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4581 - accuracy: 0.7846 - val_loss: 0.4731 - val_accuracy: 0.7941 - 138ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4536 - accuracy: 0.7818 - val_loss: 0.4682 - val_accuracy: 0.7775 - 141ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4502 - accuracy: 0.7891 - val_loss: 0.4883 - val_accuracy: 0.7890 - 123ms/epoch - 9ms/step\n",
      "Epoch 40: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "13/13 - 7s - loss: 0.6798 - accuracy: 0.5846 - val_loss: 0.6468 - val_accuracy: 0.6573 - 7s/epoch - 525ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6131 - accuracy: 0.7149 - val_loss: 0.5952 - val_accuracy: 0.7366 - 143ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.5912 - accuracy: 0.7306 - val_loss: 0.6025 - val_accuracy: 0.7379 - 123ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5665 - accuracy: 0.7523 - val_loss: 0.5460 - val_accuracy: 0.7468 - 117ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5634 - accuracy: 0.7568 - val_loss: 0.5535 - val_accuracy: 0.7596 - 112ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5364 - accuracy: 0.7638 - val_loss: 0.5382 - val_accuracy: 0.7545 - 117ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5237 - accuracy: 0.7645 - val_loss: 0.5255 - val_accuracy: 0.7609 - 114ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5246 - accuracy: 0.7626 - val_loss: 0.5166 - val_accuracy: 0.7570 - 120ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.5119 - accuracy: 0.7619 - val_loss: 0.5051 - val_accuracy: 0.7494 - 118ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.5059 - accuracy: 0.7616 - val_loss: 0.5218 - val_accuracy: 0.7609 - 114ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.4936 - accuracy: 0.7642 - val_loss: 0.4906 - val_accuracy: 0.7570 - 119ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.4936 - accuracy: 0.7645 - val_loss: 0.4971 - val_accuracy: 0.7660 - 120ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.4882 - accuracy: 0.7741 - val_loss: 0.4999 - val_accuracy: 0.7596 - 124ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4922 - accuracy: 0.7632 - val_loss: 0.4938 - val_accuracy: 0.7621 - 116ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4854 - accuracy: 0.7654 - val_loss: 0.4808 - val_accuracy: 0.7698 - 124ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4776 - accuracy: 0.7696 - val_loss: 0.4882 - val_accuracy: 0.7570 - 110ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4795 - accuracy: 0.7706 - val_loss: 0.4822 - val_accuracy: 0.7737 - 120ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4766 - accuracy: 0.7750 - val_loss: 0.4908 - val_accuracy: 0.7634 - 132ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4636 - accuracy: 0.7722 - val_loss: 0.4847 - val_accuracy: 0.7826 - 122ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4643 - accuracy: 0.7776 - val_loss: 0.4747 - val_accuracy: 0.7634 - 118ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4745 - accuracy: 0.7766 - val_loss: 0.4732 - val_accuracy: 0.7762 - 171ms/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4667 - accuracy: 0.7709 - val_loss: 0.4964 - val_accuracy: 0.7711 - 97ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4625 - accuracy: 0.7866 - val_loss: 0.4851 - val_accuracy: 0.7762 - 119ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4569 - accuracy: 0.7808 - val_loss: 0.4837 - val_accuracy: 0.7762 - 123ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.4629 - accuracy: 0.7821 - val_loss: 0.4905 - val_accuracy: 0.7788 - 109ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4489 - accuracy: 0.7933 - val_loss: 0.4767 - val_accuracy: 0.7839 - 118ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4531 - accuracy: 0.7792 - val_loss: 0.4841 - val_accuracy: 0.7839 - 117ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4637 - accuracy: 0.7798 - val_loss: 0.4618 - val_accuracy: 0.7864 - 110ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4556 - accuracy: 0.7898 - val_loss: 0.4780 - val_accuracy: 0.7839 - 107ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4554 - accuracy: 0.7770 - val_loss: 0.4811 - val_accuracy: 0.7788 - 111ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4527 - accuracy: 0.7907 - val_loss: 0.4880 - val_accuracy: 0.7711 - 111ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4407 - accuracy: 0.7891 - val_loss: 0.4722 - val_accuracy: 0.7941 - 113ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.4781 - val_accuracy: 0.7775 - 109ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4576 - accuracy: 0.7923 - val_loss: 0.4733 - val_accuracy: 0.8056 - 113ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4464 - accuracy: 0.7888 - val_loss: 0.4631 - val_accuracy: 0.7852 - 105ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4541 - accuracy: 0.7795 - val_loss: 0.4741 - val_accuracy: 0.7928 - 123ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4497 - accuracy: 0.7875 - val_loss: 0.4648 - val_accuracy: 0.7928 - 111ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4510 - accuracy: 0.7869 - val_loss: 0.4839 - val_accuracy: 0.7890 - 113ms/epoch - 9ms/step\n",
      "Epoch 38: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "13/13 - 3s - loss: 0.7240 - accuracy: 0.5069 - val_loss: 0.6653 - val_accuracy: 0.5997 - 3s/epoch - 241ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6329 - accuracy: 0.6794 - val_loss: 0.6175 - val_accuracy: 0.7008 - 183ms/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.6037 - accuracy: 0.7222 - val_loss: 0.5967 - val_accuracy: 0.7379 - 138ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5801 - accuracy: 0.7501 - val_loss: 0.5726 - val_accuracy: 0.7468 - 117ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5603 - accuracy: 0.7578 - val_loss: 0.5553 - val_accuracy: 0.7494 - 130ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5444 - accuracy: 0.7600 - val_loss: 0.5386 - val_accuracy: 0.7532 - 200ms/epoch - 15ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5324 - accuracy: 0.7658 - val_loss: 0.5321 - val_accuracy: 0.7481 - 102ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5271 - accuracy: 0.7603 - val_loss: 0.5469 - val_accuracy: 0.7570 - 117ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.5225 - accuracy: 0.7606 - val_loss: 0.5291 - val_accuracy: 0.7583 - 153ms/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.5141 - accuracy: 0.7626 - val_loss: 0.5209 - val_accuracy: 0.7558 - 145ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.5081 - accuracy: 0.7648 - val_loss: 0.5227 - val_accuracy: 0.7545 - 132ms/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.4963 - accuracy: 0.7658 - val_loss: 0.5034 - val_accuracy: 0.7685 - 136ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.4898 - accuracy: 0.7651 - val_loss: 0.4982 - val_accuracy: 0.7634 - 228ms/epoch - 18ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4852 - accuracy: 0.7706 - val_loss: 0.4959 - val_accuracy: 0.7673 - 101ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4760 - accuracy: 0.7747 - val_loss: 0.4742 - val_accuracy: 0.7711 - 186ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4858 - accuracy: 0.7680 - val_loss: 0.4913 - val_accuracy: 0.7621 - 126ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4769 - accuracy: 0.7744 - val_loss: 0.4971 - val_accuracy: 0.7801 - 217ms/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4751 - accuracy: 0.7728 - val_loss: 0.4807 - val_accuracy: 0.7775 - 132ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4697 - accuracy: 0.7677 - val_loss: 0.4778 - val_accuracy: 0.7826 - 118ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4709 - accuracy: 0.7728 - val_loss: 0.4798 - val_accuracy: 0.7762 - 144ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4683 - accuracy: 0.7706 - val_loss: 0.4855 - val_accuracy: 0.7890 - 120ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4673 - accuracy: 0.7757 - val_loss: 0.4828 - val_accuracy: 0.7788 - 115ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4660 - accuracy: 0.7741 - val_loss: 0.4791 - val_accuracy: 0.7698 - 215ms/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4608 - accuracy: 0.7776 - val_loss: 0.4787 - val_accuracy: 0.7673 - 134ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.4558 - accuracy: 0.7786 - val_loss: 0.4722 - val_accuracy: 0.7660 - 118ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4623 - accuracy: 0.7738 - val_loss: 0.4750 - val_accuracy: 0.7890 - 114ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4533 - accuracy: 0.7824 - val_loss: 0.4815 - val_accuracy: 0.7737 - 136ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4606 - accuracy: 0.7850 - val_loss: 0.4865 - val_accuracy: 0.7788 - 101ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4536 - accuracy: 0.7821 - val_loss: 0.4834 - val_accuracy: 0.7698 - 116ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4514 - accuracy: 0.7824 - val_loss: 0.4696 - val_accuracy: 0.7928 - 230ms/epoch - 18ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4536 - accuracy: 0.7869 - val_loss: 0.4661 - val_accuracy: 0.7903 - 105ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4492 - accuracy: 0.7862 - val_loss: 0.4722 - val_accuracy: 0.7852 - 134ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4507 - accuracy: 0.7859 - val_loss: 0.4674 - val_accuracy: 0.7826 - 128ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4545 - accuracy: 0.7894 - val_loss: 0.4732 - val_accuracy: 0.7711 - 133ms/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4476 - accuracy: 0.7898 - val_loss: 0.4710 - val_accuracy: 0.7954 - 142ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4519 - accuracy: 0.7834 - val_loss: 0.4742 - val_accuracy: 0.7852 - 123ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4513 - accuracy: 0.7888 - val_loss: 0.4684 - val_accuracy: 0.7877 - 133ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4458 - accuracy: 0.7837 - val_loss: 0.4660 - val_accuracy: 0.7724 - 165ms/epoch - 13ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4445 - accuracy: 0.7914 - val_loss: 0.4725 - val_accuracy: 0.7839 - 102ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4482 - accuracy: 0.7949 - val_loss: 0.4679 - val_accuracy: 0.7839 - 193ms/epoch - 15ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4461 - accuracy: 0.7866 - val_loss: 0.4660 - val_accuracy: 0.7826 - 157ms/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4460 - accuracy: 0.7824 - val_loss: 0.4706 - val_accuracy: 0.7890 - 126ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4475 - accuracy: 0.7891 - val_loss: 0.4715 - val_accuracy: 0.8005 - 115ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4496 - accuracy: 0.7834 - val_loss: 0.4741 - val_accuracy: 0.7916 - 134ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4460 - accuracy: 0.7981 - val_loss: 0.4588 - val_accuracy: 0.7852 - 102ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4455 - accuracy: 0.7853 - val_loss: 0.4672 - val_accuracy: 0.8107 - 116ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4470 - accuracy: 0.7910 - val_loss: 0.4839 - val_accuracy: 0.7737 - 113ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4437 - accuracy: 0.7920 - val_loss: 0.4730 - val_accuracy: 0.7877 - 179ms/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4361 - accuracy: 0.8000 - val_loss: 0.4624 - val_accuracy: 0.7916 - 116ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4438 - accuracy: 0.7875 - val_loss: 0.4651 - val_accuracy: 0.8043 - 116ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4442 - accuracy: 0.7901 - val_loss: 0.4744 - val_accuracy: 0.7903 - 151ms/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4414 - accuracy: 0.7958 - val_loss: 0.4644 - val_accuracy: 0.7749 - 133ms/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 0.4390 - accuracy: 0.7936 - val_loss: 0.4657 - val_accuracy: 0.7826 - 124ms/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 0.4443 - accuracy: 0.7930 - val_loss: 0.4653 - val_accuracy: 0.7928 - 112ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 0.4447 - accuracy: 0.7878 - val_loss: 0.4704 - val_accuracy: 0.7839 - 110ms/epoch - 8ms/step\n",
      "Epoch 55: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "13/13 - 3s - loss: 0.7876 - accuracy: 0.3658 - val_loss: 0.7255 - val_accuracy: 0.4463 - 3s/epoch - 214ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6933 - accuracy: 0.5229 - val_loss: 0.6486 - val_accuracy: 0.6189 - 178ms/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.6340 - accuracy: 0.6656 - val_loss: 0.6084 - val_accuracy: 0.6905 - 104ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5836 - accuracy: 0.7344 - val_loss: 0.5714 - val_accuracy: 0.7327 - 134ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5558 - accuracy: 0.7536 - val_loss: 0.5534 - val_accuracy: 0.7481 - 233ms/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5454 - accuracy: 0.7581 - val_loss: 0.5349 - val_accuracy: 0.7545 - 169ms/epoch - 13ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5331 - accuracy: 0.7642 - val_loss: 0.5452 - val_accuracy: 0.7455 - 132ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5206 - accuracy: 0.7616 - val_loss: 0.5046 - val_accuracy: 0.7519 - 134ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.5115 - accuracy: 0.7654 - val_loss: 0.5225 - val_accuracy: 0.7621 - 102ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.5132 - accuracy: 0.7648 - val_loss: 0.5044 - val_accuracy: 0.7609 - 135ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.4939 - accuracy: 0.7667 - val_loss: 0.5118 - val_accuracy: 0.7596 - 116ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.4950 - accuracy: 0.7664 - val_loss: 0.5141 - val_accuracy: 0.7583 - 116ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.4937 - accuracy: 0.7683 - val_loss: 0.5078 - val_accuracy: 0.7609 - 164ms/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4968 - accuracy: 0.7690 - val_loss: 0.4888 - val_accuracy: 0.7583 - 117ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4866 - accuracy: 0.7728 - val_loss: 0.4949 - val_accuracy: 0.7609 - 180ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4736 - accuracy: 0.7744 - val_loss: 0.4857 - val_accuracy: 0.7621 - 137ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4750 - accuracy: 0.7741 - val_loss: 0.5096 - val_accuracy: 0.7711 - 114ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4749 - accuracy: 0.7760 - val_loss: 0.5045 - val_accuracy: 0.7685 - 100ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4711 - accuracy: 0.7789 - val_loss: 0.4714 - val_accuracy: 0.7749 - 147ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4706 - accuracy: 0.7782 - val_loss: 0.4915 - val_accuracy: 0.7775 - 154ms/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4648 - accuracy: 0.7814 - val_loss: 0.5009 - val_accuracy: 0.7673 - 116ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4724 - accuracy: 0.7776 - val_loss: 0.4719 - val_accuracy: 0.7813 - 118ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4579 - accuracy: 0.7786 - val_loss: 0.4794 - val_accuracy: 0.7826 - 115ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4674 - accuracy: 0.7782 - val_loss: 0.4761 - val_accuracy: 0.7724 - 118ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.4646 - accuracy: 0.7837 - val_loss: 0.4810 - val_accuracy: 0.7801 - 166ms/epoch - 13ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4628 - accuracy: 0.7782 - val_loss: 0.4913 - val_accuracy: 0.7724 - 134ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4540 - accuracy: 0.7811 - val_loss: 0.4920 - val_accuracy: 0.7685 - 140ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4675 - accuracy: 0.7789 - val_loss: 0.4798 - val_accuracy: 0.7813 - 113ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4563 - accuracy: 0.7882 - val_loss: 0.4692 - val_accuracy: 0.7916 - 110ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.4782 - val_accuracy: 0.7737 - 123ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4723 - val_accuracy: 0.7775 - 141ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4604 - accuracy: 0.7917 - val_loss: 0.4782 - val_accuracy: 0.7660 - 126ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4587 - accuracy: 0.7914 - val_loss: 0.4844 - val_accuracy: 0.7852 - 120ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4568 - accuracy: 0.7878 - val_loss: 0.4688 - val_accuracy: 0.7813 - 117ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4582 - accuracy: 0.7856 - val_loss: 0.4763 - val_accuracy: 0.7890 - 124ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4592 - accuracy: 0.7891 - val_loss: 0.4722 - val_accuracy: 0.7813 - 138ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4477 - accuracy: 0.7917 - val_loss: 0.4961 - val_accuracy: 0.7941 - 158ms/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4592 - accuracy: 0.7856 - val_loss: 0.4934 - val_accuracy: 0.7724 - 119ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4525 - accuracy: 0.7891 - val_loss: 0.4692 - val_accuracy: 0.7801 - 131ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4497 - accuracy: 0.7885 - val_loss: 0.4549 - val_accuracy: 0.7813 - 120ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4548 - accuracy: 0.7872 - val_loss: 0.4858 - val_accuracy: 0.7967 - 111ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4476 - accuracy: 0.7914 - val_loss: 0.4926 - val_accuracy: 0.7954 - 133ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4506 - accuracy: 0.7914 - val_loss: 0.4696 - val_accuracy: 0.7877 - 116ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4516 - accuracy: 0.7914 - val_loss: 0.4849 - val_accuracy: 0.7788 - 133ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4461 - accuracy: 0.7984 - val_loss: 0.4903 - val_accuracy: 0.7737 - 117ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4532 - accuracy: 0.7901 - val_loss: 0.4864 - val_accuracy: 0.7839 - 134ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4486 - accuracy: 0.7891 - val_loss: 0.5002 - val_accuracy: 0.7852 - 116ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4505 - accuracy: 0.7904 - val_loss: 0.4604 - val_accuracy: 0.8043 - 116ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4394 - accuracy: 0.7923 - val_loss: 0.4945 - val_accuracy: 0.7916 - 116ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4495 - accuracy: 0.7904 - val_loss: 0.4823 - val_accuracy: 0.7890 - 133ms/epoch - 10ms/step\n",
      "Epoch 50: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "13/13 - 3s - loss: 0.6700 - accuracy: 0.5814 - val_loss: 0.6285 - val_accuracy: 0.6739 - 3s/epoch - 206ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6043 - accuracy: 0.7203 - val_loss: 0.5963 - val_accuracy: 0.7340 - 373ms/epoch - 29ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.5715 - accuracy: 0.7549 - val_loss: 0.5603 - val_accuracy: 0.7442 - 225ms/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5615 - accuracy: 0.7581 - val_loss: 0.5504 - val_accuracy: 0.7545 - 117ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5503 - accuracy: 0.7584 - val_loss: 0.5434 - val_accuracy: 0.7570 - 131ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5358 - accuracy: 0.7674 - val_loss: 0.5469 - val_accuracy: 0.7545 - 118ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5414 - accuracy: 0.7629 - val_loss: 0.5107 - val_accuracy: 0.7583 - 162ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5100 - accuracy: 0.7696 - val_loss: 0.5174 - val_accuracy: 0.7570 - 116ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.5189 - accuracy: 0.7728 - val_loss: 0.5145 - val_accuracy: 0.7724 - 134ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.5104 - accuracy: 0.7683 - val_loss: 0.5031 - val_accuracy: 0.7660 - 117ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.5086 - accuracy: 0.7722 - val_loss: 0.5066 - val_accuracy: 0.7698 - 377ms/epoch - 29ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.4869 - accuracy: 0.7770 - val_loss: 0.5134 - val_accuracy: 0.7596 - 137ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.5012 - accuracy: 0.7734 - val_loss: 0.5066 - val_accuracy: 0.7698 - 117ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4906 - accuracy: 0.7818 - val_loss: 0.4967 - val_accuracy: 0.7775 - 117ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4811 - accuracy: 0.7786 - val_loss: 0.4873 - val_accuracy: 0.7737 - 152ms/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4776 - accuracy: 0.7814 - val_loss: 0.4801 - val_accuracy: 0.7749 - 117ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4816 - accuracy: 0.7709 - val_loss: 0.4918 - val_accuracy: 0.7660 - 115ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4721 - accuracy: 0.7814 - val_loss: 0.4848 - val_accuracy: 0.7634 - 132ms/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4807 - accuracy: 0.7792 - val_loss: 0.4939 - val_accuracy: 0.7711 - 118ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4788 - accuracy: 0.7770 - val_loss: 0.4662 - val_accuracy: 0.7864 - 127ms/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4720 - accuracy: 0.7866 - val_loss: 0.4852 - val_accuracy: 0.7788 - 122ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4706 - accuracy: 0.7837 - val_loss: 0.4821 - val_accuracy: 0.7928 - 115ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4690 - accuracy: 0.7808 - val_loss: 0.4767 - val_accuracy: 0.7852 - 118ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4686 - accuracy: 0.7811 - val_loss: 0.4721 - val_accuracy: 0.7954 - 116ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.4709 - accuracy: 0.7834 - val_loss: 0.4715 - val_accuracy: 0.7839 - 117ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4669 - accuracy: 0.7862 - val_loss: 0.4790 - val_accuracy: 0.7749 - 268ms/epoch - 21ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4658 - accuracy: 0.7786 - val_loss: 0.4685 - val_accuracy: 0.7839 - 132ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.4665 - val_accuracy: 0.7852 - 133ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4559 - accuracy: 0.7942 - val_loss: 0.4627 - val_accuracy: 0.7839 - 133ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4507 - accuracy: 0.7942 - val_loss: 0.4738 - val_accuracy: 0.7788 - 119ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4610 - accuracy: 0.7888 - val_loss: 0.4800 - val_accuracy: 0.7916 - 491ms/epoch - 38ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4561 - accuracy: 0.7811 - val_loss: 0.4650 - val_accuracy: 0.8018 - 165ms/epoch - 13ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4558 - accuracy: 0.7898 - val_loss: 0.4777 - val_accuracy: 0.7954 - 115ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4523 - accuracy: 0.7952 - val_loss: 0.4611 - val_accuracy: 0.7954 - 116ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4516 - accuracy: 0.7930 - val_loss: 0.4549 - val_accuracy: 0.7903 - 117ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4619 - accuracy: 0.7875 - val_loss: 0.4650 - val_accuracy: 0.7826 - 117ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4546 - accuracy: 0.7901 - val_loss: 0.4660 - val_accuracy: 0.7877 - 117ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4553 - accuracy: 0.7910 - val_loss: 0.4835 - val_accuracy: 0.7852 - 136ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4607 - accuracy: 0.7914 - val_loss: 0.4750 - val_accuracy: 0.7877 - 127ms/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 0.4513 - accuracy: 0.7942 - val_loss: 0.4805 - val_accuracy: 0.7877 - 117ms/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 0.4492 - accuracy: 0.7894 - val_loss: 0.4721 - val_accuracy: 0.7801 - 131ms/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 0.4498 - accuracy: 0.7914 - val_loss: 0.4521 - val_accuracy: 0.7903 - 138ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 0.4550 - accuracy: 0.7920 - val_loss: 0.4681 - val_accuracy: 0.7954 - 125ms/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 0.4554 - accuracy: 0.7901 - val_loss: 0.4779 - val_accuracy: 0.7928 - 114ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 0.4518 - accuracy: 0.7862 - val_loss: 0.4717 - val_accuracy: 0.7916 - 118ms/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 0.4518 - accuracy: 0.7875 - val_loss: 0.4950 - val_accuracy: 0.7685 - 131ms/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 0.4552 - accuracy: 0.7898 - val_loss: 0.4712 - val_accuracy: 0.7813 - 181ms/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 0.4430 - accuracy: 0.8003 - val_loss: 0.4745 - val_accuracy: 0.7890 - 203ms/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 0.4431 - accuracy: 0.7962 - val_loss: 0.4527 - val_accuracy: 0.8043 - 123ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 0.4537 - accuracy: 0.7869 - val_loss: 0.4629 - val_accuracy: 0.7954 - 118ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 0.4461 - accuracy: 0.7933 - val_loss: 0.4710 - val_accuracy: 0.7864 - 102ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 0.4436 - accuracy: 0.7965 - val_loss: 0.4735 - val_accuracy: 0.7826 - 117ms/epoch - 9ms/step\n",
      "Epoch 52: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 0.7072 - accuracy: 0.5085 - val_loss: 0.6781 - val_accuracy: 0.5716 - 2s/epoch - 152ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6487 - accuracy: 0.6566 - val_loss: 0.6295 - val_accuracy: 0.6982 - 202ms/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.6151 - accuracy: 0.7107 - val_loss: 0.6086 - val_accuracy: 0.7315 - 131ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5853 - accuracy: 0.7437 - val_loss: 0.5890 - val_accuracy: 0.7379 - 117ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5663 - accuracy: 0.7555 - val_loss: 0.5672 - val_accuracy: 0.7532 - 121ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5459 - accuracy: 0.7632 - val_loss: 0.5495 - val_accuracy: 0.7583 - 208ms/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5425 - accuracy: 0.7613 - val_loss: 0.5363 - val_accuracy: 0.7545 - 118ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5278 - accuracy: 0.7654 - val_loss: 0.5301 - val_accuracy: 0.7596 - 252ms/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.5187 - accuracy: 0.7645 - val_loss: 0.5272 - val_accuracy: 0.7660 - 114ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.5074 - accuracy: 0.7670 - val_loss: 0.5208 - val_accuracy: 0.7583 - 100ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.4958 - accuracy: 0.7658 - val_loss: 0.4933 - val_accuracy: 0.7660 - 116ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.4916 - accuracy: 0.7638 - val_loss: 0.4961 - val_accuracy: 0.7673 - 127ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.4844 - accuracy: 0.7744 - val_loss: 0.5145 - val_accuracy: 0.7724 - 105ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4775 - accuracy: 0.7754 - val_loss: 0.4904 - val_accuracy: 0.7673 - 150ms/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4812 - accuracy: 0.7709 - val_loss: 0.5052 - val_accuracy: 0.7673 - 116ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4752 - accuracy: 0.7754 - val_loss: 0.5008 - val_accuracy: 0.7647 - 116ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4693 - accuracy: 0.7811 - val_loss: 0.4790 - val_accuracy: 0.7711 - 118ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4749 - accuracy: 0.7782 - val_loss: 0.4812 - val_accuracy: 0.7801 - 117ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4711 - accuracy: 0.7779 - val_loss: 0.4847 - val_accuracy: 0.7685 - 273ms/epoch - 21ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4687 - accuracy: 0.7763 - val_loss: 0.4720 - val_accuracy: 0.7801 - 108ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4763 - val_accuracy: 0.7775 - 116ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4675 - accuracy: 0.7869 - val_loss: 0.4614 - val_accuracy: 0.7839 - 171ms/epoch - 13ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4670 - accuracy: 0.7827 - val_loss: 0.4753 - val_accuracy: 0.7711 - 122ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4571 - accuracy: 0.7859 - val_loss: 0.4743 - val_accuracy: 0.7762 - 191ms/epoch - 15ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.4603 - accuracy: 0.7814 - val_loss: 0.4982 - val_accuracy: 0.7724 - 123ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4563 - accuracy: 0.7824 - val_loss: 0.4865 - val_accuracy: 0.7813 - 163ms/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4577 - accuracy: 0.7763 - val_loss: 0.4757 - val_accuracy: 0.7864 - 110ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4626 - accuracy: 0.7798 - val_loss: 0.4656 - val_accuracy: 0.7826 - 125ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4591 - accuracy: 0.7808 - val_loss: 0.4814 - val_accuracy: 0.7711 - 116ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4611 - accuracy: 0.7814 - val_loss: 0.4748 - val_accuracy: 0.7916 - 117ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4556 - accuracy: 0.7862 - val_loss: 0.4623 - val_accuracy: 0.7928 - 133ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4670 - val_accuracy: 0.7916 - 115ms/epoch - 9ms/step\n",
      "Epoch 32: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 0.6512 - accuracy: 0.6253 - val_loss: 0.6340 - val_accuracy: 0.6714 - 2s/epoch - 136ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6233 - accuracy: 0.6931 - val_loss: 0.6090 - val_accuracy: 0.7174 - 112ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.5977 - accuracy: 0.7306 - val_loss: 0.5903 - val_accuracy: 0.7494 - 133ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5689 - accuracy: 0.7424 - val_loss: 0.5590 - val_accuracy: 0.7494 - 133ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5502 - accuracy: 0.7590 - val_loss: 0.5629 - val_accuracy: 0.7481 - 199ms/epoch - 15ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5450 - accuracy: 0.7574 - val_loss: 0.5403 - val_accuracy: 0.7532 - 119ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5214 - accuracy: 0.7594 - val_loss: 0.5397 - val_accuracy: 0.7558 - 132ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5158 - accuracy: 0.7629 - val_loss: 0.5183 - val_accuracy: 0.7583 - 121ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.5095 - accuracy: 0.7645 - val_loss: 0.5251 - val_accuracy: 0.7545 - 114ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.5091 - accuracy: 0.7667 - val_loss: 0.5112 - val_accuracy: 0.7583 - 126ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.5076 - accuracy: 0.7638 - val_loss: 0.4995 - val_accuracy: 0.7634 - 117ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.5001 - accuracy: 0.7696 - val_loss: 0.5217 - val_accuracy: 0.7685 - 118ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.4913 - accuracy: 0.7677 - val_loss: 0.4965 - val_accuracy: 0.7660 - 147ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4903 - accuracy: 0.7696 - val_loss: 0.4886 - val_accuracy: 0.7647 - 300ms/epoch - 23ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4934 - accuracy: 0.7757 - val_loss: 0.4842 - val_accuracy: 0.7711 - 283ms/epoch - 22ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4896 - accuracy: 0.7718 - val_loss: 0.4805 - val_accuracy: 0.7724 - 143ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4804 - accuracy: 0.7814 - val_loss: 0.5044 - val_accuracy: 0.7826 - 118ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4839 - accuracy: 0.7754 - val_loss: 0.5043 - val_accuracy: 0.7749 - 104ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4736 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7762 - 131ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4716 - accuracy: 0.7814 - val_loss: 0.5022 - val_accuracy: 0.7775 - 117ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4700 - accuracy: 0.7869 - val_loss: 0.5018 - val_accuracy: 0.7826 - 133ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4618 - accuracy: 0.7837 - val_loss: 0.4948 - val_accuracy: 0.7801 - 117ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4615 - accuracy: 0.7818 - val_loss: 0.4839 - val_accuracy: 0.7852 - 117ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4635 - accuracy: 0.7808 - val_loss: 0.4768 - val_accuracy: 0.7775 - 116ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.4627 - accuracy: 0.7850 - val_loss: 0.4598 - val_accuracy: 0.7877 - 128ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4582 - accuracy: 0.7859 - val_loss: 0.4583 - val_accuracy: 0.7890 - 120ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4555 - accuracy: 0.7894 - val_loss: 0.4869 - val_accuracy: 0.7788 - 116ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4556 - accuracy: 0.7907 - val_loss: 0.4814 - val_accuracy: 0.7826 - 133ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4540 - accuracy: 0.7888 - val_loss: 0.4771 - val_accuracy: 0.7801 - 132ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4531 - accuracy: 0.7885 - val_loss: 0.4812 - val_accuracy: 0.7852 - 133ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.4690 - val_accuracy: 0.7864 - 116ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4601 - accuracy: 0.7827 - val_loss: 0.4883 - val_accuracy: 0.7852 - 116ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4523 - accuracy: 0.7907 - val_loss: 0.4794 - val_accuracy: 0.7839 - 132ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4477 - accuracy: 0.7901 - val_loss: 0.4948 - val_accuracy: 0.7775 - 214ms/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4506 - accuracy: 0.7926 - val_loss: 0.4723 - val_accuracy: 0.7762 - 148ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4551 - accuracy: 0.7840 - val_loss: 0.4653 - val_accuracy: 0.7954 - 120ms/epoch - 9ms/step\n",
      "Epoch 36: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 0.6942 - accuracy: 0.5597 - val_loss: 0.6334 - val_accuracy: 0.6611 - 2s/epoch - 143ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 0.6159 - accuracy: 0.6906 - val_loss: 0.6147 - val_accuracy: 0.7046 - 132ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 0.5864 - accuracy: 0.7379 - val_loss: 0.5791 - val_accuracy: 0.7315 - 117ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 0.5793 - accuracy: 0.7491 - val_loss: 0.5780 - val_accuracy: 0.7468 - 133ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 0.5649 - accuracy: 0.7571 - val_loss: 0.5451 - val_accuracy: 0.7366 - 116ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 0.5399 - accuracy: 0.7581 - val_loss: 0.5553 - val_accuracy: 0.7506 - 136ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 0.5345 - accuracy: 0.7622 - val_loss: 0.5314 - val_accuracy: 0.7532 - 116ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 0.5305 - accuracy: 0.7638 - val_loss: 0.5208 - val_accuracy: 0.7545 - 132ms/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 0.5298 - accuracy: 0.7568 - val_loss: 0.5128 - val_accuracy: 0.7558 - 118ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 0.5135 - accuracy: 0.7632 - val_loss: 0.5122 - val_accuracy: 0.7570 - 132ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 0.5037 - accuracy: 0.7648 - val_loss: 0.4977 - val_accuracy: 0.7621 - 117ms/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 0.5041 - accuracy: 0.7654 - val_loss: 0.4966 - val_accuracy: 0.7583 - 117ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 0.4998 - accuracy: 0.7680 - val_loss: 0.4964 - val_accuracy: 0.7660 - 149ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 0.4862 - accuracy: 0.7677 - val_loss: 0.4933 - val_accuracy: 0.7545 - 132ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 0.4920 - accuracy: 0.7661 - val_loss: 0.4952 - val_accuracy: 0.7583 - 117ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 0.4795 - accuracy: 0.7715 - val_loss: 0.4999 - val_accuracy: 0.7558 - 118ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 0.4807 - accuracy: 0.7651 - val_loss: 0.4925 - val_accuracy: 0.7634 - 128ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 0.4794 - accuracy: 0.7709 - val_loss: 0.4827 - val_accuracy: 0.7634 - 116ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 0.4743 - accuracy: 0.7706 - val_loss: 0.4921 - val_accuracy: 0.7647 - 117ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 0.4744 - accuracy: 0.7702 - val_loss: 0.4712 - val_accuracy: 0.7596 - 117ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 0.4697 - accuracy: 0.7709 - val_loss: 0.4982 - val_accuracy: 0.7724 - 117ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 0.4681 - accuracy: 0.7715 - val_loss: 0.4750 - val_accuracy: 0.7775 - 117ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 0.4601 - accuracy: 0.7728 - val_loss: 0.4771 - val_accuracy: 0.7609 - 101ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 0.4579 - accuracy: 0.7728 - val_loss: 0.4922 - val_accuracy: 0.7826 - 117ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7749 - 117ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 0.4562 - accuracy: 0.7805 - val_loss: 0.4840 - val_accuracy: 0.7749 - 132ms/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 0.4537 - accuracy: 0.7779 - val_loss: 0.4910 - val_accuracy: 0.7685 - 117ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 0.4599 - accuracy: 0.7834 - val_loss: 0.4931 - val_accuracy: 0.7775 - 117ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 0.4635 - accuracy: 0.7798 - val_loss: 0.4601 - val_accuracy: 0.7864 - 135ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 0.4530 - accuracy: 0.7805 - val_loss: 0.5042 - val_accuracy: 0.7813 - 125ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 0.4576 - accuracy: 0.7786 - val_loss: 0.4668 - val_accuracy: 0.7673 - 102ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 0.4546 - accuracy: 0.7814 - val_loss: 0.4866 - val_accuracy: 0.7788 - 117ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 0.4589 - accuracy: 0.7818 - val_loss: 0.4704 - val_accuracy: 0.7890 - 128ms/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 0.4555 - accuracy: 0.7824 - val_loss: 0.4849 - val_accuracy: 0.7826 - 118ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 0.4541 - accuracy: 0.7811 - val_loss: 0.4899 - val_accuracy: 0.7813 - 102ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 0.4554 - accuracy: 0.7866 - val_loss: 0.4632 - val_accuracy: 0.7788 - 118ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 0.4491 - accuracy: 0.7891 - val_loss: 0.4931 - val_accuracy: 0.7877 - 129ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 0.4518 - accuracy: 0.7850 - val_loss: 0.4805 - val_accuracy: 0.7801 - 133ms/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 0.4451 - accuracy: 0.7866 - val_loss: 0.4778 - val_accuracy: 0.7775 - 185ms/epoch - 14ms/step\n",
      "Epoch 39: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.4372722935317099\n",
      "epi entropy:  0.4299152274922801\n",
      "\n",
      "dataset size:  0.2\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6462 - accuracy: 0.6351 - val_loss: 0.5984 - val_accuracy: 0.7345 - 2s/epoch - 71ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.5750 - accuracy: 0.7380 - val_loss: 0.5571 - val_accuracy: 0.7530 - 257ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5412 - accuracy: 0.7540 - val_loss: 0.5273 - val_accuracy: 0.7626 - 189ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5205 - accuracy: 0.7568 - val_loss: 0.5105 - val_accuracy: 0.7594 - 184ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.5088 - accuracy: 0.7623 - val_loss: 0.4882 - val_accuracy: 0.7780 - 211ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.4909 - accuracy: 0.7728 - val_loss: 0.4825 - val_accuracy: 0.7646 - 183ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4817 - accuracy: 0.7738 - val_loss: 0.4834 - val_accuracy: 0.7818 - 200ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4801 - accuracy: 0.7770 - val_loss: 0.4772 - val_accuracy: 0.7812 - 201ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4709 - accuracy: 0.7791 - val_loss: 0.4658 - val_accuracy: 0.7850 - 201ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4711 - accuracy: 0.7789 - val_loss: 0.4618 - val_accuracy: 0.7799 - 191ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4616 - accuracy: 0.7831 - val_loss: 0.4612 - val_accuracy: 0.7850 - 192ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.4706 - accuracy: 0.7855 - val_loss: 0.4637 - val_accuracy: 0.7780 - 217ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4588 - accuracy: 0.7821 - val_loss: 0.4567 - val_accuracy: 0.7895 - 436ms/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4621 - accuracy: 0.7906 - val_loss: 0.4548 - val_accuracy: 0.7857 - 190ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4583 - accuracy: 0.7826 - val_loss: 0.4709 - val_accuracy: 0.7825 - 201ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4585 - accuracy: 0.7820 - val_loss: 0.4602 - val_accuracy: 0.7940 - 200ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4549 - accuracy: 0.7821 - val_loss: 0.4584 - val_accuracy: 0.7882 - 200ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4520 - accuracy: 0.7906 - val_loss: 0.4570 - val_accuracy: 0.7844 - 319ms/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4531 - accuracy: 0.7836 - val_loss: 0.4580 - val_accuracy: 0.7844 - 199ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4534 - accuracy: 0.7922 - val_loss: 0.4517 - val_accuracy: 0.7812 - 200ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4490 - accuracy: 0.7869 - val_loss: 0.4748 - val_accuracy: 0.7876 - 217ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.4432 - val_accuracy: 0.7921 - 202ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4515 - accuracy: 0.7903 - val_loss: 0.4477 - val_accuracy: 0.7857 - 176ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.4546 - val_accuracy: 0.7869 - 200ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4480 - accuracy: 0.7956 - val_loss: 0.4554 - val_accuracy: 0.7895 - 185ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4508 - accuracy: 0.7933 - val_loss: 0.4525 - val_accuracy: 0.7946 - 201ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4499 - accuracy: 0.7909 - val_loss: 0.4448 - val_accuracy: 0.7927 - 201ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4495 - accuracy: 0.7908 - val_loss: 0.4545 - val_accuracy: 0.7927 - 201ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.4485 - val_accuracy: 0.7953 - 178ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4487 - accuracy: 0.7896 - val_loss: 0.4508 - val_accuracy: 0.7857 - 232ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4475 - accuracy: 0.7885 - val_loss: 0.4506 - val_accuracy: 0.7972 - 201ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4477 - accuracy: 0.7938 - val_loss: 0.4438 - val_accuracy: 0.7908 - 204ms/epoch - 8ms/step\n",
      "Epoch 32: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.7174 - accuracy: 0.5052 - val_loss: 0.6290 - val_accuracy: 0.6641 - 2s/epoch - 73ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.5962 - accuracy: 0.7117 - val_loss: 0.5745 - val_accuracy: 0.7434 - 216ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5481 - accuracy: 0.7524 - val_loss: 0.5342 - val_accuracy: 0.7588 - 201ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5318 - accuracy: 0.7583 - val_loss: 0.5165 - val_accuracy: 0.7671 - 201ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.5159 - accuracy: 0.7644 - val_loss: 0.5001 - val_accuracy: 0.7806 - 175ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.4997 - accuracy: 0.7684 - val_loss: 0.4954 - val_accuracy: 0.7793 - 200ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4956 - accuracy: 0.7720 - val_loss: 0.4914 - val_accuracy: 0.7722 - 186ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4816 - accuracy: 0.7720 - val_loss: 0.4857 - val_accuracy: 0.7742 - 185ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4733 - accuracy: 0.7764 - val_loss: 0.4846 - val_accuracy: 0.7793 - 201ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4733 - accuracy: 0.7744 - val_loss: 0.4685 - val_accuracy: 0.7722 - 204ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4647 - accuracy: 0.7770 - val_loss: 0.4672 - val_accuracy: 0.7754 - 188ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.4601 - accuracy: 0.7852 - val_loss: 0.4643 - val_accuracy: 0.7748 - 205ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4606 - accuracy: 0.7800 - val_loss: 0.4759 - val_accuracy: 0.7690 - 192ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4586 - accuracy: 0.7824 - val_loss: 0.4516 - val_accuracy: 0.7780 - 244ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4618 - accuracy: 0.7794 - val_loss: 0.4593 - val_accuracy: 0.7863 - 170ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4568 - accuracy: 0.7866 - val_loss: 0.4571 - val_accuracy: 0.7710 - 185ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4526 - accuracy: 0.7861 - val_loss: 0.4664 - val_accuracy: 0.7799 - 218ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4589 - accuracy: 0.7807 - val_loss: 0.4660 - val_accuracy: 0.7742 - 217ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4528 - accuracy: 0.7823 - val_loss: 0.4508 - val_accuracy: 0.7889 - 217ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4519 - accuracy: 0.7839 - val_loss: 0.4593 - val_accuracy: 0.7684 - 201ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.4492 - val_accuracy: 0.7825 - 200ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4498 - accuracy: 0.7848 - val_loss: 0.4447 - val_accuracy: 0.7869 - 195ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4531 - accuracy: 0.7850 - val_loss: 0.4510 - val_accuracy: 0.7901 - 178ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4504 - accuracy: 0.7863 - val_loss: 0.4579 - val_accuracy: 0.7806 - 200ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4493 - accuracy: 0.7858 - val_loss: 0.4526 - val_accuracy: 0.7940 - 205ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4455 - accuracy: 0.7906 - val_loss: 0.4416 - val_accuracy: 0.7876 - 182ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4411 - accuracy: 0.7885 - val_loss: 0.4586 - val_accuracy: 0.7946 - 195ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4451 - accuracy: 0.7908 - val_loss: 0.4486 - val_accuracy: 0.7742 - 194ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4435 - accuracy: 0.7879 - val_loss: 0.4563 - val_accuracy: 0.7812 - 201ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4471 - accuracy: 0.7834 - val_loss: 0.4468 - val_accuracy: 0.7940 - 201ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4413 - accuracy: 0.7906 - val_loss: 0.4550 - val_accuracy: 0.7953 - 188ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4428 - accuracy: 0.7885 - val_loss: 0.4490 - val_accuracy: 0.7857 - 176ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4428 - accuracy: 0.7885 - val_loss: 0.4474 - val_accuracy: 0.7933 - 210ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4422 - accuracy: 0.7880 - val_loss: 0.4512 - val_accuracy: 0.7850 - 206ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4458 - accuracy: 0.7890 - val_loss: 0.4520 - val_accuracy: 0.7818 - 218ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4530 - val_accuracy: 0.7850 - 216ms/epoch - 9ms/step\n",
      "Epoch 36: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "25/25 - 1s - loss: 0.6012 - accuracy: 0.7010 - val_loss: 0.5785 - val_accuracy: 0.7383 - 1s/epoch - 50ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.5611 - accuracy: 0.7476 - val_loss: 0.5473 - val_accuracy: 0.7594 - 249ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5341 - accuracy: 0.7520 - val_loss: 0.5235 - val_accuracy: 0.7569 - 185ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5194 - accuracy: 0.7552 - val_loss: 0.5078 - val_accuracy: 0.7639 - 217ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.4993 - accuracy: 0.7567 - val_loss: 0.4988 - val_accuracy: 0.7614 - 214ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.4960 - accuracy: 0.7616 - val_loss: 0.4872 - val_accuracy: 0.7652 - 201ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4861 - accuracy: 0.7640 - val_loss: 0.4996 - val_accuracy: 0.7601 - 193ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4810 - accuracy: 0.7696 - val_loss: 0.4743 - val_accuracy: 0.7754 - 186ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4763 - accuracy: 0.7695 - val_loss: 0.4767 - val_accuracy: 0.7780 - 184ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4732 - accuracy: 0.7682 - val_loss: 0.4734 - val_accuracy: 0.7786 - 216ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4733 - accuracy: 0.7728 - val_loss: 0.4731 - val_accuracy: 0.7793 - 195ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.4695 - accuracy: 0.7743 - val_loss: 0.4783 - val_accuracy: 0.7825 - 204ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4687 - accuracy: 0.7792 - val_loss: 0.4735 - val_accuracy: 0.7818 - 193ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4611 - accuracy: 0.7781 - val_loss: 0.4760 - val_accuracy: 0.7742 - 222ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4583 - accuracy: 0.7744 - val_loss: 0.4652 - val_accuracy: 0.7786 - 205ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4582 - accuracy: 0.7804 - val_loss: 0.4621 - val_accuracy: 0.7837 - 187ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4550 - accuracy: 0.7866 - val_loss: 0.4614 - val_accuracy: 0.7786 - 217ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4563 - accuracy: 0.7824 - val_loss: 0.4621 - val_accuracy: 0.7844 - 185ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4513 - accuracy: 0.7829 - val_loss: 0.4611 - val_accuracy: 0.7869 - 186ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4565 - accuracy: 0.7832 - val_loss: 0.4601 - val_accuracy: 0.7837 - 199ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4491 - accuracy: 0.7820 - val_loss: 0.4589 - val_accuracy: 0.7869 - 193ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4540 - accuracy: 0.7834 - val_loss: 0.4573 - val_accuracy: 0.7786 - 186ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4482 - accuracy: 0.7871 - val_loss: 0.4599 - val_accuracy: 0.7857 - 200ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4513 - accuracy: 0.7799 - val_loss: 0.4556 - val_accuracy: 0.7863 - 201ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4458 - accuracy: 0.7826 - val_loss: 0.4618 - val_accuracy: 0.7825 - 201ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.4478 - val_accuracy: 0.7901 - 201ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.4506 - val_accuracy: 0.7806 - 189ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4455 - accuracy: 0.7900 - val_loss: 0.4561 - val_accuracy: 0.7837 - 187ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4409 - accuracy: 0.7912 - val_loss: 0.4611 - val_accuracy: 0.7799 - 201ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4471 - accuracy: 0.7925 - val_loss: 0.4539 - val_accuracy: 0.7876 - 201ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4453 - accuracy: 0.7864 - val_loss: 0.4473 - val_accuracy: 0.7863 - 201ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4408 - accuracy: 0.7908 - val_loss: 0.4549 - val_accuracy: 0.7953 - 186ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4453 - accuracy: 0.7900 - val_loss: 0.4558 - val_accuracy: 0.7786 - 216ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4432 - accuracy: 0.7904 - val_loss: 0.4519 - val_accuracy: 0.7965 - 201ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4440 - accuracy: 0.7932 - val_loss: 0.4621 - val_accuracy: 0.7825 - 305ms/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4449 - accuracy: 0.7920 - val_loss: 0.4474 - val_accuracy: 0.7850 - 171ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4404 - accuracy: 0.7949 - val_loss: 0.4500 - val_accuracy: 0.7997 - 205ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.4500 - val_accuracy: 0.7908 - 192ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4412 - accuracy: 0.7944 - val_loss: 0.4550 - val_accuracy: 0.7940 - 200ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4392 - accuracy: 0.7933 - val_loss: 0.4406 - val_accuracy: 0.7965 - 201ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4387 - accuracy: 0.7994 - val_loss: 0.4516 - val_accuracy: 0.7844 - 187ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4426 - accuracy: 0.7972 - val_loss: 0.4553 - val_accuracy: 0.7889 - 232ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4388 - accuracy: 0.8002 - val_loss: 0.4440 - val_accuracy: 0.8017 - 163ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4412 - accuracy: 0.7957 - val_loss: 0.4482 - val_accuracy: 0.7959 - 201ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4424 - accuracy: 0.7936 - val_loss: 0.4561 - val_accuracy: 0.7857 - 187ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4388 - accuracy: 0.7976 - val_loss: 0.4421 - val_accuracy: 0.7978 - 184ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4395 - accuracy: 0.7964 - val_loss: 0.4518 - val_accuracy: 0.7927 - 203ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4412 - accuracy: 0.7943 - val_loss: 0.4411 - val_accuracy: 0.7908 - 190ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4402 - accuracy: 0.7964 - val_loss: 0.4527 - val_accuracy: 0.7889 - 214ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4365 - accuracy: 0.7962 - val_loss: 0.4455 - val_accuracy: 0.7882 - 201ms/epoch - 8ms/step\n",
      "Epoch 50: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6298 - accuracy: 0.6714 - val_loss: 0.5711 - val_accuracy: 0.7479 - 2s/epoch - 98ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.5701 - accuracy: 0.7490 - val_loss: 0.5516 - val_accuracy: 0.7626 - 204ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5450 - accuracy: 0.7503 - val_loss: 0.5298 - val_accuracy: 0.7601 - 242ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5228 - accuracy: 0.7586 - val_loss: 0.5065 - val_accuracy: 0.7761 - 201ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.5070 - accuracy: 0.7615 - val_loss: 0.5014 - val_accuracy: 0.7799 - 216ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.4940 - accuracy: 0.7693 - val_loss: 0.4861 - val_accuracy: 0.7735 - 196ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4889 - accuracy: 0.7706 - val_loss: 0.4829 - val_accuracy: 0.7837 - 177ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4805 - accuracy: 0.7733 - val_loss: 0.4795 - val_accuracy: 0.7831 - 185ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4739 - accuracy: 0.7812 - val_loss: 0.4788 - val_accuracy: 0.7748 - 201ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4732 - accuracy: 0.7770 - val_loss: 0.4621 - val_accuracy: 0.7869 - 247ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4677 - accuracy: 0.7791 - val_loss: 0.4711 - val_accuracy: 0.7780 - 186ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.4644 - accuracy: 0.7799 - val_loss: 0.4746 - val_accuracy: 0.7799 - 201ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4650 - accuracy: 0.7800 - val_loss: 0.4689 - val_accuracy: 0.7767 - 232ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4581 - accuracy: 0.7810 - val_loss: 0.4704 - val_accuracy: 0.7799 - 185ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4571 - accuracy: 0.7829 - val_loss: 0.4742 - val_accuracy: 0.7799 - 179ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4599 - accuracy: 0.7820 - val_loss: 0.4664 - val_accuracy: 0.7882 - 203ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4528 - accuracy: 0.7874 - val_loss: 0.4696 - val_accuracy: 0.7793 - 168ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4564 - accuracy: 0.7852 - val_loss: 0.4716 - val_accuracy: 0.7754 - 194ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4534 - accuracy: 0.7864 - val_loss: 0.4612 - val_accuracy: 0.7825 - 177ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.4563 - val_accuracy: 0.7882 - 201ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4486 - accuracy: 0.7884 - val_loss: 0.4529 - val_accuracy: 0.7901 - 192ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4516 - accuracy: 0.7888 - val_loss: 0.4536 - val_accuracy: 0.7985 - 178ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4514 - accuracy: 0.7896 - val_loss: 0.4504 - val_accuracy: 0.7869 - 175ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4499 - accuracy: 0.7887 - val_loss: 0.4545 - val_accuracy: 0.7908 - 202ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4492 - accuracy: 0.7896 - val_loss: 0.4587 - val_accuracy: 0.7959 - 199ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4451 - accuracy: 0.7866 - val_loss: 0.4590 - val_accuracy: 0.7818 - 186ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4462 - accuracy: 0.7911 - val_loss: 0.4501 - val_accuracy: 0.7908 - 214ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4469 - accuracy: 0.7938 - val_loss: 0.4529 - val_accuracy: 0.7940 - 179ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4452 - accuracy: 0.7924 - val_loss: 0.4486 - val_accuracy: 0.7895 - 200ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4418 - accuracy: 0.7914 - val_loss: 0.4511 - val_accuracy: 0.7831 - 202ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4408 - accuracy: 0.7927 - val_loss: 0.4579 - val_accuracy: 0.7959 - 179ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4404 - accuracy: 0.7957 - val_loss: 0.4573 - val_accuracy: 0.7882 - 191ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4458 - accuracy: 0.7943 - val_loss: 0.4500 - val_accuracy: 0.7895 - 174ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4439 - accuracy: 0.7908 - val_loss: 0.4549 - val_accuracy: 0.7946 - 185ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4383 - accuracy: 0.7972 - val_loss: 0.4414 - val_accuracy: 0.7889 - 200ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4437 - accuracy: 0.7898 - val_loss: 0.4520 - val_accuracy: 0.7895 - 193ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4410 - accuracy: 0.7944 - val_loss: 0.4462 - val_accuracy: 0.7895 - 184ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4418 - accuracy: 0.7912 - val_loss: 0.4567 - val_accuracy: 0.7940 - 200ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4387 - accuracy: 0.7933 - val_loss: 0.4438 - val_accuracy: 0.7965 - 201ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4419 - accuracy: 0.7888 - val_loss: 0.4565 - val_accuracy: 0.7869 - 201ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4453 - accuracy: 0.7943 - val_loss: 0.4511 - val_accuracy: 0.7940 - 185ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4373 - accuracy: 0.7916 - val_loss: 0.4542 - val_accuracy: 0.7850 - 232ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4384 - accuracy: 0.7940 - val_loss: 0.4416 - val_accuracy: 0.7921 - 303ms/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4447 - accuracy: 0.7917 - val_loss: 0.4504 - val_accuracy: 0.7806 - 204ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4400 - accuracy: 0.7965 - val_loss: 0.4477 - val_accuracy: 0.7965 - 174ms/epoch - 7ms/step\n",
      "Epoch 45: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6721 - accuracy: 0.5932 - val_loss: 0.6072 - val_accuracy: 0.6987 - 2s/epoch - 66ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.5870 - accuracy: 0.7303 - val_loss: 0.5571 - val_accuracy: 0.7505 - 202ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5534 - accuracy: 0.7466 - val_loss: 0.5360 - val_accuracy: 0.7601 - 200ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5292 - accuracy: 0.7527 - val_loss: 0.5136 - val_accuracy: 0.7588 - 163ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.5125 - accuracy: 0.7551 - val_loss: 0.4849 - val_accuracy: 0.7652 - 200ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.5009 - accuracy: 0.7554 - val_loss: 0.4882 - val_accuracy: 0.7697 - 200ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4904 - accuracy: 0.7616 - val_loss: 0.4817 - val_accuracy: 0.7684 - 201ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4843 - accuracy: 0.7680 - val_loss: 0.4874 - val_accuracy: 0.7799 - 186ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4746 - accuracy: 0.7669 - val_loss: 0.4776 - val_accuracy: 0.7831 - 163ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4759 - accuracy: 0.7693 - val_loss: 0.4685 - val_accuracy: 0.7710 - 185ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4652 - accuracy: 0.7741 - val_loss: 0.4586 - val_accuracy: 0.7831 - 189ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.4651 - accuracy: 0.7759 - val_loss: 0.4686 - val_accuracy: 0.7831 - 184ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4668 - accuracy: 0.7815 - val_loss: 0.4678 - val_accuracy: 0.7869 - 243ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4658 - accuracy: 0.7744 - val_loss: 0.4685 - val_accuracy: 0.7869 - 178ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4610 - accuracy: 0.7768 - val_loss: 0.4671 - val_accuracy: 0.7710 - 177ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4566 - accuracy: 0.7832 - val_loss: 0.4683 - val_accuracy: 0.7799 - 184ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4599 - accuracy: 0.7826 - val_loss: 0.4504 - val_accuracy: 0.7850 - 202ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4575 - accuracy: 0.7836 - val_loss: 0.4617 - val_accuracy: 0.7876 - 202ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4568 - accuracy: 0.7826 - val_loss: 0.4598 - val_accuracy: 0.7882 - 197ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4528 - accuracy: 0.7856 - val_loss: 0.4566 - val_accuracy: 0.7933 - 194ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4522 - accuracy: 0.7852 - val_loss: 0.4538 - val_accuracy: 0.7812 - 201ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4538 - accuracy: 0.7884 - val_loss: 0.4525 - val_accuracy: 0.7806 - 185ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4489 - accuracy: 0.7896 - val_loss: 0.4491 - val_accuracy: 0.7914 - 217ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4506 - accuracy: 0.7908 - val_loss: 0.4531 - val_accuracy: 0.7825 - 201ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4472 - accuracy: 0.7885 - val_loss: 0.4431 - val_accuracy: 0.7818 - 179ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4504 - accuracy: 0.7874 - val_loss: 0.4499 - val_accuracy: 0.7850 - 200ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4485 - accuracy: 0.7880 - val_loss: 0.4597 - val_accuracy: 0.7831 - 218ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4442 - accuracy: 0.7900 - val_loss: 0.4489 - val_accuracy: 0.7914 - 184ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.4496 - val_accuracy: 0.7889 - 199ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4514 - accuracy: 0.7852 - val_loss: 0.4562 - val_accuracy: 0.7895 - 201ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4469 - accuracy: 0.7872 - val_loss: 0.4537 - val_accuracy: 0.7831 - 185ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4460 - accuracy: 0.7935 - val_loss: 0.4511 - val_accuracy: 0.7876 - 194ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4470 - accuracy: 0.7906 - val_loss: 0.4426 - val_accuracy: 0.7901 - 184ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4470 - accuracy: 0.7888 - val_loss: 0.4499 - val_accuracy: 0.7946 - 201ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4481 - accuracy: 0.7936 - val_loss: 0.4545 - val_accuracy: 0.7869 - 203ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4458 - accuracy: 0.7916 - val_loss: 0.4484 - val_accuracy: 0.7908 - 195ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4405 - accuracy: 0.7904 - val_loss: 0.4460 - val_accuracy: 0.7889 - 196ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4445 - accuracy: 0.7989 - val_loss: 0.4407 - val_accuracy: 0.7812 - 166ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4436 - accuracy: 0.7914 - val_loss: 0.4475 - val_accuracy: 0.7921 - 199ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4414 - accuracy: 0.7932 - val_loss: 0.4464 - val_accuracy: 0.7831 - 185ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4392 - accuracy: 0.7962 - val_loss: 0.4445 - val_accuracy: 0.7889 - 200ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4400 - accuracy: 0.7944 - val_loss: 0.4468 - val_accuracy: 0.7946 - 217ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4398 - accuracy: 0.7948 - val_loss: 0.4437 - val_accuracy: 0.7946 - 190ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4376 - accuracy: 0.7930 - val_loss: 0.4544 - val_accuracy: 0.7876 - 173ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4425 - accuracy: 0.7938 - val_loss: 0.4519 - val_accuracy: 0.7901 - 170ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4374 - accuracy: 0.7984 - val_loss: 0.4498 - val_accuracy: 0.7946 - 216ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4556 - val_accuracy: 0.7831 - 202ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4392 - accuracy: 0.7928 - val_loss: 0.4517 - val_accuracy: 0.7908 - 189ms/epoch - 8ms/step\n",
      "Epoch 48: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "25/25 - 3s - loss: 0.6682 - accuracy: 0.6167 - val_loss: 0.6121 - val_accuracy: 0.7172 - 3s/epoch - 102ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.5884 - accuracy: 0.7295 - val_loss: 0.5568 - val_accuracy: 0.7575 - 201ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5459 - accuracy: 0.7517 - val_loss: 0.5236 - val_accuracy: 0.7550 - 178ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5185 - accuracy: 0.7573 - val_loss: 0.5076 - val_accuracy: 0.7658 - 184ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.4991 - accuracy: 0.7618 - val_loss: 0.5024 - val_accuracy: 0.7639 - 201ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.4900 - accuracy: 0.7640 - val_loss: 0.4849 - val_accuracy: 0.7678 - 170ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4799 - accuracy: 0.7652 - val_loss: 0.4793 - val_accuracy: 0.7844 - 200ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4721 - accuracy: 0.7704 - val_loss: 0.4685 - val_accuracy: 0.7729 - 179ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4692 - accuracy: 0.7759 - val_loss: 0.4680 - val_accuracy: 0.7729 - 254ms/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4593 - accuracy: 0.7770 - val_loss: 0.4670 - val_accuracy: 0.7812 - 200ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4578 - accuracy: 0.7800 - val_loss: 0.4689 - val_accuracy: 0.7806 - 186ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.4566 - accuracy: 0.7864 - val_loss: 0.4658 - val_accuracy: 0.7863 - 506ms/epoch - 20ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4579 - accuracy: 0.7829 - val_loss: 0.4533 - val_accuracy: 0.7818 - 232ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4611 - accuracy: 0.7829 - val_loss: 0.4640 - val_accuracy: 0.7831 - 204ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4537 - accuracy: 0.7871 - val_loss: 0.4664 - val_accuracy: 0.7780 - 183ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4557 - accuracy: 0.7908 - val_loss: 0.4548 - val_accuracy: 0.7799 - 218ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4498 - accuracy: 0.7892 - val_loss: 0.4605 - val_accuracy: 0.7844 - 292ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4504 - accuracy: 0.7887 - val_loss: 0.4542 - val_accuracy: 0.7837 - 407ms/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4458 - accuracy: 0.7922 - val_loss: 0.4629 - val_accuracy: 0.7978 - 241ms/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4472 - accuracy: 0.7954 - val_loss: 0.4574 - val_accuracy: 0.7933 - 210ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4531 - accuracy: 0.7919 - val_loss: 0.4521 - val_accuracy: 0.7965 - 247ms/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4445 - accuracy: 0.7922 - val_loss: 0.4439 - val_accuracy: 0.7972 - 248ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4499 - accuracy: 0.7920 - val_loss: 0.4492 - val_accuracy: 0.7901 - 207ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4444 - accuracy: 0.7949 - val_loss: 0.4562 - val_accuracy: 0.7997 - 243ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4456 - accuracy: 0.7935 - val_loss: 0.4509 - val_accuracy: 0.7972 - 325ms/epoch - 13ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4412 - accuracy: 0.8000 - val_loss: 0.4548 - val_accuracy: 0.7799 - 212ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4450 - accuracy: 0.7975 - val_loss: 0.4457 - val_accuracy: 0.7927 - 235ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4447 - accuracy: 0.7930 - val_loss: 0.4574 - val_accuracy: 0.7863 - 241ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4415 - accuracy: 0.7973 - val_loss: 0.4477 - val_accuracy: 0.7869 - 262ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4409 - accuracy: 0.7984 - val_loss: 0.4426 - val_accuracy: 0.7991 - 210ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4388 - accuracy: 0.7981 - val_loss: 0.4446 - val_accuracy: 0.7972 - 221ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4422 - accuracy: 0.7951 - val_loss: 0.4542 - val_accuracy: 0.7869 - 217ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4414 - accuracy: 0.7988 - val_loss: 0.4462 - val_accuracy: 0.7978 - 208ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4420 - accuracy: 0.7954 - val_loss: 0.4499 - val_accuracy: 0.7940 - 190ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4413 - accuracy: 0.7976 - val_loss: 0.4510 - val_accuracy: 0.7921 - 229ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4386 - accuracy: 0.7975 - val_loss: 0.4404 - val_accuracy: 0.7914 - 253ms/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4404 - accuracy: 0.7994 - val_loss: 0.4478 - val_accuracy: 0.7882 - 190ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4374 - accuracy: 0.7956 - val_loss: 0.4457 - val_accuracy: 0.7914 - 166ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4403 - accuracy: 0.7968 - val_loss: 0.4476 - val_accuracy: 0.7863 - 185ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4360 - accuracy: 0.7984 - val_loss: 0.4502 - val_accuracy: 0.7901 - 191ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4414 - accuracy: 0.7964 - val_loss: 0.4449 - val_accuracy: 0.7933 - 317ms/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4368 - accuracy: 0.7983 - val_loss: 0.4458 - val_accuracy: 0.7953 - 293ms/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4379 - accuracy: 0.7960 - val_loss: 0.4487 - val_accuracy: 0.7921 - 287ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4331 - accuracy: 0.8016 - val_loss: 0.4475 - val_accuracy: 0.7933 - 273ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4401 - accuracy: 0.7972 - val_loss: 0.4515 - val_accuracy: 0.7882 - 263ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4367 - accuracy: 0.7988 - val_loss: 0.4472 - val_accuracy: 0.7889 - 281ms/epoch - 11ms/step\n",
      "Epoch 46: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "25/25 - 3s - loss: 0.6271 - accuracy: 0.6773 - val_loss: 0.5733 - val_accuracy: 0.7454 - 3s/epoch - 123ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.5689 - accuracy: 0.7476 - val_loss: 0.5432 - val_accuracy: 0.7588 - 238ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5407 - accuracy: 0.7517 - val_loss: 0.5283 - val_accuracy: 0.7607 - 375ms/epoch - 15ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5220 - accuracy: 0.7560 - val_loss: 0.5103 - val_accuracy: 0.7607 - 187ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.5057 - accuracy: 0.7567 - val_loss: 0.4978 - val_accuracy: 0.7582 - 188ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.4980 - accuracy: 0.7604 - val_loss: 0.4832 - val_accuracy: 0.7658 - 203ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4836 - accuracy: 0.7666 - val_loss: 0.4768 - val_accuracy: 0.7754 - 209ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4775 - accuracy: 0.7696 - val_loss: 0.4652 - val_accuracy: 0.7837 - 203ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4706 - accuracy: 0.7756 - val_loss: 0.4751 - val_accuracy: 0.7793 - 206ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4681 - accuracy: 0.7783 - val_loss: 0.4608 - val_accuracy: 0.7844 - 196ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4611 - accuracy: 0.7794 - val_loss: 0.4679 - val_accuracy: 0.7786 - 200ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.4599 - accuracy: 0.7808 - val_loss: 0.4618 - val_accuracy: 0.7869 - 204ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4539 - accuracy: 0.7810 - val_loss: 0.4573 - val_accuracy: 0.7876 - 201ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.4589 - accuracy: 0.7781 - val_loss: 0.4510 - val_accuracy: 0.7799 - 741ms/epoch - 30ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4552 - accuracy: 0.7815 - val_loss: 0.4503 - val_accuracy: 0.7793 - 211ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4533 - accuracy: 0.7871 - val_loss: 0.4638 - val_accuracy: 0.7818 - 207ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4520 - accuracy: 0.7836 - val_loss: 0.4677 - val_accuracy: 0.7697 - 194ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4524 - accuracy: 0.7855 - val_loss: 0.4609 - val_accuracy: 0.7857 - 188ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4498 - accuracy: 0.7829 - val_loss: 0.4497 - val_accuracy: 0.7869 - 213ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4520 - accuracy: 0.7848 - val_loss: 0.4575 - val_accuracy: 0.7735 - 184ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4510 - accuracy: 0.7816 - val_loss: 0.4497 - val_accuracy: 0.7946 - 202ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4470 - accuracy: 0.7900 - val_loss: 0.4547 - val_accuracy: 0.7793 - 188ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4461 - accuracy: 0.7877 - val_loss: 0.4516 - val_accuracy: 0.7831 - 219ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4445 - accuracy: 0.7888 - val_loss: 0.4522 - val_accuracy: 0.7889 - 186ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4453 - accuracy: 0.7884 - val_loss: 0.4531 - val_accuracy: 0.7869 - 236ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4463 - accuracy: 0.7893 - val_loss: 0.4606 - val_accuracy: 0.7793 - 200ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4420 - accuracy: 0.7912 - val_loss: 0.4505 - val_accuracy: 0.7882 - 199ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4476 - accuracy: 0.7837 - val_loss: 0.4538 - val_accuracy: 0.7837 - 210ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4433 - accuracy: 0.7962 - val_loss: 0.4492 - val_accuracy: 0.7933 - 204ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4453 - accuracy: 0.7914 - val_loss: 0.4582 - val_accuracy: 0.7857 - 196ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4434 - accuracy: 0.7893 - val_loss: 0.4616 - val_accuracy: 0.7818 - 188ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4439 - accuracy: 0.7896 - val_loss: 0.4489 - val_accuracy: 0.7933 - 197ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4426 - accuracy: 0.7884 - val_loss: 0.4546 - val_accuracy: 0.7869 - 186ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4408 - accuracy: 0.7932 - val_loss: 0.4512 - val_accuracy: 0.7914 - 210ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4424 - accuracy: 0.7914 - val_loss: 0.4499 - val_accuracy: 0.7844 - 220ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4421 - accuracy: 0.7911 - val_loss: 0.4451 - val_accuracy: 0.7825 - 175ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4425 - accuracy: 0.7887 - val_loss: 0.4530 - val_accuracy: 0.7901 - 198ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4401 - accuracy: 0.7935 - val_loss: 0.4521 - val_accuracy: 0.7882 - 190ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4420 - accuracy: 0.7928 - val_loss: 0.4562 - val_accuracy: 0.7946 - 226ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4411 - accuracy: 0.7916 - val_loss: 0.4519 - val_accuracy: 0.7901 - 175ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4419 - accuracy: 0.7912 - val_loss: 0.4495 - val_accuracy: 0.7901 - 201ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4416 - accuracy: 0.7879 - val_loss: 0.4557 - val_accuracy: 0.7978 - 195ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 0s - loss: 0.4376 - accuracy: 0.7922 - val_loss: 0.4500 - val_accuracy: 0.7933 - 195ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 0s - loss: 0.4387 - accuracy: 0.7959 - val_loss: 0.4466 - val_accuracy: 0.7959 - 362ms/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 0s - loss: 0.4411 - accuracy: 0.7901 - val_loss: 0.4450 - val_accuracy: 0.7940 - 182ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 0s - loss: 0.4349 - accuracy: 0.7932 - val_loss: 0.4478 - val_accuracy: 0.7850 - 174ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 0s - loss: 0.4379 - accuracy: 0.7933 - val_loss: 0.4462 - val_accuracy: 0.7876 - 185ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 0s - loss: 0.4378 - accuracy: 0.7933 - val_loss: 0.4438 - val_accuracy: 0.7908 - 189ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 0s - loss: 0.4382 - accuracy: 0.7943 - val_loss: 0.4480 - val_accuracy: 0.7889 - 183ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 0s - loss: 0.4388 - accuracy: 0.7964 - val_loss: 0.4517 - val_accuracy: 0.7837 - 186ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 0s - loss: 0.4370 - accuracy: 0.7927 - val_loss: 0.4523 - val_accuracy: 0.7901 - 209ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 0s - loss: 0.4394 - accuracy: 0.7941 - val_loss: 0.4405 - val_accuracy: 0.7927 - 210ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 0s - loss: 0.4382 - accuracy: 0.7959 - val_loss: 0.4443 - val_accuracy: 0.7959 - 190ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 0s - loss: 0.4376 - accuracy: 0.7880 - val_loss: 0.4419 - val_accuracy: 0.7895 - 201ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 0s - loss: 0.4366 - accuracy: 0.7935 - val_loss: 0.4469 - val_accuracy: 0.7965 - 261ms/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 0s - loss: 0.4381 - accuracy: 0.7919 - val_loss: 0.4369 - val_accuracy: 0.7908 - 186ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 0s - loss: 0.4383 - accuracy: 0.7940 - val_loss: 0.4463 - val_accuracy: 0.7889 - 185ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 0s - loss: 0.4363 - accuracy: 0.7924 - val_loss: 0.4501 - val_accuracy: 0.7908 - 198ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 0s - loss: 0.4385 - accuracy: 0.7922 - val_loss: 0.4454 - val_accuracy: 0.7818 - 170ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 0s - loss: 0.4327 - accuracy: 0.7978 - val_loss: 0.4418 - val_accuracy: 0.7933 - 180ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 0s - loss: 0.4340 - accuracy: 0.7928 - val_loss: 0.4416 - val_accuracy: 0.7946 - 186ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 0s - loss: 0.4377 - accuracy: 0.7930 - val_loss: 0.4460 - val_accuracy: 0.7933 - 180ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 0s - loss: 0.4345 - accuracy: 0.7940 - val_loss: 0.4451 - val_accuracy: 0.7889 - 213ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 0s - loss: 0.4386 - accuracy: 0.7912 - val_loss: 0.4498 - val_accuracy: 0.7895 - 190ms/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 0s - loss: 0.4324 - accuracy: 0.7967 - val_loss: 0.4506 - val_accuracy: 0.7889 - 207ms/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 0s - loss: 0.4366 - accuracy: 0.7941 - val_loss: 0.4463 - val_accuracy: 0.7806 - 180ms/epoch - 7ms/step\n",
      "Epoch 66: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "25/25 - 7s - loss: 0.6885 - accuracy: 0.5681 - val_loss: 0.6273 - val_accuracy: 0.6859 - 7s/epoch - 298ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.6074 - accuracy: 0.7154 - val_loss: 0.5746 - val_accuracy: 0.7428 - 219ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5648 - accuracy: 0.7456 - val_loss: 0.5465 - val_accuracy: 0.7582 - 222ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5446 - accuracy: 0.7525 - val_loss: 0.5320 - val_accuracy: 0.7646 - 296ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.5267 - accuracy: 0.7544 - val_loss: 0.5255 - val_accuracy: 0.7678 - 179ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.5118 - accuracy: 0.7620 - val_loss: 0.5063 - val_accuracy: 0.7697 - 203ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4977 - accuracy: 0.7645 - val_loss: 0.4791 - val_accuracy: 0.7690 - 188ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4884 - accuracy: 0.7690 - val_loss: 0.4767 - val_accuracy: 0.7774 - 329ms/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4805 - accuracy: 0.7740 - val_loss: 0.4745 - val_accuracy: 0.7767 - 189ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4718 - accuracy: 0.7796 - val_loss: 0.4742 - val_accuracy: 0.7889 - 189ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4720 - accuracy: 0.7764 - val_loss: 0.4773 - val_accuracy: 0.7729 - 265ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.4629 - accuracy: 0.7824 - val_loss: 0.4677 - val_accuracy: 0.7818 - 166ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4641 - accuracy: 0.7807 - val_loss: 0.4674 - val_accuracy: 0.7690 - 409ms/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4575 - accuracy: 0.7853 - val_loss: 0.4625 - val_accuracy: 0.7876 - 211ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4552 - accuracy: 0.7837 - val_loss: 0.4647 - val_accuracy: 0.7774 - 179ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4541 - accuracy: 0.7903 - val_loss: 0.4633 - val_accuracy: 0.7761 - 200ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4510 - accuracy: 0.7900 - val_loss: 0.4602 - val_accuracy: 0.7786 - 202ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4509 - accuracy: 0.7892 - val_loss: 0.4604 - val_accuracy: 0.7882 - 188ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4556 - accuracy: 0.7898 - val_loss: 0.4472 - val_accuracy: 0.7876 - 192ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4510 - accuracy: 0.7922 - val_loss: 0.4605 - val_accuracy: 0.7869 - 164ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4552 - accuracy: 0.7826 - val_loss: 0.4619 - val_accuracy: 0.7793 - 164ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4547 - accuracy: 0.7880 - val_loss: 0.4533 - val_accuracy: 0.7953 - 188ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4518 - accuracy: 0.7874 - val_loss: 0.4485 - val_accuracy: 0.8010 - 201ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4466 - accuracy: 0.7911 - val_loss: 0.4500 - val_accuracy: 0.7863 - 186ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4461 - accuracy: 0.7906 - val_loss: 0.4567 - val_accuracy: 0.7812 - 199ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4489 - accuracy: 0.7879 - val_loss: 0.4414 - val_accuracy: 0.7921 - 191ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4606 - val_accuracy: 0.7761 - 188ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4437 - accuracy: 0.7946 - val_loss: 0.4549 - val_accuracy: 0.7882 - 186ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4392 - accuracy: 0.7965 - val_loss: 0.4554 - val_accuracy: 0.7940 - 173ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4436 - accuracy: 0.7960 - val_loss: 0.4500 - val_accuracy: 0.7959 - 273ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4440 - accuracy: 0.7908 - val_loss: 0.4486 - val_accuracy: 0.7953 - 247ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4420 - accuracy: 0.7951 - val_loss: 0.4509 - val_accuracy: 0.7895 - 184ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4453 - accuracy: 0.7946 - val_loss: 0.4544 - val_accuracy: 0.7921 - 180ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4415 - accuracy: 0.7930 - val_loss: 0.4440 - val_accuracy: 0.7946 - 172ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4424 - accuracy: 0.7920 - val_loss: 0.4474 - val_accuracy: 0.7895 - 197ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4442 - accuracy: 0.7888 - val_loss: 0.4594 - val_accuracy: 0.7895 - 178ms/epoch - 7ms/step\n",
      "Epoch 36: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6170 - accuracy: 0.6954 - val_loss: 0.5686 - val_accuracy: 0.7473 - 2s/epoch - 69ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.5591 - accuracy: 0.7488 - val_loss: 0.5287 - val_accuracy: 0.7614 - 211ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5276 - accuracy: 0.7575 - val_loss: 0.5013 - val_accuracy: 0.7665 - 255ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5055 - accuracy: 0.7639 - val_loss: 0.4903 - val_accuracy: 0.7710 - 197ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.4994 - accuracy: 0.7642 - val_loss: 0.4936 - val_accuracy: 0.7722 - 188ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.4839 - accuracy: 0.7677 - val_loss: 0.4776 - val_accuracy: 0.7774 - 182ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4784 - accuracy: 0.7709 - val_loss: 0.4821 - val_accuracy: 0.7665 - 176ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.4646 - val_accuracy: 0.7850 - 203ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4682 - accuracy: 0.7797 - val_loss: 0.4834 - val_accuracy: 0.7754 - 193ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4694 - val_accuracy: 0.7882 - 180ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4604 - accuracy: 0.7826 - val_loss: 0.4596 - val_accuracy: 0.7748 - 195ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.4593 - accuracy: 0.7868 - val_loss: 0.4671 - val_accuracy: 0.7927 - 195ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.4630 - val_accuracy: 0.7882 - 203ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4569 - accuracy: 0.7882 - val_loss: 0.4636 - val_accuracy: 0.7825 - 209ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4495 - accuracy: 0.7855 - val_loss: 0.4598 - val_accuracy: 0.7876 - 178ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4518 - accuracy: 0.7842 - val_loss: 0.4528 - val_accuracy: 0.7921 - 194ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4516 - accuracy: 0.7879 - val_loss: 0.4542 - val_accuracy: 0.7882 - 191ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4450 - accuracy: 0.7888 - val_loss: 0.4502 - val_accuracy: 0.7889 - 193ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4526 - accuracy: 0.7927 - val_loss: 0.4458 - val_accuracy: 0.7921 - 181ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4507 - accuracy: 0.7884 - val_loss: 0.4455 - val_accuracy: 0.7940 - 209ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4463 - accuracy: 0.7959 - val_loss: 0.4484 - val_accuracy: 0.7889 - 190ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4454 - accuracy: 0.7952 - val_loss: 0.4540 - val_accuracy: 0.7921 - 196ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4413 - accuracy: 0.7954 - val_loss: 0.4543 - val_accuracy: 0.7959 - 195ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4437 - accuracy: 0.7916 - val_loss: 0.4458 - val_accuracy: 0.7914 - 225ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4437 - accuracy: 0.7968 - val_loss: 0.4460 - val_accuracy: 0.7972 - 194ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4443 - accuracy: 0.7975 - val_loss: 0.4458 - val_accuracy: 0.7921 - 185ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4416 - accuracy: 0.7941 - val_loss: 0.4464 - val_accuracy: 0.7876 - 196ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4411 - accuracy: 0.7938 - val_loss: 0.4443 - val_accuracy: 0.7857 - 199ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4382 - accuracy: 0.7984 - val_loss: 0.4451 - val_accuracy: 0.7895 - 172ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4411 - accuracy: 0.7954 - val_loss: 0.4438 - val_accuracy: 0.7863 - 190ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.4424 - val_accuracy: 0.7953 - 199ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4379 - accuracy: 0.7948 - val_loss: 0.4398 - val_accuracy: 0.7946 - 207ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4437 - accuracy: 0.7956 - val_loss: 0.4466 - val_accuracy: 0.7876 - 219ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4416 - accuracy: 0.7988 - val_loss: 0.4503 - val_accuracy: 0.7953 - 202ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4420 - accuracy: 0.7941 - val_loss: 0.4509 - val_accuracy: 0.7908 - 186ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4400 - accuracy: 0.7973 - val_loss: 0.4505 - val_accuracy: 0.7978 - 194ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4408 - accuracy: 0.7940 - val_loss: 0.4504 - val_accuracy: 0.7857 - 212ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4386 - accuracy: 0.7965 - val_loss: 0.4447 - val_accuracy: 0.7946 - 188ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4375 - accuracy: 0.7960 - val_loss: 0.4472 - val_accuracy: 0.7882 - 215ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4323 - accuracy: 0.7997 - val_loss: 0.4467 - val_accuracy: 0.7876 - 204ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 0s - loss: 0.4359 - accuracy: 0.8004 - val_loss: 0.4452 - val_accuracy: 0.7908 - 195ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 0s - loss: 0.4386 - accuracy: 0.7988 - val_loss: 0.4501 - val_accuracy: 0.7933 - 188ms/epoch - 8ms/step\n",
      "Epoch 42: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "25/25 - 4s - loss: 0.6539 - accuracy: 0.6340 - val_loss: 0.5981 - val_accuracy: 0.7159 - 4s/epoch - 168ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 0s - loss: 0.5846 - accuracy: 0.7450 - val_loss: 0.5568 - val_accuracy: 0.7543 - 219ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 0s - loss: 0.5477 - accuracy: 0.7533 - val_loss: 0.5239 - val_accuracy: 0.7652 - 172ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 0s - loss: 0.5237 - accuracy: 0.7576 - val_loss: 0.4946 - val_accuracy: 0.7710 - 187ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 0s - loss: 0.5014 - accuracy: 0.7656 - val_loss: 0.4906 - val_accuracy: 0.7882 - 203ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 0s - loss: 0.4894 - accuracy: 0.7724 - val_loss: 0.4927 - val_accuracy: 0.7774 - 234ms/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 0s - loss: 0.4924 - accuracy: 0.7615 - val_loss: 0.4810 - val_accuracy: 0.7729 - 205ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 0s - loss: 0.4815 - accuracy: 0.7762 - val_loss: 0.4766 - val_accuracy: 0.7825 - 187ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 0s - loss: 0.4758 - accuracy: 0.7717 - val_loss: 0.4711 - val_accuracy: 0.7818 - 219ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 0s - loss: 0.4759 - accuracy: 0.7746 - val_loss: 0.4736 - val_accuracy: 0.7806 - 187ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 0s - loss: 0.4663 - accuracy: 0.7807 - val_loss: 0.4601 - val_accuracy: 0.7863 - 203ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 0s - loss: 0.4604 - accuracy: 0.7844 - val_loss: 0.4598 - val_accuracy: 0.7831 - 187ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 0s - loss: 0.4637 - accuracy: 0.7818 - val_loss: 0.4509 - val_accuracy: 0.7959 - 188ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 0s - loss: 0.4604 - accuracy: 0.7855 - val_loss: 0.4643 - val_accuracy: 0.7850 - 172ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 0s - loss: 0.4548 - accuracy: 0.7852 - val_loss: 0.4720 - val_accuracy: 0.7857 - 188ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 0s - loss: 0.4559 - accuracy: 0.7872 - val_loss: 0.4558 - val_accuracy: 0.7774 - 187ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 0s - loss: 0.4491 - accuracy: 0.7850 - val_loss: 0.4590 - val_accuracy: 0.7908 - 172ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 0s - loss: 0.4592 - accuracy: 0.7868 - val_loss: 0.4641 - val_accuracy: 0.7972 - 219ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 0s - loss: 0.4495 - accuracy: 0.7901 - val_loss: 0.4554 - val_accuracy: 0.7863 - 172ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 0s - loss: 0.4577 - accuracy: 0.7805 - val_loss: 0.4517 - val_accuracy: 0.7908 - 187ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 0s - loss: 0.4518 - accuracy: 0.7903 - val_loss: 0.4500 - val_accuracy: 0.7895 - 187ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 0s - loss: 0.4512 - accuracy: 0.7932 - val_loss: 0.4526 - val_accuracy: 0.7889 - 183ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 0s - loss: 0.4481 - accuracy: 0.7872 - val_loss: 0.4500 - val_accuracy: 0.7825 - 176ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 0s - loss: 0.4468 - accuracy: 0.7927 - val_loss: 0.4572 - val_accuracy: 0.7921 - 172ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 0s - loss: 0.4490 - accuracy: 0.7935 - val_loss: 0.4485 - val_accuracy: 0.7869 - 187ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 0s - loss: 0.4438 - accuracy: 0.7938 - val_loss: 0.4562 - val_accuracy: 0.7806 - 196ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 0s - loss: 0.4496 - accuracy: 0.7912 - val_loss: 0.4557 - val_accuracy: 0.7895 - 172ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 0s - loss: 0.4411 - accuracy: 0.7892 - val_loss: 0.4494 - val_accuracy: 0.7991 - 172ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 0s - loss: 0.4451 - accuracy: 0.7948 - val_loss: 0.4523 - val_accuracy: 0.7895 - 187ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 0s - loss: 0.4485 - accuracy: 0.7887 - val_loss: 0.4413 - val_accuracy: 0.7978 - 188ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 0s - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.4496 - val_accuracy: 0.7940 - 188ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 0s - loss: 0.4418 - accuracy: 0.7972 - val_loss: 0.4478 - val_accuracy: 0.7940 - 172ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 0s - loss: 0.4425 - accuracy: 0.7932 - val_loss: 0.4499 - val_accuracy: 0.7863 - 302ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 0s - loss: 0.4427 - accuracy: 0.7940 - val_loss: 0.4509 - val_accuracy: 0.7818 - 203ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 0s - loss: 0.4468 - accuracy: 0.7968 - val_loss: 0.4491 - val_accuracy: 0.7927 - 219ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 0s - loss: 0.4463 - accuracy: 0.7948 - val_loss: 0.4464 - val_accuracy: 0.7857 - 172ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 0s - loss: 0.4386 - accuracy: 0.7928 - val_loss: 0.4509 - val_accuracy: 0.7908 - 187ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 0s - loss: 0.4442 - accuracy: 0.7938 - val_loss: 0.4444 - val_accuracy: 0.8017 - 187ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 0s - loss: 0.4419 - accuracy: 0.7924 - val_loss: 0.4459 - val_accuracy: 0.7914 - 177ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 0s - loss: 0.4436 - accuracy: 0.7964 - val_loss: 0.4478 - val_accuracy: 0.7850 - 188ms/epoch - 8ms/step\n",
      "Epoch 40: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.4087815525819864\n",
      "epi entropy:  0.3970674522992296\n",
      "\n",
      "dataset size:  0.3\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 0.6386 - accuracy: 0.6607 - val_loss: 0.5888 - val_accuracy: 0.7403 - 2s/epoch - 62ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5611 - accuracy: 0.7609 - val_loss: 0.5524 - val_accuracy: 0.7522 - 297ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.5215 - accuracy: 0.7708 - val_loss: 0.5318 - val_accuracy: 0.7552 - 250ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.4964 - accuracy: 0.7750 - val_loss: 0.5094 - val_accuracy: 0.7578 - 250ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.4822 - accuracy: 0.7727 - val_loss: 0.5036 - val_accuracy: 0.7591 - 266ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4686 - accuracy: 0.7819 - val_loss: 0.4910 - val_accuracy: 0.7659 - 250ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4640 - accuracy: 0.7824 - val_loss: 0.4915 - val_accuracy: 0.7672 - 266ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4625 - accuracy: 0.7837 - val_loss: 0.4847 - val_accuracy: 0.7731 - 250ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4535 - accuracy: 0.7840 - val_loss: 0.4870 - val_accuracy: 0.7659 - 266ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4560 - accuracy: 0.7858 - val_loss: 0.4782 - val_accuracy: 0.7770 - 266ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.4725 - val_accuracy: 0.7736 - 266ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4500 - accuracy: 0.7854 - val_loss: 0.4800 - val_accuracy: 0.7740 - 268ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4463 - accuracy: 0.7856 - val_loss: 0.4713 - val_accuracy: 0.7795 - 250ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4461 - accuracy: 0.7867 - val_loss: 0.4705 - val_accuracy: 0.7821 - 281ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4471 - accuracy: 0.7889 - val_loss: 0.4685 - val_accuracy: 0.7774 - 250ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4438 - accuracy: 0.7870 - val_loss: 0.4777 - val_accuracy: 0.7659 - 250ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4446 - accuracy: 0.7896 - val_loss: 0.4710 - val_accuracy: 0.7770 - 250ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4433 - accuracy: 0.7894 - val_loss: 0.4602 - val_accuracy: 0.7787 - 234ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4404 - accuracy: 0.7935 - val_loss: 0.4606 - val_accuracy: 0.7761 - 266ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4401 - accuracy: 0.7905 - val_loss: 0.4732 - val_accuracy: 0.7872 - 281ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4388 - accuracy: 0.7892 - val_loss: 0.4610 - val_accuracy: 0.7825 - 263ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4387 - accuracy: 0.7942 - val_loss: 0.4586 - val_accuracy: 0.7800 - 250ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4371 - accuracy: 0.7953 - val_loss: 0.4660 - val_accuracy: 0.7795 - 266ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4356 - accuracy: 0.7967 - val_loss: 0.4657 - val_accuracy: 0.7710 - 250ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4394 - accuracy: 0.7929 - val_loss: 0.4604 - val_accuracy: 0.7855 - 266ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4362 - accuracy: 0.7950 - val_loss: 0.4630 - val_accuracy: 0.7915 - 250ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4339 - accuracy: 0.7975 - val_loss: 0.4590 - val_accuracy: 0.7838 - 266ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4333 - accuracy: 0.7955 - val_loss: 0.4566 - val_accuracy: 0.7851 - 266ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4330 - accuracy: 0.7984 - val_loss: 0.4581 - val_accuracy: 0.7987 - 281ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4316 - accuracy: 0.7985 - val_loss: 0.4592 - val_accuracy: 0.7846 - 266ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4380 - accuracy: 0.7936 - val_loss: 0.4569 - val_accuracy: 0.7795 - 266ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4362 - accuracy: 0.7952 - val_loss: 0.4626 - val_accuracy: 0.7893 - 266ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4303 - accuracy: 0.7991 - val_loss: 0.4539 - val_accuracy: 0.7936 - 281ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4314 - accuracy: 0.7980 - val_loss: 0.4558 - val_accuracy: 0.7881 - 266ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4338 - accuracy: 0.7965 - val_loss: 0.4574 - val_accuracy: 0.7778 - 250ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4620 - val_accuracy: 0.7834 - 266ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4301 - accuracy: 0.7996 - val_loss: 0.4534 - val_accuracy: 0.7906 - 266ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4301 - accuracy: 0.7977 - val_loss: 0.4566 - val_accuracy: 0.7893 - 266ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4317 - accuracy: 0.7988 - val_loss: 0.4535 - val_accuracy: 0.7829 - 250ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4317 - accuracy: 0.7945 - val_loss: 0.4563 - val_accuracy: 0.7928 - 266ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4307 - accuracy: 0.8038 - val_loss: 0.4585 - val_accuracy: 0.7910 - 266ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4282 - accuracy: 0.7975 - val_loss: 0.4591 - val_accuracy: 0.7855 - 266ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 0s - loss: 0.4324 - accuracy: 0.8002 - val_loss: 0.4581 - val_accuracy: 0.7829 - 266ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 0s - loss: 0.4304 - accuracy: 0.7980 - val_loss: 0.4575 - val_accuracy: 0.7885 - 266ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 0s - loss: 0.4275 - accuracy: 0.7992 - val_loss: 0.4611 - val_accuracy: 0.7838 - 266ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 0s - loss: 0.4287 - accuracy: 0.7985 - val_loss: 0.4579 - val_accuracy: 0.7864 - 297ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 0s - loss: 0.4274 - accuracy: 0.8018 - val_loss: 0.4552 - val_accuracy: 0.7859 - 282ms/epoch - 8ms/step\n",
      "Epoch 47: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "37/37 - 3s - loss: 0.6228 - accuracy: 0.6863 - val_loss: 0.5859 - val_accuracy: 0.7416 - 3s/epoch - 84ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5549 - accuracy: 0.7632 - val_loss: 0.5628 - val_accuracy: 0.7488 - 313ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.5249 - accuracy: 0.7650 - val_loss: 0.5406 - val_accuracy: 0.7514 - 266ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.4995 - accuracy: 0.7667 - val_loss: 0.5132 - val_accuracy: 0.7505 - 250ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.4848 - accuracy: 0.7665 - val_loss: 0.4998 - val_accuracy: 0.7505 - 266ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4775 - accuracy: 0.7693 - val_loss: 0.5005 - val_accuracy: 0.7514 - 266ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4706 - accuracy: 0.7718 - val_loss: 0.4807 - val_accuracy: 0.7561 - 328ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.4816 - val_accuracy: 0.7608 - 266ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4563 - accuracy: 0.7729 - val_loss: 0.4778 - val_accuracy: 0.7582 - 344ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4594 - accuracy: 0.7777 - val_loss: 0.4700 - val_accuracy: 0.7655 - 266ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4511 - accuracy: 0.7753 - val_loss: 0.4773 - val_accuracy: 0.7689 - 281ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4518 - accuracy: 0.7759 - val_loss: 0.4794 - val_accuracy: 0.7638 - 266ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4484 - accuracy: 0.7787 - val_loss: 0.4732 - val_accuracy: 0.7697 - 266ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4424 - accuracy: 0.7835 - val_loss: 0.4762 - val_accuracy: 0.7633 - 266ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4471 - accuracy: 0.7858 - val_loss: 0.4742 - val_accuracy: 0.7727 - 250ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4445 - accuracy: 0.7897 - val_loss: 0.4730 - val_accuracy: 0.7753 - 266ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4441 - accuracy: 0.7839 - val_loss: 0.4660 - val_accuracy: 0.7834 - 266ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4440 - accuracy: 0.7895 - val_loss: 0.4728 - val_accuracy: 0.7603 - 344ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4388 - accuracy: 0.7918 - val_loss: 0.4668 - val_accuracy: 0.7825 - 266ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4403 - accuracy: 0.7911 - val_loss: 0.4646 - val_accuracy: 0.7804 - 252ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4386 - accuracy: 0.7950 - val_loss: 0.4763 - val_accuracy: 0.7787 - 278ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4376 - accuracy: 0.7921 - val_loss: 0.4655 - val_accuracy: 0.7889 - 379ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4371 - accuracy: 0.7935 - val_loss: 0.4583 - val_accuracy: 0.7859 - 281ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4333 - accuracy: 0.7972 - val_loss: 0.4634 - val_accuracy: 0.7893 - 259ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4339 - accuracy: 0.8009 - val_loss: 0.4638 - val_accuracy: 0.7829 - 266ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4340 - accuracy: 0.8014 - val_loss: 0.4647 - val_accuracy: 0.7868 - 250ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4347 - accuracy: 0.7966 - val_loss: 0.4680 - val_accuracy: 0.7804 - 266ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4321 - accuracy: 0.7955 - val_loss: 0.4589 - val_accuracy: 0.7868 - 375ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4344 - accuracy: 0.7991 - val_loss: 0.4570 - val_accuracy: 0.7889 - 250ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4314 - accuracy: 0.7993 - val_loss: 0.4649 - val_accuracy: 0.7910 - 297ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4337 - accuracy: 0.8001 - val_loss: 0.4619 - val_accuracy: 0.7906 - 250ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4329 - accuracy: 0.7997 - val_loss: 0.4580 - val_accuracy: 0.7885 - 250ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4331 - accuracy: 0.8012 - val_loss: 0.4548 - val_accuracy: 0.7945 - 250ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4333 - accuracy: 0.8003 - val_loss: 0.4641 - val_accuracy: 0.7876 - 281ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4322 - accuracy: 0.7997 - val_loss: 0.4589 - val_accuracy: 0.7885 - 250ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4296 - accuracy: 0.8018 - val_loss: 0.4639 - val_accuracy: 0.7876 - 279ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4306 - accuracy: 0.8008 - val_loss: 0.4595 - val_accuracy: 0.7932 - 250ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4316 - accuracy: 0.7998 - val_loss: 0.4589 - val_accuracy: 0.7932 - 250ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4302 - accuracy: 0.8029 - val_loss: 0.4609 - val_accuracy: 0.7859 - 250ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4329 - accuracy: 0.8022 - val_loss: 0.4542 - val_accuracy: 0.7932 - 266ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4318 - accuracy: 0.8047 - val_loss: 0.4502 - val_accuracy: 0.7923 - 266ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4296 - accuracy: 0.8034 - val_loss: 0.4566 - val_accuracy: 0.7885 - 266ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 0s - loss: 0.4309 - accuracy: 0.8010 - val_loss: 0.4581 - val_accuracy: 0.7928 - 250ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 0s - loss: 0.4310 - accuracy: 0.8026 - val_loss: 0.4539 - val_accuracy: 0.7915 - 234ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 0s - loss: 0.4318 - accuracy: 0.8014 - val_loss: 0.4567 - val_accuracy: 0.7940 - 266ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 0s - loss: 0.4297 - accuracy: 0.8024 - val_loss: 0.4583 - val_accuracy: 0.7893 - 250ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 0s - loss: 0.4300 - accuracy: 0.8040 - val_loss: 0.4572 - val_accuracy: 0.7928 - 281ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "37/37 - 0s - loss: 0.4290 - accuracy: 0.8043 - val_loss: 0.4580 - val_accuracy: 0.7979 - 250ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "37/37 - 0s - loss: 0.4294 - accuracy: 0.8025 - val_loss: 0.4551 - val_accuracy: 0.7923 - 250ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "37/37 - 0s - loss: 0.4277 - accuracy: 0.8046 - val_loss: 0.4587 - val_accuracy: 0.7902 - 250ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "37/37 - 0s - loss: 0.4294 - accuracy: 0.8014 - val_loss: 0.4559 - val_accuracy: 0.7889 - 266ms/epoch - 7ms/step\n",
      "Epoch 51: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 0.6337 - accuracy: 0.6533 - val_loss: 0.5782 - val_accuracy: 0.7313 - 2s/epoch - 48ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5388 - accuracy: 0.7602 - val_loss: 0.5476 - val_accuracy: 0.7488 - 345ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.5139 - accuracy: 0.7670 - val_loss: 0.5311 - val_accuracy: 0.7518 - 275ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.4947 - accuracy: 0.7685 - val_loss: 0.5048 - val_accuracy: 0.7616 - 256ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.4794 - accuracy: 0.7701 - val_loss: 0.4962 - val_accuracy: 0.7608 - 264ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4689 - accuracy: 0.7746 - val_loss: 0.5002 - val_accuracy: 0.7629 - 271ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4660 - accuracy: 0.7783 - val_loss: 0.4889 - val_accuracy: 0.7663 - 275ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4588 - accuracy: 0.7793 - val_loss: 0.4751 - val_accuracy: 0.7701 - 254ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4816 - val_accuracy: 0.7757 - 327ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.4764 - val_accuracy: 0.7642 - 248ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4526 - accuracy: 0.7878 - val_loss: 0.4782 - val_accuracy: 0.7736 - 245ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4522 - accuracy: 0.7832 - val_loss: 0.4719 - val_accuracy: 0.7872 - 238ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4508 - accuracy: 0.7826 - val_loss: 0.4712 - val_accuracy: 0.7676 - 280ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4454 - accuracy: 0.7935 - val_loss: 0.4678 - val_accuracy: 0.7787 - 280ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4474 - accuracy: 0.7890 - val_loss: 0.4657 - val_accuracy: 0.7812 - 286ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4495 - accuracy: 0.7927 - val_loss: 0.4706 - val_accuracy: 0.7774 - 293ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4431 - accuracy: 0.7908 - val_loss: 0.4740 - val_accuracy: 0.7821 - 258ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4430 - accuracy: 0.7927 - val_loss: 0.4671 - val_accuracy: 0.7701 - 260ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4435 - accuracy: 0.7904 - val_loss: 0.4685 - val_accuracy: 0.7868 - 280ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4386 - accuracy: 0.7961 - val_loss: 0.4603 - val_accuracy: 0.7851 - 284ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4421 - accuracy: 0.7931 - val_loss: 0.4689 - val_accuracy: 0.7851 - 290ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4411 - accuracy: 0.7929 - val_loss: 0.4710 - val_accuracy: 0.7825 - 280ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4396 - accuracy: 0.7939 - val_loss: 0.4617 - val_accuracy: 0.7800 - 280ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4408 - accuracy: 0.7939 - val_loss: 0.4623 - val_accuracy: 0.7846 - 266ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4407 - accuracy: 0.7932 - val_loss: 0.4678 - val_accuracy: 0.7757 - 250ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4385 - accuracy: 0.7965 - val_loss: 0.4631 - val_accuracy: 0.7821 - 289ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4366 - accuracy: 0.7950 - val_loss: 0.4574 - val_accuracy: 0.7757 - 285ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4371 - accuracy: 0.7954 - val_loss: 0.4668 - val_accuracy: 0.7821 - 244ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4363 - accuracy: 0.7978 - val_loss: 0.4628 - val_accuracy: 0.7829 - 234ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4392 - accuracy: 0.7953 - val_loss: 0.4686 - val_accuracy: 0.7876 - 251ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4363 - accuracy: 0.7963 - val_loss: 0.4622 - val_accuracy: 0.7842 - 272ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4383 - accuracy: 0.7922 - val_loss: 0.4605 - val_accuracy: 0.7893 - 254ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4348 - accuracy: 0.7978 - val_loss: 0.4665 - val_accuracy: 0.7804 - 251ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4348 - accuracy: 0.7954 - val_loss: 0.4653 - val_accuracy: 0.7834 - 265ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4335 - accuracy: 0.7985 - val_loss: 0.4596 - val_accuracy: 0.7859 - 267ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4303 - accuracy: 0.7997 - val_loss: 0.4592 - val_accuracy: 0.7829 - 269ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4360 - accuracy: 0.7972 - val_loss: 0.4584 - val_accuracy: 0.7885 - 241ms/epoch - 7ms/step\n",
      "Epoch 37: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "37/37 - 3s - loss: 0.6166 - accuracy: 0.6960 - val_loss: 0.5837 - val_accuracy: 0.7399 - 3s/epoch - 92ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5381 - accuracy: 0.7606 - val_loss: 0.5375 - val_accuracy: 0.7441 - 304ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.5086 - accuracy: 0.7676 - val_loss: 0.5231 - val_accuracy: 0.7493 - 274ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.4884 - accuracy: 0.7721 - val_loss: 0.5095 - val_accuracy: 0.7544 - 256ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.4745 - accuracy: 0.7697 - val_loss: 0.4975 - val_accuracy: 0.7586 - 283ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4719 - accuracy: 0.7728 - val_loss: 0.4883 - val_accuracy: 0.7569 - 262ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4635 - accuracy: 0.7776 - val_loss: 0.4888 - val_accuracy: 0.7599 - 373ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4582 - accuracy: 0.7783 - val_loss: 0.4781 - val_accuracy: 0.7629 - 243ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4518 - accuracy: 0.7790 - val_loss: 0.4760 - val_accuracy: 0.7701 - 234ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4524 - accuracy: 0.7791 - val_loss: 0.4793 - val_accuracy: 0.7655 - 346ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4485 - accuracy: 0.7838 - val_loss: 0.4834 - val_accuracy: 0.7783 - 253ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4466 - accuracy: 0.7863 - val_loss: 0.4753 - val_accuracy: 0.7697 - 276ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4458 - accuracy: 0.7818 - val_loss: 0.4702 - val_accuracy: 0.7761 - 250ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4463 - accuracy: 0.7860 - val_loss: 0.4670 - val_accuracy: 0.7736 - 271ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4422 - accuracy: 0.7898 - val_loss: 0.4673 - val_accuracy: 0.7723 - 234ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4418 - accuracy: 0.7898 - val_loss: 0.4658 - val_accuracy: 0.7765 - 247ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4397 - accuracy: 0.7911 - val_loss: 0.4691 - val_accuracy: 0.7710 - 268ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4409 - accuracy: 0.7920 - val_loss: 0.4684 - val_accuracy: 0.7783 - 267ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4392 - accuracy: 0.7937 - val_loss: 0.4668 - val_accuracy: 0.7757 - 275ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4386 - accuracy: 0.7950 - val_loss: 0.4551 - val_accuracy: 0.7893 - 257ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4390 - accuracy: 0.7939 - val_loss: 0.4592 - val_accuracy: 0.7838 - 271ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4348 - accuracy: 0.7961 - val_loss: 0.4618 - val_accuracy: 0.7834 - 264ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.4572 - val_accuracy: 0.7821 - 259ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4385 - accuracy: 0.7975 - val_loss: 0.4637 - val_accuracy: 0.7825 - 282ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4355 - accuracy: 0.7929 - val_loss: 0.4495 - val_accuracy: 0.7876 - 383ms/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4363 - accuracy: 0.7972 - val_loss: 0.4599 - val_accuracy: 0.7851 - 263ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4349 - accuracy: 0.7960 - val_loss: 0.4609 - val_accuracy: 0.7868 - 257ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4332 - accuracy: 0.7991 - val_loss: 0.4598 - val_accuracy: 0.7855 - 261ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4329 - accuracy: 0.7980 - val_loss: 0.4586 - val_accuracy: 0.7842 - 259ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4332 - accuracy: 0.7988 - val_loss: 0.4634 - val_accuracy: 0.7889 - 271ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4342 - accuracy: 0.7983 - val_loss: 0.4673 - val_accuracy: 0.7842 - 297ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4307 - accuracy: 0.7979 - val_loss: 0.4596 - val_accuracy: 0.7864 - 269ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4300 - accuracy: 0.8050 - val_loss: 0.4612 - val_accuracy: 0.7885 - 260ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4341 - accuracy: 0.7956 - val_loss: 0.4621 - val_accuracy: 0.7842 - 250ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4336 - accuracy: 0.7996 - val_loss: 0.4598 - val_accuracy: 0.7825 - 252ms/epoch - 7ms/step\n",
      "Epoch 35: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 0.6275 - accuracy: 0.6924 - val_loss: 0.5892 - val_accuracy: 0.7386 - 2s/epoch - 53ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5576 - accuracy: 0.7641 - val_loss: 0.5579 - val_accuracy: 0.7501 - 298ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.5247 - accuracy: 0.7670 - val_loss: 0.5215 - val_accuracy: 0.7561 - 271ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.5003 - accuracy: 0.7686 - val_loss: 0.5051 - val_accuracy: 0.7595 - 260ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.4779 - accuracy: 0.7719 - val_loss: 0.4971 - val_accuracy: 0.7616 - 350ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4651 - accuracy: 0.7756 - val_loss: 0.4880 - val_accuracy: 0.7672 - 290ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4592 - accuracy: 0.7784 - val_loss: 0.4864 - val_accuracy: 0.7680 - 259ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4528 - accuracy: 0.7874 - val_loss: 0.4809 - val_accuracy: 0.7642 - 267ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4502 - accuracy: 0.7843 - val_loss: 0.4704 - val_accuracy: 0.7748 - 270ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4510 - accuracy: 0.7835 - val_loss: 0.4747 - val_accuracy: 0.7719 - 268ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4452 - accuracy: 0.7850 - val_loss: 0.4726 - val_accuracy: 0.7829 - 276ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4441 - accuracy: 0.7880 - val_loss: 0.4757 - val_accuracy: 0.7757 - 266ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4427 - accuracy: 0.7891 - val_loss: 0.4643 - val_accuracy: 0.7774 - 247ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4447 - accuracy: 0.7883 - val_loss: 0.4646 - val_accuracy: 0.7795 - 297ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4449 - accuracy: 0.7896 - val_loss: 0.4660 - val_accuracy: 0.7808 - 267ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4435 - accuracy: 0.7890 - val_loss: 0.4671 - val_accuracy: 0.7761 - 269ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4439 - accuracy: 0.7910 - val_loss: 0.4699 - val_accuracy: 0.7859 - 279ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4388 - accuracy: 0.7936 - val_loss: 0.4678 - val_accuracy: 0.7812 - 273ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4430 - accuracy: 0.7923 - val_loss: 0.4675 - val_accuracy: 0.7804 - 281ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4377 - accuracy: 0.7916 - val_loss: 0.4647 - val_accuracy: 0.7808 - 271ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4381 - accuracy: 0.7938 - val_loss: 0.4572 - val_accuracy: 0.7800 - 259ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4382 - accuracy: 0.7975 - val_loss: 0.4618 - val_accuracy: 0.7804 - 250ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4383 - accuracy: 0.7947 - val_loss: 0.4585 - val_accuracy: 0.7906 - 267ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4359 - accuracy: 0.7952 - val_loss: 0.4561 - val_accuracy: 0.7906 - 256ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4343 - accuracy: 0.7940 - val_loss: 0.4573 - val_accuracy: 0.7915 - 266ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4327 - accuracy: 0.7955 - val_loss: 0.4653 - val_accuracy: 0.7876 - 283ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4348 - accuracy: 0.7977 - val_loss: 0.4588 - val_accuracy: 0.7864 - 297ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4343 - accuracy: 0.7970 - val_loss: 0.4577 - val_accuracy: 0.7872 - 249ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4313 - accuracy: 0.8012 - val_loss: 0.4576 - val_accuracy: 0.7910 - 267ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4296 - accuracy: 0.8016 - val_loss: 0.4604 - val_accuracy: 0.7902 - 293ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4314 - accuracy: 0.8001 - val_loss: 0.4615 - val_accuracy: 0.7864 - 262ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4303 - accuracy: 0.8015 - val_loss: 0.4549 - val_accuracy: 0.7945 - 260ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.4555 - val_accuracy: 0.7962 - 283ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4278 - accuracy: 0.8006 - val_loss: 0.4627 - val_accuracy: 0.7928 - 242ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4308 - accuracy: 0.8018 - val_loss: 0.4573 - val_accuracy: 0.7940 - 250ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4330 - accuracy: 0.8010 - val_loss: 0.4596 - val_accuracy: 0.7872 - 269ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4296 - accuracy: 0.8019 - val_loss: 0.4621 - val_accuracy: 0.7915 - 250ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4302 - accuracy: 0.8011 - val_loss: 0.4583 - val_accuracy: 0.7876 - 268ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4321 - accuracy: 0.7990 - val_loss: 0.4597 - val_accuracy: 0.7889 - 266ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4296 - accuracy: 0.8022 - val_loss: 0.4586 - val_accuracy: 0.7932 - 280ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4306 - accuracy: 0.8036 - val_loss: 0.4568 - val_accuracy: 0.7945 - 266ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4294 - accuracy: 0.8002 - val_loss: 0.4607 - val_accuracy: 0.7898 - 253ms/epoch - 7ms/step\n",
      "Epoch 42: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 0.6593 - accuracy: 0.6177 - val_loss: 0.5641 - val_accuracy: 0.7343 - 2s/epoch - 55ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5363 - accuracy: 0.7600 - val_loss: 0.5385 - val_accuracy: 0.7505 - 260ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.4970 - accuracy: 0.7674 - val_loss: 0.5123 - val_accuracy: 0.7527 - 281ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.4828 - accuracy: 0.7698 - val_loss: 0.5005 - val_accuracy: 0.7522 - 253ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.4727 - accuracy: 0.7724 - val_loss: 0.4984 - val_accuracy: 0.7603 - 250ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4617 - accuracy: 0.7745 - val_loss: 0.4883 - val_accuracy: 0.7548 - 265ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4562 - accuracy: 0.7793 - val_loss: 0.4830 - val_accuracy: 0.7642 - 254ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4540 - accuracy: 0.7799 - val_loss: 0.4809 - val_accuracy: 0.7723 - 343ms/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4540 - accuracy: 0.7847 - val_loss: 0.4822 - val_accuracy: 0.7710 - 234ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4541 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7680 - 251ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4487 - accuracy: 0.7862 - val_loss: 0.4713 - val_accuracy: 0.7778 - 266ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4451 - accuracy: 0.7900 - val_loss: 0.4753 - val_accuracy: 0.7736 - 267ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4456 - accuracy: 0.7947 - val_loss: 0.4643 - val_accuracy: 0.7855 - 250ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4435 - accuracy: 0.7892 - val_loss: 0.4710 - val_accuracy: 0.7753 - 253ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4407 - accuracy: 0.7910 - val_loss: 0.4668 - val_accuracy: 0.7731 - 266ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4388 - accuracy: 0.7910 - val_loss: 0.4588 - val_accuracy: 0.7795 - 266ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4368 - accuracy: 0.7919 - val_loss: 0.4583 - val_accuracy: 0.7842 - 234ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4368 - accuracy: 0.7999 - val_loss: 0.4673 - val_accuracy: 0.7800 - 237ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4390 - accuracy: 0.7966 - val_loss: 0.4672 - val_accuracy: 0.7795 - 255ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4346 - accuracy: 0.7971 - val_loss: 0.4682 - val_accuracy: 0.7817 - 261ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4324 - accuracy: 0.7991 - val_loss: 0.4622 - val_accuracy: 0.7876 - 250ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4341 - accuracy: 0.7952 - val_loss: 0.4695 - val_accuracy: 0.7736 - 251ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4355 - accuracy: 0.7961 - val_loss: 0.4686 - val_accuracy: 0.7783 - 266ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4315 - accuracy: 0.7978 - val_loss: 0.4614 - val_accuracy: 0.7923 - 268ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4359 - accuracy: 0.8002 - val_loss: 0.4583 - val_accuracy: 0.7872 - 250ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4327 - accuracy: 0.7980 - val_loss: 0.4539 - val_accuracy: 0.7864 - 267ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4320 - accuracy: 0.7976 - val_loss: 0.4645 - val_accuracy: 0.7842 - 281ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4306 - accuracy: 0.8006 - val_loss: 0.4566 - val_accuracy: 0.7940 - 268ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4297 - accuracy: 0.8019 - val_loss: 0.4622 - val_accuracy: 0.7864 - 375ms/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4312 - accuracy: 0.7994 - val_loss: 0.4627 - val_accuracy: 0.7881 - 266ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4303 - accuracy: 0.7982 - val_loss: 0.4582 - val_accuracy: 0.7898 - 281ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4315 - accuracy: 0.7992 - val_loss: 0.4568 - val_accuracy: 0.7864 - 283ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4286 - accuracy: 0.8016 - val_loss: 0.4574 - val_accuracy: 0.7872 - 250ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4302 - accuracy: 0.8010 - val_loss: 0.4601 - val_accuracy: 0.7864 - 283ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4302 - accuracy: 0.8032 - val_loss: 0.4611 - val_accuracy: 0.7881 - 266ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4303 - accuracy: 0.8024 - val_loss: 0.4540 - val_accuracy: 0.7859 - 266ms/epoch - 7ms/step\n",
      "Epoch 36: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 0.6011 - accuracy: 0.7018 - val_loss: 0.5651 - val_accuracy: 0.7399 - 2s/epoch - 44ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5263 - accuracy: 0.7635 - val_loss: 0.5305 - val_accuracy: 0.7527 - 281ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.4931 - accuracy: 0.7689 - val_loss: 0.5082 - val_accuracy: 0.7586 - 298ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.4708 - accuracy: 0.7752 - val_loss: 0.4992 - val_accuracy: 0.7514 - 280ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.4660 - accuracy: 0.7724 - val_loss: 0.4780 - val_accuracy: 0.7595 - 250ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4620 - accuracy: 0.7728 - val_loss: 0.4793 - val_accuracy: 0.7603 - 272ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4579 - accuracy: 0.7730 - val_loss: 0.4778 - val_accuracy: 0.7646 - 243ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4552 - accuracy: 0.7777 - val_loss: 0.4770 - val_accuracy: 0.7655 - 234ms/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4509 - accuracy: 0.7797 - val_loss: 0.4834 - val_accuracy: 0.7638 - 251ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4502 - accuracy: 0.7816 - val_loss: 0.4708 - val_accuracy: 0.7667 - 266ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4412 - accuracy: 0.7847 - val_loss: 0.4723 - val_accuracy: 0.7765 - 252ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4453 - accuracy: 0.7843 - val_loss: 0.4689 - val_accuracy: 0.7650 - 250ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4365 - accuracy: 0.7897 - val_loss: 0.4774 - val_accuracy: 0.7625 - 251ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4432 - accuracy: 0.7876 - val_loss: 0.4653 - val_accuracy: 0.7817 - 250ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4410 - accuracy: 0.7896 - val_loss: 0.4626 - val_accuracy: 0.7693 - 268ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4402 - accuracy: 0.7858 - val_loss: 0.4610 - val_accuracy: 0.7885 - 266ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4385 - accuracy: 0.7912 - val_loss: 0.4647 - val_accuracy: 0.7846 - 250ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4370 - accuracy: 0.7944 - val_loss: 0.4660 - val_accuracy: 0.7808 - 250ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4340 - accuracy: 0.7965 - val_loss: 0.4658 - val_accuracy: 0.7774 - 267ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4360 - accuracy: 0.7992 - val_loss: 0.4612 - val_accuracy: 0.7855 - 250ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4360 - accuracy: 0.7967 - val_loss: 0.4655 - val_accuracy: 0.7770 - 267ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4363 - accuracy: 0.7991 - val_loss: 0.4634 - val_accuracy: 0.7842 - 250ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4331 - accuracy: 0.8031 - val_loss: 0.4621 - val_accuracy: 0.7846 - 298ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4353 - accuracy: 0.8024 - val_loss: 0.4631 - val_accuracy: 0.7872 - 266ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4338 - accuracy: 0.8007 - val_loss: 0.4623 - val_accuracy: 0.7864 - 253ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4334 - accuracy: 0.7970 - val_loss: 0.4650 - val_accuracy: 0.7885 - 266ms/epoch - 7ms/step\n",
      "Epoch 26: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "37/37 - 3s - loss: 0.6317 - accuracy: 0.6626 - val_loss: 0.5860 - val_accuracy: 0.7394 - 3s/epoch - 88ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5493 - accuracy: 0.7584 - val_loss: 0.5469 - val_accuracy: 0.7527 - 304ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.5152 - accuracy: 0.7664 - val_loss: 0.5215 - val_accuracy: 0.7565 - 290ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.5005 - accuracy: 0.7689 - val_loss: 0.5076 - val_accuracy: 0.7569 - 305ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.4852 - accuracy: 0.7722 - val_loss: 0.5071 - val_accuracy: 0.7650 - 250ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4727 - accuracy: 0.7792 - val_loss: 0.4863 - val_accuracy: 0.7714 - 281ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4660 - accuracy: 0.7836 - val_loss: 0.4929 - val_accuracy: 0.7663 - 273ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4642 - accuracy: 0.7830 - val_loss: 0.4778 - val_accuracy: 0.7672 - 266ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4604 - accuracy: 0.7815 - val_loss: 0.4916 - val_accuracy: 0.7714 - 266ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4560 - accuracy: 0.7858 - val_loss: 0.4695 - val_accuracy: 0.7727 - 266ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4526 - accuracy: 0.7866 - val_loss: 0.4699 - val_accuracy: 0.7881 - 275ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4534 - accuracy: 0.7854 - val_loss: 0.4749 - val_accuracy: 0.7864 - 304ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4463 - accuracy: 0.7906 - val_loss: 0.4694 - val_accuracy: 0.7804 - 267ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4424 - accuracy: 0.7932 - val_loss: 0.4654 - val_accuracy: 0.7800 - 281ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4450 - accuracy: 0.7921 - val_loss: 0.4668 - val_accuracy: 0.7821 - 266ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4401 - accuracy: 0.7972 - val_loss: 0.4686 - val_accuracy: 0.7808 - 250ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4415 - accuracy: 0.7912 - val_loss: 0.4636 - val_accuracy: 0.7825 - 266ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4370 - accuracy: 0.7963 - val_loss: 0.4633 - val_accuracy: 0.7855 - 317ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4374 - accuracy: 0.7978 - val_loss: 0.4676 - val_accuracy: 0.7774 - 271ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4403 - accuracy: 0.7952 - val_loss: 0.4612 - val_accuracy: 0.7906 - 336ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4343 - accuracy: 0.7952 - val_loss: 0.4647 - val_accuracy: 0.7864 - 246ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4374 - accuracy: 0.7942 - val_loss: 0.4565 - val_accuracy: 0.7846 - 306ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.4603 - val_accuracy: 0.7898 - 269ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4381 - accuracy: 0.7962 - val_loss: 0.4609 - val_accuracy: 0.7893 - 283ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4349 - accuracy: 0.7958 - val_loss: 0.4549 - val_accuracy: 0.7834 - 247ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4375 - accuracy: 0.7977 - val_loss: 0.4600 - val_accuracy: 0.7855 - 279ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4329 - accuracy: 0.7995 - val_loss: 0.4633 - val_accuracy: 0.7808 - 268ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4337 - accuracy: 0.8016 - val_loss: 0.4545 - val_accuracy: 0.7902 - 254ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4332 - accuracy: 0.7995 - val_loss: 0.4565 - val_accuracy: 0.7881 - 276ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4312 - accuracy: 0.7987 - val_loss: 0.4572 - val_accuracy: 0.7855 - 265ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4320 - accuracy: 0.7999 - val_loss: 0.4568 - val_accuracy: 0.7919 - 275ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4336 - accuracy: 0.8000 - val_loss: 0.4628 - val_accuracy: 0.7804 - 290ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4312 - accuracy: 0.7987 - val_loss: 0.4607 - val_accuracy: 0.7825 - 276ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4328 - accuracy: 0.7956 - val_loss: 0.4516 - val_accuracy: 0.7898 - 266ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4313 - accuracy: 0.7998 - val_loss: 0.4574 - val_accuracy: 0.7898 - 266ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4294 - accuracy: 0.8001 - val_loss: 0.4630 - val_accuracy: 0.7902 - 266ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4313 - accuracy: 0.7970 - val_loss: 0.4532 - val_accuracy: 0.7915 - 260ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4302 - accuracy: 0.8003 - val_loss: 0.4573 - val_accuracy: 0.7910 - 266ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4298 - accuracy: 0.7997 - val_loss: 0.4580 - val_accuracy: 0.7846 - 339ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4294 - accuracy: 0.7990 - val_loss: 0.4538 - val_accuracy: 0.7872 - 292ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4304 - accuracy: 0.8007 - val_loss: 0.4524 - val_accuracy: 0.7885 - 255ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4298 - accuracy: 0.7996 - val_loss: 0.4612 - val_accuracy: 0.7915 - 277ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 0s - loss: 0.4295 - accuracy: 0.8024 - val_loss: 0.4579 - val_accuracy: 0.7898 - 277ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 0s - loss: 0.4287 - accuracy: 0.7998 - val_loss: 0.4537 - val_accuracy: 0.7940 - 294ms/epoch - 8ms/step\n",
      "Epoch 44: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 0.6704 - accuracy: 0.5866 - val_loss: 0.6096 - val_accuracy: 0.7190 - 2s/epoch - 47ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5734 - accuracy: 0.7557 - val_loss: 0.5751 - val_accuracy: 0.7446 - 268ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.5395 - accuracy: 0.7661 - val_loss: 0.5492 - val_accuracy: 0.7497 - 284ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.5207 - accuracy: 0.7683 - val_loss: 0.5292 - val_accuracy: 0.7552 - 267ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.5090 - accuracy: 0.7714 - val_loss: 0.5176 - val_accuracy: 0.7646 - 259ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4874 - accuracy: 0.7766 - val_loss: 0.5176 - val_accuracy: 0.7574 - 262ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4816 - accuracy: 0.7755 - val_loss: 0.4939 - val_accuracy: 0.7642 - 280ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4681 - accuracy: 0.7733 - val_loss: 0.4903 - val_accuracy: 0.7727 - 268ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4659 - accuracy: 0.7814 - val_loss: 0.4830 - val_accuracy: 0.7765 - 267ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4560 - accuracy: 0.7853 - val_loss: 0.4775 - val_accuracy: 0.7744 - 323ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4578 - accuracy: 0.7794 - val_loss: 0.4758 - val_accuracy: 0.7783 - 304ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4515 - accuracy: 0.7844 - val_loss: 0.4786 - val_accuracy: 0.7719 - 277ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4504 - accuracy: 0.7876 - val_loss: 0.4795 - val_accuracy: 0.7778 - 267ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4478 - accuracy: 0.7904 - val_loss: 0.4727 - val_accuracy: 0.7778 - 318ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4423 - accuracy: 0.7929 - val_loss: 0.4730 - val_accuracy: 0.7821 - 261ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4441 - accuracy: 0.7881 - val_loss: 0.4707 - val_accuracy: 0.7808 - 284ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4427 - accuracy: 0.7911 - val_loss: 0.4633 - val_accuracy: 0.7817 - 296ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4409 - accuracy: 0.7920 - val_loss: 0.4655 - val_accuracy: 0.7753 - 275ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4400 - accuracy: 0.7949 - val_loss: 0.4636 - val_accuracy: 0.7761 - 264ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4377 - accuracy: 0.7929 - val_loss: 0.4704 - val_accuracy: 0.7846 - 281ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4433 - accuracy: 0.7912 - val_loss: 0.4689 - val_accuracy: 0.7774 - 272ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.4668 - val_accuracy: 0.7778 - 292ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4361 - accuracy: 0.8004 - val_loss: 0.4584 - val_accuracy: 0.7821 - 272ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.4647 - val_accuracy: 0.7821 - 258ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4365 - accuracy: 0.7956 - val_loss: 0.4665 - val_accuracy: 0.7872 - 278ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4363 - accuracy: 0.8007 - val_loss: 0.4665 - val_accuracy: 0.7744 - 292ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4368 - accuracy: 0.7970 - val_loss: 0.4593 - val_accuracy: 0.7778 - 277ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4354 - accuracy: 0.7944 - val_loss: 0.4544 - val_accuracy: 0.7821 - 250ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4640 - val_accuracy: 0.7872 - 282ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4358 - accuracy: 0.7978 - val_loss: 0.4509 - val_accuracy: 0.7885 - 250ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4359 - accuracy: 0.7981 - val_loss: 0.4595 - val_accuracy: 0.7783 - 247ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4348 - accuracy: 0.7955 - val_loss: 0.4559 - val_accuracy: 0.7885 - 266ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4346 - accuracy: 0.7972 - val_loss: 0.4631 - val_accuracy: 0.7817 - 266ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4311 - accuracy: 0.8010 - val_loss: 0.4567 - val_accuracy: 0.7872 - 266ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4348 - accuracy: 0.8000 - val_loss: 0.4602 - val_accuracy: 0.7881 - 266ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4332 - accuracy: 0.8014 - val_loss: 0.4539 - val_accuracy: 0.7885 - 251ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4322 - accuracy: 0.8000 - val_loss: 0.4617 - val_accuracy: 0.7846 - 245ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4299 - accuracy: 0.7966 - val_loss: 0.4597 - val_accuracy: 0.7846 - 267ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4316 - accuracy: 0.8010 - val_loss: 0.4575 - val_accuracy: 0.7898 - 254ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4307 - accuracy: 0.8014 - val_loss: 0.4568 - val_accuracy: 0.7945 - 287ms/epoch - 8ms/step\n",
      "Epoch 40: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "37/37 - 2s - loss: 0.5875 - accuracy: 0.7452 - val_loss: 0.5728 - val_accuracy: 0.7514 - 2s/epoch - 45ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 0s - loss: 0.5327 - accuracy: 0.7663 - val_loss: 0.5332 - val_accuracy: 0.7505 - 321ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 0s - loss: 0.4947 - accuracy: 0.7675 - val_loss: 0.5028 - val_accuracy: 0.7539 - 356ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 0s - loss: 0.4784 - accuracy: 0.7701 - val_loss: 0.4856 - val_accuracy: 0.7574 - 285ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 0s - loss: 0.4632 - accuracy: 0.7733 - val_loss: 0.4808 - val_accuracy: 0.7659 - 291ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 0s - loss: 0.4594 - accuracy: 0.7770 - val_loss: 0.4871 - val_accuracy: 0.7586 - 282ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 0s - loss: 0.4556 - accuracy: 0.7817 - val_loss: 0.4791 - val_accuracy: 0.7783 - 268ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 0s - loss: 0.4538 - accuracy: 0.7787 - val_loss: 0.4861 - val_accuracy: 0.7676 - 257ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 0s - loss: 0.4480 - accuracy: 0.7818 - val_loss: 0.4771 - val_accuracy: 0.7719 - 278ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 0s - loss: 0.4503 - accuracy: 0.7833 - val_loss: 0.4711 - val_accuracy: 0.7800 - 244ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 0s - loss: 0.4441 - accuracy: 0.7879 - val_loss: 0.4802 - val_accuracy: 0.7748 - 270ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 0s - loss: 0.4464 - accuracy: 0.7887 - val_loss: 0.4692 - val_accuracy: 0.7855 - 272ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 0s - loss: 0.4450 - accuracy: 0.7874 - val_loss: 0.4773 - val_accuracy: 0.7791 - 258ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 0s - loss: 0.4439 - accuracy: 0.7881 - val_loss: 0.4654 - val_accuracy: 0.7859 - 271ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 0s - loss: 0.4389 - accuracy: 0.7959 - val_loss: 0.4762 - val_accuracy: 0.7659 - 298ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 0s - loss: 0.4400 - accuracy: 0.7971 - val_loss: 0.4658 - val_accuracy: 0.7821 - 297ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 0s - loss: 0.4414 - accuracy: 0.7939 - val_loss: 0.4696 - val_accuracy: 0.7868 - 305ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 0s - loss: 0.4394 - accuracy: 0.7945 - val_loss: 0.4770 - val_accuracy: 0.7851 - 288ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 0s - loss: 0.4372 - accuracy: 0.7935 - val_loss: 0.4723 - val_accuracy: 0.7753 - 278ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 0s - loss: 0.4378 - accuracy: 0.7949 - val_loss: 0.4707 - val_accuracy: 0.7812 - 273ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 0s - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.4631 - val_accuracy: 0.7812 - 296ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 0s - loss: 0.4394 - accuracy: 0.7939 - val_loss: 0.4672 - val_accuracy: 0.7898 - 286ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 0s - loss: 0.4397 - accuracy: 0.7907 - val_loss: 0.4661 - val_accuracy: 0.7795 - 259ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 0s - loss: 0.4368 - accuracy: 0.7975 - val_loss: 0.4660 - val_accuracy: 0.7812 - 264ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 0s - loss: 0.4406 - accuracy: 0.7945 - val_loss: 0.4612 - val_accuracy: 0.7829 - 291ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 0s - loss: 0.4358 - accuracy: 0.7956 - val_loss: 0.4651 - val_accuracy: 0.7859 - 279ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 0s - loss: 0.4383 - accuracy: 0.7953 - val_loss: 0.4668 - val_accuracy: 0.7855 - 242ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 0s - loss: 0.4362 - accuracy: 0.7944 - val_loss: 0.4612 - val_accuracy: 0.7842 - 256ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 0s - loss: 0.4379 - accuracy: 0.7952 - val_loss: 0.4643 - val_accuracy: 0.7842 - 250ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 0s - loss: 0.4352 - accuracy: 0.7963 - val_loss: 0.4615 - val_accuracy: 0.7868 - 292ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 0s - loss: 0.4316 - accuracy: 0.8008 - val_loss: 0.4568 - val_accuracy: 0.7893 - 255ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 0s - loss: 0.4334 - accuracy: 0.7956 - val_loss: 0.4604 - val_accuracy: 0.7859 - 255ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 0s - loss: 0.4301 - accuracy: 0.7993 - val_loss: 0.4622 - val_accuracy: 0.7868 - 250ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 0s - loss: 0.4369 - accuracy: 0.7927 - val_loss: 0.4568 - val_accuracy: 0.7859 - 343ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 0s - loss: 0.4325 - accuracy: 0.7993 - val_loss: 0.4579 - val_accuracy: 0.7864 - 253ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 0s - loss: 0.4336 - accuracy: 0.7967 - val_loss: 0.4612 - val_accuracy: 0.7855 - 259ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 0s - loss: 0.4318 - accuracy: 0.7996 - val_loss: 0.4600 - val_accuracy: 0.7928 - 268ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 0s - loss: 0.4349 - accuracy: 0.7975 - val_loss: 0.4577 - val_accuracy: 0.7838 - 298ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 0s - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.4549 - val_accuracy: 0.7834 - 250ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 0s - loss: 0.4329 - accuracy: 0.7988 - val_loss: 0.4614 - val_accuracy: 0.7842 - 266ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 0s - loss: 0.4311 - accuracy: 0.7996 - val_loss: 0.4562 - val_accuracy: 0.7855 - 254ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 0s - loss: 0.4285 - accuracy: 0.8007 - val_loss: 0.4546 - val_accuracy: 0.7855 - 265ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 0s - loss: 0.4314 - accuracy: 0.7977 - val_loss: 0.4577 - val_accuracy: 0.7851 - 305ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 0s - loss: 0.4290 - accuracy: 0.7983 - val_loss: 0.4613 - val_accuracy: 0.7787 - 272ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 0s - loss: 0.4298 - accuracy: 0.7991 - val_loss: 0.4551 - val_accuracy: 0.7910 - 262ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 0s - loss: 0.4319 - accuracy: 0.8020 - val_loss: 0.4588 - val_accuracy: 0.7834 - 266ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 0s - loss: 0.4329 - accuracy: 0.7994 - val_loss: 0.4567 - val_accuracy: 0.7868 - 262ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "37/37 - 0s - loss: 0.4268 - accuracy: 0.7964 - val_loss: 0.4609 - val_accuracy: 0.7834 - 250ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "37/37 - 0s - loss: 0.4262 - accuracy: 0.7972 - val_loss: 0.4593 - val_accuracy: 0.7800 - 261ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "37/37 - 0s - loss: 0.4285 - accuracy: 0.8004 - val_loss: 0.4647 - val_accuracy: 0.7821 - 293ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "37/37 - 0s - loss: 0.4295 - accuracy: 0.7972 - val_loss: 0.4613 - val_accuracy: 0.7804 - 242ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "37/37 - 0s - loss: 0.4282 - accuracy: 0.7966 - val_loss: 0.4597 - val_accuracy: 0.7842 - 253ms/epoch - 7ms/step\n",
      "Epoch 52: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.38071962967802947\n",
      "epi entropy:  0.3708748322640115\n",
      "\n",
      "dataset size:  0.4\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 0.5922 - accuracy: 0.7102 - val_loss: 0.5571 - val_accuracy: 0.7441 - 2s/epoch - 42ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5368 - accuracy: 0.7581 - val_loss: 0.5151 - val_accuracy: 0.7524 - 388ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.5037 - accuracy: 0.7606 - val_loss: 0.4913 - val_accuracy: 0.7498 - 351ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.4866 - accuracy: 0.7640 - val_loss: 0.4816 - val_accuracy: 0.7642 - 386ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4711 - accuracy: 0.7717 - val_loss: 0.4707 - val_accuracy: 0.7703 - 335ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4642 - accuracy: 0.7762 - val_loss: 0.4609 - val_accuracy: 0.7850 - 344ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4588 - accuracy: 0.7793 - val_loss: 0.4514 - val_accuracy: 0.7841 - 385ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4527 - accuracy: 0.7830 - val_loss: 0.4558 - val_accuracy: 0.7834 - 321ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4503 - accuracy: 0.7861 - val_loss: 0.4517 - val_accuracy: 0.7857 - 382ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4491 - accuracy: 0.7876 - val_loss: 0.4526 - val_accuracy: 0.7898 - 351ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4470 - accuracy: 0.7880 - val_loss: 0.4527 - val_accuracy: 0.7825 - 369ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4494 - accuracy: 0.7853 - val_loss: 0.4528 - val_accuracy: 0.7828 - 383ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4470 - accuracy: 0.7873 - val_loss: 0.4432 - val_accuracy: 0.7876 - 368ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4448 - accuracy: 0.7893 - val_loss: 0.4446 - val_accuracy: 0.7853 - 356ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4425 - accuracy: 0.7877 - val_loss: 0.4484 - val_accuracy: 0.7866 - 350ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4438 - accuracy: 0.7916 - val_loss: 0.4479 - val_accuracy: 0.7905 - 319ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4420 - accuracy: 0.7926 - val_loss: 0.4389 - val_accuracy: 0.7921 - 344ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4411 - accuracy: 0.7904 - val_loss: 0.4438 - val_accuracy: 0.7869 - 342ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4381 - accuracy: 0.7925 - val_loss: 0.4382 - val_accuracy: 0.7933 - 377ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4415 - accuracy: 0.7898 - val_loss: 0.4365 - val_accuracy: 0.7901 - 343ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4387 - accuracy: 0.7916 - val_loss: 0.4377 - val_accuracy: 0.7879 - 377ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4375 - accuracy: 0.7923 - val_loss: 0.4350 - val_accuracy: 0.7943 - 377ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4359 - accuracy: 0.7944 - val_loss: 0.4385 - val_accuracy: 0.7895 - 310ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4385 - accuracy: 0.7946 - val_loss: 0.4357 - val_accuracy: 0.7933 - 319ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4378 - accuracy: 0.7920 - val_loss: 0.4412 - val_accuracy: 0.7908 - 374ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4354 - accuracy: 0.7922 - val_loss: 0.4332 - val_accuracy: 0.7985 - 367ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4354 - accuracy: 0.7956 - val_loss: 0.4377 - val_accuracy: 0.7921 - 364ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4346 - accuracy: 0.7972 - val_loss: 0.4372 - val_accuracy: 0.7949 - 327ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4350 - accuracy: 0.7931 - val_loss: 0.4376 - val_accuracy: 0.7930 - 392ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4344 - accuracy: 0.7958 - val_loss: 0.4353 - val_accuracy: 0.7975 - 324ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4350 - accuracy: 0.7959 - val_loss: 0.4334 - val_accuracy: 0.7930 - 349ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4346 - accuracy: 0.7936 - val_loss: 0.4367 - val_accuracy: 0.7965 - 338ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4338 - accuracy: 0.7950 - val_loss: 0.4328 - val_accuracy: 0.7965 - 326ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4343 - accuracy: 0.7964 - val_loss: 0.4367 - val_accuracy: 0.7956 - 356ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4348 - accuracy: 0.7944 - val_loss: 0.4361 - val_accuracy: 0.7869 - 344ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4360 - accuracy: 0.7956 - val_loss: 0.4341 - val_accuracy: 0.7901 - 350ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4334 - accuracy: 0.7992 - val_loss: 0.4385 - val_accuracy: 0.7953 - 332ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4342 - accuracy: 0.7988 - val_loss: 0.4399 - val_accuracy: 0.7937 - 361ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4332 - accuracy: 0.7956 - val_loss: 0.4329 - val_accuracy: 0.7978 - 347ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4337 - accuracy: 0.7961 - val_loss: 0.4380 - val_accuracy: 0.7921 - 314ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4368 - val_accuracy: 0.7991 - 329ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4325 - accuracy: 0.8000 - val_loss: 0.4344 - val_accuracy: 0.7975 - 389ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4328 - accuracy: 0.7972 - val_loss: 0.4354 - val_accuracy: 0.7949 - 365ms/epoch - 7ms/step\n",
      "Epoch 43: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 0.6606 - accuracy: 0.6310 - val_loss: 0.5923 - val_accuracy: 0.7188 - 2s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5680 - accuracy: 0.7448 - val_loss: 0.5427 - val_accuracy: 0.7476 - 336ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.5247 - accuracy: 0.7603 - val_loss: 0.5100 - val_accuracy: 0.7655 - 334ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.4998 - accuracy: 0.7685 - val_loss: 0.4896 - val_accuracy: 0.7668 - 332ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4832 - accuracy: 0.7715 - val_loss: 0.4796 - val_accuracy: 0.7710 - 346ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4747 - accuracy: 0.7745 - val_loss: 0.4709 - val_accuracy: 0.7751 - 374ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4707 - accuracy: 0.7781 - val_loss: 0.4617 - val_accuracy: 0.7815 - 356ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4664 - accuracy: 0.7792 - val_loss: 0.4600 - val_accuracy: 0.7767 - 330ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4599 - accuracy: 0.7792 - val_loss: 0.4573 - val_accuracy: 0.7850 - 358ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4579 - accuracy: 0.7809 - val_loss: 0.4524 - val_accuracy: 0.7885 - 379ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4571 - accuracy: 0.7793 - val_loss: 0.4548 - val_accuracy: 0.7873 - 350ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4525 - accuracy: 0.7841 - val_loss: 0.4525 - val_accuracy: 0.7853 - 394ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4535 - accuracy: 0.7825 - val_loss: 0.4507 - val_accuracy: 0.7927 - 351ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4478 - accuracy: 0.7832 - val_loss: 0.4540 - val_accuracy: 0.7844 - 329ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4513 - accuracy: 0.7852 - val_loss: 0.4449 - val_accuracy: 0.7873 - 411ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4474 - accuracy: 0.7843 - val_loss: 0.4461 - val_accuracy: 0.7895 - 327ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4471 - accuracy: 0.7882 - val_loss: 0.4420 - val_accuracy: 0.7863 - 352ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4423 - accuracy: 0.7911 - val_loss: 0.4426 - val_accuracy: 0.7914 - 368ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.4458 - val_accuracy: 0.7898 - 340ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4465 - accuracy: 0.7868 - val_loss: 0.4382 - val_accuracy: 0.7905 - 326ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4441 - accuracy: 0.7891 - val_loss: 0.4406 - val_accuracy: 0.7924 - 364ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4431 - val_accuracy: 0.7911 - 340ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4443 - accuracy: 0.7905 - val_loss: 0.4438 - val_accuracy: 0.7863 - 389ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4427 - accuracy: 0.7909 - val_loss: 0.4405 - val_accuracy: 0.7943 - 373ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4399 - accuracy: 0.7920 - val_loss: 0.4380 - val_accuracy: 0.7969 - 348ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4406 - accuracy: 0.7926 - val_loss: 0.4381 - val_accuracy: 0.7908 - 382ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4417 - accuracy: 0.7879 - val_loss: 0.4382 - val_accuracy: 0.7972 - 333ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4410 - accuracy: 0.7927 - val_loss: 0.4389 - val_accuracy: 0.7972 - 383ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4371 - accuracy: 0.7941 - val_loss: 0.4424 - val_accuracy: 0.7962 - 332ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4402 - accuracy: 0.7924 - val_loss: 0.4395 - val_accuracy: 0.7921 - 396ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4380 - accuracy: 0.7934 - val_loss: 0.4377 - val_accuracy: 0.7940 - 340ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4374 - accuracy: 0.7942 - val_loss: 0.4428 - val_accuracy: 0.7969 - 352ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4374 - accuracy: 0.7952 - val_loss: 0.4420 - val_accuracy: 0.7908 - 367ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4391 - accuracy: 0.7928 - val_loss: 0.4331 - val_accuracy: 0.7937 - 368ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4393 - accuracy: 0.7915 - val_loss: 0.4407 - val_accuracy: 0.7933 - 341ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4335 - accuracy: 0.7977 - val_loss: 0.4365 - val_accuracy: 0.7959 - 359ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4367 - accuracy: 0.7944 - val_loss: 0.4381 - val_accuracy: 0.7905 - 378ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4356 - accuracy: 0.7971 - val_loss: 0.4353 - val_accuracy: 0.7962 - 345ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4351 - accuracy: 0.7933 - val_loss: 0.4334 - val_accuracy: 0.7994 - 334ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4354 - accuracy: 0.7962 - val_loss: 0.4343 - val_accuracy: 0.7969 - 391ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4352 - accuracy: 0.7963 - val_loss: 0.4335 - val_accuracy: 0.7956 - 325ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4351 - accuracy: 0.7955 - val_loss: 0.4347 - val_accuracy: 0.7975 - 313ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4368 - accuracy: 0.7958 - val_loss: 0.4385 - val_accuracy: 0.7921 - 331ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4350 - accuracy: 0.7970 - val_loss: 0.4373 - val_accuracy: 0.7933 - 348ms/epoch - 7ms/step\n",
      "Epoch 44: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 0.6135 - accuracy: 0.6907 - val_loss: 0.5633 - val_accuracy: 0.7457 - 2s/epoch - 34ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5309 - accuracy: 0.7555 - val_loss: 0.5065 - val_accuracy: 0.7562 - 487ms/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.5041 - accuracy: 0.7657 - val_loss: 0.4914 - val_accuracy: 0.7665 - 360ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.4883 - accuracy: 0.7663 - val_loss: 0.4756 - val_accuracy: 0.7630 - 362ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4723 - accuracy: 0.7750 - val_loss: 0.4614 - val_accuracy: 0.7780 - 312ms/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4659 - accuracy: 0.7776 - val_loss: 0.4625 - val_accuracy: 0.7722 - 311ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4635 - accuracy: 0.7773 - val_loss: 0.4606 - val_accuracy: 0.7767 - 357ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4581 - accuracy: 0.7816 - val_loss: 0.4513 - val_accuracy: 0.7806 - 374ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4564 - accuracy: 0.7847 - val_loss: 0.4548 - val_accuracy: 0.7860 - 348ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4548 - accuracy: 0.7839 - val_loss: 0.4568 - val_accuracy: 0.7786 - 371ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4564 - accuracy: 0.7827 - val_loss: 0.4482 - val_accuracy: 0.7882 - 342ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4523 - accuracy: 0.7842 - val_loss: 0.4482 - val_accuracy: 0.7908 - 381ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4504 - accuracy: 0.7839 - val_loss: 0.4506 - val_accuracy: 0.7879 - 376ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4432 - accuracy: 0.7874 - val_loss: 0.4444 - val_accuracy: 0.7847 - 368ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4479 - accuracy: 0.7883 - val_loss: 0.4481 - val_accuracy: 0.7933 - 375ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4446 - accuracy: 0.7894 - val_loss: 0.4401 - val_accuracy: 0.7882 - 355ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4456 - accuracy: 0.7889 - val_loss: 0.4373 - val_accuracy: 0.7863 - 317ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4418 - accuracy: 0.7880 - val_loss: 0.4459 - val_accuracy: 0.7911 - 349ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4431 - accuracy: 0.7872 - val_loss: 0.4368 - val_accuracy: 0.7882 - 369ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4405 - accuracy: 0.7898 - val_loss: 0.4496 - val_accuracy: 0.7857 - 330ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4439 - accuracy: 0.7920 - val_loss: 0.4446 - val_accuracy: 0.7879 - 331ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4414 - accuracy: 0.7948 - val_loss: 0.4396 - val_accuracy: 0.7889 - 365ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4406 - accuracy: 0.7923 - val_loss: 0.4303 - val_accuracy: 0.7997 - 322ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4393 - accuracy: 0.7901 - val_loss: 0.4392 - val_accuracy: 0.7969 - 357ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4373 - accuracy: 0.7932 - val_loss: 0.4362 - val_accuracy: 0.7908 - 349ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4373 - accuracy: 0.7924 - val_loss: 0.4385 - val_accuracy: 0.7933 - 369ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4384 - accuracy: 0.7966 - val_loss: 0.4442 - val_accuracy: 0.7927 - 365ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4374 - accuracy: 0.7938 - val_loss: 0.4391 - val_accuracy: 0.7985 - 343ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4397 - accuracy: 0.7924 - val_loss: 0.4371 - val_accuracy: 0.7969 - 374ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4356 - accuracy: 0.7927 - val_loss: 0.4382 - val_accuracy: 0.7937 - 347ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4362 - accuracy: 0.7944 - val_loss: 0.4405 - val_accuracy: 0.7882 - 334ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4379 - accuracy: 0.7907 - val_loss: 0.4320 - val_accuracy: 0.7949 - 380ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4383 - accuracy: 0.7939 - val_loss: 0.4388 - val_accuracy: 0.7946 - 378ms/epoch - 8ms/step\n",
      "Epoch 33: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 0.6335 - accuracy: 0.6632 - val_loss: 0.5798 - val_accuracy: 0.7370 - 2s/epoch - 49ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5457 - accuracy: 0.7541 - val_loss: 0.5267 - val_accuracy: 0.7591 - 420ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.5097 - accuracy: 0.7649 - val_loss: 0.4939 - val_accuracy: 0.7687 - 472ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.4878 - accuracy: 0.7709 - val_loss: 0.4801 - val_accuracy: 0.7697 - 339ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4708 - accuracy: 0.7797 - val_loss: 0.4730 - val_accuracy: 0.7793 - 359ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4711 - accuracy: 0.7781 - val_loss: 0.4679 - val_accuracy: 0.7777 - 351ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4601 - accuracy: 0.7859 - val_loss: 0.4603 - val_accuracy: 0.7783 - 497ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4563 - accuracy: 0.7829 - val_loss: 0.4543 - val_accuracy: 0.7869 - 366ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4528 - accuracy: 0.7849 - val_loss: 0.4575 - val_accuracy: 0.7885 - 370ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4543 - accuracy: 0.7877 - val_loss: 0.4594 - val_accuracy: 0.7853 - 394ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4506 - accuracy: 0.7867 - val_loss: 0.4516 - val_accuracy: 0.7908 - 357ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4493 - accuracy: 0.7850 - val_loss: 0.4480 - val_accuracy: 0.7882 - 387ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4501 - accuracy: 0.7868 - val_loss: 0.4487 - val_accuracy: 0.7853 - 359ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4453 - accuracy: 0.7889 - val_loss: 0.4405 - val_accuracy: 0.7959 - 379ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4453 - accuracy: 0.7918 - val_loss: 0.4420 - val_accuracy: 0.7921 - 356ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4422 - accuracy: 0.7906 - val_loss: 0.4480 - val_accuracy: 0.7895 - 363ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4447 - accuracy: 0.7879 - val_loss: 0.4414 - val_accuracy: 0.7917 - 351ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4403 - accuracy: 0.7930 - val_loss: 0.4444 - val_accuracy: 0.7940 - 355ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4413 - accuracy: 0.7944 - val_loss: 0.4353 - val_accuracy: 0.7930 - 366ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4419 - accuracy: 0.7913 - val_loss: 0.4373 - val_accuracy: 0.7924 - 436ms/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4395 - accuracy: 0.7913 - val_loss: 0.4368 - val_accuracy: 0.7911 - 334ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4405 - accuracy: 0.7908 - val_loss: 0.4385 - val_accuracy: 0.7946 - 414ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4406 - accuracy: 0.7940 - val_loss: 0.4384 - val_accuracy: 0.7959 - 354ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4367 - accuracy: 0.7923 - val_loss: 0.4321 - val_accuracy: 0.7969 - 365ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.4374 - val_accuracy: 0.7940 - 388ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4369 - val_accuracy: 0.7972 - 365ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4397 - accuracy: 0.7948 - val_loss: 0.4359 - val_accuracy: 0.7946 - 370ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4375 - accuracy: 0.7922 - val_loss: 0.4425 - val_accuracy: 0.7927 - 394ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4363 - accuracy: 0.7965 - val_loss: 0.4345 - val_accuracy: 0.7937 - 361ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4342 - accuracy: 0.7925 - val_loss: 0.4396 - val_accuracy: 0.7908 - 354ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4381 - accuracy: 0.7958 - val_loss: 0.4334 - val_accuracy: 0.7911 - 339ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4355 - accuracy: 0.7930 - val_loss: 0.4287 - val_accuracy: 0.8026 - 382ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4344 - accuracy: 0.7946 - val_loss: 0.4340 - val_accuracy: 0.7985 - 357ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4349 - accuracy: 0.7931 - val_loss: 0.4320 - val_accuracy: 0.7997 - 407ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4365 - accuracy: 0.7936 - val_loss: 0.4305 - val_accuracy: 0.7943 - 388ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4363 - accuracy: 0.7935 - val_loss: 0.4357 - val_accuracy: 0.7937 - 362ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4349 - accuracy: 0.7944 - val_loss: 0.4338 - val_accuracy: 0.7972 - 386ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4322 - accuracy: 0.7946 - val_loss: 0.4347 - val_accuracy: 0.7965 - 362ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4321 - accuracy: 0.7962 - val_loss: 0.4306 - val_accuracy: 0.7965 - 360ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4342 - accuracy: 0.7957 - val_loss: 0.4356 - val_accuracy: 0.7991 - 375ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4341 - accuracy: 0.7954 - val_loss: 0.4342 - val_accuracy: 0.8001 - 372ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4332 - accuracy: 0.7935 - val_loss: 0.4327 - val_accuracy: 0.7972 - 336ms/epoch - 7ms/step\n",
      "Epoch 42: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 0.6250 - accuracy: 0.6756 - val_loss: 0.5698 - val_accuracy: 0.7463 - 2s/epoch - 49ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5455 - accuracy: 0.7597 - val_loss: 0.5226 - val_accuracy: 0.7575 - 359ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.5058 - accuracy: 0.7685 - val_loss: 0.4833 - val_accuracy: 0.7684 - 365ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.4815 - accuracy: 0.7728 - val_loss: 0.4697 - val_accuracy: 0.7758 - 440ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4718 - accuracy: 0.7782 - val_loss: 0.4650 - val_accuracy: 0.7783 - 380ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4653 - accuracy: 0.7781 - val_loss: 0.4665 - val_accuracy: 0.7774 - 341ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4571 - accuracy: 0.7829 - val_loss: 0.4598 - val_accuracy: 0.7799 - 338ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4552 - accuracy: 0.7877 - val_loss: 0.4488 - val_accuracy: 0.7866 - 338ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4566 - accuracy: 0.7829 - val_loss: 0.4491 - val_accuracy: 0.7895 - 384ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4506 - accuracy: 0.7833 - val_loss: 0.4453 - val_accuracy: 0.7802 - 414ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4489 - accuracy: 0.7858 - val_loss: 0.4546 - val_accuracy: 0.7834 - 340ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4486 - accuracy: 0.7909 - val_loss: 0.4386 - val_accuracy: 0.7940 - 406ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4461 - accuracy: 0.7841 - val_loss: 0.4443 - val_accuracy: 0.7898 - 372ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4475 - accuracy: 0.7869 - val_loss: 0.4395 - val_accuracy: 0.7911 - 351ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4439 - accuracy: 0.7866 - val_loss: 0.4483 - val_accuracy: 0.7831 - 349ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4431 - accuracy: 0.7885 - val_loss: 0.4408 - val_accuracy: 0.7847 - 361ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4441 - accuracy: 0.7855 - val_loss: 0.4420 - val_accuracy: 0.7933 - 356ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4421 - accuracy: 0.7866 - val_loss: 0.4487 - val_accuracy: 0.7844 - 391ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4424 - accuracy: 0.7913 - val_loss: 0.4409 - val_accuracy: 0.7898 - 338ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4415 - accuracy: 0.7928 - val_loss: 0.4480 - val_accuracy: 0.7901 - 364ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4387 - accuracy: 0.7920 - val_loss: 0.4395 - val_accuracy: 0.7927 - 345ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4394 - accuracy: 0.7920 - val_loss: 0.4412 - val_accuracy: 0.7908 - 371ms/epoch - 8ms/step\n",
      "Epoch 22: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 0.6006 - accuracy: 0.6945 - val_loss: 0.5423 - val_accuracy: 0.7537 - 2s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5236 - accuracy: 0.7613 - val_loss: 0.4993 - val_accuracy: 0.7626 - 448ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.4899 - accuracy: 0.7733 - val_loss: 0.4734 - val_accuracy: 0.7777 - 362ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.4770 - accuracy: 0.7764 - val_loss: 0.4796 - val_accuracy: 0.7767 - 385ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4686 - accuracy: 0.7794 - val_loss: 0.4593 - val_accuracy: 0.7786 - 412ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4633 - accuracy: 0.7801 - val_loss: 0.4516 - val_accuracy: 0.7748 - 369ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4555 - accuracy: 0.7822 - val_loss: 0.4532 - val_accuracy: 0.7876 - 363ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4524 - accuracy: 0.7862 - val_loss: 0.4539 - val_accuracy: 0.7825 - 399ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4523 - accuracy: 0.7859 - val_loss: 0.4445 - val_accuracy: 0.7831 - 333ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4465 - accuracy: 0.7893 - val_loss: 0.4508 - val_accuracy: 0.7898 - 349ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4458 - accuracy: 0.7890 - val_loss: 0.4497 - val_accuracy: 0.7844 - 349ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4454 - accuracy: 0.7923 - val_loss: 0.4421 - val_accuracy: 0.7885 - 357ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4442 - accuracy: 0.7908 - val_loss: 0.4456 - val_accuracy: 0.7911 - 396ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4406 - accuracy: 0.7916 - val_loss: 0.4401 - val_accuracy: 0.7949 - 328ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4433 - accuracy: 0.7915 - val_loss: 0.4425 - val_accuracy: 0.7901 - 376ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4409 - accuracy: 0.7901 - val_loss: 0.4432 - val_accuracy: 0.7869 - 365ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4417 - accuracy: 0.7931 - val_loss: 0.4411 - val_accuracy: 0.7946 - 332ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4388 - accuracy: 0.7948 - val_loss: 0.4408 - val_accuracy: 0.7924 - 388ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4392 - accuracy: 0.7916 - val_loss: 0.4362 - val_accuracy: 0.7924 - 384ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4395 - accuracy: 0.7918 - val_loss: 0.4396 - val_accuracy: 0.7937 - 370ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4365 - accuracy: 0.7957 - val_loss: 0.4374 - val_accuracy: 0.7933 - 396ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4380 - accuracy: 0.7928 - val_loss: 0.4363 - val_accuracy: 0.7892 - 341ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4379 - accuracy: 0.7920 - val_loss: 0.4406 - val_accuracy: 0.7946 - 365ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4357 - accuracy: 0.7970 - val_loss: 0.4388 - val_accuracy: 0.7933 - 355ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4352 - accuracy: 0.7968 - val_loss: 0.4368 - val_accuracy: 0.7895 - 383ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4368 - accuracy: 0.7921 - val_loss: 0.4372 - val_accuracy: 0.7949 - 333ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4358 - accuracy: 0.7907 - val_loss: 0.4354 - val_accuracy: 0.7921 - 382ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4361 - accuracy: 0.7935 - val_loss: 0.4388 - val_accuracy: 0.7965 - 353ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4349 - accuracy: 0.7982 - val_loss: 0.4353 - val_accuracy: 0.8026 - 374ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4358 - accuracy: 0.7950 - val_loss: 0.4344 - val_accuracy: 0.7978 - 324ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4358 - accuracy: 0.7960 - val_loss: 0.4320 - val_accuracy: 0.8013 - 362ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4366 - accuracy: 0.7946 - val_loss: 0.4366 - val_accuracy: 0.7975 - 365ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4340 - accuracy: 0.7962 - val_loss: 0.4377 - val_accuracy: 0.7933 - 358ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4331 - accuracy: 0.7961 - val_loss: 0.4371 - val_accuracy: 0.7962 - 334ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4325 - accuracy: 0.7963 - val_loss: 0.4322 - val_accuracy: 0.7965 - 338ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4357 - accuracy: 0.7950 - val_loss: 0.4388 - val_accuracy: 0.7949 - 377ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4343 - accuracy: 0.7949 - val_loss: 0.4375 - val_accuracy: 0.8004 - 336ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4327 - accuracy: 0.7946 - val_loss: 0.4342 - val_accuracy: 0.7927 - 378ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4317 - accuracy: 0.7976 - val_loss: 0.4343 - val_accuracy: 0.7969 - 368ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4334 - accuracy: 0.7977 - val_loss: 0.4351 - val_accuracy: 0.8036 - 319ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4349 - accuracy: 0.7960 - val_loss: 0.4318 - val_accuracy: 0.8017 - 357ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4365 - accuracy: 0.7950 - val_loss: 0.4388 - val_accuracy: 0.8017 - 356ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.4363 - val_accuracy: 0.7889 - 386ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4318 - accuracy: 0.7961 - val_loss: 0.4396 - val_accuracy: 0.7953 - 357ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 0s - loss: 0.4310 - accuracy: 0.7984 - val_loss: 0.4332 - val_accuracy: 0.7959 - 334ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 0s - loss: 0.4341 - accuracy: 0.7957 - val_loss: 0.4322 - val_accuracy: 0.7991 - 333ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "49/49 - 0s - loss: 0.4311 - accuracy: 0.7973 - val_loss: 0.4370 - val_accuracy: 0.7953 - 343ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "49/49 - 0s - loss: 0.4336 - accuracy: 0.7992 - val_loss: 0.4350 - val_accuracy: 0.8004 - 328ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "49/49 - 0s - loss: 0.4329 - accuracy: 0.7956 - val_loss: 0.4329 - val_accuracy: 0.8004 - 312ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "49/49 - 0s - loss: 0.4341 - accuracy: 0.7980 - val_loss: 0.4343 - val_accuracy: 0.7991 - 344ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "49/49 - 0s - loss: 0.4323 - accuracy: 0.7981 - val_loss: 0.4339 - val_accuracy: 0.7975 - 359ms/epoch - 7ms/step\n",
      "Epoch 51: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 0.6205 - accuracy: 0.6953 - val_loss: 0.5811 - val_accuracy: 0.7386 - 2s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5526 - accuracy: 0.7540 - val_loss: 0.5428 - val_accuracy: 0.7498 - 375ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.5194 - accuracy: 0.7638 - val_loss: 0.5106 - val_accuracy: 0.7524 - 328ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.4916 - accuracy: 0.7736 - val_loss: 0.4923 - val_accuracy: 0.7607 - 344ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4807 - accuracy: 0.7705 - val_loss: 0.4820 - val_accuracy: 0.7703 - 342ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4692 - accuracy: 0.7797 - val_loss: 0.4673 - val_accuracy: 0.7706 - 333ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4655 - accuracy: 0.7814 - val_loss: 0.4613 - val_accuracy: 0.7694 - 344ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4619 - accuracy: 0.7781 - val_loss: 0.4682 - val_accuracy: 0.7780 - 328ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4539 - accuracy: 0.7825 - val_loss: 0.4530 - val_accuracy: 0.7853 - 302ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4530 - accuracy: 0.7849 - val_loss: 0.4437 - val_accuracy: 0.7869 - 328ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4521 - accuracy: 0.7823 - val_loss: 0.4510 - val_accuracy: 0.7917 - 312ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4514 - accuracy: 0.7880 - val_loss: 0.4501 - val_accuracy: 0.7885 - 374ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4460 - accuracy: 0.7874 - val_loss: 0.4495 - val_accuracy: 0.7863 - 342ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4448 - accuracy: 0.7887 - val_loss: 0.4501 - val_accuracy: 0.7866 - 383ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4439 - accuracy: 0.7929 - val_loss: 0.4430 - val_accuracy: 0.7873 - 374ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4431 - accuracy: 0.7923 - val_loss: 0.4430 - val_accuracy: 0.7853 - 346ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4410 - accuracy: 0.7916 - val_loss: 0.4412 - val_accuracy: 0.7892 - 347ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4428 - accuracy: 0.7936 - val_loss: 0.4415 - val_accuracy: 0.7914 - 328ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4408 - accuracy: 0.7984 - val_loss: 0.4423 - val_accuracy: 0.7943 - 345ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4386 - accuracy: 0.7946 - val_loss: 0.4470 - val_accuracy: 0.7895 - 382ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4423 - accuracy: 0.7945 - val_loss: 0.4413 - val_accuracy: 0.7924 - 371ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4411 - accuracy: 0.7944 - val_loss: 0.4450 - val_accuracy: 0.7937 - 350ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4383 - accuracy: 0.7961 - val_loss: 0.4341 - val_accuracy: 0.7946 - 333ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4388 - accuracy: 0.7947 - val_loss: 0.4403 - val_accuracy: 0.7985 - 395ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4376 - accuracy: 0.7905 - val_loss: 0.4421 - val_accuracy: 0.7924 - 399ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4371 - accuracy: 0.7952 - val_loss: 0.4377 - val_accuracy: 0.7879 - 354ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4390 - accuracy: 0.7974 - val_loss: 0.4371 - val_accuracy: 0.7937 - 398ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4353 - accuracy: 0.7966 - val_loss: 0.4359 - val_accuracy: 0.8007 - 405ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4378 - accuracy: 0.7945 - val_loss: 0.4356 - val_accuracy: 0.7978 - 373ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4354 - accuracy: 0.7952 - val_loss: 0.4418 - val_accuracy: 0.7997 - 353ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4344 - accuracy: 0.7961 - val_loss: 0.4339 - val_accuracy: 0.7975 - 328ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4371 - accuracy: 0.7963 - val_loss: 0.4374 - val_accuracy: 0.7933 - 345ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4341 - accuracy: 0.7953 - val_loss: 0.4380 - val_accuracy: 0.7911 - 366ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4357 - accuracy: 0.7953 - val_loss: 0.4387 - val_accuracy: 0.7956 - 428ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4359 - accuracy: 0.7956 - val_loss: 0.4397 - val_accuracy: 0.7914 - 360ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4371 - accuracy: 0.7976 - val_loss: 0.4332 - val_accuracy: 0.7930 - 368ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4351 - accuracy: 0.7947 - val_loss: 0.4378 - val_accuracy: 0.7959 - 347ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4366 - accuracy: 0.7948 - val_loss: 0.4406 - val_accuracy: 0.7933 - 328ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4339 - accuracy: 0.7967 - val_loss: 0.4362 - val_accuracy: 0.7975 - 365ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4341 - accuracy: 0.7952 - val_loss: 0.4350 - val_accuracy: 0.7985 - 361ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4354 - accuracy: 0.7971 - val_loss: 0.4336 - val_accuracy: 0.7949 - 318ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4346 - accuracy: 0.7941 - val_loss: 0.4338 - val_accuracy: 0.7937 - 304ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.4362 - val_accuracy: 0.7985 - 343ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4337 - accuracy: 0.7968 - val_loss: 0.4308 - val_accuracy: 0.7956 - 396ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 0s - loss: 0.4343 - accuracy: 0.7980 - val_loss: 0.4335 - val_accuracy: 0.7930 - 369ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 0s - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.4344 - val_accuracy: 0.7969 - 363ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "49/49 - 0s - loss: 0.4328 - accuracy: 0.7958 - val_loss: 0.4296 - val_accuracy: 0.7940 - 351ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "49/49 - 0s - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.4338 - val_accuracy: 0.7965 - 430ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "49/49 - 0s - loss: 0.4343 - accuracy: 0.7977 - val_loss: 0.4352 - val_accuracy: 0.7962 - 359ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "49/49 - 0s - loss: 0.4319 - accuracy: 0.7940 - val_loss: 0.4344 - val_accuracy: 0.7975 - 370ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "49/49 - 0s - loss: 0.4322 - accuracy: 0.7962 - val_loss: 0.4307 - val_accuracy: 0.7972 - 385ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "49/49 - 0s - loss: 0.4304 - accuracy: 0.7964 - val_loss: 0.4350 - val_accuracy: 0.7953 - 365ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "49/49 - 0s - loss: 0.4322 - accuracy: 0.7968 - val_loss: 0.4299 - val_accuracy: 0.8029 - 338ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "49/49 - 0s - loss: 0.4329 - accuracy: 0.7968 - val_loss: 0.4347 - val_accuracy: 0.7956 - 362ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "49/49 - 0s - loss: 0.4333 - accuracy: 0.7967 - val_loss: 0.4363 - val_accuracy: 0.7965 - 346ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "49/49 - 0s - loss: 0.4319 - accuracy: 0.7999 - val_loss: 0.4340 - val_accuracy: 0.7975 - 330ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "49/49 - 0s - loss: 0.4307 - accuracy: 0.7943 - val_loss: 0.4318 - val_accuracy: 0.7997 - 373ms/epoch - 8ms/step\n",
      "Epoch 57: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 0.6354 - accuracy: 0.6708 - val_loss: 0.5763 - val_accuracy: 0.7473 - 2s/epoch - 32ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5471 - accuracy: 0.7581 - val_loss: 0.5233 - val_accuracy: 0.7537 - 344ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.5047 - accuracy: 0.7645 - val_loss: 0.4818 - val_accuracy: 0.7697 - 312ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.4788 - accuracy: 0.7750 - val_loss: 0.4692 - val_accuracy: 0.7793 - 387ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4664 - accuracy: 0.7764 - val_loss: 0.4645 - val_accuracy: 0.7735 - 346ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4652 - accuracy: 0.7797 - val_loss: 0.4595 - val_accuracy: 0.7751 - 372ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4585 - accuracy: 0.7836 - val_loss: 0.4539 - val_accuracy: 0.7895 - 377ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4553 - accuracy: 0.7853 - val_loss: 0.4510 - val_accuracy: 0.7812 - 385ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4464 - accuracy: 0.7886 - val_loss: 0.4486 - val_accuracy: 0.7850 - 376ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4485 - accuracy: 0.7872 - val_loss: 0.4474 - val_accuracy: 0.7793 - 341ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4521 - accuracy: 0.7888 - val_loss: 0.4479 - val_accuracy: 0.7844 - 363ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4450 - accuracy: 0.7886 - val_loss: 0.4448 - val_accuracy: 0.7895 - 342ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4454 - accuracy: 0.7913 - val_loss: 0.4411 - val_accuracy: 0.7933 - 404ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4440 - accuracy: 0.7901 - val_loss: 0.4386 - val_accuracy: 0.7924 - 376ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4412 - accuracy: 0.7914 - val_loss: 0.4432 - val_accuracy: 0.7898 - 362ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4442 - accuracy: 0.7932 - val_loss: 0.4432 - val_accuracy: 0.7927 - 363ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4421 - accuracy: 0.7903 - val_loss: 0.4442 - val_accuracy: 0.7895 - 387ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4407 - accuracy: 0.7886 - val_loss: 0.4342 - val_accuracy: 0.7924 - 394ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4381 - accuracy: 0.7950 - val_loss: 0.4391 - val_accuracy: 0.7962 - 389ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4378 - accuracy: 0.7915 - val_loss: 0.4379 - val_accuracy: 0.7956 - 386ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4385 - accuracy: 0.7948 - val_loss: 0.4394 - val_accuracy: 0.7940 - 400ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4384 - accuracy: 0.7944 - val_loss: 0.4412 - val_accuracy: 0.7924 - 380ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4400 - accuracy: 0.7905 - val_loss: 0.4392 - val_accuracy: 0.7892 - 384ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4356 - accuracy: 0.7952 - val_loss: 0.4422 - val_accuracy: 0.7933 - 351ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4365 - accuracy: 0.7944 - val_loss: 0.4388 - val_accuracy: 0.7917 - 423ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4339 - accuracy: 0.7949 - val_loss: 0.4386 - val_accuracy: 0.7962 - 396ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.4403 - val_accuracy: 0.8026 - 365ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4377 - accuracy: 0.7979 - val_loss: 0.4335 - val_accuracy: 0.7978 - 406ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4362 - accuracy: 0.7960 - val_loss: 0.4329 - val_accuracy: 0.7956 - 377ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4347 - accuracy: 0.7929 - val_loss: 0.4357 - val_accuracy: 0.7940 - 360ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4335 - accuracy: 0.7963 - val_loss: 0.4377 - val_accuracy: 0.7949 - 355ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4353 - accuracy: 0.7947 - val_loss: 0.4326 - val_accuracy: 0.7994 - 383ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4346 - accuracy: 0.7966 - val_loss: 0.4376 - val_accuracy: 0.7927 - 395ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4359 - accuracy: 0.7966 - val_loss: 0.4362 - val_accuracy: 0.7962 - 354ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4360 - accuracy: 0.7948 - val_loss: 0.4347 - val_accuracy: 0.7946 - 386ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4340 - accuracy: 0.7958 - val_loss: 0.4376 - val_accuracy: 0.7930 - 380ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4340 - accuracy: 0.7955 - val_loss: 0.4342 - val_accuracy: 0.7927 - 395ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4314 - accuracy: 0.7945 - val_loss: 0.4298 - val_accuracy: 0.7965 - 444ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4329 - accuracy: 0.7960 - val_loss: 0.4351 - val_accuracy: 0.7956 - 359ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4344 - accuracy: 0.7964 - val_loss: 0.4366 - val_accuracy: 0.7956 - 408ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4330 - accuracy: 0.7958 - val_loss: 0.4343 - val_accuracy: 0.7933 - 393ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4350 - accuracy: 0.7963 - val_loss: 0.4369 - val_accuracy: 0.7962 - 365ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4345 - accuracy: 0.7976 - val_loss: 0.4374 - val_accuracy: 0.7962 - 357ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4344 - accuracy: 0.7935 - val_loss: 0.4339 - val_accuracy: 0.7956 - 350ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 0s - loss: 0.4319 - accuracy: 0.7959 - val_loss: 0.4369 - val_accuracy: 0.7953 - 363ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 0s - loss: 0.4333 - accuracy: 0.7960 - val_loss: 0.4323 - val_accuracy: 0.7949 - 371ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "49/49 - 0s - loss: 0.4328 - accuracy: 0.7971 - val_loss: 0.4394 - val_accuracy: 0.7949 - 383ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "49/49 - 0s - loss: 0.4327 - accuracy: 0.7941 - val_loss: 0.4302 - val_accuracy: 0.7962 - 382ms/epoch - 8ms/step\n",
      "Epoch 48: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 0.6042 - accuracy: 0.7046 - val_loss: 0.5530 - val_accuracy: 0.7479 - 2s/epoch - 34ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5306 - accuracy: 0.7573 - val_loss: 0.5165 - val_accuracy: 0.7550 - 387ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.5025 - accuracy: 0.7637 - val_loss: 0.4890 - val_accuracy: 0.7642 - 355ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.4822 - accuracy: 0.7736 - val_loss: 0.4825 - val_accuracy: 0.7690 - 336ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4742 - accuracy: 0.7750 - val_loss: 0.4732 - val_accuracy: 0.7626 - 367ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4642 - accuracy: 0.7755 - val_loss: 0.4650 - val_accuracy: 0.7732 - 362ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4616 - accuracy: 0.7797 - val_loss: 0.4549 - val_accuracy: 0.7802 - 348ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4583 - accuracy: 0.7789 - val_loss: 0.4601 - val_accuracy: 0.7793 - 383ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4523 - accuracy: 0.7849 - val_loss: 0.4590 - val_accuracy: 0.7780 - 356ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4504 - accuracy: 0.7832 - val_loss: 0.4526 - val_accuracy: 0.7898 - 346ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.4533 - val_accuracy: 0.7869 - 312ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4486 - accuracy: 0.7866 - val_loss: 0.4405 - val_accuracy: 0.7908 - 356ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4448 - accuracy: 0.7889 - val_loss: 0.4416 - val_accuracy: 0.7860 - 335ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4474 - accuracy: 0.7858 - val_loss: 0.4410 - val_accuracy: 0.7879 - 313ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4474 - accuracy: 0.7894 - val_loss: 0.4453 - val_accuracy: 0.7946 - 331ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4432 - accuracy: 0.7940 - val_loss: 0.4374 - val_accuracy: 0.7882 - 344ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4417 - accuracy: 0.7925 - val_loss: 0.4435 - val_accuracy: 0.7927 - 371ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4413 - accuracy: 0.7908 - val_loss: 0.4463 - val_accuracy: 0.7879 - 339ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4413 - accuracy: 0.7948 - val_loss: 0.4401 - val_accuracy: 0.7924 - 375ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4397 - accuracy: 0.7919 - val_loss: 0.4415 - val_accuracy: 0.7860 - 386ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4382 - accuracy: 0.7957 - val_loss: 0.4363 - val_accuracy: 0.7988 - 394ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4400 - accuracy: 0.7914 - val_loss: 0.4407 - val_accuracy: 0.7943 - 382ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4381 - accuracy: 0.7942 - val_loss: 0.4413 - val_accuracy: 0.7927 - 328ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4385 - accuracy: 0.7921 - val_loss: 0.4389 - val_accuracy: 0.7927 - 420ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4346 - accuracy: 0.7953 - val_loss: 0.4354 - val_accuracy: 0.7956 - 411ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4368 - accuracy: 0.7922 - val_loss: 0.4386 - val_accuracy: 0.7937 - 403ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4388 - accuracy: 0.7953 - val_loss: 0.4384 - val_accuracy: 0.7917 - 396ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4356 - accuracy: 0.7929 - val_loss: 0.4457 - val_accuracy: 0.7876 - 383ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4366 - accuracy: 0.7956 - val_loss: 0.4397 - val_accuracy: 0.7956 - 402ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4378 - accuracy: 0.7944 - val_loss: 0.4383 - val_accuracy: 0.7940 - 340ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4333 - accuracy: 0.7968 - val_loss: 0.4325 - val_accuracy: 0.7962 - 408ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4338 - accuracy: 0.7944 - val_loss: 0.4358 - val_accuracy: 0.7965 - 477ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4345 - accuracy: 0.8008 - val_loss: 0.4303 - val_accuracy: 0.7927 - 391ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4354 - accuracy: 0.7956 - val_loss: 0.4316 - val_accuracy: 0.7991 - 411ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4375 - accuracy: 0.7932 - val_loss: 0.4329 - val_accuracy: 0.7994 - 348ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4330 - accuracy: 0.7982 - val_loss: 0.4369 - val_accuracy: 0.7914 - 344ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4332 - accuracy: 0.7960 - val_loss: 0.4347 - val_accuracy: 0.8013 - 333ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4367 - accuracy: 0.7964 - val_loss: 0.4386 - val_accuracy: 0.7949 - 359ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4344 - accuracy: 0.7942 - val_loss: 0.4374 - val_accuracy: 0.7962 - 354ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4342 - accuracy: 0.7976 - val_loss: 0.4369 - val_accuracy: 0.7937 - 375ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4308 - accuracy: 0.7981 - val_loss: 0.4391 - val_accuracy: 0.7879 - 365ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4346 - accuracy: 0.7936 - val_loss: 0.4391 - val_accuracy: 0.7946 - 402ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4326 - accuracy: 0.7964 - val_loss: 0.4379 - val_accuracy: 0.7908 - 312ms/epoch - 6ms/step\n",
      "Epoch 43: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "49/49 - 2s - loss: 0.6177 - accuracy: 0.6878 - val_loss: 0.5738 - val_accuracy: 0.7438 - 2s/epoch - 32ms/step\n",
      "Epoch 2/100\n",
      "49/49 - 0s - loss: 0.5418 - accuracy: 0.7569 - val_loss: 0.5155 - val_accuracy: 0.7534 - 364ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "49/49 - 0s - loss: 0.4963 - accuracy: 0.7602 - val_loss: 0.4920 - val_accuracy: 0.7553 - 359ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "49/49 - 0s - loss: 0.4833 - accuracy: 0.7644 - val_loss: 0.4757 - val_accuracy: 0.7594 - 370ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "49/49 - 0s - loss: 0.4707 - accuracy: 0.7666 - val_loss: 0.4758 - val_accuracy: 0.7652 - 377ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "49/49 - 0s - loss: 0.4649 - accuracy: 0.7681 - val_loss: 0.4695 - val_accuracy: 0.7636 - 375ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "49/49 - 0s - loss: 0.4608 - accuracy: 0.7706 - val_loss: 0.4559 - val_accuracy: 0.7719 - 334ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "49/49 - 0s - loss: 0.4582 - accuracy: 0.7705 - val_loss: 0.4641 - val_accuracy: 0.7630 - 345ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "49/49 - 0s - loss: 0.4561 - accuracy: 0.7745 - val_loss: 0.4492 - val_accuracy: 0.7758 - 353ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "49/49 - 0s - loss: 0.4556 - accuracy: 0.7787 - val_loss: 0.4569 - val_accuracy: 0.7726 - 404ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "49/49 - 0s - loss: 0.4524 - accuracy: 0.7816 - val_loss: 0.4524 - val_accuracy: 0.7796 - 412ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "49/49 - 0s - loss: 0.4469 - accuracy: 0.7819 - val_loss: 0.4610 - val_accuracy: 0.7809 - 365ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "49/49 - 0s - loss: 0.4492 - accuracy: 0.7839 - val_loss: 0.4485 - val_accuracy: 0.7908 - 353ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "49/49 - 0s - loss: 0.4448 - accuracy: 0.7892 - val_loss: 0.4481 - val_accuracy: 0.7825 - 366ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "49/49 - 0s - loss: 0.4459 - accuracy: 0.7885 - val_loss: 0.4451 - val_accuracy: 0.7901 - 386ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "49/49 - 0s - loss: 0.4436 - accuracy: 0.7836 - val_loss: 0.4425 - val_accuracy: 0.7876 - 329ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "49/49 - 0s - loss: 0.4427 - accuracy: 0.7884 - val_loss: 0.4426 - val_accuracy: 0.7905 - 367ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "49/49 - 0s - loss: 0.4472 - accuracy: 0.7882 - val_loss: 0.4417 - val_accuracy: 0.7844 - 347ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "49/49 - 0s - loss: 0.4401 - accuracy: 0.7904 - val_loss: 0.4412 - val_accuracy: 0.7873 - 333ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "49/49 - 0s - loss: 0.4436 - accuracy: 0.7909 - val_loss: 0.4398 - val_accuracy: 0.7905 - 359ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "49/49 - 0s - loss: 0.4408 - accuracy: 0.7919 - val_loss: 0.4403 - val_accuracy: 0.7901 - 322ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "49/49 - 0s - loss: 0.4372 - accuracy: 0.7920 - val_loss: 0.4405 - val_accuracy: 0.7914 - 353ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "49/49 - 0s - loss: 0.4368 - accuracy: 0.7957 - val_loss: 0.4430 - val_accuracy: 0.7917 - 333ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "49/49 - 0s - loss: 0.4373 - accuracy: 0.7959 - val_loss: 0.4387 - val_accuracy: 0.7953 - 357ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "49/49 - 0s - loss: 0.4386 - accuracy: 0.7916 - val_loss: 0.4380 - val_accuracy: 0.7940 - 358ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "49/49 - 0s - loss: 0.4342 - accuracy: 0.7961 - val_loss: 0.4382 - val_accuracy: 0.7933 - 380ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "49/49 - 0s - loss: 0.4367 - accuracy: 0.7957 - val_loss: 0.4389 - val_accuracy: 0.7972 - 359ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "49/49 - 0s - loss: 0.4345 - accuracy: 0.7982 - val_loss: 0.4381 - val_accuracy: 0.7969 - 382ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "49/49 - 0s - loss: 0.4371 - accuracy: 0.7979 - val_loss: 0.4390 - val_accuracy: 0.7940 - 388ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "49/49 - 0s - loss: 0.4354 - accuracy: 0.7966 - val_loss: 0.4392 - val_accuracy: 0.7985 - 383ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "49/49 - 0s - loss: 0.4334 - accuracy: 0.7958 - val_loss: 0.4362 - val_accuracy: 0.7972 - 372ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "49/49 - 0s - loss: 0.4359 - accuracy: 0.7984 - val_loss: 0.4398 - val_accuracy: 0.7981 - 403ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "49/49 - 0s - loss: 0.4371 - accuracy: 0.7960 - val_loss: 0.4387 - val_accuracy: 0.7924 - 389ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "49/49 - 0s - loss: 0.4355 - accuracy: 0.7965 - val_loss: 0.4378 - val_accuracy: 0.7927 - 393ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "49/49 - 0s - loss: 0.4349 - accuracy: 0.7966 - val_loss: 0.4348 - val_accuracy: 0.7975 - 334ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "49/49 - 0s - loss: 0.4357 - accuracy: 0.7973 - val_loss: 0.4385 - val_accuracy: 0.7975 - 364ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "49/49 - 0s - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.4346 - val_accuracy: 0.8007 - 346ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "49/49 - 0s - loss: 0.4358 - accuracy: 0.7973 - val_loss: 0.4368 - val_accuracy: 0.7940 - 343ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "49/49 - 0s - loss: 0.4337 - accuracy: 0.7952 - val_loss: 0.4327 - val_accuracy: 0.7981 - 365ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "49/49 - 0s - loss: 0.4340 - accuracy: 0.7964 - val_loss: 0.4350 - val_accuracy: 0.7943 - 355ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "49/49 - 0s - loss: 0.4331 - accuracy: 0.8003 - val_loss: 0.4336 - val_accuracy: 0.7969 - 345ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "49/49 - 0s - loss: 0.4345 - accuracy: 0.7960 - val_loss: 0.4380 - val_accuracy: 0.8013 - 368ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "49/49 - 0s - loss: 0.4335 - accuracy: 0.7965 - val_loss: 0.4357 - val_accuracy: 0.7949 - 368ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "49/49 - 0s - loss: 0.4338 - accuracy: 0.7988 - val_loss: 0.4350 - val_accuracy: 0.7988 - 341ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "49/49 - 0s - loss: 0.4322 - accuracy: 0.7989 - val_loss: 0.4347 - val_accuracy: 0.7943 - 370ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "49/49 - 0s - loss: 0.4353 - accuracy: 0.7974 - val_loss: 0.4294 - val_accuracy: 0.7975 - 346ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "49/49 - 0s - loss: 0.4319 - accuracy: 0.7960 - val_loss: 0.4310 - val_accuracy: 0.7985 - 343ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "49/49 - 0s - loss: 0.4339 - accuracy: 0.7996 - val_loss: 0.4358 - val_accuracy: 0.7981 - 359ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "49/49 - 0s - loss: 0.4327 - accuracy: 0.7984 - val_loss: 0.4347 - val_accuracy: 0.7972 - 363ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "49/49 - 0s - loss: 0.4304 - accuracy: 0.7964 - val_loss: 0.4368 - val_accuracy: 0.7985 - 363ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "49/49 - 0s - loss: 0.4326 - accuracy: 0.7991 - val_loss: 0.4358 - val_accuracy: 0.7924 - 342ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "49/49 - 0s - loss: 0.4319 - accuracy: 0.7967 - val_loss: 0.4359 - val_accuracy: 0.7956 - 345ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "49/49 - 0s - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.4327 - val_accuracy: 0.7988 - 344ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "49/49 - 0s - loss: 0.4338 - accuracy: 0.7993 - val_loss: 0.4335 - val_accuracy: 0.7956 - 378ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "49/49 - 0s - loss: 0.4321 - accuracy: 0.7995 - val_loss: 0.4301 - val_accuracy: 0.8010 - 349ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "49/49 - 0s - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4360 - val_accuracy: 0.7985 - 339ms/epoch - 7ms/step\n",
      "Epoch 56: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.387198803150255\n",
      "epi entropy:  0.366570313793259\n",
      "\n",
      "dataset size:  0.5\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 0.6452 - accuracy: 0.6435 - val_loss: 0.5598 - val_accuracy: 0.7546 - 2s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 0.5358 - accuracy: 0.7576 - val_loss: 0.5087 - val_accuracy: 0.7689 - 518ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 1s - loss: 0.4997 - accuracy: 0.7684 - val_loss: 0.4798 - val_accuracy: 0.7802 - 509ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.4763 - accuracy: 0.7765 - val_loss: 0.4547 - val_accuracy: 0.7863 - 411ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.4455 - val_accuracy: 0.7948 - 406ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.4592 - accuracy: 0.7846 - val_loss: 0.4424 - val_accuracy: 0.7922 - 429ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4535 - accuracy: 0.7854 - val_loss: 0.4389 - val_accuracy: 0.7935 - 422ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4489 - accuracy: 0.7860 - val_loss: 0.4312 - val_accuracy: 0.7968 - 438ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.4474 - accuracy: 0.7856 - val_loss: 0.4337 - val_accuracy: 0.8012 - 461ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 0s - loss: 0.4448 - accuracy: 0.7897 - val_loss: 0.4298 - val_accuracy: 0.7953 - 496ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 0s - loss: 0.4462 - accuracy: 0.7870 - val_loss: 0.4270 - val_accuracy: 0.8009 - 437ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.4394 - accuracy: 0.7933 - val_loss: 0.4341 - val_accuracy: 0.7991 - 454ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4297 - val_accuracy: 0.7963 - 503ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 0s - loss: 0.4412 - accuracy: 0.7910 - val_loss: 0.4349 - val_accuracy: 0.7994 - 445ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4421 - accuracy: 0.7912 - val_loss: 0.4236 - val_accuracy: 0.8040 - 597ms/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.4378 - accuracy: 0.7900 - val_loss: 0.4303 - val_accuracy: 0.7953 - 446ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.4372 - accuracy: 0.7953 - val_loss: 0.4272 - val_accuracy: 0.8030 - 408ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.4367 - accuracy: 0.7936 - val_loss: 0.4300 - val_accuracy: 0.8032 - 429ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.4400 - accuracy: 0.7932 - val_loss: 0.4277 - val_accuracy: 0.8009 - 419ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4371 - accuracy: 0.7943 - val_loss: 0.4295 - val_accuracy: 0.7958 - 506ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.4377 - accuracy: 0.7949 - val_loss: 0.4231 - val_accuracy: 0.7999 - 442ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 0s - loss: 0.4377 - accuracy: 0.7924 - val_loss: 0.4252 - val_accuracy: 0.8037 - 446ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.4347 - accuracy: 0.7968 - val_loss: 0.4255 - val_accuracy: 0.8007 - 467ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.4375 - accuracy: 0.7950 - val_loss: 0.4232 - val_accuracy: 0.8022 - 435ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4345 - accuracy: 0.7977 - val_loss: 0.4243 - val_accuracy: 0.7981 - 506ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 0s - loss: 0.4360 - accuracy: 0.7939 - val_loss: 0.4222 - val_accuracy: 0.8037 - 436ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.4367 - accuracy: 0.7956 - val_loss: 0.4198 - val_accuracy: 0.8063 - 446ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.4354 - accuracy: 0.7965 - val_loss: 0.4222 - val_accuracy: 0.7999 - 484ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 0s - loss: 0.4358 - accuracy: 0.7979 - val_loss: 0.4250 - val_accuracy: 0.8040 - 491ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 0s - loss: 0.4353 - accuracy: 0.7956 - val_loss: 0.4252 - val_accuracy: 0.8040 - 416ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.4351 - accuracy: 0.7965 - val_loss: 0.4201 - val_accuracy: 0.8081 - 468ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 0s - loss: 0.4321 - accuracy: 0.7955 - val_loss: 0.4233 - val_accuracy: 0.8027 - 422ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 0s - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.4280 - val_accuracy: 0.8009 - 431ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 0s - loss: 0.4349 - accuracy: 0.7961 - val_loss: 0.4215 - val_accuracy: 0.8055 - 470ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 0s - loss: 0.4339 - accuracy: 0.7970 - val_loss: 0.4244 - val_accuracy: 0.8053 - 429ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 0s - loss: 0.4329 - accuracy: 0.7976 - val_loss: 0.4208 - val_accuracy: 0.8063 - 481ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 0s - loss: 0.4323 - accuracy: 0.7971 - val_loss: 0.4245 - val_accuracy: 0.8078 - 449ms/epoch - 7ms/step\n",
      "Epoch 37: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 0.5906 - accuracy: 0.7217 - val_loss: 0.5347 - val_accuracy: 0.7643 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 0s - loss: 0.5212 - accuracy: 0.7585 - val_loss: 0.4939 - val_accuracy: 0.7638 - 487ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 0.4913 - accuracy: 0.7658 - val_loss: 0.4751 - val_accuracy: 0.7766 - 432ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.4667 - accuracy: 0.7738 - val_loss: 0.4527 - val_accuracy: 0.7817 - 445ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.4609 - accuracy: 0.7773 - val_loss: 0.4433 - val_accuracy: 0.7909 - 411ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.4547 - accuracy: 0.7840 - val_loss: 0.4430 - val_accuracy: 0.7945 - 423ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4499 - accuracy: 0.7847 - val_loss: 0.4338 - val_accuracy: 0.8004 - 489ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4483 - accuracy: 0.7876 - val_loss: 0.4349 - val_accuracy: 0.7981 - 493ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.4443 - accuracy: 0.7899 - val_loss: 0.4296 - val_accuracy: 0.7986 - 497ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 0s - loss: 0.4455 - accuracy: 0.7899 - val_loss: 0.4348 - val_accuracy: 0.7932 - 451ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 0s - loss: 0.4442 - accuracy: 0.7905 - val_loss: 0.4220 - val_accuracy: 0.7979 - 427ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.4411 - accuracy: 0.7923 - val_loss: 0.4287 - val_accuracy: 0.7984 - 448ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 0s - loss: 0.4411 - accuracy: 0.7908 - val_loss: 0.4229 - val_accuracy: 0.8007 - 483ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.4251 - val_accuracy: 0.8004 - 523ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 0s - loss: 0.4385 - accuracy: 0.7947 - val_loss: 0.4229 - val_accuracy: 0.8032 - 428ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.4396 - accuracy: 0.7942 - val_loss: 0.4272 - val_accuracy: 0.8048 - 441ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.4358 - accuracy: 0.7966 - val_loss: 0.4255 - val_accuracy: 0.7991 - 460ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.4364 - accuracy: 0.7968 - val_loss: 0.4247 - val_accuracy: 0.8017 - 438ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 1s - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.4306 - val_accuracy: 0.7991 - 504ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 1s - loss: 0.4376 - accuracy: 0.7940 - val_loss: 0.4156 - val_accuracy: 0.8014 - 502ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.4354 - accuracy: 0.7974 - val_loss: 0.4197 - val_accuracy: 0.8012 - 438ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 0s - loss: 0.4356 - accuracy: 0.7949 - val_loss: 0.4259 - val_accuracy: 0.8014 - 437ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.4347 - accuracy: 0.7984 - val_loss: 0.4219 - val_accuracy: 0.8117 - 394ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.4337 - accuracy: 0.7976 - val_loss: 0.4252 - val_accuracy: 0.8035 - 465ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 0s - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.4270 - val_accuracy: 0.7999 - 434ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 0s - loss: 0.4337 - accuracy: 0.7982 - val_loss: 0.4232 - val_accuracy: 0.7989 - 442ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.4340 - accuracy: 0.7972 - val_loss: 0.4210 - val_accuracy: 0.8068 - 440ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.4334 - accuracy: 0.7977 - val_loss: 0.4224 - val_accuracy: 0.8002 - 469ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 0s - loss: 0.4344 - accuracy: 0.7974 - val_loss: 0.4216 - val_accuracy: 0.8086 - 463ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 0s - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.4269 - val_accuracy: 0.8050 - 495ms/epoch - 8ms/step\n",
      "Epoch 30: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 0.5961 - accuracy: 0.7147 - val_loss: 0.5463 - val_accuracy: 0.7600 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 0.5284 - accuracy: 0.7572 - val_loss: 0.4954 - val_accuracy: 0.7646 - 548ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 0.4882 - accuracy: 0.7588 - val_loss: 0.4617 - val_accuracy: 0.7638 - 460ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.4689 - accuracy: 0.7613 - val_loss: 0.4495 - val_accuracy: 0.7700 - 460ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.4594 - accuracy: 0.7661 - val_loss: 0.4462 - val_accuracy: 0.7815 - 432ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.4553 - accuracy: 0.7778 - val_loss: 0.4424 - val_accuracy: 0.7843 - 443ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4526 - accuracy: 0.7793 - val_loss: 0.4419 - val_accuracy: 0.7828 - 474ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4507 - accuracy: 0.7828 - val_loss: 0.4465 - val_accuracy: 0.7935 - 446ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.4358 - val_accuracy: 0.7953 - 481ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 0s - loss: 0.4445 - accuracy: 0.7895 - val_loss: 0.4351 - val_accuracy: 0.8063 - 428ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4409 - accuracy: 0.7927 - val_loss: 0.4311 - val_accuracy: 0.8030 - 505ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.4429 - accuracy: 0.7950 - val_loss: 0.4240 - val_accuracy: 0.8058 - 446ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 0s - loss: 0.4397 - accuracy: 0.7942 - val_loss: 0.4308 - val_accuracy: 0.8060 - 446ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 0s - loss: 0.4382 - accuracy: 0.7972 - val_loss: 0.4270 - val_accuracy: 0.8050 - 468ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 0s - loss: 0.4366 - accuracy: 0.7978 - val_loss: 0.4291 - val_accuracy: 0.8014 - 440ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.4377 - accuracy: 0.7978 - val_loss: 0.4234 - val_accuracy: 0.8050 - 460ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.4370 - accuracy: 0.7968 - val_loss: 0.4255 - val_accuracy: 0.8027 - 427ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.4377 - accuracy: 0.7978 - val_loss: 0.4275 - val_accuracy: 0.8060 - 436ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.4355 - accuracy: 0.7984 - val_loss: 0.4226 - val_accuracy: 0.8030 - 461ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.4372 - accuracy: 0.7983 - val_loss: 0.4256 - val_accuracy: 0.8073 - 461ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.4362 - accuracy: 0.7974 - val_loss: 0.4187 - val_accuracy: 0.8094 - 450ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4360 - accuracy: 0.7967 - val_loss: 0.4265 - val_accuracy: 0.8063 - 530ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.4391 - accuracy: 0.7987 - val_loss: 0.4257 - val_accuracy: 0.8055 - 484ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.4364 - accuracy: 0.7998 - val_loss: 0.4195 - val_accuracy: 0.8025 - 481ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 0s - loss: 0.4368 - accuracy: 0.7977 - val_loss: 0.4221 - val_accuracy: 0.8053 - 435ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 0s - loss: 0.4347 - accuracy: 0.7976 - val_loss: 0.4246 - val_accuracy: 0.8027 - 499ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.4324 - accuracy: 0.7988 - val_loss: 0.4232 - val_accuracy: 0.8066 - 437ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.4322 - accuracy: 0.7983 - val_loss: 0.4222 - val_accuracy: 0.8063 - 448ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.4256 - val_accuracy: 0.8019 - 513ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4326 - accuracy: 0.7966 - val_loss: 0.4227 - val_accuracy: 0.8025 - 525ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.4329 - accuracy: 0.7993 - val_loss: 0.4232 - val_accuracy: 0.8055 - 487ms/epoch - 8ms/step\n",
      "Epoch 31: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 0.6255 - accuracy: 0.6557 - val_loss: 0.5522 - val_accuracy: 0.7572 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 1s - loss: 0.5251 - accuracy: 0.7594 - val_loss: 0.4928 - val_accuracy: 0.7751 - 506ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 0.4887 - accuracy: 0.7700 - val_loss: 0.4629 - val_accuracy: 0.7897 - 450ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.4716 - accuracy: 0.7777 - val_loss: 0.4526 - val_accuracy: 0.7868 - 492ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.4595 - accuracy: 0.7816 - val_loss: 0.4459 - val_accuracy: 0.7876 - 453ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.4582 - accuracy: 0.7835 - val_loss: 0.4391 - val_accuracy: 0.7881 - 462ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4547 - accuracy: 0.7838 - val_loss: 0.4404 - val_accuracy: 0.7871 - 485ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4484 - accuracy: 0.7869 - val_loss: 0.4431 - val_accuracy: 0.7940 - 473ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4486 - accuracy: 0.7879 - val_loss: 0.4368 - val_accuracy: 0.8012 - 508ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 0s - loss: 0.4471 - accuracy: 0.7900 - val_loss: 0.4386 - val_accuracy: 0.8004 - 462ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 0s - loss: 0.4462 - accuracy: 0.7892 - val_loss: 0.4344 - val_accuracy: 0.7932 - 451ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4441 - accuracy: 0.7911 - val_loss: 0.4298 - val_accuracy: 0.7930 - 531ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4442 - accuracy: 0.7895 - val_loss: 0.4349 - val_accuracy: 0.7994 - 525ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 0s - loss: 0.4446 - accuracy: 0.7915 - val_loss: 0.4285 - val_accuracy: 0.7976 - 461ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 0s - loss: 0.4441 - accuracy: 0.7906 - val_loss: 0.4271 - val_accuracy: 0.8068 - 499ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.4403 - accuracy: 0.7898 - val_loss: 0.4320 - val_accuracy: 0.7984 - 483ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.4408 - accuracy: 0.7918 - val_loss: 0.4366 - val_accuracy: 0.7973 - 467ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.4387 - accuracy: 0.7902 - val_loss: 0.4336 - val_accuracy: 0.7989 - 417ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.4390 - accuracy: 0.7959 - val_loss: 0.4291 - val_accuracy: 0.8030 - 437ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.4394 - accuracy: 0.7935 - val_loss: 0.4320 - val_accuracy: 0.7989 - 462ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.4379 - accuracy: 0.7953 - val_loss: 0.4294 - val_accuracy: 0.7963 - 429ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 0s - loss: 0.4412 - accuracy: 0.7914 - val_loss: 0.4269 - val_accuracy: 0.8083 - 436ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.4362 - accuracy: 0.7974 - val_loss: 0.4283 - val_accuracy: 0.7994 - 429ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.4397 - accuracy: 0.7949 - val_loss: 0.4276 - val_accuracy: 0.7981 - 467ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 0s - loss: 0.4358 - accuracy: 0.7941 - val_loss: 0.4315 - val_accuracy: 0.7984 - 485ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 0s - loss: 0.4324 - accuracy: 0.7959 - val_loss: 0.4213 - val_accuracy: 0.8037 - 437ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.4368 - accuracy: 0.7952 - val_loss: 0.4295 - val_accuracy: 0.7950 - 429ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.4376 - accuracy: 0.7933 - val_loss: 0.4269 - val_accuracy: 0.8012 - 482ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 0s - loss: 0.4361 - accuracy: 0.7921 - val_loss: 0.4267 - val_accuracy: 0.8055 - 460ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 1s - loss: 0.4355 - accuracy: 0.7958 - val_loss: 0.4246 - val_accuracy: 0.8053 - 506ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.4359 - accuracy: 0.7938 - val_loss: 0.4273 - val_accuracy: 0.8081 - 445ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 0s - loss: 0.4331 - accuracy: 0.7965 - val_loss: 0.4302 - val_accuracy: 0.8027 - 443ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 0s - loss: 0.4362 - accuracy: 0.7961 - val_loss: 0.4294 - val_accuracy: 0.8022 - 463ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 0s - loss: 0.4348 - accuracy: 0.7935 - val_loss: 0.4299 - val_accuracy: 0.8030 - 420ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 0s - loss: 0.4363 - accuracy: 0.7958 - val_loss: 0.4258 - val_accuracy: 0.8040 - 451ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 0s - loss: 0.4342 - accuracy: 0.7964 - val_loss: 0.4269 - val_accuracy: 0.8019 - 456ms/epoch - 7ms/step\n",
      "Epoch 36: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 0.6110 - accuracy: 0.6803 - val_loss: 0.5344 - val_accuracy: 0.7595 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 0s - loss: 0.5234 - accuracy: 0.7563 - val_loss: 0.4961 - val_accuracy: 0.7687 - 469ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 0.4940 - accuracy: 0.7625 - val_loss: 0.4712 - val_accuracy: 0.7687 - 422ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.4768 - accuracy: 0.7660 - val_loss: 0.4586 - val_accuracy: 0.7756 - 422ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.4691 - accuracy: 0.7735 - val_loss: 0.4555 - val_accuracy: 0.7820 - 438ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 1s - loss: 0.4605 - accuracy: 0.7776 - val_loss: 0.4466 - val_accuracy: 0.7879 - 514ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4549 - accuracy: 0.7798 - val_loss: 0.4446 - val_accuracy: 0.7822 - 465ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4531 - accuracy: 0.7801 - val_loss: 0.4377 - val_accuracy: 0.7917 - 477ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.4488 - accuracy: 0.7844 - val_loss: 0.4302 - val_accuracy: 0.7915 - 459ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 0s - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4255 - val_accuracy: 0.7973 - 467ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 0s - loss: 0.4439 - accuracy: 0.7884 - val_loss: 0.4266 - val_accuracy: 0.7892 - 431ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.4431 - accuracy: 0.7872 - val_loss: 0.4321 - val_accuracy: 0.7922 - 450ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 0s - loss: 0.4439 - accuracy: 0.7878 - val_loss: 0.4293 - val_accuracy: 0.7976 - 429ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 0s - loss: 0.4440 - accuracy: 0.7889 - val_loss: 0.4299 - val_accuracy: 0.7999 - 456ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 0s - loss: 0.4414 - accuracy: 0.7902 - val_loss: 0.4309 - val_accuracy: 0.7963 - 393ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.4400 - accuracy: 0.7924 - val_loss: 0.4331 - val_accuracy: 0.7991 - 481ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.4384 - accuracy: 0.7913 - val_loss: 0.4287 - val_accuracy: 0.8002 - 482ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.4392 - accuracy: 0.7938 - val_loss: 0.4244 - val_accuracy: 0.8066 - 420ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.4380 - accuracy: 0.7947 - val_loss: 0.4257 - val_accuracy: 0.8014 - 478ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.4392 - accuracy: 0.7955 - val_loss: 0.4274 - val_accuracy: 0.7935 - 480ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.4376 - accuracy: 0.7950 - val_loss: 0.4246 - val_accuracy: 0.8009 - 473ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 0s - loss: 0.4369 - accuracy: 0.7935 - val_loss: 0.4280 - val_accuracy: 0.8014 - 432ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.4369 - accuracy: 0.7956 - val_loss: 0.4261 - val_accuracy: 0.8030 - 465ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.4358 - accuracy: 0.7946 - val_loss: 0.4233 - val_accuracy: 0.8007 - 422ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 0s - loss: 0.4368 - accuracy: 0.7965 - val_loss: 0.4251 - val_accuracy: 0.8019 - 466ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4366 - accuracy: 0.7962 - val_loss: 0.4274 - val_accuracy: 0.8027 - 513ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.4373 - accuracy: 0.7981 - val_loss: 0.4242 - val_accuracy: 0.8076 - 456ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.4354 - accuracy: 0.7963 - val_loss: 0.4214 - val_accuracy: 0.7984 - 422ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 0s - loss: 0.4343 - accuracy: 0.7987 - val_loss: 0.4197 - val_accuracy: 0.8040 - 489ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 0s - loss: 0.4330 - accuracy: 0.7979 - val_loss: 0.4217 - val_accuracy: 0.8032 - 417ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.4339 - accuracy: 0.7972 - val_loss: 0.4230 - val_accuracy: 0.8007 - 453ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 0s - loss: 0.4335 - accuracy: 0.7971 - val_loss: 0.4189 - val_accuracy: 0.8063 - 475ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 1s - loss: 0.4335 - accuracy: 0.7968 - val_loss: 0.4249 - val_accuracy: 0.8004 - 559ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 0s - loss: 0.4329 - accuracy: 0.7970 - val_loss: 0.4199 - val_accuracy: 0.8019 - 429ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 0s - loss: 0.4367 - accuracy: 0.7990 - val_loss: 0.4200 - val_accuracy: 0.8066 - 435ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 0s - loss: 0.4339 - accuracy: 0.7993 - val_loss: 0.4235 - val_accuracy: 0.8055 - 448ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 1s - loss: 0.4344 - accuracy: 0.7963 - val_loss: 0.4255 - val_accuracy: 0.8086 - 514ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 0s - loss: 0.4323 - accuracy: 0.7993 - val_loss: 0.4249 - val_accuracy: 0.8040 - 496ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 0s - loss: 0.4324 - accuracy: 0.7988 - val_loss: 0.4210 - val_accuracy: 0.8035 - 453ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 0s - loss: 0.4337 - accuracy: 0.7974 - val_loss: 0.4208 - val_accuracy: 0.8078 - 451ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 0s - loss: 0.4325 - accuracy: 0.7981 - val_loss: 0.4257 - val_accuracy: 0.8032 - 465ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 0s - loss: 0.4323 - accuracy: 0.7998 - val_loss: 0.4237 - val_accuracy: 0.8068 - 449ms/epoch - 7ms/step\n",
      "Epoch 42: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 0.6063 - accuracy: 0.7092 - val_loss: 0.5441 - val_accuracy: 0.7618 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 0s - loss: 0.5231 - accuracy: 0.7585 - val_loss: 0.4922 - val_accuracy: 0.7702 - 443ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 0.4918 - accuracy: 0.7660 - val_loss: 0.4676 - val_accuracy: 0.7779 - 442ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.4726 - accuracy: 0.7702 - val_loss: 0.4552 - val_accuracy: 0.7848 - 470ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.4670 - accuracy: 0.7737 - val_loss: 0.4580 - val_accuracy: 0.7838 - 459ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.4600 - accuracy: 0.7782 - val_loss: 0.4444 - val_accuracy: 0.7866 - 455ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4548 - accuracy: 0.7791 - val_loss: 0.4434 - val_accuracy: 0.7874 - 456ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4497 - accuracy: 0.7796 - val_loss: 0.4416 - val_accuracy: 0.7874 - 454ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.4529 - accuracy: 0.7833 - val_loss: 0.4351 - val_accuracy: 0.7881 - 440ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 0s - loss: 0.4483 - accuracy: 0.7855 - val_loss: 0.4312 - val_accuracy: 0.7912 - 471ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 0s - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.4374 - val_accuracy: 0.7922 - 438ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.4436 - accuracy: 0.7872 - val_loss: 0.4352 - val_accuracy: 0.7851 - 484ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 0s - loss: 0.4418 - accuracy: 0.7906 - val_loss: 0.4227 - val_accuracy: 0.7986 - 476ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 0s - loss: 0.4432 - accuracy: 0.7896 - val_loss: 0.4300 - val_accuracy: 0.7955 - 470ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 1s - loss: 0.4390 - accuracy: 0.7929 - val_loss: 0.4317 - val_accuracy: 0.7963 - 519ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.4406 - accuracy: 0.7904 - val_loss: 0.4255 - val_accuracy: 0.7994 - 443ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.4402 - accuracy: 0.7922 - val_loss: 0.4259 - val_accuracy: 0.8009 - 411ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.4375 - accuracy: 0.7936 - val_loss: 0.4293 - val_accuracy: 0.7999 - 459ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.4379 - accuracy: 0.7914 - val_loss: 0.4286 - val_accuracy: 0.8022 - 422ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.4370 - accuracy: 0.7945 - val_loss: 0.4250 - val_accuracy: 0.8035 - 420ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.4332 - accuracy: 0.7934 - val_loss: 0.4222 - val_accuracy: 0.8027 - 483ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 0s - loss: 0.4355 - accuracy: 0.7945 - val_loss: 0.4270 - val_accuracy: 0.7945 - 491ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.4351 - accuracy: 0.7946 - val_loss: 0.4210 - val_accuracy: 0.8045 - 424ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.4348 - accuracy: 0.7947 - val_loss: 0.4242 - val_accuracy: 0.8027 - 463ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 0s - loss: 0.4362 - accuracy: 0.7946 - val_loss: 0.4233 - val_accuracy: 0.8019 - 456ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 0s - loss: 0.4372 - accuracy: 0.7946 - val_loss: 0.4231 - val_accuracy: 0.7996 - 427ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.4337 - accuracy: 0.7934 - val_loss: 0.4212 - val_accuracy: 0.8032 - 449ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.4332 - accuracy: 0.7947 - val_loss: 0.4222 - val_accuracy: 0.8004 - 434ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 0s - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.4247 - val_accuracy: 0.7948 - 461ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 0s - loss: 0.4338 - accuracy: 0.7922 - val_loss: 0.4220 - val_accuracy: 0.8012 - 462ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.4330 - accuracy: 0.7974 - val_loss: 0.4179 - val_accuracy: 0.8045 - 440ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 0s - loss: 0.4361 - accuracy: 0.7954 - val_loss: 0.4199 - val_accuracy: 0.8053 - 432ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 0s - loss: 0.4323 - accuracy: 0.7960 - val_loss: 0.4256 - val_accuracy: 0.8012 - 451ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 1s - loss: 0.4318 - accuracy: 0.7963 - val_loss: 0.4208 - val_accuracy: 0.8058 - 533ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 0s - loss: 0.4313 - accuracy: 0.7991 - val_loss: 0.4235 - val_accuracy: 0.8002 - 478ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 0s - loss: 0.4349 - accuracy: 0.7965 - val_loss: 0.4242 - val_accuracy: 0.7996 - 425ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 0s - loss: 0.4318 - accuracy: 0.7970 - val_loss: 0.4281 - val_accuracy: 0.8022 - 462ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 0s - loss: 0.4314 - accuracy: 0.7943 - val_loss: 0.4229 - val_accuracy: 0.8083 - 460ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 0s - loss: 0.4304 - accuracy: 0.7970 - val_loss: 0.4210 - val_accuracy: 0.8025 - 441ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 0s - loss: 0.4313 - accuracy: 0.7991 - val_loss: 0.4226 - val_accuracy: 0.8032 - 406ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 0s - loss: 0.4313 - accuracy: 0.7976 - val_loss: 0.4197 - val_accuracy: 0.8035 - 441ms/epoch - 7ms/step\n",
      "Epoch 41: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 0.6313 - accuracy: 0.6516 - val_loss: 0.5477 - val_accuracy: 0.7631 - 2s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 0s - loss: 0.5299 - accuracy: 0.7584 - val_loss: 0.4936 - val_accuracy: 0.7743 - 455ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 0.4901 - accuracy: 0.7700 - val_loss: 0.4661 - val_accuracy: 0.7805 - 468ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.4731 - accuracy: 0.7776 - val_loss: 0.4620 - val_accuracy: 0.7874 - 457ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.4639 - accuracy: 0.7796 - val_loss: 0.4486 - val_accuracy: 0.7858 - 457ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.4585 - accuracy: 0.7799 - val_loss: 0.4475 - val_accuracy: 0.7892 - 411ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4549 - accuracy: 0.7849 - val_loss: 0.4470 - val_accuracy: 0.7866 - 434ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4553 - accuracy: 0.7815 - val_loss: 0.4449 - val_accuracy: 0.7907 - 454ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 1s - loss: 0.4512 - accuracy: 0.7873 - val_loss: 0.4443 - val_accuracy: 0.7932 - 502ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4478 - accuracy: 0.7874 - val_loss: 0.4423 - val_accuracy: 0.7935 - 558ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 0s - loss: 0.4474 - accuracy: 0.7899 - val_loss: 0.4428 - val_accuracy: 0.7915 - 449ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 1s - loss: 0.4448 - accuracy: 0.7901 - val_loss: 0.4328 - val_accuracy: 0.8030 - 509ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4466 - accuracy: 0.7883 - val_loss: 0.4370 - val_accuracy: 0.7984 - 568ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 1s - loss: 0.4413 - accuracy: 0.7889 - val_loss: 0.4357 - val_accuracy: 0.7897 - 532ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 0s - loss: 0.4391 - accuracy: 0.7934 - val_loss: 0.4327 - val_accuracy: 0.7935 - 453ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.4424 - accuracy: 0.7922 - val_loss: 0.4312 - val_accuracy: 0.8022 - 417ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.4382 - accuracy: 0.7939 - val_loss: 0.4239 - val_accuracy: 0.8035 - 494ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 1s - loss: 0.4368 - accuracy: 0.7897 - val_loss: 0.4260 - val_accuracy: 0.7973 - 504ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.4378 - accuracy: 0.7949 - val_loss: 0.4218 - val_accuracy: 0.8025 - 488ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.4354 - accuracy: 0.7940 - val_loss: 0.4257 - val_accuracy: 0.7986 - 460ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.4342 - accuracy: 0.7961 - val_loss: 0.4234 - val_accuracy: 0.8040 - 466ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 1s - loss: 0.4331 - accuracy: 0.7968 - val_loss: 0.4277 - val_accuracy: 0.8017 - 505ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.4354 - accuracy: 0.7956 - val_loss: 0.4237 - val_accuracy: 0.8045 - 441ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.4341 - accuracy: 0.7953 - val_loss: 0.4203 - val_accuracy: 0.8025 - 439ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 0s - loss: 0.4353 - accuracy: 0.7978 - val_loss: 0.4249 - val_accuracy: 0.8045 - 481ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 0s - loss: 0.4357 - accuracy: 0.7955 - val_loss: 0.4243 - val_accuracy: 0.8025 - 414ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.4172 - val_accuracy: 0.8073 - 422ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.4345 - accuracy: 0.7952 - val_loss: 0.4200 - val_accuracy: 0.8032 - 423ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 0s - loss: 0.4329 - accuracy: 0.7984 - val_loss: 0.4241 - val_accuracy: 0.8025 - 419ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 0s - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.4257 - val_accuracy: 0.8009 - 495ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4237 - val_accuracy: 0.7996 - 454ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 0s - loss: 0.4330 - accuracy: 0.7977 - val_loss: 0.4244 - val_accuracy: 0.8048 - 445ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 0s - loss: 0.4319 - accuracy: 0.7988 - val_loss: 0.4224 - val_accuracy: 0.8048 - 432ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 0s - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4205 - val_accuracy: 0.8045 - 431ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 0s - loss: 0.4334 - accuracy: 0.7958 - val_loss: 0.4225 - val_accuracy: 0.8027 - 472ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 0s - loss: 0.4333 - accuracy: 0.7965 - val_loss: 0.4230 - val_accuracy: 0.8022 - 459ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 0s - loss: 0.4304 - accuracy: 0.7974 - val_loss: 0.4220 - val_accuracy: 0.8050 - 447ms/epoch - 7ms/step\n",
      "Epoch 37: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 0.5937 - accuracy: 0.7239 - val_loss: 0.5405 - val_accuracy: 0.7613 - 2s/epoch - 26ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 0s - loss: 0.5231 - accuracy: 0.7622 - val_loss: 0.4942 - val_accuracy: 0.7766 - 493ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 0.4889 - accuracy: 0.7705 - val_loss: 0.4744 - val_accuracy: 0.7794 - 424ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.4713 - accuracy: 0.7803 - val_loss: 0.4574 - val_accuracy: 0.7840 - 459ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.4616 - accuracy: 0.7798 - val_loss: 0.4541 - val_accuracy: 0.7915 - 433ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.4581 - accuracy: 0.7837 - val_loss: 0.4377 - val_accuracy: 0.7920 - 464ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4549 - accuracy: 0.7842 - val_loss: 0.4422 - val_accuracy: 0.7904 - 457ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4521 - accuracy: 0.7843 - val_loss: 0.4380 - val_accuracy: 0.7999 - 487ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.4475 - accuracy: 0.7885 - val_loss: 0.4406 - val_accuracy: 0.7909 - 466ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 0s - loss: 0.4460 - accuracy: 0.7899 - val_loss: 0.4306 - val_accuracy: 0.7902 - 433ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 0s - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.4324 - val_accuracy: 0.7994 - 459ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.4423 - accuracy: 0.7874 - val_loss: 0.4321 - val_accuracy: 0.8012 - 420ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 0s - loss: 0.4402 - accuracy: 0.7894 - val_loss: 0.4281 - val_accuracy: 0.7999 - 442ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 0s - loss: 0.4416 - accuracy: 0.7883 - val_loss: 0.4269 - val_accuracy: 0.7968 - 433ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 0s - loss: 0.4398 - accuracy: 0.7918 - val_loss: 0.4262 - val_accuracy: 0.7999 - 453ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.4402 - accuracy: 0.7926 - val_loss: 0.4237 - val_accuracy: 0.8017 - 457ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.4399 - accuracy: 0.7902 - val_loss: 0.4321 - val_accuracy: 0.7961 - 427ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.4373 - accuracy: 0.7920 - val_loss: 0.4245 - val_accuracy: 0.8027 - 445ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.4352 - accuracy: 0.7959 - val_loss: 0.4253 - val_accuracy: 0.8009 - 462ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.4339 - accuracy: 0.7931 - val_loss: 0.4316 - val_accuracy: 0.7968 - 420ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.4377 - accuracy: 0.7948 - val_loss: 0.4215 - val_accuracy: 0.8050 - 431ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 0s - loss: 0.4344 - accuracy: 0.7965 - val_loss: 0.4231 - val_accuracy: 0.8007 - 465ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.4369 - accuracy: 0.7937 - val_loss: 0.4280 - val_accuracy: 0.7984 - 468ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.4369 - accuracy: 0.7929 - val_loss: 0.4265 - val_accuracy: 0.8037 - 471ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 0s - loss: 0.4381 - accuracy: 0.7932 - val_loss: 0.4254 - val_accuracy: 0.8017 - 445ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 0s - loss: 0.4365 - accuracy: 0.7949 - val_loss: 0.4235 - val_accuracy: 0.7971 - 455ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.4326 - accuracy: 0.7927 - val_loss: 0.4208 - val_accuracy: 0.8002 - 498ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.4316 - accuracy: 0.7949 - val_loss: 0.4251 - val_accuracy: 0.7984 - 443ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 0s - loss: 0.4337 - accuracy: 0.7972 - val_loss: 0.4206 - val_accuracy: 0.8066 - 491ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 0s - loss: 0.4361 - accuracy: 0.7921 - val_loss: 0.4206 - val_accuracy: 0.7999 - 419ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.4324 - accuracy: 0.7959 - val_loss: 0.4235 - val_accuracy: 0.8030 - 479ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 1s - loss: 0.4311 - accuracy: 0.7975 - val_loss: 0.4203 - val_accuracy: 0.8078 - 506ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 0s - loss: 0.4342 - accuracy: 0.7949 - val_loss: 0.4228 - val_accuracy: 0.8025 - 433ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 0s - loss: 0.4337 - accuracy: 0.7961 - val_loss: 0.4207 - val_accuracy: 0.7999 - 454ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 0s - loss: 0.4306 - accuracy: 0.7974 - val_loss: 0.4209 - val_accuracy: 0.8019 - 442ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 0s - loss: 0.4333 - accuracy: 0.7939 - val_loss: 0.4216 - val_accuracy: 0.8078 - 433ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 0s - loss: 0.4296 - accuracy: 0.7973 - val_loss: 0.4214 - val_accuracy: 0.8025 - 439ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 0s - loss: 0.4315 - accuracy: 0.7988 - val_loss: 0.4237 - val_accuracy: 0.8030 - 420ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 0s - loss: 0.4306 - accuracy: 0.7952 - val_loss: 0.4200 - val_accuracy: 0.8004 - 453ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 0s - loss: 0.4329 - accuracy: 0.7984 - val_loss: 0.4230 - val_accuracy: 0.8060 - 451ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 0s - loss: 0.4315 - accuracy: 0.7970 - val_loss: 0.4226 - val_accuracy: 0.8066 - 490ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 1s - loss: 0.4282 - accuracy: 0.7966 - val_loss: 0.4216 - val_accuracy: 0.8025 - 520ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "62/62 - 0s - loss: 0.4294 - accuracy: 0.7995 - val_loss: 0.4237 - val_accuracy: 0.8012 - 450ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "62/62 - 0s - loss: 0.4309 - accuracy: 0.7994 - val_loss: 0.4218 - val_accuracy: 0.8027 - 452ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "62/62 - 0s - loss: 0.4311 - accuracy: 0.7975 - val_loss: 0.4189 - val_accuracy: 0.8007 - 423ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "62/62 - 1s - loss: 0.4297 - accuracy: 0.7985 - val_loss: 0.4234 - val_accuracy: 0.8027 - 521ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "62/62 - 0s - loss: 0.4304 - accuracy: 0.7974 - val_loss: 0.4158 - val_accuracy: 0.8045 - 459ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "62/62 - 0s - loss: 0.4297 - accuracy: 0.7973 - val_loss: 0.4238 - val_accuracy: 0.8002 - 470ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "62/62 - 0s - loss: 0.4318 - accuracy: 0.7970 - val_loss: 0.4229 - val_accuracy: 0.8030 - 484ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "62/62 - 1s - loss: 0.4297 - accuracy: 0.7979 - val_loss: 0.4228 - val_accuracy: 0.8050 - 545ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "62/62 - 0s - loss: 0.4286 - accuracy: 0.7980 - val_loss: 0.4235 - val_accuracy: 0.8037 - 481ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "62/62 - 0s - loss: 0.4312 - accuracy: 0.7987 - val_loss: 0.4215 - val_accuracy: 0.8071 - 439ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "62/62 - 0s - loss: 0.4280 - accuracy: 0.7990 - val_loss: 0.4240 - val_accuracy: 0.8012 - 478ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "62/62 - 1s - loss: 0.4303 - accuracy: 0.7984 - val_loss: 0.4142 - val_accuracy: 0.8094 - 511ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "62/62 - 0s - loss: 0.4321 - accuracy: 0.7970 - val_loss: 0.4201 - val_accuracy: 0.8053 - 465ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "62/62 - 0s - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.4182 - val_accuracy: 0.8040 - 472ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "62/62 - 1s - loss: 0.4301 - accuracy: 0.7979 - val_loss: 0.4167 - val_accuracy: 0.8050 - 514ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "62/62 - 1s - loss: 0.4297 - accuracy: 0.7980 - val_loss: 0.4179 - val_accuracy: 0.8091 - 509ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "62/62 - 0s - loss: 0.4300 - accuracy: 0.7992 - val_loss: 0.4170 - val_accuracy: 0.8089 - 456ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "62/62 - 0s - loss: 0.4284 - accuracy: 0.7990 - val_loss: 0.4189 - val_accuracy: 0.8035 - 482ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "62/62 - 0s - loss: 0.4278 - accuracy: 0.7972 - val_loss: 0.4181 - val_accuracy: 0.8078 - 494ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "62/62 - 1s - loss: 0.4289 - accuracy: 0.7972 - val_loss: 0.4210 - val_accuracy: 0.8066 - 506ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "62/62 - 0s - loss: 0.4313 - accuracy: 0.7975 - val_loss: 0.4188 - val_accuracy: 0.8063 - 482ms/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "62/62 - 0s - loss: 0.4295 - accuracy: 0.8006 - val_loss: 0.4206 - val_accuracy: 0.8083 - 457ms/epoch - 7ms/step\n",
      "Epoch 64: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 0.5806 - accuracy: 0.7322 - val_loss: 0.5348 - val_accuracy: 0.7643 - 2s/epoch - 28ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 0s - loss: 0.5203 - accuracy: 0.7560 - val_loss: 0.4876 - val_accuracy: 0.7748 - 479ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 0.4882 - accuracy: 0.7718 - val_loss: 0.4725 - val_accuracy: 0.7725 - 420ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.4740 - accuracy: 0.7760 - val_loss: 0.4525 - val_accuracy: 0.7861 - 492ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.4635 - accuracy: 0.7817 - val_loss: 0.4487 - val_accuracy: 0.7881 - 440ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.4443 - val_accuracy: 0.7876 - 448ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4533 - accuracy: 0.7861 - val_loss: 0.4445 - val_accuracy: 0.7981 - 479ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4480 - accuracy: 0.7899 - val_loss: 0.4299 - val_accuracy: 0.7935 - 441ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.4504 - accuracy: 0.7872 - val_loss: 0.4324 - val_accuracy: 0.7966 - 455ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 1s - loss: 0.4455 - accuracy: 0.7905 - val_loss: 0.4311 - val_accuracy: 0.7940 - 516ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 1s - loss: 0.4430 - accuracy: 0.7926 - val_loss: 0.4305 - val_accuracy: 0.8027 - 513ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.4429 - accuracy: 0.7886 - val_loss: 0.4262 - val_accuracy: 0.8048 - 472ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 1s - loss: 0.4420 - accuracy: 0.7889 - val_loss: 0.4280 - val_accuracy: 0.8017 - 523ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 0s - loss: 0.4408 - accuracy: 0.7908 - val_loss: 0.4285 - val_accuracy: 0.7963 - 457ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 0s - loss: 0.4396 - accuracy: 0.7929 - val_loss: 0.4276 - val_accuracy: 0.8007 - 430ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.4372 - accuracy: 0.7919 - val_loss: 0.4303 - val_accuracy: 0.7973 - 453ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 0s - loss: 0.4372 - accuracy: 0.7937 - val_loss: 0.4238 - val_accuracy: 0.8055 - 462ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.4365 - accuracy: 0.7954 - val_loss: 0.4261 - val_accuracy: 0.8007 - 487ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.4340 - accuracy: 0.7961 - val_loss: 0.4249 - val_accuracy: 0.7989 - 452ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.4360 - accuracy: 0.7956 - val_loss: 0.4199 - val_accuracy: 0.8012 - 464ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 0s - loss: 0.4350 - accuracy: 0.7966 - val_loss: 0.4246 - val_accuracy: 0.8014 - 441ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 0s - loss: 0.4342 - accuracy: 0.7944 - val_loss: 0.4261 - val_accuracy: 0.8050 - 428ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.4328 - accuracy: 0.7966 - val_loss: 0.4240 - val_accuracy: 0.7994 - 461ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 0s - loss: 0.4334 - accuracy: 0.7956 - val_loss: 0.4193 - val_accuracy: 0.7991 - 463ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 0s - loss: 0.4329 - accuracy: 0.7960 - val_loss: 0.4237 - val_accuracy: 0.8022 - 436ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 0s - loss: 0.4313 - accuracy: 0.7984 - val_loss: 0.4185 - val_accuracy: 0.8058 - 483ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 1s - loss: 0.4309 - accuracy: 0.7966 - val_loss: 0.4265 - val_accuracy: 0.8060 - 515ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.4327 - accuracy: 0.7968 - val_loss: 0.4220 - val_accuracy: 0.8048 - 447ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 0s - loss: 0.4332 - accuracy: 0.7961 - val_loss: 0.4217 - val_accuracy: 0.8068 - 487ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 0s - loss: 0.4316 - accuracy: 0.7978 - val_loss: 0.4214 - val_accuracy: 0.7976 - 459ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.4324 - accuracy: 0.7971 - val_loss: 0.4215 - val_accuracy: 0.8032 - 467ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 0s - loss: 0.4303 - accuracy: 0.7975 - val_loss: 0.4200 - val_accuracy: 0.8060 - 458ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 0s - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.4209 - val_accuracy: 0.8063 - 467ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 0s - loss: 0.4315 - accuracy: 0.7984 - val_loss: 0.4177 - val_accuracy: 0.8048 - 464ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 0s - loss: 0.4318 - accuracy: 0.7990 - val_loss: 0.4195 - val_accuracy: 0.8035 - 466ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 0s - loss: 0.4307 - accuracy: 0.7994 - val_loss: 0.4216 - val_accuracy: 0.8081 - 477ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 0s - loss: 0.4289 - accuracy: 0.7988 - val_loss: 0.4185 - val_accuracy: 0.8063 - 433ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 0s - loss: 0.4289 - accuracy: 0.8002 - val_loss: 0.4178 - val_accuracy: 0.8055 - 434ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 1s - loss: 0.4333 - accuracy: 0.7980 - val_loss: 0.4164 - val_accuracy: 0.8078 - 546ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "62/62 - 0s - loss: 0.4320 - accuracy: 0.7974 - val_loss: 0.4184 - val_accuracy: 0.8053 - 467ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "62/62 - 0s - loss: 0.4289 - accuracy: 0.7979 - val_loss: 0.4191 - val_accuracy: 0.8073 - 454ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "62/62 - 0s - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4200 - val_accuracy: 0.8050 - 486ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "62/62 - 0s - loss: 0.4300 - accuracy: 0.7975 - val_loss: 0.4212 - val_accuracy: 0.8060 - 473ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "62/62 - 0s - loss: 0.4300 - accuracy: 0.7980 - val_loss: 0.4223 - val_accuracy: 0.8037 - 490ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "62/62 - 1s - loss: 0.4322 - accuracy: 0.7977 - val_loss: 0.4203 - val_accuracy: 0.8094 - 500ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "62/62 - 0s - loss: 0.4293 - accuracy: 0.8000 - val_loss: 0.4179 - val_accuracy: 0.8032 - 460ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "62/62 - 1s - loss: 0.4307 - accuracy: 0.7979 - val_loss: 0.4194 - val_accuracy: 0.8076 - 532ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "62/62 - 0s - loss: 0.4286 - accuracy: 0.8000 - val_loss: 0.4176 - val_accuracy: 0.8104 - 469ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "62/62 - 0s - loss: 0.4297 - accuracy: 0.7981 - val_loss: 0.4208 - val_accuracy: 0.8096 - 482ms/epoch - 8ms/step\n",
      "Epoch 49: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "62/62 - 2s - loss: 0.6144 - accuracy: 0.6856 - val_loss: 0.5479 - val_accuracy: 0.7618 - 2s/epoch - 28ms/step\n",
      "Epoch 2/100\n",
      "62/62 - 0s - loss: 0.5275 - accuracy: 0.7590 - val_loss: 0.4890 - val_accuracy: 0.7728 - 441ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "62/62 - 0s - loss: 0.4937 - accuracy: 0.7677 - val_loss: 0.4731 - val_accuracy: 0.7725 - 463ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "62/62 - 0s - loss: 0.4794 - accuracy: 0.7724 - val_loss: 0.4630 - val_accuracy: 0.7797 - 421ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "62/62 - 0s - loss: 0.4679 - accuracy: 0.7746 - val_loss: 0.4554 - val_accuracy: 0.7825 - 435ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "62/62 - 0s - loss: 0.4579 - accuracy: 0.7786 - val_loss: 0.4477 - val_accuracy: 0.7881 - 463ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "62/62 - 0s - loss: 0.4580 - accuracy: 0.7815 - val_loss: 0.4450 - val_accuracy: 0.7976 - 430ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "62/62 - 0s - loss: 0.4499 - accuracy: 0.7843 - val_loss: 0.4443 - val_accuracy: 0.7899 - 439ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "62/62 - 0s - loss: 0.4484 - accuracy: 0.7823 - val_loss: 0.4394 - val_accuracy: 0.7991 - 431ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "62/62 - 0s - loss: 0.4438 - accuracy: 0.7860 - val_loss: 0.4339 - val_accuracy: 0.7981 - 437ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "62/62 - 0s - loss: 0.4446 - accuracy: 0.7874 - val_loss: 0.4342 - val_accuracy: 0.8022 - 411ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "62/62 - 0s - loss: 0.4435 - accuracy: 0.7918 - val_loss: 0.4323 - val_accuracy: 0.8035 - 454ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "62/62 - 0s - loss: 0.4423 - accuracy: 0.7924 - val_loss: 0.4302 - val_accuracy: 0.7989 - 456ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "62/62 - 0s - loss: 0.4429 - accuracy: 0.7914 - val_loss: 0.4328 - val_accuracy: 0.7981 - 396ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "62/62 - 0s - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4265 - val_accuracy: 0.7991 - 473ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "62/62 - 0s - loss: 0.4388 - accuracy: 0.7954 - val_loss: 0.4308 - val_accuracy: 0.8007 - 469ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "62/62 - 1s - loss: 0.4371 - accuracy: 0.7955 - val_loss: 0.4232 - val_accuracy: 0.8004 - 538ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "62/62 - 0s - loss: 0.4395 - accuracy: 0.7942 - val_loss: 0.4252 - val_accuracy: 0.8045 - 468ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "62/62 - 0s - loss: 0.4356 - accuracy: 0.7943 - val_loss: 0.4253 - val_accuracy: 0.8032 - 460ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "62/62 - 0s - loss: 0.4370 - accuracy: 0.7932 - val_loss: 0.4251 - val_accuracy: 0.8014 - 453ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "62/62 - 1s - loss: 0.4366 - accuracy: 0.7949 - val_loss: 0.4260 - val_accuracy: 0.7989 - 518ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "62/62 - 0s - loss: 0.4347 - accuracy: 0.7961 - val_loss: 0.4250 - val_accuracy: 0.7991 - 488ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "62/62 - 0s - loss: 0.4366 - accuracy: 0.7949 - val_loss: 0.4239 - val_accuracy: 0.8007 - 496ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "62/62 - 1s - loss: 0.4378 - accuracy: 0.7936 - val_loss: 0.4197 - val_accuracy: 0.8048 - 551ms/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "62/62 - 1s - loss: 0.4344 - accuracy: 0.7952 - val_loss: 0.4230 - val_accuracy: 0.8025 - 511ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "62/62 - 1s - loss: 0.4330 - accuracy: 0.7933 - val_loss: 0.4197 - val_accuracy: 0.8037 - 536ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "62/62 - 0s - loss: 0.4344 - accuracy: 0.7967 - val_loss: 0.4266 - val_accuracy: 0.8042 - 479ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "62/62 - 0s - loss: 0.4354 - accuracy: 0.7945 - val_loss: 0.4218 - val_accuracy: 0.8027 - 439ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "62/62 - 1s - loss: 0.4339 - accuracy: 0.7942 - val_loss: 0.4167 - val_accuracy: 0.8027 - 508ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "62/62 - 0s - loss: 0.4346 - accuracy: 0.7992 - val_loss: 0.4233 - val_accuracy: 0.8007 - 435ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "62/62 - 0s - loss: 0.4326 - accuracy: 0.7984 - val_loss: 0.4180 - val_accuracy: 0.8089 - 463ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "62/62 - 0s - loss: 0.4333 - accuracy: 0.7954 - val_loss: 0.4252 - val_accuracy: 0.8014 - 484ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "62/62 - 0s - loss: 0.4333 - accuracy: 0.8003 - val_loss: 0.4250 - val_accuracy: 0.8053 - 479ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "62/62 - 0s - loss: 0.4342 - accuracy: 0.7962 - val_loss: 0.4212 - val_accuracy: 0.7991 - 475ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "62/62 - 1s - loss: 0.4322 - accuracy: 0.7968 - val_loss: 0.4229 - val_accuracy: 0.8025 - 507ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "62/62 - 0s - loss: 0.4336 - accuracy: 0.7984 - val_loss: 0.4191 - val_accuracy: 0.8009 - 477ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "62/62 - 0s - loss: 0.4306 - accuracy: 0.7974 - val_loss: 0.4209 - val_accuracy: 0.8048 - 456ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "62/62 - 0s - loss: 0.4332 - accuracy: 0.7974 - val_loss: 0.4193 - val_accuracy: 0.8030 - 494ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "62/62 - 0s - loss: 0.4322 - accuracy: 0.8006 - val_loss: 0.4246 - val_accuracy: 0.8050 - 498ms/epoch - 8ms/step\n",
      "Epoch 39: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.3861303614192076\n",
      "epi entropy:  0.3720618487291568\n",
      "\n",
      "dataset size:  0.6\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 0.5684 - accuracy: 0.7372 - val_loss: 0.5259 - val_accuracy: 0.7635 - 2s/epoch - 28ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 0.4997 - accuracy: 0.7653 - val_loss: 0.4904 - val_accuracy: 0.7782 - 612ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.4737 - accuracy: 0.7734 - val_loss: 0.4797 - val_accuracy: 0.7776 - 530ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.4637 - accuracy: 0.7752 - val_loss: 0.4702 - val_accuracy: 0.7733 - 513ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4579 - accuracy: 0.7785 - val_loss: 0.4587 - val_accuracy: 0.7837 - 554ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4536 - accuracy: 0.7818 - val_loss: 0.4554 - val_accuracy: 0.7916 - 584ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4482 - accuracy: 0.7866 - val_loss: 0.4564 - val_accuracy: 0.7895 - 543ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4443 - accuracy: 0.7878 - val_loss: 0.4538 - val_accuracy: 0.7897 - 578ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4416 - accuracy: 0.7877 - val_loss: 0.4441 - val_accuracy: 0.7948 - 555ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4398 - accuracy: 0.7866 - val_loss: 0.4433 - val_accuracy: 0.7931 - 512ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 0s - loss: 0.4373 - accuracy: 0.7896 - val_loss: 0.4408 - val_accuracy: 0.7906 - 491ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4373 - accuracy: 0.7909 - val_loss: 0.4429 - val_accuracy: 0.7940 - 510ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 0s - loss: 0.4352 - accuracy: 0.7924 - val_loss: 0.4445 - val_accuracy: 0.7968 - 493ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4356 - accuracy: 0.7925 - val_loss: 0.4446 - val_accuracy: 0.7951 - 528ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4351 - accuracy: 0.7930 - val_loss: 0.4433 - val_accuracy: 0.7974 - 606ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4356 - accuracy: 0.7919 - val_loss: 0.4424 - val_accuracy: 0.7940 - 578ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 0s - loss: 0.4329 - accuracy: 0.7919 - val_loss: 0.4415 - val_accuracy: 0.7983 - 479ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 0s - loss: 0.4331 - accuracy: 0.7942 - val_loss: 0.4453 - val_accuracy: 0.7944 - 497ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 0s - loss: 0.4333 - accuracy: 0.7944 - val_loss: 0.4420 - val_accuracy: 0.7953 - 488ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 0s - loss: 0.4338 - accuracy: 0.7957 - val_loss: 0.4432 - val_accuracy: 0.7942 - 495ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4345 - accuracy: 0.7941 - val_loss: 0.4423 - val_accuracy: 0.7944 - 515ms/epoch - 7ms/step\n",
      "Epoch 21: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 0.5570 - accuracy: 0.7266 - val_loss: 0.5039 - val_accuracy: 0.7652 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 0.4940 - accuracy: 0.7662 - val_loss: 0.4837 - val_accuracy: 0.7733 - 551ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.4710 - accuracy: 0.7739 - val_loss: 0.4772 - val_accuracy: 0.7778 - 520ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.4569 - accuracy: 0.7798 - val_loss: 0.4694 - val_accuracy: 0.7784 - 532ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4537 - accuracy: 0.7832 - val_loss: 0.4622 - val_accuracy: 0.7816 - 539ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4499 - accuracy: 0.7850 - val_loss: 0.4587 - val_accuracy: 0.7882 - 591ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4453 - accuracy: 0.7856 - val_loss: 0.4549 - val_accuracy: 0.7899 - 562ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 0s - loss: 0.4440 - accuracy: 0.7842 - val_loss: 0.4511 - val_accuracy: 0.7965 - 486ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.4565 - val_accuracy: 0.7901 - 536ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4405 - accuracy: 0.7873 - val_loss: 0.4560 - val_accuracy: 0.7880 - 510ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 0s - loss: 0.4391 - accuracy: 0.7892 - val_loss: 0.4574 - val_accuracy: 0.7899 - 480ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 0s - loss: 0.4400 - accuracy: 0.7901 - val_loss: 0.4567 - val_accuracy: 0.7895 - 495ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 0s - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.4500 - val_accuracy: 0.7936 - 499ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4360 - accuracy: 0.7907 - val_loss: 0.4504 - val_accuracy: 0.7904 - 553ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4381 - accuracy: 0.7892 - val_loss: 0.4452 - val_accuracy: 0.7936 - 504ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4351 - accuracy: 0.7936 - val_loss: 0.4469 - val_accuracy: 0.7980 - 502ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4365 - accuracy: 0.7920 - val_loss: 0.4452 - val_accuracy: 0.7980 - 529ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4359 - accuracy: 0.7918 - val_loss: 0.4433 - val_accuracy: 0.7925 - 539ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4363 - accuracy: 0.7912 - val_loss: 0.4458 - val_accuracy: 0.7944 - 525ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4338 - accuracy: 0.7937 - val_loss: 0.4515 - val_accuracy: 0.7948 - 552ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4377 - accuracy: 0.7928 - val_loss: 0.4458 - val_accuracy: 0.7991 - 527ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4341 - accuracy: 0.7941 - val_loss: 0.4455 - val_accuracy: 0.7987 - 518ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4336 - accuracy: 0.7921 - val_loss: 0.4463 - val_accuracy: 0.7980 - 506ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4348 - accuracy: 0.7927 - val_loss: 0.4449 - val_accuracy: 0.7965 - 519ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4312 - accuracy: 0.7932 - val_loss: 0.4421 - val_accuracy: 0.7959 - 578ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4334 - accuracy: 0.7939 - val_loss: 0.4406 - val_accuracy: 0.7991 - 518ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4313 - accuracy: 0.7934 - val_loss: 0.4406 - val_accuracy: 0.7993 - 546ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4305 - accuracy: 0.7930 - val_loss: 0.4415 - val_accuracy: 0.7951 - 527ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 0s - loss: 0.4322 - accuracy: 0.7929 - val_loss: 0.4384 - val_accuracy: 0.7963 - 474ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4301 - accuracy: 0.7943 - val_loss: 0.4400 - val_accuracy: 0.7974 - 501ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4299 - accuracy: 0.7939 - val_loss: 0.4474 - val_accuracy: 0.7991 - 533ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4300 - accuracy: 0.7944 - val_loss: 0.4403 - val_accuracy: 0.7957 - 500ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4306 - accuracy: 0.7920 - val_loss: 0.4408 - val_accuracy: 0.7991 - 501ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4297 - accuracy: 0.7951 - val_loss: 0.4386 - val_accuracy: 0.7980 - 503ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4297 - accuracy: 0.7948 - val_loss: 0.4398 - val_accuracy: 0.7965 - 501ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4293 - accuracy: 0.7954 - val_loss: 0.4414 - val_accuracy: 0.7948 - 518ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4307 - accuracy: 0.7942 - val_loss: 0.4366 - val_accuracy: 0.7978 - 502ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4291 - accuracy: 0.7946 - val_loss: 0.4423 - val_accuracy: 0.7959 - 531ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4277 - accuracy: 0.7951 - val_loss: 0.4389 - val_accuracy: 0.7985 - 573ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4292 - accuracy: 0.7974 - val_loss: 0.4376 - val_accuracy: 0.7955 - 556ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4297 - accuracy: 0.7943 - val_loss: 0.4390 - val_accuracy: 0.7946 - 537ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 0s - loss: 0.4302 - accuracy: 0.7959 - val_loss: 0.4391 - val_accuracy: 0.7953 - 469ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4279 - accuracy: 0.7978 - val_loss: 0.4360 - val_accuracy: 0.8027 - 516ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "74/74 - 0s - loss: 0.4265 - accuracy: 0.7954 - val_loss: 0.4385 - val_accuracy: 0.7997 - 500ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "74/74 - 1s - loss: 0.4286 - accuracy: 0.7963 - val_loss: 0.4409 - val_accuracy: 0.7970 - 516ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "74/74 - 0s - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4357 - val_accuracy: 0.7948 - 496ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "74/74 - 0s - loss: 0.4298 - accuracy: 0.7962 - val_loss: 0.4389 - val_accuracy: 0.7946 - 500ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "74/74 - 1s - loss: 0.4289 - accuracy: 0.7973 - val_loss: 0.4397 - val_accuracy: 0.7970 - 500ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "74/74 - 1s - loss: 0.4269 - accuracy: 0.7989 - val_loss: 0.4366 - val_accuracy: 0.7936 - 516ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "74/74 - 0s - loss: 0.4282 - accuracy: 0.7960 - val_loss: 0.4405 - val_accuracy: 0.7974 - 493ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "74/74 - 1s - loss: 0.4296 - accuracy: 0.7965 - val_loss: 0.4395 - val_accuracy: 0.7970 - 516ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "74/74 - 1s - loss: 0.4297 - accuracy: 0.7946 - val_loss: 0.4396 - val_accuracy: 0.7980 - 516ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "74/74 - 1s - loss: 0.4288 - accuracy: 0.7935 - val_loss: 0.4384 - val_accuracy: 0.7976 - 531ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "74/74 - 0s - loss: 0.4282 - accuracy: 0.7935 - val_loss: 0.4393 - val_accuracy: 0.7955 - 498ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "74/74 - 0s - loss: 0.4257 - accuracy: 0.7952 - val_loss: 0.4338 - val_accuracy: 0.7944 - 498ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "74/74 - 0s - loss: 0.4274 - accuracy: 0.7965 - val_loss: 0.4386 - val_accuracy: 0.7972 - 498ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "74/74 - 1s - loss: 0.4259 - accuracy: 0.7983 - val_loss: 0.4353 - val_accuracy: 0.7961 - 519ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "74/74 - 1s - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4372 - val_accuracy: 0.7974 - 517ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "74/74 - 1s - loss: 0.4263 - accuracy: 0.7960 - val_loss: 0.4374 - val_accuracy: 0.7983 - 516ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "74/74 - 0s - loss: 0.4269 - accuracy: 0.7957 - val_loss: 0.4405 - val_accuracy: 0.8002 - 468ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "74/74 - 1s - loss: 0.4290 - accuracy: 0.7966 - val_loss: 0.4378 - val_accuracy: 0.7989 - 516ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "74/74 - 0s - loss: 0.4271 - accuracy: 0.7989 - val_loss: 0.4388 - val_accuracy: 0.7980 - 484ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "74/74 - 1s - loss: 0.4270 - accuracy: 0.7924 - val_loss: 0.4358 - val_accuracy: 0.7993 - 506ms/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "74/74 - 1s - loss: 0.4273 - accuracy: 0.7962 - val_loss: 0.4393 - val_accuracy: 0.7931 - 523ms/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "74/74 - 1s - loss: 0.4261 - accuracy: 0.7948 - val_loss: 0.4367 - val_accuracy: 0.7929 - 510ms/epoch - 7ms/step\n",
      "Epoch 65: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 0.5973 - accuracy: 0.6984 - val_loss: 0.5272 - val_accuracy: 0.7631 - 2s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 0.5156 - accuracy: 0.7577 - val_loss: 0.4943 - val_accuracy: 0.7654 - 672ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.4776 - accuracy: 0.7651 - val_loss: 0.4777 - val_accuracy: 0.7714 - 523ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.4683 - accuracy: 0.7736 - val_loss: 0.4645 - val_accuracy: 0.7774 - 526ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 0s - loss: 0.4577 - accuracy: 0.7798 - val_loss: 0.4690 - val_accuracy: 0.7850 - 494ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4534 - accuracy: 0.7797 - val_loss: 0.4640 - val_accuracy: 0.7818 - 504ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4495 - accuracy: 0.7852 - val_loss: 0.4518 - val_accuracy: 0.7889 - 526ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4463 - accuracy: 0.7836 - val_loss: 0.4564 - val_accuracy: 0.7895 - 519ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4447 - accuracy: 0.7900 - val_loss: 0.4515 - val_accuracy: 0.7921 - 517ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4457 - accuracy: 0.7890 - val_loss: 0.4495 - val_accuracy: 0.7899 - 513ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 0s - loss: 0.4415 - accuracy: 0.7905 - val_loss: 0.4525 - val_accuracy: 0.7946 - 470ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4501 - val_accuracy: 0.7946 - 532ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4402 - accuracy: 0.7885 - val_loss: 0.4485 - val_accuracy: 0.7910 - 513ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4383 - accuracy: 0.7952 - val_loss: 0.4492 - val_accuracy: 0.7923 - 502ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4375 - accuracy: 0.7937 - val_loss: 0.4470 - val_accuracy: 0.7910 - 519ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4377 - accuracy: 0.7931 - val_loss: 0.4491 - val_accuracy: 0.7997 - 561ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4376 - accuracy: 0.7941 - val_loss: 0.4475 - val_accuracy: 0.7923 - 515ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4334 - accuracy: 0.7939 - val_loss: 0.4469 - val_accuracy: 0.7955 - 584ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4360 - accuracy: 0.7956 - val_loss: 0.4476 - val_accuracy: 0.7961 - 520ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4342 - accuracy: 0.7913 - val_loss: 0.4454 - val_accuracy: 0.7948 - 532ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4380 - accuracy: 0.7889 - val_loss: 0.4438 - val_accuracy: 0.7929 - 551ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4352 - accuracy: 0.7944 - val_loss: 0.4384 - val_accuracy: 0.7942 - 602ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4336 - accuracy: 0.7918 - val_loss: 0.4391 - val_accuracy: 0.7974 - 572ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4340 - accuracy: 0.7918 - val_loss: 0.4451 - val_accuracy: 0.7925 - 586ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4332 - accuracy: 0.7957 - val_loss: 0.4393 - val_accuracy: 0.7972 - 662ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4315 - accuracy: 0.7932 - val_loss: 0.4416 - val_accuracy: 0.8015 - 566ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4339 - accuracy: 0.7941 - val_loss: 0.4379 - val_accuracy: 0.7944 - 564ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4323 - accuracy: 0.7941 - val_loss: 0.4433 - val_accuracy: 0.7936 - 514ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4313 - accuracy: 0.7924 - val_loss: 0.4427 - val_accuracy: 0.7970 - 566ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4310 - accuracy: 0.7950 - val_loss: 0.4390 - val_accuracy: 0.7968 - 508ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4305 - accuracy: 0.7959 - val_loss: 0.4469 - val_accuracy: 0.7959 - 530ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4304 - accuracy: 0.7956 - val_loss: 0.4395 - val_accuracy: 0.7953 - 574ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4271 - accuracy: 0.7967 - val_loss: 0.4371 - val_accuracy: 0.7923 - 536ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 0s - loss: 0.4310 - accuracy: 0.7944 - val_loss: 0.4419 - val_accuracy: 0.7925 - 498ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4328 - accuracy: 0.7936 - val_loss: 0.4422 - val_accuracy: 0.7980 - 572ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4289 - accuracy: 0.7950 - val_loss: 0.4399 - val_accuracy: 0.7899 - 607ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4319 - accuracy: 0.7948 - val_loss: 0.4416 - val_accuracy: 0.7970 - 536ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4295 - accuracy: 0.7935 - val_loss: 0.4435 - val_accuracy: 0.7963 - 592ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4301 - accuracy: 0.7954 - val_loss: 0.4448 - val_accuracy: 0.7959 - 509ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4302 - accuracy: 0.7975 - val_loss: 0.4398 - val_accuracy: 0.7948 - 507ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4300 - accuracy: 0.7914 - val_loss: 0.4402 - val_accuracy: 0.7974 - 650ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 1s - loss: 0.4291 - accuracy: 0.7950 - val_loss: 0.4389 - val_accuracy: 0.7959 - 523ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4282 - accuracy: 0.7955 - val_loss: 0.4385 - val_accuracy: 0.7963 - 546ms/epoch - 7ms/step\n",
      "Epoch 43: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 0.5678 - accuracy: 0.7328 - val_loss: 0.5194 - val_accuracy: 0.7656 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 0s - loss: 0.5012 - accuracy: 0.7660 - val_loss: 0.4808 - val_accuracy: 0.7652 - 500ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.4751 - accuracy: 0.7722 - val_loss: 0.4698 - val_accuracy: 0.7799 - 596ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.4584 - accuracy: 0.7747 - val_loss: 0.4640 - val_accuracy: 0.7801 - 567ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4535 - accuracy: 0.7814 - val_loss: 0.4568 - val_accuracy: 0.7846 - 561ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4469 - accuracy: 0.7823 - val_loss: 0.4621 - val_accuracy: 0.7899 - 520ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4480 - accuracy: 0.7835 - val_loss: 0.4573 - val_accuracy: 0.7878 - 530ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 0s - loss: 0.4457 - accuracy: 0.7842 - val_loss: 0.4522 - val_accuracy: 0.7914 - 494ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4431 - accuracy: 0.7853 - val_loss: 0.4550 - val_accuracy: 0.7904 - 516ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4383 - accuracy: 0.7876 - val_loss: 0.4579 - val_accuracy: 0.7959 - 516ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 0s - loss: 0.4422 - accuracy: 0.7866 - val_loss: 0.4477 - val_accuracy: 0.7940 - 491ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4408 - accuracy: 0.7888 - val_loss: 0.4550 - val_accuracy: 0.7931 - 578ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 0s - loss: 0.4390 - accuracy: 0.7901 - val_loss: 0.4490 - val_accuracy: 0.7912 - 500ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4379 - accuracy: 0.7910 - val_loss: 0.4465 - val_accuracy: 0.7953 - 504ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4371 - accuracy: 0.7924 - val_loss: 0.4465 - val_accuracy: 0.7916 - 545ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4361 - accuracy: 0.7913 - val_loss: 0.4441 - val_accuracy: 0.7925 - 520ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4366 - accuracy: 0.7900 - val_loss: 0.4426 - val_accuracy: 0.7948 - 505ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4358 - accuracy: 0.7928 - val_loss: 0.4478 - val_accuracy: 0.7882 - 540ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4332 - accuracy: 0.7930 - val_loss: 0.4427 - val_accuracy: 0.7910 - 514ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4349 - accuracy: 0.7915 - val_loss: 0.4412 - val_accuracy: 0.7944 - 530ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4341 - accuracy: 0.7944 - val_loss: 0.4419 - val_accuracy: 0.7978 - 521ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4336 - accuracy: 0.7918 - val_loss: 0.4474 - val_accuracy: 0.7933 - 523ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4323 - accuracy: 0.7942 - val_loss: 0.4457 - val_accuracy: 0.7961 - 514ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4319 - accuracy: 0.7920 - val_loss: 0.4399 - val_accuracy: 0.7921 - 545ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4320 - accuracy: 0.7935 - val_loss: 0.4447 - val_accuracy: 0.7978 - 527ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4304 - accuracy: 0.7941 - val_loss: 0.4417 - val_accuracy: 0.7957 - 540ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4311 - accuracy: 0.7924 - val_loss: 0.4426 - val_accuracy: 0.7974 - 523ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4285 - accuracy: 0.7948 - val_loss: 0.4450 - val_accuracy: 0.7970 - 565ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4307 - accuracy: 0.7932 - val_loss: 0.4383 - val_accuracy: 0.7972 - 526ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4305 - accuracy: 0.7966 - val_loss: 0.4413 - val_accuracy: 0.7970 - 516ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4298 - accuracy: 0.7957 - val_loss: 0.4379 - val_accuracy: 0.7959 - 505ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4302 - accuracy: 0.7953 - val_loss: 0.4381 - val_accuracy: 0.7993 - 534ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 0s - loss: 0.4292 - accuracy: 0.7963 - val_loss: 0.4414 - val_accuracy: 0.7959 - 481ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4299 - accuracy: 0.7987 - val_loss: 0.4416 - val_accuracy: 0.7980 - 520ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4302 - accuracy: 0.7971 - val_loss: 0.4377 - val_accuracy: 0.7991 - 516ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4294 - accuracy: 0.7950 - val_loss: 0.4393 - val_accuracy: 0.7957 - 600ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4299 - accuracy: 0.7963 - val_loss: 0.4379 - val_accuracy: 0.8010 - 503ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4285 - accuracy: 0.7968 - val_loss: 0.4432 - val_accuracy: 0.7968 - 500ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4286 - accuracy: 0.7959 - val_loss: 0.4421 - val_accuracy: 0.7978 - 554ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4284 - accuracy: 0.7955 - val_loss: 0.4396 - val_accuracy: 0.7995 - 523ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4285 - accuracy: 0.7943 - val_loss: 0.4419 - val_accuracy: 0.7983 - 526ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 1s - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.4406 - val_accuracy: 0.7912 - 521ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4287 - accuracy: 0.7966 - val_loss: 0.4392 - val_accuracy: 0.8000 - 507ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "74/74 - 1s - loss: 0.4281 - accuracy: 0.7954 - val_loss: 0.4363 - val_accuracy: 0.8012 - 572ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "74/74 - 1s - loss: 0.4304 - accuracy: 0.7954 - val_loss: 0.4407 - val_accuracy: 0.8002 - 552ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "74/74 - 1s - loss: 0.4258 - accuracy: 0.7975 - val_loss: 0.4415 - val_accuracy: 0.7953 - 519ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "74/74 - 1s - loss: 0.4283 - accuracy: 0.7965 - val_loss: 0.4397 - val_accuracy: 0.7953 - 550ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "74/74 - 1s - loss: 0.4296 - accuracy: 0.7951 - val_loss: 0.4395 - val_accuracy: 0.8008 - 517ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "74/74 - 0s - loss: 0.4299 - accuracy: 0.7948 - val_loss: 0.4431 - val_accuracy: 0.7961 - 471ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "74/74 - 0s - loss: 0.4286 - accuracy: 0.7966 - val_loss: 0.4379 - val_accuracy: 0.7997 - 500ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "74/74 - 0s - loss: 0.4274 - accuracy: 0.7942 - val_loss: 0.4378 - val_accuracy: 0.7983 - 496ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "74/74 - 0s - loss: 0.4284 - accuracy: 0.7971 - val_loss: 0.4401 - val_accuracy: 0.7940 - 486ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "74/74 - 1s - loss: 0.4270 - accuracy: 0.7971 - val_loss: 0.4399 - val_accuracy: 0.7985 - 504ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "74/74 - 1s - loss: 0.4276 - accuracy: 0.7975 - val_loss: 0.4378 - val_accuracy: 0.7955 - 507ms/epoch - 7ms/step\n",
      "Epoch 54: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 0.6484 - accuracy: 0.6467 - val_loss: 0.5652 - val_accuracy: 0.7535 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 0.5324 - accuracy: 0.7596 - val_loss: 0.5003 - val_accuracy: 0.7718 - 593ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.4923 - accuracy: 0.7692 - val_loss: 0.4811 - val_accuracy: 0.7733 - 533ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.4779 - accuracy: 0.7740 - val_loss: 0.4653 - val_accuracy: 0.7771 - 509ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 0s - loss: 0.4597 - accuracy: 0.7810 - val_loss: 0.4714 - val_accuracy: 0.7801 - 497ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4552 - accuracy: 0.7830 - val_loss: 0.4539 - val_accuracy: 0.7889 - 546ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4553 - accuracy: 0.7844 - val_loss: 0.4614 - val_accuracy: 0.7831 - 528ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4510 - accuracy: 0.7835 - val_loss: 0.4524 - val_accuracy: 0.7829 - 540ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.4461 - val_accuracy: 0.7887 - 518ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4449 - accuracy: 0.7833 - val_loss: 0.4501 - val_accuracy: 0.7876 - 591ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4426 - accuracy: 0.7878 - val_loss: 0.4509 - val_accuracy: 0.7878 - 558ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4400 - accuracy: 0.7896 - val_loss: 0.4535 - val_accuracy: 0.7844 - 620ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4405 - accuracy: 0.7897 - val_loss: 0.4475 - val_accuracy: 0.7880 - 650ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4403 - accuracy: 0.7887 - val_loss: 0.4446 - val_accuracy: 0.7921 - 520ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4385 - accuracy: 0.7901 - val_loss: 0.4478 - val_accuracy: 0.7948 - 532ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4379 - accuracy: 0.7904 - val_loss: 0.4452 - val_accuracy: 0.7965 - 530ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4410 - accuracy: 0.7888 - val_loss: 0.4422 - val_accuracy: 0.7961 - 554ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4361 - accuracy: 0.7919 - val_loss: 0.4425 - val_accuracy: 0.7948 - 547ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4359 - accuracy: 0.7919 - val_loss: 0.4473 - val_accuracy: 0.7933 - 540ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4345 - accuracy: 0.7925 - val_loss: 0.4498 - val_accuracy: 0.7901 - 566ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4453 - val_accuracy: 0.7899 - 550ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4351 - accuracy: 0.7941 - val_loss: 0.4412 - val_accuracy: 0.7944 - 593ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4344 - accuracy: 0.7934 - val_loss: 0.4449 - val_accuracy: 0.7959 - 518ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4338 - accuracy: 0.7931 - val_loss: 0.4437 - val_accuracy: 0.7955 - 532ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4329 - accuracy: 0.7951 - val_loss: 0.4400 - val_accuracy: 0.7989 - 546ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4348 - accuracy: 0.7932 - val_loss: 0.4399 - val_accuracy: 0.7955 - 564ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4333 - accuracy: 0.7941 - val_loss: 0.4389 - val_accuracy: 0.7978 - 549ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 0s - loss: 0.4318 - accuracy: 0.7943 - val_loss: 0.4421 - val_accuracy: 0.7908 - 490ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4313 - accuracy: 0.7965 - val_loss: 0.4418 - val_accuracy: 0.7946 - 553ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.4408 - val_accuracy: 0.7968 - 510ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4304 - accuracy: 0.7950 - val_loss: 0.4424 - val_accuracy: 0.7940 - 521ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4304 - accuracy: 0.7950 - val_loss: 0.4445 - val_accuracy: 0.7929 - 532ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4310 - accuracy: 0.7957 - val_loss: 0.4429 - val_accuracy: 0.7919 - 569ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4314 - accuracy: 0.7953 - val_loss: 0.4403 - val_accuracy: 0.7965 - 530ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4309 - accuracy: 0.7950 - val_loss: 0.4394 - val_accuracy: 0.7974 - 518ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 0s - loss: 0.4293 - accuracy: 0.7957 - val_loss: 0.4421 - val_accuracy: 0.7946 - 494ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4311 - accuracy: 0.7966 - val_loss: 0.4401 - val_accuracy: 0.7970 - 519ms/epoch - 7ms/step\n",
      "Epoch 37: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 0.5811 - accuracy: 0.7275 - val_loss: 0.5309 - val_accuracy: 0.7646 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 0.5034 - accuracy: 0.7642 - val_loss: 0.4876 - val_accuracy: 0.7690 - 563ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.4754 - accuracy: 0.7751 - val_loss: 0.4752 - val_accuracy: 0.7761 - 518ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.4645 - accuracy: 0.7773 - val_loss: 0.4639 - val_accuracy: 0.7806 - 522ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4557 - accuracy: 0.7796 - val_loss: 0.4631 - val_accuracy: 0.7820 - 509ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4518 - accuracy: 0.7796 - val_loss: 0.4582 - val_accuracy: 0.7901 - 514ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 0s - loss: 0.4474 - accuracy: 0.7851 - val_loss: 0.4512 - val_accuracy: 0.7852 - 467ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 0s - loss: 0.4467 - accuracy: 0.7858 - val_loss: 0.4539 - val_accuracy: 0.7865 - 492ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4441 - accuracy: 0.7860 - val_loss: 0.4499 - val_accuracy: 0.7899 - 513ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4417 - accuracy: 0.7886 - val_loss: 0.4501 - val_accuracy: 0.7895 - 513ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4386 - accuracy: 0.7875 - val_loss: 0.4495 - val_accuracy: 0.7857 - 544ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4381 - accuracy: 0.7906 - val_loss: 0.4480 - val_accuracy: 0.7914 - 514ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4399 - accuracy: 0.7868 - val_loss: 0.4439 - val_accuracy: 0.7933 - 511ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4363 - accuracy: 0.7898 - val_loss: 0.4442 - val_accuracy: 0.7955 - 582ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4348 - accuracy: 0.7932 - val_loss: 0.4435 - val_accuracy: 0.8000 - 504ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 0s - loss: 0.4355 - accuracy: 0.7922 - val_loss: 0.4498 - val_accuracy: 0.7867 - 476ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4348 - accuracy: 0.7915 - val_loss: 0.4416 - val_accuracy: 0.7919 - 525ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4347 - accuracy: 0.7922 - val_loss: 0.4419 - val_accuracy: 0.7895 - 527ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4333 - accuracy: 0.7952 - val_loss: 0.4423 - val_accuracy: 0.7963 - 534ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4334 - accuracy: 0.7925 - val_loss: 0.4436 - val_accuracy: 0.7914 - 515ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4341 - accuracy: 0.7940 - val_loss: 0.4462 - val_accuracy: 0.7957 - 534ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4315 - accuracy: 0.7930 - val_loss: 0.4381 - val_accuracy: 0.7919 - 507ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4329 - accuracy: 0.7939 - val_loss: 0.4430 - val_accuracy: 0.7927 - 522ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4327 - accuracy: 0.7948 - val_loss: 0.4429 - val_accuracy: 0.7942 - 577ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 0s - loss: 0.4322 - accuracy: 0.7937 - val_loss: 0.4425 - val_accuracy: 0.7980 - 491ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4307 - accuracy: 0.7934 - val_loss: 0.4437 - val_accuracy: 0.7895 - 505ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4300 - accuracy: 0.7936 - val_loss: 0.4418 - val_accuracy: 0.7959 - 594ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4302 - accuracy: 0.7916 - val_loss: 0.4377 - val_accuracy: 0.7995 - 532ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4323 - accuracy: 0.7925 - val_loss: 0.4429 - val_accuracy: 0.7953 - 521ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4310 - accuracy: 0.7926 - val_loss: 0.4382 - val_accuracy: 0.7978 - 522ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4289 - accuracy: 0.7956 - val_loss: 0.4465 - val_accuracy: 0.7925 - 545ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4311 - accuracy: 0.7962 - val_loss: 0.4406 - val_accuracy: 0.7972 - 534ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4294 - accuracy: 0.7968 - val_loss: 0.4394 - val_accuracy: 0.7951 - 589ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 0s - loss: 0.4302 - accuracy: 0.7943 - val_loss: 0.4408 - val_accuracy: 0.7965 - 500ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4291 - accuracy: 0.7935 - val_loss: 0.4376 - val_accuracy: 0.7991 - 542ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4287 - accuracy: 0.7959 - val_loss: 0.4402 - val_accuracy: 0.7972 - 514ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4305 - accuracy: 0.7967 - val_loss: 0.4376 - val_accuracy: 0.7974 - 534ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 0s - loss: 0.4285 - accuracy: 0.7956 - val_loss: 0.4405 - val_accuracy: 0.7970 - 495ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4301 - accuracy: 0.7959 - val_loss: 0.4371 - val_accuracy: 0.7997 - 540ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4278 - accuracy: 0.7988 - val_loss: 0.4367 - val_accuracy: 0.7985 - 507ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4299 - accuracy: 0.7939 - val_loss: 0.4390 - val_accuracy: 0.7951 - 549ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 1s - loss: 0.4288 - accuracy: 0.7950 - val_loss: 0.4406 - val_accuracy: 0.7929 - 545ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4312 - accuracy: 0.7977 - val_loss: 0.4381 - val_accuracy: 0.7987 - 522ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "74/74 - 1s - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.4380 - val_accuracy: 0.8002 - 537ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "74/74 - 1s - loss: 0.4279 - accuracy: 0.7942 - val_loss: 0.4379 - val_accuracy: 0.8017 - 573ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "74/74 - 1s - loss: 0.4257 - accuracy: 0.7991 - val_loss: 0.4366 - val_accuracy: 0.7983 - 511ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "74/74 - 1s - loss: 0.4281 - accuracy: 0.7958 - val_loss: 0.4361 - val_accuracy: 0.7963 - 531ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "74/74 - 1s - loss: 0.4293 - accuracy: 0.7973 - val_loss: 0.4419 - val_accuracy: 0.7942 - 522ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "74/74 - 1s - loss: 0.4283 - accuracy: 0.7971 - val_loss: 0.4421 - val_accuracy: 0.7985 - 573ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "74/74 - 1s - loss: 0.4278 - accuracy: 0.7967 - val_loss: 0.4384 - val_accuracy: 0.7972 - 537ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "74/74 - 1s - loss: 0.4282 - accuracy: 0.7973 - val_loss: 0.4374 - val_accuracy: 0.7980 - 579ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "74/74 - 1s - loss: 0.4279 - accuracy: 0.7964 - val_loss: 0.4320 - val_accuracy: 0.7974 - 532ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "74/74 - 1s - loss: 0.4278 - accuracy: 0.7972 - val_loss: 0.4386 - val_accuracy: 0.8021 - 525ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "74/74 - 1s - loss: 0.4267 - accuracy: 0.7987 - val_loss: 0.4408 - val_accuracy: 0.7989 - 560ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "74/74 - 1s - loss: 0.4284 - accuracy: 0.7967 - val_loss: 0.4385 - val_accuracy: 0.7970 - 553ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "74/74 - 1s - loss: 0.4271 - accuracy: 0.8001 - val_loss: 0.4391 - val_accuracy: 0.7974 - 535ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "74/74 - 1s - loss: 0.4278 - accuracy: 0.7976 - val_loss: 0.4401 - val_accuracy: 0.8008 - 516ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "74/74 - 0s - loss: 0.4281 - accuracy: 0.7978 - val_loss: 0.4391 - val_accuracy: 0.7951 - 486ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "74/74 - 1s - loss: 0.4265 - accuracy: 0.7989 - val_loss: 0.4401 - val_accuracy: 0.8019 - 540ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "74/74 - 1s - loss: 0.4266 - accuracy: 0.7959 - val_loss: 0.4375 - val_accuracy: 0.7987 - 519ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "74/74 - 1s - loss: 0.4261 - accuracy: 0.7966 - val_loss: 0.4406 - val_accuracy: 0.8017 - 533ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "74/74 - 0s - loss: 0.4267 - accuracy: 0.7976 - val_loss: 0.4365 - val_accuracy: 0.7976 - 496ms/epoch - 7ms/step\n",
      "Epoch 62: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 0.5727 - accuracy: 0.7369 - val_loss: 0.5172 - val_accuracy: 0.7639 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 0.5027 - accuracy: 0.7633 - val_loss: 0.4907 - val_accuracy: 0.7716 - 520ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 0s - loss: 0.4730 - accuracy: 0.7679 - val_loss: 0.4763 - val_accuracy: 0.7710 - 479ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.4607 - accuracy: 0.7767 - val_loss: 0.4643 - val_accuracy: 0.7791 - 516ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4506 - accuracy: 0.7818 - val_loss: 0.4603 - val_accuracy: 0.7859 - 527ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4480 - accuracy: 0.7845 - val_loss: 0.4588 - val_accuracy: 0.7844 - 547ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 0s - loss: 0.4486 - accuracy: 0.7832 - val_loss: 0.4601 - val_accuracy: 0.7872 - 482ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4446 - accuracy: 0.7864 - val_loss: 0.4591 - val_accuracy: 0.7829 - 579ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4425 - accuracy: 0.7860 - val_loss: 0.4512 - val_accuracy: 0.7831 - 539ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4435 - accuracy: 0.7856 - val_loss: 0.4509 - val_accuracy: 0.7908 - 547ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4447 - accuracy: 0.7856 - val_loss: 0.4536 - val_accuracy: 0.7884 - 546ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4379 - accuracy: 0.7891 - val_loss: 0.4515 - val_accuracy: 0.7887 - 562ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4400 - accuracy: 0.7883 - val_loss: 0.4483 - val_accuracy: 0.7833 - 620ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4383 - accuracy: 0.7866 - val_loss: 0.4509 - val_accuracy: 0.7887 - 617ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4371 - accuracy: 0.7870 - val_loss: 0.4437 - val_accuracy: 0.7893 - 585ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4384 - accuracy: 0.7886 - val_loss: 0.4490 - val_accuracy: 0.7906 - 604ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4378 - accuracy: 0.7909 - val_loss: 0.4444 - val_accuracy: 0.7944 - 585ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4351 - accuracy: 0.7915 - val_loss: 0.4490 - val_accuracy: 0.7919 - 601ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4340 - accuracy: 0.7922 - val_loss: 0.4476 - val_accuracy: 0.7887 - 536ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4335 - accuracy: 0.7915 - val_loss: 0.4414 - val_accuracy: 0.7910 - 558ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4316 - accuracy: 0.7928 - val_loss: 0.4437 - val_accuracy: 0.7959 - 646ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4319 - accuracy: 0.7970 - val_loss: 0.4400 - val_accuracy: 0.8010 - 550ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 0s - loss: 0.4336 - accuracy: 0.7931 - val_loss: 0.4434 - val_accuracy: 0.7933 - 495ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 0s - loss: 0.4336 - accuracy: 0.7928 - val_loss: 0.4469 - val_accuracy: 0.7985 - 478ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4324 - accuracy: 0.7938 - val_loss: 0.4414 - val_accuracy: 0.7961 - 541ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4316 - accuracy: 0.7938 - val_loss: 0.4392 - val_accuracy: 0.7957 - 523ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4307 - accuracy: 0.7950 - val_loss: 0.4460 - val_accuracy: 0.7993 - 574ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4300 - accuracy: 0.7949 - val_loss: 0.4387 - val_accuracy: 0.7968 - 570ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 0s - loss: 0.4296 - accuracy: 0.7931 - val_loss: 0.4405 - val_accuracy: 0.7957 - 476ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4291 - accuracy: 0.7937 - val_loss: 0.4406 - val_accuracy: 0.7959 - 508ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4303 - accuracy: 0.7936 - val_loss: 0.4416 - val_accuracy: 0.8017 - 518ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4310 - accuracy: 0.7933 - val_loss: 0.4401 - val_accuracy: 0.7944 - 513ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4319 - accuracy: 0.7943 - val_loss: 0.4410 - val_accuracy: 0.7968 - 539ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4286 - accuracy: 0.7944 - val_loss: 0.4421 - val_accuracy: 0.8015 - 531ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 0s - loss: 0.4302 - accuracy: 0.7946 - val_loss: 0.4373 - val_accuracy: 0.8051 - 491ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4278 - accuracy: 0.7966 - val_loss: 0.4389 - val_accuracy: 0.7997 - 553ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 0s - loss: 0.4294 - accuracy: 0.7949 - val_loss: 0.4404 - val_accuracy: 0.7961 - 467ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4291 - accuracy: 0.7981 - val_loss: 0.4437 - val_accuracy: 0.7972 - 507ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4290 - accuracy: 0.7961 - val_loss: 0.4423 - val_accuracy: 0.7965 - 614ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4296 - accuracy: 0.7949 - val_loss: 0.4409 - val_accuracy: 0.7976 - 521ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4294 - accuracy: 0.7975 - val_loss: 0.4409 - val_accuracy: 0.7985 - 517ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 1s - loss: 0.4295 - accuracy: 0.7956 - val_loss: 0.4432 - val_accuracy: 0.7968 - 507ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4303 - accuracy: 0.7937 - val_loss: 0.4419 - val_accuracy: 0.7965 - 501ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "74/74 - 1s - loss: 0.4295 - accuracy: 0.7950 - val_loss: 0.4396 - val_accuracy: 0.8021 - 544ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "74/74 - 0s - loss: 0.4276 - accuracy: 0.7964 - val_loss: 0.4398 - val_accuracy: 0.7997 - 477ms/epoch - 6ms/step\n",
      "Epoch 45: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 0.5803 - accuracy: 0.7420 - val_loss: 0.5358 - val_accuracy: 0.7637 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 0.5156 - accuracy: 0.7623 - val_loss: 0.4906 - val_accuracy: 0.7714 - 528ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 0s - loss: 0.4797 - accuracy: 0.7717 - val_loss: 0.4686 - val_accuracy: 0.7793 - 470ms/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.4648 - accuracy: 0.7800 - val_loss: 0.4657 - val_accuracy: 0.7857 - 535ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4559 - accuracy: 0.7797 - val_loss: 0.4561 - val_accuracy: 0.7818 - 503ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4507 - accuracy: 0.7819 - val_loss: 0.4511 - val_accuracy: 0.7867 - 545ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4435 - accuracy: 0.7869 - val_loss: 0.4490 - val_accuracy: 0.7872 - 524ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 0s - loss: 0.4457 - accuracy: 0.7860 - val_loss: 0.4483 - val_accuracy: 0.7857 - 492ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 0s - loss: 0.4410 - accuracy: 0.7875 - val_loss: 0.4527 - val_accuracy: 0.7891 - 485ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4385 - accuracy: 0.7866 - val_loss: 0.4496 - val_accuracy: 0.7872 - 585ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4424 - accuracy: 0.7855 - val_loss: 0.4497 - val_accuracy: 0.7887 - 578ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4382 - accuracy: 0.7882 - val_loss: 0.4484 - val_accuracy: 0.7910 - 577ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4357 - accuracy: 0.7930 - val_loss: 0.4439 - val_accuracy: 0.7906 - 581ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4380 - accuracy: 0.7909 - val_loss: 0.4428 - val_accuracy: 0.7965 - 535ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 0s - loss: 0.4371 - accuracy: 0.7918 - val_loss: 0.4445 - val_accuracy: 0.7897 - 472ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4366 - accuracy: 0.7906 - val_loss: 0.4447 - val_accuracy: 0.7951 - 507ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4358 - accuracy: 0.7906 - val_loss: 0.4410 - val_accuracy: 0.7970 - 541ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4340 - accuracy: 0.7952 - val_loss: 0.4465 - val_accuracy: 0.7904 - 530ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4334 - accuracy: 0.7924 - val_loss: 0.4402 - val_accuracy: 0.7938 - 535ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4344 - accuracy: 0.7947 - val_loss: 0.4411 - val_accuracy: 0.7936 - 508ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4347 - accuracy: 0.7942 - val_loss: 0.4382 - val_accuracy: 0.7995 - 517ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4311 - accuracy: 0.7931 - val_loss: 0.4427 - val_accuracy: 0.7946 - 558ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4336 - accuracy: 0.7924 - val_loss: 0.4437 - val_accuracy: 0.7965 - 610ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4326 - accuracy: 0.7943 - val_loss: 0.4400 - val_accuracy: 0.7942 - 550ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4319 - accuracy: 0.7960 - val_loss: 0.4416 - val_accuracy: 0.7951 - 580ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4331 - accuracy: 0.7962 - val_loss: 0.4404 - val_accuracy: 0.7970 - 536ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4329 - accuracy: 0.7938 - val_loss: 0.4411 - val_accuracy: 0.7965 - 530ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4332 - accuracy: 0.7934 - val_loss: 0.4386 - val_accuracy: 0.7961 - 584ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4314 - accuracy: 0.7928 - val_loss: 0.4416 - val_accuracy: 0.7991 - 523ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4303 - accuracy: 0.7964 - val_loss: 0.4364 - val_accuracy: 0.8021 - 567ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4310 - accuracy: 0.7954 - val_loss: 0.4412 - val_accuracy: 0.7989 - 547ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4302 - accuracy: 0.7956 - val_loss: 0.4372 - val_accuracy: 0.8000 - 551ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4300 - accuracy: 0.7966 - val_loss: 0.4389 - val_accuracy: 0.7970 - 582ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4293 - accuracy: 0.7948 - val_loss: 0.4371 - val_accuracy: 0.7978 - 549ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4296 - accuracy: 0.7964 - val_loss: 0.4398 - val_accuracy: 0.7997 - 529ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 0s - loss: 0.4295 - accuracy: 0.7970 - val_loss: 0.4387 - val_accuracy: 0.7989 - 493ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4299 - accuracy: 0.7988 - val_loss: 0.4388 - val_accuracy: 0.8000 - 533ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 1s - loss: 0.4296 - accuracy: 0.7946 - val_loss: 0.4455 - val_accuracy: 0.7955 - 583ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4284 - accuracy: 0.7963 - val_loss: 0.4446 - val_accuracy: 0.7946 - 616ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4289 - accuracy: 0.7968 - val_loss: 0.4372 - val_accuracy: 0.7993 - 552ms/epoch - 7ms/step\n",
      "Epoch 40: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 0.6163 - accuracy: 0.6785 - val_loss: 0.5306 - val_accuracy: 0.7633 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 0.5123 - accuracy: 0.7651 - val_loss: 0.4888 - val_accuracy: 0.7754 - 513ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.4811 - accuracy: 0.7721 - val_loss: 0.4793 - val_accuracy: 0.7823 - 503ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 0s - loss: 0.4662 - accuracy: 0.7799 - val_loss: 0.4651 - val_accuracy: 0.7808 - 473ms/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4570 - accuracy: 0.7793 - val_loss: 0.4563 - val_accuracy: 0.7835 - 516ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 0s - loss: 0.4513 - accuracy: 0.7850 - val_loss: 0.4593 - val_accuracy: 0.7818 - 472ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4473 - accuracy: 0.7861 - val_loss: 0.4479 - val_accuracy: 0.7925 - 510ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 1s - loss: 0.4456 - accuracy: 0.7852 - val_loss: 0.4557 - val_accuracy: 0.7933 - 531ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 0s - loss: 0.4435 - accuracy: 0.7879 - val_loss: 0.4505 - val_accuracy: 0.7908 - 494ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4398 - accuracy: 0.7855 - val_loss: 0.4489 - val_accuracy: 0.7946 - 531ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 1s - loss: 0.4404 - accuracy: 0.7872 - val_loss: 0.4498 - val_accuracy: 0.7895 - 541ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4385 - accuracy: 0.7884 - val_loss: 0.4468 - val_accuracy: 0.7912 - 573ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4356 - accuracy: 0.7904 - val_loss: 0.4423 - val_accuracy: 0.7957 - 534ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4384 - accuracy: 0.7916 - val_loss: 0.4419 - val_accuracy: 0.7959 - 503ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4372 - accuracy: 0.7910 - val_loss: 0.4489 - val_accuracy: 0.7933 - 512ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 1s - loss: 0.4340 - accuracy: 0.7918 - val_loss: 0.4431 - val_accuracy: 0.8002 - 505ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 1s - loss: 0.4356 - accuracy: 0.7927 - val_loss: 0.4431 - val_accuracy: 0.7991 - 556ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4339 - accuracy: 0.7927 - val_loss: 0.4440 - val_accuracy: 0.7985 - 505ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4340 - accuracy: 0.7941 - val_loss: 0.4497 - val_accuracy: 0.7948 - 504ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4338 - accuracy: 0.7942 - val_loss: 0.4403 - val_accuracy: 0.7959 - 534ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4319 - accuracy: 0.7950 - val_loss: 0.4434 - val_accuracy: 0.7968 - 596ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4335 - accuracy: 0.7935 - val_loss: 0.4387 - val_accuracy: 0.7976 - 632ms/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4329 - accuracy: 0.7951 - val_loss: 0.4411 - val_accuracy: 0.7931 - 551ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4324 - accuracy: 0.7963 - val_loss: 0.4416 - val_accuracy: 0.7968 - 565ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 1s - loss: 0.4331 - accuracy: 0.7936 - val_loss: 0.4429 - val_accuracy: 0.7908 - 602ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 1s - loss: 0.4327 - accuracy: 0.7941 - val_loss: 0.4380 - val_accuracy: 0.7951 - 586ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4308 - accuracy: 0.7956 - val_loss: 0.4403 - val_accuracy: 0.7940 - 579ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4293 - accuracy: 0.7964 - val_loss: 0.4401 - val_accuracy: 0.7957 - 568ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4301 - accuracy: 0.7958 - val_loss: 0.4455 - val_accuracy: 0.7948 - 604ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4305 - accuracy: 0.7963 - val_loss: 0.4418 - val_accuracy: 0.7925 - 560ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4315 - accuracy: 0.7947 - val_loss: 0.4393 - val_accuracy: 0.7980 - 576ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "74/74 - 1s - loss: 0.4312 - accuracy: 0.7938 - val_loss: 0.4390 - val_accuracy: 0.7974 - 532ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "74/74 - 1s - loss: 0.4301 - accuracy: 0.7928 - val_loss: 0.4385 - val_accuracy: 0.7983 - 500ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "74/74 - 1s - loss: 0.4294 - accuracy: 0.7926 - val_loss: 0.4415 - val_accuracy: 0.7976 - 568ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "74/74 - 1s - loss: 0.4300 - accuracy: 0.7955 - val_loss: 0.4385 - val_accuracy: 0.7970 - 669ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "74/74 - 1s - loss: 0.4314 - accuracy: 0.7963 - val_loss: 0.4360 - val_accuracy: 0.7974 - 576ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "74/74 - 1s - loss: 0.4305 - accuracy: 0.7957 - val_loss: 0.4370 - val_accuracy: 0.7959 - 524ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "74/74 - 0s - loss: 0.4277 - accuracy: 0.7990 - val_loss: 0.4419 - val_accuracy: 0.7965 - 484ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "74/74 - 1s - loss: 0.4299 - accuracy: 0.7946 - val_loss: 0.4379 - val_accuracy: 0.8021 - 532ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "74/74 - 1s - loss: 0.4286 - accuracy: 0.7954 - val_loss: 0.4409 - val_accuracy: 0.7965 - 516ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "74/74 - 1s - loss: 0.4280 - accuracy: 0.7976 - val_loss: 0.4434 - val_accuracy: 0.7983 - 518ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "74/74 - 1s - loss: 0.4283 - accuracy: 0.7982 - val_loss: 0.4341 - val_accuracy: 0.7972 - 563ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "74/74 - 1s - loss: 0.4294 - accuracy: 0.7960 - val_loss: 0.4404 - val_accuracy: 0.7942 - 534ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "74/74 - 1s - loss: 0.4280 - accuracy: 0.7972 - val_loss: 0.4425 - val_accuracy: 0.7953 - 559ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "74/74 - 1s - loss: 0.4265 - accuracy: 0.7965 - val_loss: 0.4391 - val_accuracy: 0.7983 - 528ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "74/74 - 1s - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.4370 - val_accuracy: 0.8002 - 513ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "74/74 - 1s - loss: 0.4286 - accuracy: 0.7956 - val_loss: 0.4375 - val_accuracy: 0.7963 - 529ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "74/74 - 1s - loss: 0.4279 - accuracy: 0.7963 - val_loss: 0.4379 - val_accuracy: 0.8000 - 547ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "74/74 - 1s - loss: 0.4275 - accuracy: 0.7965 - val_loss: 0.4369 - val_accuracy: 0.7968 - 574ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "74/74 - 1s - loss: 0.4280 - accuracy: 0.7947 - val_loss: 0.4401 - val_accuracy: 0.7970 - 512ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "74/74 - 1s - loss: 0.4265 - accuracy: 0.7995 - val_loss: 0.4392 - val_accuracy: 0.7989 - 517ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "74/74 - 1s - loss: 0.4279 - accuracy: 0.7984 - val_loss: 0.4397 - val_accuracy: 0.7985 - 527ms/epoch - 7ms/step\n",
      "Epoch 52: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "74/74 - 2s - loss: 0.6183 - accuracy: 0.6688 - val_loss: 0.5223 - val_accuracy: 0.7648 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "74/74 - 1s - loss: 0.5000 - accuracy: 0.7673 - val_loss: 0.4873 - val_accuracy: 0.7684 - 549ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "74/74 - 1s - loss: 0.4760 - accuracy: 0.7743 - val_loss: 0.4762 - val_accuracy: 0.7769 - 520ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "74/74 - 1s - loss: 0.4641 - accuracy: 0.7756 - val_loss: 0.4612 - val_accuracy: 0.7855 - 555ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "74/74 - 1s - loss: 0.4561 - accuracy: 0.7811 - val_loss: 0.4677 - val_accuracy: 0.7833 - 517ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "74/74 - 1s - loss: 0.4530 - accuracy: 0.7800 - val_loss: 0.4620 - val_accuracy: 0.7887 - 556ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "74/74 - 1s - loss: 0.4483 - accuracy: 0.7836 - val_loss: 0.4563 - val_accuracy: 0.7891 - 519ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "74/74 - 0s - loss: 0.4449 - accuracy: 0.7864 - val_loss: 0.4501 - val_accuracy: 0.7867 - 488ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "74/74 - 1s - loss: 0.4432 - accuracy: 0.7859 - val_loss: 0.4528 - val_accuracy: 0.7867 - 530ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "74/74 - 1s - loss: 0.4441 - accuracy: 0.7876 - val_loss: 0.4454 - val_accuracy: 0.7850 - 521ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "74/74 - 0s - loss: 0.4393 - accuracy: 0.7874 - val_loss: 0.4520 - val_accuracy: 0.7893 - 490ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "74/74 - 1s - loss: 0.4417 - accuracy: 0.7883 - val_loss: 0.4495 - val_accuracy: 0.7891 - 555ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "74/74 - 1s - loss: 0.4366 - accuracy: 0.7917 - val_loss: 0.4462 - val_accuracy: 0.7923 - 515ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "74/74 - 1s - loss: 0.4377 - accuracy: 0.7914 - val_loss: 0.4479 - val_accuracy: 0.7944 - 516ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "74/74 - 1s - loss: 0.4382 - accuracy: 0.7865 - val_loss: 0.4469 - val_accuracy: 0.7904 - 533ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "74/74 - 0s - loss: 0.4370 - accuracy: 0.7913 - val_loss: 0.4456 - val_accuracy: 0.7933 - 499ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "74/74 - 0s - loss: 0.4352 - accuracy: 0.7932 - val_loss: 0.4458 - val_accuracy: 0.7923 - 483ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "74/74 - 1s - loss: 0.4345 - accuracy: 0.7928 - val_loss: 0.4431 - val_accuracy: 0.7978 - 517ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "74/74 - 1s - loss: 0.4373 - accuracy: 0.7911 - val_loss: 0.4463 - val_accuracy: 0.7955 - 554ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "74/74 - 1s - loss: 0.4336 - accuracy: 0.7915 - val_loss: 0.4459 - val_accuracy: 0.7968 - 508ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "74/74 - 1s - loss: 0.4350 - accuracy: 0.7933 - val_loss: 0.4397 - val_accuracy: 0.8004 - 523ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "74/74 - 1s - loss: 0.4345 - accuracy: 0.7950 - val_loss: 0.4405 - val_accuracy: 0.7944 - 523ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "74/74 - 1s - loss: 0.4358 - accuracy: 0.7936 - val_loss: 0.4412 - val_accuracy: 0.7978 - 517ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "74/74 - 1s - loss: 0.4323 - accuracy: 0.7972 - val_loss: 0.4416 - val_accuracy: 0.7968 - 528ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "74/74 - 0s - loss: 0.4330 - accuracy: 0.7949 - val_loss: 0.4453 - val_accuracy: 0.7929 - 468ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "74/74 - 0s - loss: 0.4321 - accuracy: 0.7944 - val_loss: 0.4413 - val_accuracy: 0.7953 - 483ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "74/74 - 1s - loss: 0.4327 - accuracy: 0.7939 - val_loss: 0.4431 - val_accuracy: 0.7942 - 566ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "74/74 - 1s - loss: 0.4318 - accuracy: 0.7952 - val_loss: 0.4428 - val_accuracy: 0.7963 - 550ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "74/74 - 1s - loss: 0.4336 - accuracy: 0.7914 - val_loss: 0.4408 - val_accuracy: 0.7974 - 526ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "74/74 - 1s - loss: 0.4308 - accuracy: 0.7966 - val_loss: 0.4415 - val_accuracy: 0.7974 - 502ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "74/74 - 1s - loss: 0.4315 - accuracy: 0.7960 - val_loss: 0.4447 - val_accuracy: 0.7968 - 505ms/epoch - 7ms/step\n",
      "Epoch 31: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.38957228566957974\n",
      "epi entropy:  0.3716298815172853\n",
      "\n",
      "dataset size:  0.7\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 0.5703 - accuracy: 0.7342 - val_loss: 0.5180 - val_accuracy: 0.7622 - 2s/epoch - 28ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.4943 - accuracy: 0.7693 - val_loss: 0.4718 - val_accuracy: 0.7755 - 680ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4659 - accuracy: 0.7798 - val_loss: 0.4677 - val_accuracy: 0.7801 - 609ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4594 - accuracy: 0.7823 - val_loss: 0.4608 - val_accuracy: 0.7783 - 639ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4500 - accuracy: 0.7846 - val_loss: 0.4538 - val_accuracy: 0.7810 - 590ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4484 - accuracy: 0.7874 - val_loss: 0.4494 - val_accuracy: 0.7850 - 562ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4446 - accuracy: 0.7906 - val_loss: 0.4415 - val_accuracy: 0.7834 - 632ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4406 - accuracy: 0.7926 - val_loss: 0.4417 - val_accuracy: 0.7929 - 594ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4386 - accuracy: 0.7925 - val_loss: 0.4464 - val_accuracy: 0.7889 - 588ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4384 - accuracy: 0.7941 - val_loss: 0.4407 - val_accuracy: 0.7964 - 618ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4363 - accuracy: 0.7930 - val_loss: 0.4401 - val_accuracy: 0.7938 - 613ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4361 - accuracy: 0.7947 - val_loss: 0.4382 - val_accuracy: 0.7935 - 654ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.4404 - val_accuracy: 0.7920 - 625ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4332 - accuracy: 0.7978 - val_loss: 0.4419 - val_accuracy: 0.7927 - 571ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4319 - accuracy: 0.7963 - val_loss: 0.4400 - val_accuracy: 0.7944 - 596ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4307 - accuracy: 0.7961 - val_loss: 0.4351 - val_accuracy: 0.7927 - 603ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4320 - accuracy: 0.7996 - val_loss: 0.4340 - val_accuracy: 0.7931 - 625ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4313 - accuracy: 0.7997 - val_loss: 0.4365 - val_accuracy: 0.7936 - 656ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4318 - accuracy: 0.7984 - val_loss: 0.4391 - val_accuracy: 0.7935 - 632ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4296 - accuracy: 0.7984 - val_loss: 0.4389 - val_accuracy: 0.7918 - 619ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4292 - accuracy: 0.7996 - val_loss: 0.4333 - val_accuracy: 0.7975 - 663ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4303 - accuracy: 0.7994 - val_loss: 0.4362 - val_accuracy: 0.7964 - 592ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4310 - accuracy: 0.8017 - val_loss: 0.4350 - val_accuracy: 0.7962 - 617ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4287 - accuracy: 0.8004 - val_loss: 0.4359 - val_accuracy: 0.7927 - 622ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.4343 - val_accuracy: 0.7978 - 609ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4296 - accuracy: 0.8009 - val_loss: 0.4357 - val_accuracy: 0.7966 - 639ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4288 - accuracy: 0.8028 - val_loss: 0.4331 - val_accuracy: 0.7960 - 662ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4280 - accuracy: 0.8019 - val_loss: 0.4356 - val_accuracy: 0.7949 - 611ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4278 - accuracy: 0.8005 - val_loss: 0.4360 - val_accuracy: 0.7955 - 656ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4293 - accuracy: 0.7995 - val_loss: 0.4356 - val_accuracy: 0.7969 - 604ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4269 - accuracy: 0.8014 - val_loss: 0.4361 - val_accuracy: 0.8004 - 594ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4261 - accuracy: 0.8011 - val_loss: 0.4333 - val_accuracy: 0.7933 - 673ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4275 - accuracy: 0.8007 - val_loss: 0.4335 - val_accuracy: 0.7997 - 656ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.7996 - val_loss: 0.4354 - val_accuracy: 0.7938 - 665ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4271 - accuracy: 0.8000 - val_loss: 0.4322 - val_accuracy: 0.7980 - 653ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4255 - accuracy: 0.8012 - val_loss: 0.4353 - val_accuracy: 0.7938 - 609ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4259 - accuracy: 0.8014 - val_loss: 0.4352 - val_accuracy: 0.7935 - 696ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4266 - accuracy: 0.8009 - val_loss: 0.4343 - val_accuracy: 0.8002 - 637ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4267 - accuracy: 0.8031 - val_loss: 0.4339 - val_accuracy: 0.7999 - 730ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4264 - accuracy: 0.8017 - val_loss: 0.4322 - val_accuracy: 0.7997 - 673ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4252 - accuracy: 0.8013 - val_loss: 0.4336 - val_accuracy: 0.7955 - 639ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4254 - accuracy: 0.8023 - val_loss: 0.4313 - val_accuracy: 0.7975 - 647ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4268 - accuracy: 0.7999 - val_loss: 0.4311 - val_accuracy: 0.7997 - 727ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4259 - accuracy: 0.8036 - val_loss: 0.4336 - val_accuracy: 0.7964 - 748ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4268 - accuracy: 0.8020 - val_loss: 0.4333 - val_accuracy: 0.7953 - 710ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "86/86 - 1s - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.4309 - val_accuracy: 0.7946 - 664ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "86/86 - 1s - loss: 0.4250 - accuracy: 0.8026 - val_loss: 0.4359 - val_accuracy: 0.7958 - 697ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "86/86 - 1s - loss: 0.4253 - accuracy: 0.8011 - val_loss: 0.4317 - val_accuracy: 0.7982 - 703ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "86/86 - 1s - loss: 0.4247 - accuracy: 0.8026 - val_loss: 0.4338 - val_accuracy: 0.7962 - 699ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "86/86 - 1s - loss: 0.4240 - accuracy: 0.7992 - val_loss: 0.4347 - val_accuracy: 0.7947 - 663ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "86/86 - 1s - loss: 0.4238 - accuracy: 0.8020 - val_loss: 0.4303 - val_accuracy: 0.8000 - 633ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "86/86 - 1s - loss: 0.4236 - accuracy: 0.8019 - val_loss: 0.4352 - val_accuracy: 0.7975 - 704ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "86/86 - 1s - loss: 0.4251 - accuracy: 0.8011 - val_loss: 0.4302 - val_accuracy: 0.7953 - 609ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "86/86 - 1s - loss: 0.4244 - accuracy: 0.8016 - val_loss: 0.4319 - val_accuracy: 0.7988 - 609ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "86/86 - 1s - loss: 0.4250 - accuracy: 0.8014 - val_loss: 0.4304 - val_accuracy: 0.7997 - 661ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "86/86 - 1s - loss: 0.4233 - accuracy: 0.8015 - val_loss: 0.4310 - val_accuracy: 0.7947 - 615ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "86/86 - 1s - loss: 0.4255 - accuracy: 0.8029 - val_loss: 0.4318 - val_accuracy: 0.7942 - 607ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "86/86 - 1s - loss: 0.4247 - accuracy: 0.8006 - val_loss: 0.4303 - val_accuracy: 0.7980 - 610ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "86/86 - 1s - loss: 0.4259 - accuracy: 0.8001 - val_loss: 0.4329 - val_accuracy: 0.7967 - 615ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "86/86 - 1s - loss: 0.4246 - accuracy: 0.8035 - val_loss: 0.4317 - val_accuracy: 0.8008 - 591ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "86/86 - 1s - loss: 0.4251 - accuracy: 0.8014 - val_loss: 0.4321 - val_accuracy: 0.7975 - 602ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "86/86 - 1s - loss: 0.4237 - accuracy: 0.8018 - val_loss: 0.4347 - val_accuracy: 0.7940 - 606ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "86/86 - 1s - loss: 0.4255 - accuracy: 0.8009 - val_loss: 0.4326 - val_accuracy: 0.7973 - 656ms/epoch - 8ms/step\n",
      "Epoch 63: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "86/86 - 3s - loss: 0.5858 - accuracy: 0.7104 - val_loss: 0.5252 - val_accuracy: 0.7615 - 3s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.5012 - accuracy: 0.7608 - val_loss: 0.4781 - val_accuracy: 0.7646 - 696ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4696 - accuracy: 0.7686 - val_loss: 0.4678 - val_accuracy: 0.7691 - 623ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4567 - accuracy: 0.7808 - val_loss: 0.4562 - val_accuracy: 0.7850 - 615ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4511 - accuracy: 0.7846 - val_loss: 0.4425 - val_accuracy: 0.7849 - 651ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4433 - accuracy: 0.7907 - val_loss: 0.4419 - val_accuracy: 0.7865 - 651ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4390 - accuracy: 0.7952 - val_loss: 0.4448 - val_accuracy: 0.7878 - 665ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4349 - accuracy: 0.7971 - val_loss: 0.4418 - val_accuracy: 0.7953 - 639ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4364 - accuracy: 0.7944 - val_loss: 0.4422 - val_accuracy: 0.7944 - 640ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4355 - accuracy: 0.8003 - val_loss: 0.4408 - val_accuracy: 0.7924 - 657ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4343 - accuracy: 0.7961 - val_loss: 0.4397 - val_accuracy: 0.7918 - 622ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4324 - accuracy: 0.7998 - val_loss: 0.4411 - val_accuracy: 0.7949 - 699ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4340 - accuracy: 0.7993 - val_loss: 0.4412 - val_accuracy: 0.7964 - 625ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4328 - accuracy: 0.8005 - val_loss: 0.4357 - val_accuracy: 0.7969 - 647ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4341 - accuracy: 0.8003 - val_loss: 0.4398 - val_accuracy: 0.7991 - 635ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4309 - accuracy: 0.8022 - val_loss: 0.4351 - val_accuracy: 0.7955 - 868ms/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4324 - accuracy: 0.8000 - val_loss: 0.4354 - val_accuracy: 0.7967 - 654ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4309 - accuracy: 0.8011 - val_loss: 0.4363 - val_accuracy: 0.8000 - 633ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4311 - accuracy: 0.7994 - val_loss: 0.4360 - val_accuracy: 0.7973 - 676ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4314 - accuracy: 0.8013 - val_loss: 0.4368 - val_accuracy: 0.7962 - 656ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4300 - accuracy: 0.8024 - val_loss: 0.4378 - val_accuracy: 0.7955 - 628ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4315 - accuracy: 0.8000 - val_loss: 0.4347 - val_accuracy: 0.7929 - 624ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4297 - accuracy: 0.8000 - val_loss: 0.4380 - val_accuracy: 0.7969 - 647ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4295 - accuracy: 0.7999 - val_loss: 0.4355 - val_accuracy: 0.7956 - 696ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.4331 - val_accuracy: 0.8008 - 686ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4298 - accuracy: 0.8002 - val_loss: 0.4336 - val_accuracy: 0.7967 - 660ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4284 - accuracy: 0.8012 - val_loss: 0.4338 - val_accuracy: 0.7969 - 752ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4300 - accuracy: 0.8013 - val_loss: 0.4343 - val_accuracy: 0.7969 - 680ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4271 - accuracy: 0.8010 - val_loss: 0.4362 - val_accuracy: 0.7988 - 664ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4282 - accuracy: 0.8018 - val_loss: 0.4354 - val_accuracy: 0.7958 - 692ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4282 - accuracy: 0.8018 - val_loss: 0.4366 - val_accuracy: 0.7995 - 655ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4293 - accuracy: 0.8017 - val_loss: 0.4358 - val_accuracy: 0.7969 - 629ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.8013 - val_loss: 0.4336 - val_accuracy: 0.7991 - 634ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4277 - accuracy: 0.8017 - val_loss: 0.4363 - val_accuracy: 0.7995 - 675ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4273 - accuracy: 0.8037 - val_loss: 0.4347 - val_accuracy: 0.7978 - 604ms/epoch - 7ms/step\n",
      "Epoch 35: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "86/86 - 3s - loss: 0.5557 - accuracy: 0.7458 - val_loss: 0.5030 - val_accuracy: 0.7653 - 3s/epoch - 30ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.4878 - accuracy: 0.7686 - val_loss: 0.4724 - val_accuracy: 0.7737 - 686ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4668 - accuracy: 0.7769 - val_loss: 0.4534 - val_accuracy: 0.7840 - 706ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4565 - accuracy: 0.7818 - val_loss: 0.4560 - val_accuracy: 0.7814 - 756ms/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4527 - accuracy: 0.7853 - val_loss: 0.4499 - val_accuracy: 0.7829 - 627ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4450 - accuracy: 0.7862 - val_loss: 0.4485 - val_accuracy: 0.7849 - 704ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4437 - accuracy: 0.7912 - val_loss: 0.4426 - val_accuracy: 0.7898 - 604ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4423 - accuracy: 0.7891 - val_loss: 0.4425 - val_accuracy: 0.7838 - 620ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4385 - accuracy: 0.7916 - val_loss: 0.4423 - val_accuracy: 0.7909 - 623ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4366 - accuracy: 0.7967 - val_loss: 0.4406 - val_accuracy: 0.7933 - 638ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4341 - accuracy: 0.7963 - val_loss: 0.4389 - val_accuracy: 0.7933 - 607ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4335 - accuracy: 0.7972 - val_loss: 0.4394 - val_accuracy: 0.7922 - 634ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4332 - accuracy: 0.7976 - val_loss: 0.4393 - val_accuracy: 0.7933 - 658ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4348 - accuracy: 0.7975 - val_loss: 0.4406 - val_accuracy: 0.7960 - 693ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4344 - accuracy: 0.7971 - val_loss: 0.4392 - val_accuracy: 0.7960 - 669ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4372 - val_accuracy: 0.7975 - 635ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4319 - accuracy: 0.7982 - val_loss: 0.4356 - val_accuracy: 0.7933 - 685ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4306 - accuracy: 0.8006 - val_loss: 0.4395 - val_accuracy: 0.7949 - 694ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4295 - accuracy: 0.7999 - val_loss: 0.4344 - val_accuracy: 0.7942 - 597ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4300 - accuracy: 0.7994 - val_loss: 0.4343 - val_accuracy: 0.7977 - 639ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4297 - accuracy: 0.8006 - val_loss: 0.4367 - val_accuracy: 0.7969 - 663ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4288 - accuracy: 0.8008 - val_loss: 0.4388 - val_accuracy: 0.7907 - 681ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.7992 - val_loss: 0.4324 - val_accuracy: 0.8002 - 651ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4292 - accuracy: 0.8014 - val_loss: 0.4416 - val_accuracy: 0.7969 - 638ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.4337 - val_accuracy: 0.7988 - 635ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4290 - accuracy: 0.8010 - val_loss: 0.4354 - val_accuracy: 0.7924 - 668ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4269 - accuracy: 0.8005 - val_loss: 0.4347 - val_accuracy: 0.7935 - 798ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4266 - accuracy: 0.7996 - val_loss: 0.4342 - val_accuracy: 0.7991 - 624ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.4327 - val_accuracy: 0.7980 - 569ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4280 - accuracy: 0.8012 - val_loss: 0.4378 - val_accuracy: 0.7944 - 589ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4268 - accuracy: 0.8008 - val_loss: 0.4304 - val_accuracy: 0.7971 - 589ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4264 - accuracy: 0.8025 - val_loss: 0.4341 - val_accuracy: 0.7978 - 588ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4263 - accuracy: 0.8010 - val_loss: 0.4351 - val_accuracy: 0.7929 - 594ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4269 - accuracy: 0.8012 - val_loss: 0.4357 - val_accuracy: 0.7962 - 813ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4272 - accuracy: 0.8013 - val_loss: 0.4308 - val_accuracy: 0.8008 - 694ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4270 - accuracy: 0.8004 - val_loss: 0.4336 - val_accuracy: 0.7973 - 618ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4271 - accuracy: 0.8034 - val_loss: 0.4331 - val_accuracy: 0.7977 - 617ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4267 - accuracy: 0.8022 - val_loss: 0.4390 - val_accuracy: 0.7967 - 753ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4268 - accuracy: 0.8005 - val_loss: 0.4320 - val_accuracy: 0.7988 - 605ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4260 - accuracy: 0.8030 - val_loss: 0.4355 - val_accuracy: 0.7966 - 660ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4267 - accuracy: 0.8018 - val_loss: 0.4329 - val_accuracy: 0.7973 - 609ms/epoch - 7ms/step\n",
      "Epoch 41: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "86/86 - 5s - loss: 0.5919 - accuracy: 0.7088 - val_loss: 0.5327 - val_accuracy: 0.7582 - 5s/epoch - 59ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.5064 - accuracy: 0.7687 - val_loss: 0.4883 - val_accuracy: 0.7746 - 722ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4748 - accuracy: 0.7774 - val_loss: 0.4641 - val_accuracy: 0.7823 - 612ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4599 - accuracy: 0.7849 - val_loss: 0.4598 - val_accuracy: 0.7850 - 688ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4531 - accuracy: 0.7879 - val_loss: 0.4546 - val_accuracy: 0.7893 - 675ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4492 - accuracy: 0.7884 - val_loss: 0.4516 - val_accuracy: 0.7825 - 609ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4426 - accuracy: 0.7918 - val_loss: 0.4452 - val_accuracy: 0.7949 - 578ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4415 - accuracy: 0.7938 - val_loss: 0.4461 - val_accuracy: 0.7894 - 622ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4398 - accuracy: 0.7928 - val_loss: 0.4456 - val_accuracy: 0.7946 - 569ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4348 - accuracy: 0.7953 - val_loss: 0.4384 - val_accuracy: 0.7951 - 612ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4368 - accuracy: 0.7950 - val_loss: 0.4418 - val_accuracy: 0.7909 - 632ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4369 - accuracy: 0.7960 - val_loss: 0.4441 - val_accuracy: 0.7907 - 625ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4338 - accuracy: 0.7974 - val_loss: 0.4388 - val_accuracy: 0.7938 - 563ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4323 - accuracy: 0.7952 - val_loss: 0.4362 - val_accuracy: 0.7929 - 662ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4318 - accuracy: 0.7979 - val_loss: 0.4348 - val_accuracy: 0.7940 - 634ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4321 - accuracy: 0.7956 - val_loss: 0.4373 - val_accuracy: 0.7916 - 636ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4302 - accuracy: 0.7961 - val_loss: 0.4393 - val_accuracy: 0.7925 - 608ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4309 - accuracy: 0.7994 - val_loss: 0.4356 - val_accuracy: 0.7982 - 564ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4327 - accuracy: 0.7964 - val_loss: 0.4374 - val_accuracy: 0.7916 - 603ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4308 - accuracy: 0.7993 - val_loss: 0.4330 - val_accuracy: 0.7925 - 677ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4294 - accuracy: 0.7992 - val_loss: 0.4353 - val_accuracy: 0.7918 - 657ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4288 - accuracy: 0.7996 - val_loss: 0.4335 - val_accuracy: 0.7967 - 643ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4282 - accuracy: 0.8002 - val_loss: 0.4324 - val_accuracy: 0.7922 - 566ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4277 - accuracy: 0.8016 - val_loss: 0.4351 - val_accuracy: 0.7975 - 596ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4286 - accuracy: 0.7992 - val_loss: 0.4329 - val_accuracy: 0.7962 - 623ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4298 - accuracy: 0.7994 - val_loss: 0.4325 - val_accuracy: 0.7969 - 651ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4282 - accuracy: 0.8011 - val_loss: 0.4334 - val_accuracy: 0.8000 - 620ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4268 - accuracy: 0.8014 - val_loss: 0.4346 - val_accuracy: 0.7956 - 665ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4272 - accuracy: 0.7976 - val_loss: 0.4347 - val_accuracy: 0.7936 - 688ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4257 - accuracy: 0.8012 - val_loss: 0.4337 - val_accuracy: 0.7947 - 729ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4272 - accuracy: 0.8002 - val_loss: 0.4330 - val_accuracy: 0.8017 - 597ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4269 - accuracy: 0.7994 - val_loss: 0.4322 - val_accuracy: 0.7978 - 717ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4271 - accuracy: 0.8001 - val_loss: 0.4328 - val_accuracy: 0.7986 - 640ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4256 - accuracy: 0.7998 - val_loss: 0.4318 - val_accuracy: 0.7984 - 620ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4274 - accuracy: 0.8000 - val_loss: 0.4304 - val_accuracy: 0.7995 - 562ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.4344 - val_accuracy: 0.7953 - 587ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4271 - accuracy: 0.8003 - val_loss: 0.4314 - val_accuracy: 0.7953 - 625ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4254 - accuracy: 0.8014 - val_loss: 0.4295 - val_accuracy: 0.7984 - 645ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4250 - accuracy: 0.8010 - val_loss: 0.4328 - val_accuracy: 0.7977 - 594ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4260 - accuracy: 0.8025 - val_loss: 0.4361 - val_accuracy: 0.7962 - 637ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.4324 - val_accuracy: 0.7975 - 639ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4265 - accuracy: 0.8003 - val_loss: 0.4331 - val_accuracy: 0.7929 - 644ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.4338 - val_accuracy: 0.7964 - 601ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4263 - accuracy: 0.8000 - val_loss: 0.4308 - val_accuracy: 0.7942 - 614ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4253 - accuracy: 0.8020 - val_loss: 0.4345 - val_accuracy: 0.7936 - 582ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "86/86 - 1s - loss: 0.4255 - accuracy: 0.8009 - val_loss: 0.4323 - val_accuracy: 0.7984 - 594ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "86/86 - 1s - loss: 0.4273 - accuracy: 0.8012 - val_loss: 0.4344 - val_accuracy: 0.7935 - 581ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "86/86 - 1s - loss: 0.4265 - accuracy: 0.8011 - val_loss: 0.4290 - val_accuracy: 0.8019 - 610ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "86/86 - 1s - loss: 0.4248 - accuracy: 0.8008 - val_loss: 0.4297 - val_accuracy: 0.7999 - 581ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "86/86 - 1s - loss: 0.4246 - accuracy: 0.8000 - val_loss: 0.4332 - val_accuracy: 0.7980 - 644ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "86/86 - 1s - loss: 0.4265 - accuracy: 0.7997 - val_loss: 0.4343 - val_accuracy: 0.7947 - 612ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "86/86 - 1s - loss: 0.4253 - accuracy: 0.7995 - val_loss: 0.4310 - val_accuracy: 0.7962 - 606ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "86/86 - 1s - loss: 0.4234 - accuracy: 0.8011 - val_loss: 0.4331 - val_accuracy: 0.7947 - 640ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "86/86 - 1s - loss: 0.4264 - accuracy: 0.8028 - val_loss: 0.4316 - val_accuracy: 0.7966 - 645ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "86/86 - 1s - loss: 0.4249 - accuracy: 0.8005 - val_loss: 0.4331 - val_accuracy: 0.7982 - 749ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "86/86 - 1s - loss: 0.4250 - accuracy: 0.8027 - val_loss: 0.4296 - val_accuracy: 0.7980 - 838ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "86/86 - 1s - loss: 0.4268 - accuracy: 0.7998 - val_loss: 0.4316 - val_accuracy: 0.7980 - 715ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "86/86 - 1s - loss: 0.4256 - accuracy: 0.8007 - val_loss: 0.4315 - val_accuracy: 0.7936 - 683ms/epoch - 8ms/step\n",
      "Epoch 58: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 0.5956 - accuracy: 0.7055 - val_loss: 0.5273 - val_accuracy: 0.7611 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.5040 - accuracy: 0.7666 - val_loss: 0.4785 - val_accuracy: 0.7713 - 641ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4692 - accuracy: 0.7776 - val_loss: 0.4642 - val_accuracy: 0.7794 - 641ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4586 - accuracy: 0.7821 - val_loss: 0.4569 - val_accuracy: 0.7825 - 609ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4527 - accuracy: 0.7846 - val_loss: 0.4518 - val_accuracy: 0.7878 - 612ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4471 - accuracy: 0.7877 - val_loss: 0.4468 - val_accuracy: 0.7885 - 651ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4442 - accuracy: 0.7902 - val_loss: 0.4510 - val_accuracy: 0.7852 - 775ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4405 - accuracy: 0.7916 - val_loss: 0.4473 - val_accuracy: 0.7887 - 580ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4369 - accuracy: 0.7927 - val_loss: 0.4424 - val_accuracy: 0.7907 - 618ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4376 - accuracy: 0.7927 - val_loss: 0.4392 - val_accuracy: 0.7891 - 622ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4384 - val_accuracy: 0.7931 - 702ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4431 - val_accuracy: 0.7894 - 623ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4352 - accuracy: 0.7955 - val_loss: 0.4420 - val_accuracy: 0.7938 - 625ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4328 - accuracy: 0.7965 - val_loss: 0.4400 - val_accuracy: 0.7924 - 625ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4335 - accuracy: 0.7972 - val_loss: 0.4373 - val_accuracy: 0.7960 - 661ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4333 - accuracy: 0.7979 - val_loss: 0.4399 - val_accuracy: 0.7907 - 597ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4319 - accuracy: 0.7972 - val_loss: 0.4406 - val_accuracy: 0.7872 - 676ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4314 - accuracy: 0.7990 - val_loss: 0.4390 - val_accuracy: 0.7925 - 622ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4302 - accuracy: 0.8009 - val_loss: 0.4415 - val_accuracy: 0.7942 - 658ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4317 - accuracy: 0.7989 - val_loss: 0.4365 - val_accuracy: 0.7927 - 646ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4303 - accuracy: 0.7989 - val_loss: 0.4342 - val_accuracy: 0.7960 - 707ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4293 - accuracy: 0.7983 - val_loss: 0.4429 - val_accuracy: 0.7914 - 654ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4296 - accuracy: 0.7995 - val_loss: 0.4379 - val_accuracy: 0.7984 - 613ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4312 - accuracy: 0.7980 - val_loss: 0.4383 - val_accuracy: 0.7960 - 661ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4299 - accuracy: 0.8001 - val_loss: 0.4364 - val_accuracy: 0.7935 - 606ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4356 - val_accuracy: 0.7931 - 653ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4298 - accuracy: 0.7997 - val_loss: 0.4372 - val_accuracy: 0.7946 - 690ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4285 - accuracy: 0.8007 - val_loss: 0.4366 - val_accuracy: 0.7969 - 651ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4281 - accuracy: 0.8006 - val_loss: 0.4375 - val_accuracy: 0.7940 - 711ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4281 - accuracy: 0.7995 - val_loss: 0.4382 - val_accuracy: 0.7931 - 769ms/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4294 - accuracy: 0.7992 - val_loss: 0.4330 - val_accuracy: 0.7984 - 718ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4293 - accuracy: 0.8014 - val_loss: 0.4330 - val_accuracy: 0.7980 - 713ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4281 - accuracy: 0.8012 - val_loss: 0.4375 - val_accuracy: 0.7971 - 675ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4285 - accuracy: 0.8008 - val_loss: 0.4333 - val_accuracy: 0.7940 - 603ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.8012 - val_loss: 0.4312 - val_accuracy: 0.7969 - 618ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4291 - accuracy: 0.7999 - val_loss: 0.4347 - val_accuracy: 0.7973 - 685ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4273 - accuracy: 0.8001 - val_loss: 0.4345 - val_accuracy: 0.7933 - 779ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4278 - accuracy: 0.7985 - val_loss: 0.4332 - val_accuracy: 0.7958 - 649ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4254 - accuracy: 0.8019 - val_loss: 0.4353 - val_accuracy: 0.7935 - 666ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4273 - accuracy: 0.8006 - val_loss: 0.4333 - val_accuracy: 0.7964 - 683ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4264 - accuracy: 0.7992 - val_loss: 0.4320 - val_accuracy: 0.7982 - 618ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4265 - accuracy: 0.8010 - val_loss: 0.4332 - val_accuracy: 0.7955 - 633ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4273 - accuracy: 0.8003 - val_loss: 0.4360 - val_accuracy: 0.7953 - 633ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4285 - accuracy: 0.7993 - val_loss: 0.4324 - val_accuracy: 0.7955 - 635ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4251 - accuracy: 0.7994 - val_loss: 0.4326 - val_accuracy: 0.7975 - 653ms/epoch - 8ms/step\n",
      "Epoch 45: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "86/86 - 20s - loss: 0.5676 - accuracy: 0.7346 - val_loss: 0.5204 - val_accuracy: 0.7593 - 20s/epoch - 237ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.4959 - accuracy: 0.7638 - val_loss: 0.4783 - val_accuracy: 0.7781 - 641ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4652 - accuracy: 0.7807 - val_loss: 0.4657 - val_accuracy: 0.7797 - 687ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4563 - accuracy: 0.7851 - val_loss: 0.4537 - val_accuracy: 0.7821 - 609ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4492 - accuracy: 0.7867 - val_loss: 0.4479 - val_accuracy: 0.7840 - 875ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4425 - accuracy: 0.7910 - val_loss: 0.4433 - val_accuracy: 0.7896 - 609ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4419 - accuracy: 0.7906 - val_loss: 0.4444 - val_accuracy: 0.7924 - 844ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4362 - accuracy: 0.7964 - val_loss: 0.4367 - val_accuracy: 0.7938 - 625ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4362 - accuracy: 0.7949 - val_loss: 0.4380 - val_accuracy: 0.7947 - 625ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4356 - accuracy: 0.7964 - val_loss: 0.4381 - val_accuracy: 0.7951 - 609ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4315 - accuracy: 0.8002 - val_loss: 0.4393 - val_accuracy: 0.7947 - 625ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4338 - accuracy: 0.7963 - val_loss: 0.4432 - val_accuracy: 0.7920 - 609ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4321 - accuracy: 0.8004 - val_loss: 0.4368 - val_accuracy: 0.7933 - 594ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4311 - accuracy: 0.7993 - val_loss: 0.4397 - val_accuracy: 0.7942 - 609ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4309 - accuracy: 0.7992 - val_loss: 0.4416 - val_accuracy: 0.7944 - 562ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4315 - accuracy: 0.8009 - val_loss: 0.4404 - val_accuracy: 0.7938 - 625ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4325 - accuracy: 0.7984 - val_loss: 0.4421 - val_accuracy: 0.7914 - 594ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4294 - accuracy: 0.8010 - val_loss: 0.4365 - val_accuracy: 0.7982 - 609ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4290 - accuracy: 0.8017 - val_loss: 0.4384 - val_accuracy: 0.7944 - 609ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4294 - accuracy: 0.8005 - val_loss: 0.4369 - val_accuracy: 0.7978 - 609ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4297 - accuracy: 0.8005 - val_loss: 0.4340 - val_accuracy: 0.8008 - 578ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4298 - accuracy: 0.8020 - val_loss: 0.4353 - val_accuracy: 0.7947 - 609ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4287 - accuracy: 0.7995 - val_loss: 0.4347 - val_accuracy: 0.7977 - 578ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4294 - accuracy: 0.8013 - val_loss: 0.4340 - val_accuracy: 0.8008 - 657ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4295 - accuracy: 0.8027 - val_loss: 0.4340 - val_accuracy: 0.7967 - 631ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4267 - accuracy: 0.8016 - val_loss: 0.4374 - val_accuracy: 0.7955 - 626ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4301 - accuracy: 0.8012 - val_loss: 0.4395 - val_accuracy: 0.7949 - 605ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4296 - accuracy: 0.7991 - val_loss: 0.4386 - val_accuracy: 0.7978 - 919ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4280 - accuracy: 0.7992 - val_loss: 0.4367 - val_accuracy: 0.7988 - 591ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4290 - accuracy: 0.8031 - val_loss: 0.4333 - val_accuracy: 0.7973 - 633ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.8004 - val_loss: 0.4359 - val_accuracy: 0.7938 - 594ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4266 - accuracy: 0.8029 - val_loss: 0.4371 - val_accuracy: 0.7962 - 656ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4263 - accuracy: 0.8041 - val_loss: 0.4360 - val_accuracy: 0.7986 - 625ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4254 - accuracy: 0.8025 - val_loss: 0.4371 - val_accuracy: 0.7995 - 638ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4268 - accuracy: 0.8028 - val_loss: 0.4351 - val_accuracy: 0.7995 - 562ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4280 - accuracy: 0.8000 - val_loss: 0.4340 - val_accuracy: 0.7982 - 622ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.8025 - val_loss: 0.4349 - val_accuracy: 0.7977 - 625ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4252 - accuracy: 0.8027 - val_loss: 0.4313 - val_accuracy: 0.7973 - 609ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4282 - accuracy: 0.8013 - val_loss: 0.4359 - val_accuracy: 0.7971 - 609ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4270 - accuracy: 0.8026 - val_loss: 0.4352 - val_accuracy: 0.8019 - 609ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4271 - accuracy: 0.8015 - val_loss: 0.4358 - val_accuracy: 0.7953 - 609ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4254 - accuracy: 0.8023 - val_loss: 0.4302 - val_accuracy: 0.8008 - 609ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4265 - accuracy: 0.8010 - val_loss: 0.4335 - val_accuracy: 0.7971 - 625ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4252 - accuracy: 0.8009 - val_loss: 0.4351 - val_accuracy: 0.7953 - 594ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "86/86 - 1s - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.4334 - val_accuracy: 0.7973 - 625ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "86/86 - 1s - loss: 0.4264 - accuracy: 0.8034 - val_loss: 0.4327 - val_accuracy: 0.7969 - 594ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "86/86 - 1s - loss: 0.4271 - accuracy: 0.8011 - val_loss: 0.4335 - val_accuracy: 0.7966 - 611ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "86/86 - 1s - loss: 0.4253 - accuracy: 0.8019 - val_loss: 0.4336 - val_accuracy: 0.7967 - 614ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "86/86 - 1s - loss: 0.4253 - accuracy: 0.8029 - val_loss: 0.4351 - val_accuracy: 0.7986 - 607ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "86/86 - 1s - loss: 0.4263 - accuracy: 0.8021 - val_loss: 0.4278 - val_accuracy: 0.7980 - 604ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "86/86 - 1s - loss: 0.4250 - accuracy: 0.8015 - val_loss: 0.4333 - val_accuracy: 0.7960 - 623ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "86/86 - 1s - loss: 0.4255 - accuracy: 0.8023 - val_loss: 0.4325 - val_accuracy: 0.7940 - 620ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "86/86 - 1s - loss: 0.4250 - accuracy: 0.8017 - val_loss: 0.4308 - val_accuracy: 0.7958 - 622ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "86/86 - 1s - loss: 0.4254 - accuracy: 0.8030 - val_loss: 0.4365 - val_accuracy: 0.7977 - 607ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "86/86 - 1s - loss: 0.4259 - accuracy: 0.8016 - val_loss: 0.4319 - val_accuracy: 0.8017 - 616ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "86/86 - 1s - loss: 0.4257 - accuracy: 0.8032 - val_loss: 0.4273 - val_accuracy: 0.7973 - 616ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "86/86 - 1s - loss: 0.4248 - accuracy: 0.8020 - val_loss: 0.4324 - val_accuracy: 0.7933 - 643ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "86/86 - 1s - loss: 0.4239 - accuracy: 0.8038 - val_loss: 0.4346 - val_accuracy: 0.7958 - 595ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "86/86 - 1s - loss: 0.4247 - accuracy: 0.8026 - val_loss: 0.4323 - val_accuracy: 0.7982 - 609ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "86/86 - 1s - loss: 0.4256 - accuracy: 0.8022 - val_loss: 0.4341 - val_accuracy: 0.7949 - 633ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "86/86 - 1s - loss: 0.4248 - accuracy: 0.8016 - val_loss: 0.4344 - val_accuracy: 0.7995 - 613ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "86/86 - 1s - loss: 0.4259 - accuracy: 0.8007 - val_loss: 0.4325 - val_accuracy: 0.7991 - 570ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "86/86 - 1s - loss: 0.4250 - accuracy: 0.8039 - val_loss: 0.4335 - val_accuracy: 0.7966 - 619ms/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "86/86 - 1s - loss: 0.4248 - accuracy: 0.8031 - val_loss: 0.4299 - val_accuracy: 0.7989 - 610ms/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "86/86 - 1s - loss: 0.4212 - accuracy: 0.8028 - val_loss: 0.4333 - val_accuracy: 0.7946 - 615ms/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "86/86 - 1s - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.4323 - val_accuracy: 0.7969 - 634ms/epoch - 7ms/step\n",
      "Epoch 66: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "86/86 - 2s - loss: 0.6048 - accuracy: 0.6854 - val_loss: 0.5242 - val_accuracy: 0.7640 - 2s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.5007 - accuracy: 0.7606 - val_loss: 0.4893 - val_accuracy: 0.7649 - 594ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4764 - accuracy: 0.7677 - val_loss: 0.4724 - val_accuracy: 0.7688 - 685ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4642 - accuracy: 0.7731 - val_loss: 0.4643 - val_accuracy: 0.7713 - 605ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4582 - accuracy: 0.7807 - val_loss: 0.4590 - val_accuracy: 0.7754 - 619ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4522 - accuracy: 0.7835 - val_loss: 0.4480 - val_accuracy: 0.7838 - 654ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4475 - accuracy: 0.7837 - val_loss: 0.4500 - val_accuracy: 0.7829 - 617ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4484 - accuracy: 0.7862 - val_loss: 0.4476 - val_accuracy: 0.7852 - 667ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4447 - accuracy: 0.7880 - val_loss: 0.4458 - val_accuracy: 0.7863 - 609ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4437 - accuracy: 0.7913 - val_loss: 0.4458 - val_accuracy: 0.7885 - 653ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4420 - accuracy: 0.7907 - val_loss: 0.4457 - val_accuracy: 0.7894 - 687ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4377 - accuracy: 0.7913 - val_loss: 0.4412 - val_accuracy: 0.7863 - 665ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4351 - accuracy: 0.7945 - val_loss: 0.4412 - val_accuracy: 0.7900 - 615ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4356 - accuracy: 0.7939 - val_loss: 0.4427 - val_accuracy: 0.7887 - 609ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.4395 - val_accuracy: 0.7907 - 609ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4368 - accuracy: 0.7941 - val_loss: 0.4407 - val_accuracy: 0.7914 - 672ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4331 - accuracy: 0.7963 - val_loss: 0.4391 - val_accuracy: 0.7960 - 656ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4347 - accuracy: 0.7936 - val_loss: 0.4384 - val_accuracy: 0.7958 - 594ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4329 - accuracy: 0.7963 - val_loss: 0.4403 - val_accuracy: 0.7916 - 630ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4313 - accuracy: 0.7967 - val_loss: 0.4392 - val_accuracy: 0.7949 - 611ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4311 - accuracy: 0.7967 - val_loss: 0.4395 - val_accuracy: 0.7914 - 684ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4313 - accuracy: 0.7965 - val_loss: 0.4385 - val_accuracy: 0.7955 - 666ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4309 - accuracy: 0.7993 - val_loss: 0.4371 - val_accuracy: 0.7944 - 698ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4301 - accuracy: 0.7982 - val_loss: 0.4355 - val_accuracy: 0.7951 - 661ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4280 - accuracy: 0.7985 - val_loss: 0.4362 - val_accuracy: 0.7969 - 659ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4288 - accuracy: 0.7972 - val_loss: 0.4356 - val_accuracy: 0.7953 - 787ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4286 - accuracy: 0.7997 - val_loss: 0.4329 - val_accuracy: 0.7916 - 825ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4278 - accuracy: 0.7964 - val_loss: 0.4346 - val_accuracy: 0.7951 - 639ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4396 - val_accuracy: 0.7947 - 641ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4290 - accuracy: 0.7993 - val_loss: 0.4369 - val_accuracy: 0.8000 - 625ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4300 - accuracy: 0.7979 - val_loss: 0.4350 - val_accuracy: 0.7975 - 656ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4279 - accuracy: 0.7978 - val_loss: 0.4358 - val_accuracy: 0.7958 - 672ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.4353 - val_accuracy: 0.7977 - 656ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.7965 - val_loss: 0.4292 - val_accuracy: 0.7977 - 656ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4305 - accuracy: 0.7964 - val_loss: 0.4364 - val_accuracy: 0.7903 - 604ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4268 - accuracy: 0.7985 - val_loss: 0.4341 - val_accuracy: 0.7964 - 626ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4274 - accuracy: 0.7979 - val_loss: 0.4349 - val_accuracy: 0.7936 - 611ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4275 - accuracy: 0.7983 - val_loss: 0.4323 - val_accuracy: 0.7962 - 580ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4265 - accuracy: 0.8004 - val_loss: 0.4365 - val_accuracy: 0.7975 - 613ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4271 - accuracy: 0.8010 - val_loss: 0.4339 - val_accuracy: 0.7955 - 655ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4270 - accuracy: 0.7989 - val_loss: 0.4300 - val_accuracy: 0.7975 - 594ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4258 - accuracy: 0.7998 - val_loss: 0.4343 - val_accuracy: 0.7967 - 611ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "86/86 - 1s - loss: 0.4247 - accuracy: 0.8011 - val_loss: 0.4336 - val_accuracy: 0.7967 - 587ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "86/86 - 1s - loss: 0.4266 - accuracy: 0.8011 - val_loss: 0.4346 - val_accuracy: 0.7933 - 609ms/epoch - 7ms/step\n",
      "Epoch 44: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "86/86 - 4s - loss: 0.6035 - accuracy: 0.7101 - val_loss: 0.5479 - val_accuracy: 0.7591 - 4s/epoch - 42ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.5156 - accuracy: 0.7651 - val_loss: 0.4906 - val_accuracy: 0.7712 - 712ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4763 - accuracy: 0.7785 - val_loss: 0.4689 - val_accuracy: 0.7781 - 631ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4625 - accuracy: 0.7840 - val_loss: 0.4603 - val_accuracy: 0.7836 - 673ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4535 - accuracy: 0.7879 - val_loss: 0.4619 - val_accuracy: 0.7818 - 631ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4485 - accuracy: 0.7894 - val_loss: 0.4452 - val_accuracy: 0.7856 - 633ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4470 - accuracy: 0.7899 - val_loss: 0.4481 - val_accuracy: 0.7893 - 589ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4431 - accuracy: 0.7920 - val_loss: 0.4514 - val_accuracy: 0.7816 - 607ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4390 - accuracy: 0.7958 - val_loss: 0.4485 - val_accuracy: 0.7929 - 625ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4369 - accuracy: 0.7960 - val_loss: 0.4413 - val_accuracy: 0.7911 - 632ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4366 - accuracy: 0.7926 - val_loss: 0.4418 - val_accuracy: 0.7940 - 615ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4344 - accuracy: 0.7937 - val_loss: 0.4405 - val_accuracy: 0.7927 - 640ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4341 - accuracy: 0.7965 - val_loss: 0.4413 - val_accuracy: 0.7924 - 644ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4333 - accuracy: 0.7964 - val_loss: 0.4382 - val_accuracy: 0.7949 - 624ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4332 - accuracy: 0.7972 - val_loss: 0.4381 - val_accuracy: 0.7913 - 616ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4315 - accuracy: 0.7989 - val_loss: 0.4373 - val_accuracy: 0.7962 - 606ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4315 - accuracy: 0.7965 - val_loss: 0.4349 - val_accuracy: 0.7947 - 607ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4300 - accuracy: 0.7980 - val_loss: 0.4372 - val_accuracy: 0.7971 - 638ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4306 - accuracy: 0.7992 - val_loss: 0.4367 - val_accuracy: 0.7958 - 607ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4313 - accuracy: 0.7997 - val_loss: 0.4338 - val_accuracy: 0.7995 - 617ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.4336 - val_accuracy: 0.7951 - 634ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4298 - accuracy: 0.8001 - val_loss: 0.4392 - val_accuracy: 0.7946 - 631ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4311 - accuracy: 0.7994 - val_loss: 0.4325 - val_accuracy: 0.7991 - 661ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4299 - accuracy: 0.8000 - val_loss: 0.4339 - val_accuracy: 0.7947 - 619ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4293 - accuracy: 0.8008 - val_loss: 0.4355 - val_accuracy: 0.7973 - 583ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4282 - accuracy: 0.8011 - val_loss: 0.4325 - val_accuracy: 0.7933 - 596ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4292 - accuracy: 0.7996 - val_loss: 0.4354 - val_accuracy: 0.7927 - 614ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4292 - accuracy: 0.8003 - val_loss: 0.4339 - val_accuracy: 0.8011 - 611ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4279 - accuracy: 0.8013 - val_loss: 0.4353 - val_accuracy: 0.7960 - 657ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4278 - accuracy: 0.8029 - val_loss: 0.4372 - val_accuracy: 0.7977 - 676ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4279 - accuracy: 0.8005 - val_loss: 0.4361 - val_accuracy: 0.7951 - 611ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4271 - accuracy: 0.8016 - val_loss: 0.4301 - val_accuracy: 0.7993 - 647ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4257 - accuracy: 0.7999 - val_loss: 0.4348 - val_accuracy: 0.7966 - 639ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4263 - accuracy: 0.8021 - val_loss: 0.4316 - val_accuracy: 0.7971 - 675ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4266 - accuracy: 0.8020 - val_loss: 0.4345 - val_accuracy: 0.7977 - 608ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4252 - accuracy: 0.8038 - val_loss: 0.4342 - val_accuracy: 0.7962 - 610ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4273 - accuracy: 0.8001 - val_loss: 0.4315 - val_accuracy: 0.8022 - 659ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4270 - accuracy: 0.8001 - val_loss: 0.4365 - val_accuracy: 0.7929 - 589ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "86/86 - 1s - loss: 0.4283 - accuracy: 0.8020 - val_loss: 0.4335 - val_accuracy: 0.7940 - 651ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "86/86 - 1s - loss: 0.4257 - accuracy: 0.8005 - val_loss: 0.4325 - val_accuracy: 0.7982 - 624ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "86/86 - 1s - loss: 0.4275 - accuracy: 0.7997 - val_loss: 0.4329 - val_accuracy: 0.7986 - 638ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "86/86 - 1s - loss: 0.4260 - accuracy: 0.8034 - val_loss: 0.4328 - val_accuracy: 0.7982 - 603ms/epoch - 7ms/step\n",
      "Epoch 42: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "86/86 - 5s - loss: 0.6001 - accuracy: 0.6941 - val_loss: 0.5227 - val_accuracy: 0.7620 - 5s/epoch - 62ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.4991 - accuracy: 0.7657 - val_loss: 0.4817 - val_accuracy: 0.7702 - 696ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4680 - accuracy: 0.7791 - val_loss: 0.4628 - val_accuracy: 0.7830 - 711ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4579 - accuracy: 0.7829 - val_loss: 0.4633 - val_accuracy: 0.7830 - 668ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4506 - accuracy: 0.7869 - val_loss: 0.4619 - val_accuracy: 0.7840 - 635ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4491 - accuracy: 0.7866 - val_loss: 0.4478 - val_accuracy: 0.7816 - 728ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4465 - accuracy: 0.7878 - val_loss: 0.4489 - val_accuracy: 0.7885 - 798ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4442 - accuracy: 0.7935 - val_loss: 0.4515 - val_accuracy: 0.7911 - 670ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4413 - accuracy: 0.7911 - val_loss: 0.4443 - val_accuracy: 0.7969 - 643ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4374 - accuracy: 0.7949 - val_loss: 0.4453 - val_accuracy: 0.7909 - 673ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4389 - accuracy: 0.7960 - val_loss: 0.4445 - val_accuracy: 0.7933 - 700ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4343 - accuracy: 0.7948 - val_loss: 0.4465 - val_accuracy: 0.7929 - 680ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4343 - accuracy: 0.7970 - val_loss: 0.4392 - val_accuracy: 0.7913 - 765ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4346 - accuracy: 0.7968 - val_loss: 0.4398 - val_accuracy: 0.7935 - 741ms/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4336 - accuracy: 0.7961 - val_loss: 0.4401 - val_accuracy: 0.7918 - 734ms/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4333 - accuracy: 0.7952 - val_loss: 0.4350 - val_accuracy: 0.7935 - 1s/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4317 - accuracy: 0.7979 - val_loss: 0.4365 - val_accuracy: 0.7946 - 896ms/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4319 - accuracy: 0.7984 - val_loss: 0.4364 - val_accuracy: 0.7989 - 657ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4316 - accuracy: 0.7990 - val_loss: 0.4406 - val_accuracy: 0.7956 - 714ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4310 - accuracy: 0.7972 - val_loss: 0.4382 - val_accuracy: 0.7938 - 631ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4292 - accuracy: 0.7983 - val_loss: 0.4370 - val_accuracy: 0.7949 - 685ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4312 - accuracy: 0.7983 - val_loss: 0.4336 - val_accuracy: 0.7958 - 678ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4315 - accuracy: 0.7974 - val_loss: 0.4346 - val_accuracy: 0.7907 - 680ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4283 - accuracy: 0.8001 - val_loss: 0.4339 - val_accuracy: 0.7953 - 628ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4296 - accuracy: 0.8005 - val_loss: 0.4361 - val_accuracy: 0.7946 - 782ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4283 - accuracy: 0.7995 - val_loss: 0.4352 - val_accuracy: 0.7953 - 646ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4278 - accuracy: 0.8016 - val_loss: 0.4338 - val_accuracy: 0.7993 - 684ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4292 - accuracy: 0.7995 - val_loss: 0.4342 - val_accuracy: 0.8000 - 670ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4258 - accuracy: 0.8002 - val_loss: 0.4377 - val_accuracy: 0.7922 - 685ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4280 - accuracy: 0.7991 - val_loss: 0.4365 - val_accuracy: 0.7944 - 662ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4310 - accuracy: 0.7984 - val_loss: 0.4352 - val_accuracy: 0.7949 - 684ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4281 - accuracy: 0.8012 - val_loss: 0.4348 - val_accuracy: 0.7949 - 645ms/epoch - 8ms/step\n",
      "Epoch 32: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "86/86 - 6s - loss: 0.6220 - accuracy: 0.6650 - val_loss: 0.5315 - val_accuracy: 0.7617 - 6s/epoch - 75ms/step\n",
      "Epoch 2/100\n",
      "86/86 - 1s - loss: 0.5098 - accuracy: 0.7675 - val_loss: 0.4887 - val_accuracy: 0.7737 - 680ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "86/86 - 1s - loss: 0.4763 - accuracy: 0.7783 - val_loss: 0.4667 - val_accuracy: 0.7810 - 800ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "86/86 - 1s - loss: 0.4602 - accuracy: 0.7842 - val_loss: 0.4598 - val_accuracy: 0.7840 - 680ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "86/86 - 1s - loss: 0.4524 - accuracy: 0.7856 - val_loss: 0.4507 - val_accuracy: 0.7874 - 650ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "86/86 - 1s - loss: 0.4454 - accuracy: 0.7890 - val_loss: 0.4544 - val_accuracy: 0.7865 - 670ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "86/86 - 1s - loss: 0.4450 - accuracy: 0.7900 - val_loss: 0.4475 - val_accuracy: 0.7896 - 662ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "86/86 - 1s - loss: 0.4425 - accuracy: 0.7889 - val_loss: 0.4465 - val_accuracy: 0.7911 - 616ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "86/86 - 1s - loss: 0.4411 - accuracy: 0.7946 - val_loss: 0.4456 - val_accuracy: 0.7920 - 637ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "86/86 - 1s - loss: 0.4387 - accuracy: 0.7920 - val_loss: 0.4426 - val_accuracy: 0.7913 - 660ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "86/86 - 1s - loss: 0.4366 - accuracy: 0.7962 - val_loss: 0.4393 - val_accuracy: 0.7944 - 722ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "86/86 - 1s - loss: 0.4380 - accuracy: 0.7938 - val_loss: 0.4389 - val_accuracy: 0.7918 - 629ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "86/86 - 1s - loss: 0.4332 - accuracy: 0.7967 - val_loss: 0.4400 - val_accuracy: 0.7916 - 720ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "86/86 - 1s - loss: 0.4326 - accuracy: 0.7973 - val_loss: 0.4383 - val_accuracy: 0.7958 - 660ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "86/86 - 1s - loss: 0.4352 - accuracy: 0.7944 - val_loss: 0.4369 - val_accuracy: 0.7935 - 660ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "86/86 - 1s - loss: 0.4360 - accuracy: 0.7941 - val_loss: 0.4378 - val_accuracy: 0.7988 - 655ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "86/86 - 1s - loss: 0.4347 - accuracy: 0.7963 - val_loss: 0.4355 - val_accuracy: 0.7942 - 660ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "86/86 - 1s - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4379 - val_accuracy: 0.7925 - 645ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "86/86 - 1s - loss: 0.4306 - accuracy: 0.7989 - val_loss: 0.4404 - val_accuracy: 0.7922 - 691ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "86/86 - 1s - loss: 0.4317 - accuracy: 0.7977 - val_loss: 0.4357 - val_accuracy: 0.7942 - 668ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "86/86 - 1s - loss: 0.4310 - accuracy: 0.7967 - val_loss: 0.4402 - val_accuracy: 0.7989 - 704ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "86/86 - 1s - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4345 - val_accuracy: 0.7991 - 661ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "86/86 - 1s - loss: 0.4320 - accuracy: 0.7982 - val_loss: 0.4374 - val_accuracy: 0.7988 - 667ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "86/86 - 1s - loss: 0.4289 - accuracy: 0.7979 - val_loss: 0.4372 - val_accuracy: 0.7964 - 637ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "86/86 - 1s - loss: 0.4299 - accuracy: 0.7973 - val_loss: 0.4362 - val_accuracy: 0.7955 - 674ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "86/86 - 1s - loss: 0.4306 - accuracy: 0.7999 - val_loss: 0.4376 - val_accuracy: 0.7942 - 651ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "86/86 - 1s - loss: 0.4306 - accuracy: 0.7990 - val_loss: 0.4355 - val_accuracy: 0.7946 - 679ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "86/86 - 1s - loss: 0.4306 - accuracy: 0.7992 - val_loss: 0.4304 - val_accuracy: 0.7978 - 646ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "86/86 - 1s - loss: 0.4277 - accuracy: 0.8019 - val_loss: 0.4342 - val_accuracy: 0.7993 - 599ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "86/86 - 1s - loss: 0.4292 - accuracy: 0.7998 - val_loss: 0.4357 - val_accuracy: 0.7966 - 640ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "86/86 - 1s - loss: 0.4273 - accuracy: 0.8004 - val_loss: 0.4322 - val_accuracy: 0.7951 - 652ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "86/86 - 1s - loss: 0.4269 - accuracy: 0.8010 - val_loss: 0.4311 - val_accuracy: 0.7995 - 624ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "86/86 - 1s - loss: 0.4276 - accuracy: 0.8000 - val_loss: 0.4328 - val_accuracy: 0.7975 - 641ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "86/86 - 1s - loss: 0.4273 - accuracy: 0.8012 - val_loss: 0.4367 - val_accuracy: 0.7946 - 633ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "86/86 - 1s - loss: 0.4271 - accuracy: 0.8007 - val_loss: 0.4349 - val_accuracy: 0.7991 - 588ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "86/86 - 1s - loss: 0.4280 - accuracy: 0.8004 - val_loss: 0.4384 - val_accuracy: 0.7944 - 616ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "86/86 - 1s - loss: 0.4288 - accuracy: 0.7993 - val_loss: 0.4380 - val_accuracy: 0.7975 - 651ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "86/86 - 1s - loss: 0.4265 - accuracy: 0.8027 - val_loss: 0.4356 - val_accuracy: 0.7977 - 594ms/epoch - 7ms/step\n",
      "Epoch 38: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.37922286468089633\n",
      "epi entropy:  0.36004314366085577\n",
      "\n",
      "dataset size:  0.8\n",
      "Epoch 1/100\n",
      "98/98 - 4s - loss: 0.5866 - accuracy: 0.7156 - val_loss: 0.5172 - val_accuracy: 0.7604 - 4s/epoch - 37ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.4949 - accuracy: 0.7671 - val_loss: 0.4745 - val_accuracy: 0.7759 - 686ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4687 - accuracy: 0.7773 - val_loss: 0.4614 - val_accuracy: 0.7790 - 682ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4579 - accuracy: 0.7796 - val_loss: 0.4585 - val_accuracy: 0.7802 - 683ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4516 - accuracy: 0.7836 - val_loss: 0.4596 - val_accuracy: 0.7821 - 730ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4461 - accuracy: 0.7867 - val_loss: 0.4540 - val_accuracy: 0.7869 - 710ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4454 - accuracy: 0.7875 - val_loss: 0.4481 - val_accuracy: 0.7887 - 700ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4423 - accuracy: 0.7879 - val_loss: 0.4502 - val_accuracy: 0.7905 - 683ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4397 - accuracy: 0.7904 - val_loss: 0.4451 - val_accuracy: 0.7866 - 739ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4396 - accuracy: 0.7903 - val_loss: 0.4408 - val_accuracy: 0.7969 - 713ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4386 - accuracy: 0.7938 - val_loss: 0.4440 - val_accuracy: 0.7961 - 754ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4385 - accuracy: 0.7933 - val_loss: 0.4439 - val_accuracy: 0.7916 - 842ms/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4359 - accuracy: 0.7966 - val_loss: 0.4381 - val_accuracy: 0.7957 - 713ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4355 - accuracy: 0.7939 - val_loss: 0.4393 - val_accuracy: 0.7959 - 723ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4348 - accuracy: 0.7958 - val_loss: 0.4391 - val_accuracy: 0.7973 - 675ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4340 - accuracy: 0.7976 - val_loss: 0.4416 - val_accuracy: 0.7935 - 711ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4334 - accuracy: 0.7963 - val_loss: 0.4393 - val_accuracy: 0.7970 - 705ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4341 - accuracy: 0.7960 - val_loss: 0.4358 - val_accuracy: 0.7994 - 720ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4330 - accuracy: 0.7995 - val_loss: 0.4390 - val_accuracy: 0.7970 - 782ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4323 - accuracy: 0.7980 - val_loss: 0.4369 - val_accuracy: 0.7961 - 735ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4317 - accuracy: 0.7990 - val_loss: 0.4390 - val_accuracy: 0.7964 - 660ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4317 - accuracy: 0.7992 - val_loss: 0.4372 - val_accuracy: 0.7973 - 710ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4323 - accuracy: 0.7976 - val_loss: 0.4389 - val_accuracy: 0.7986 - 710ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4434 - val_accuracy: 0.7977 - 805ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4313 - accuracy: 0.7992 - val_loss: 0.4416 - val_accuracy: 0.8002 - 891ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4321 - accuracy: 0.7993 - val_loss: 0.4404 - val_accuracy: 0.7969 - 731ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4302 - accuracy: 0.7996 - val_loss: 0.4383 - val_accuracy: 0.7986 - 715ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4308 - accuracy: 0.7972 - val_loss: 0.4383 - val_accuracy: 0.8021 - 640ms/epoch - 7ms/step\n",
      "Epoch 28: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "98/98 - 3s - loss: 0.5824 - accuracy: 0.7159 - val_loss: 0.5230 - val_accuracy: 0.7623 - 3s/epoch - 28ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.4931 - accuracy: 0.7656 - val_loss: 0.4871 - val_accuracy: 0.7716 - 716ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4665 - accuracy: 0.7789 - val_loss: 0.4726 - val_accuracy: 0.7837 - 718ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4548 - accuracy: 0.7864 - val_loss: 0.4590 - val_accuracy: 0.7868 - 700ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4501 - accuracy: 0.7887 - val_loss: 0.4504 - val_accuracy: 0.7917 - 720ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4454 - accuracy: 0.7876 - val_loss: 0.4524 - val_accuracy: 0.7906 - 680ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4447 - accuracy: 0.7916 - val_loss: 0.4497 - val_accuracy: 0.7908 - 680ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4447 - accuracy: 0.7891 - val_loss: 0.4417 - val_accuracy: 0.7956 - 665ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4400 - accuracy: 0.7928 - val_loss: 0.4440 - val_accuracy: 0.7901 - 666ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4394 - accuracy: 0.7913 - val_loss: 0.4399 - val_accuracy: 0.7946 - 789ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4402 - accuracy: 0.7931 - val_loss: 0.4383 - val_accuracy: 0.7911 - 703ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4367 - accuracy: 0.7962 - val_loss: 0.4428 - val_accuracy: 0.7932 - 666ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4366 - accuracy: 0.7936 - val_loss: 0.4410 - val_accuracy: 0.7989 - 674ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4358 - accuracy: 0.7954 - val_loss: 0.4398 - val_accuracy: 0.7949 - 708ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4338 - accuracy: 0.7960 - val_loss: 0.4418 - val_accuracy: 0.7957 - 773ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4335 - accuracy: 0.7973 - val_loss: 0.4402 - val_accuracy: 0.7996 - 682ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4406 - val_accuracy: 0.7941 - 716ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4335 - accuracy: 0.7958 - val_loss: 0.4380 - val_accuracy: 0.7954 - 742ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4322 - accuracy: 0.7980 - val_loss: 0.4420 - val_accuracy: 0.7949 - 705ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4339 - accuracy: 0.7971 - val_loss: 0.4368 - val_accuracy: 0.7940 - 705ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4321 - accuracy: 0.7984 - val_loss: 0.4372 - val_accuracy: 0.7970 - 695ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4311 - accuracy: 0.7984 - val_loss: 0.4388 - val_accuracy: 0.7964 - 691ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4301 - accuracy: 0.7988 - val_loss: 0.4382 - val_accuracy: 0.7980 - 708ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4299 - accuracy: 0.7985 - val_loss: 0.4371 - val_accuracy: 0.7961 - 720ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4318 - accuracy: 0.7984 - val_loss: 0.4371 - val_accuracy: 0.7965 - 636ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4306 - accuracy: 0.7977 - val_loss: 0.4370 - val_accuracy: 0.7972 - 759ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4309 - accuracy: 0.7984 - val_loss: 0.4377 - val_accuracy: 0.7951 - 722ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4294 - accuracy: 0.7994 - val_loss: 0.4404 - val_accuracy: 0.7946 - 682ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4308 - accuracy: 0.7970 - val_loss: 0.4388 - val_accuracy: 0.7970 - 676ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4301 - accuracy: 0.7981 - val_loss: 0.4383 - val_accuracy: 0.7956 - 708ms/epoch - 7ms/step\n",
      "Epoch 30: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "98/98 - 4s - loss: 0.5720 - accuracy: 0.7269 - val_loss: 0.5166 - val_accuracy: 0.7634 - 4s/epoch - 40ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.4894 - accuracy: 0.7704 - val_loss: 0.4759 - val_accuracy: 0.7769 - 770ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4619 - accuracy: 0.7809 - val_loss: 0.4608 - val_accuracy: 0.7884 - 727ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4523 - accuracy: 0.7846 - val_loss: 0.4566 - val_accuracy: 0.7844 - 665ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4439 - accuracy: 0.7906 - val_loss: 0.4501 - val_accuracy: 0.7911 - 711ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4420 - accuracy: 0.7924 - val_loss: 0.4489 - val_accuracy: 0.7909 - 680ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4418 - accuracy: 0.7912 - val_loss: 0.4474 - val_accuracy: 0.7919 - 740ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4385 - accuracy: 0.7909 - val_loss: 0.4404 - val_accuracy: 0.8015 - 777ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4378 - accuracy: 0.7973 - val_loss: 0.4380 - val_accuracy: 0.7951 - 700ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4339 - accuracy: 0.7962 - val_loss: 0.4459 - val_accuracy: 0.7959 - 708ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.4436 - val_accuracy: 0.7938 - 799ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.4407 - val_accuracy: 0.7964 - 681ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4341 - accuracy: 0.7973 - val_loss: 0.4403 - val_accuracy: 0.7965 - 773ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4337 - accuracy: 0.7976 - val_loss: 0.4397 - val_accuracy: 0.7981 - 694ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4326 - accuracy: 0.7973 - val_loss: 0.4393 - val_accuracy: 0.7953 - 699ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4319 - accuracy: 0.7992 - val_loss: 0.4401 - val_accuracy: 0.7978 - 707ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4318 - accuracy: 0.7985 - val_loss: 0.4398 - val_accuracy: 0.7956 - 682ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4307 - accuracy: 0.7984 - val_loss: 0.4390 - val_accuracy: 0.7940 - 700ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.4406 - val_accuracy: 0.7953 - 694ms/epoch - 7ms/step\n",
      "Epoch 19: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "98/98 - 2s - loss: 0.5805 - accuracy: 0.7243 - val_loss: 0.5197 - val_accuracy: 0.7630 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.4987 - accuracy: 0.7694 - val_loss: 0.4783 - val_accuracy: 0.7769 - 896ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4671 - accuracy: 0.7769 - val_loss: 0.4650 - val_accuracy: 0.7817 - 876ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4560 - accuracy: 0.7842 - val_loss: 0.4616 - val_accuracy: 0.7860 - 814ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4498 - accuracy: 0.7864 - val_loss: 0.4572 - val_accuracy: 0.7892 - 792ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4496 - accuracy: 0.7892 - val_loss: 0.4493 - val_accuracy: 0.7916 - 760ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4452 - accuracy: 0.7895 - val_loss: 0.4509 - val_accuracy: 0.7924 - 877ms/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4394 - accuracy: 0.7948 - val_loss: 0.4439 - val_accuracy: 0.7935 - 760ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.4425 - val_accuracy: 0.7922 - 875ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4369 - accuracy: 0.7929 - val_loss: 0.4420 - val_accuracy: 0.7965 - 739ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4384 - accuracy: 0.7927 - val_loss: 0.4438 - val_accuracy: 0.7927 - 703ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4372 - accuracy: 0.7950 - val_loss: 0.4428 - val_accuracy: 0.7884 - 704ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4372 - accuracy: 0.7944 - val_loss: 0.4438 - val_accuracy: 0.7935 - 674ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4330 - accuracy: 0.7998 - val_loss: 0.4410 - val_accuracy: 0.7962 - 710ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.4415 - val_accuracy: 0.7980 - 678ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4337 - accuracy: 0.7982 - val_loss: 0.4377 - val_accuracy: 0.7996 - 683ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4327 - accuracy: 0.7972 - val_loss: 0.4421 - val_accuracy: 0.7925 - 694ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4322 - accuracy: 0.7979 - val_loss: 0.4377 - val_accuracy: 0.7978 - 710ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4313 - accuracy: 0.7984 - val_loss: 0.4379 - val_accuracy: 0.7956 - 686ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4315 - accuracy: 0.7982 - val_loss: 0.4398 - val_accuracy: 0.7977 - 718ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4301 - accuracy: 0.7994 - val_loss: 0.4363 - val_accuracy: 0.7954 - 729ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4316 - accuracy: 0.7963 - val_loss: 0.4384 - val_accuracy: 0.7972 - 781ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4318 - accuracy: 0.7988 - val_loss: 0.4359 - val_accuracy: 0.8010 - 766ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4307 - accuracy: 0.7978 - val_loss: 0.4350 - val_accuracy: 0.7967 - 730ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4321 - accuracy: 0.7981 - val_loss: 0.4384 - val_accuracy: 0.7977 - 759ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4299 - accuracy: 0.8015 - val_loss: 0.4387 - val_accuracy: 0.7991 - 675ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4292 - accuracy: 0.7998 - val_loss: 0.4377 - val_accuracy: 0.7954 - 662ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4302 - accuracy: 0.7998 - val_loss: 0.4396 - val_accuracy: 0.7969 - 725ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4289 - accuracy: 0.7991 - val_loss: 0.4359 - val_accuracy: 0.7970 - 629ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4292 - accuracy: 0.7982 - val_loss: 0.4358 - val_accuracy: 0.7991 - 701ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4289 - accuracy: 0.7997 - val_loss: 0.4412 - val_accuracy: 0.7959 - 728ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4283 - accuracy: 0.8008 - val_loss: 0.4382 - val_accuracy: 0.7986 - 737ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4280 - accuracy: 0.7998 - val_loss: 0.4346 - val_accuracy: 0.7989 - 722ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4305 - accuracy: 0.7982 - val_loss: 0.4380 - val_accuracy: 0.7969 - 763ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4284 - accuracy: 0.7979 - val_loss: 0.4373 - val_accuracy: 0.7964 - 698ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4293 - accuracy: 0.7992 - val_loss: 0.4356 - val_accuracy: 0.7978 - 691ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4283 - accuracy: 0.7995 - val_loss: 0.4364 - val_accuracy: 0.8005 - 787ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4281 - accuracy: 0.7991 - val_loss: 0.4334 - val_accuracy: 0.7985 - 799ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4278 - accuracy: 0.7996 - val_loss: 0.4356 - val_accuracy: 0.7996 - 721ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.4272 - accuracy: 0.8008 - val_loss: 0.4375 - val_accuracy: 0.7980 - 776ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.4270 - accuracy: 0.7998 - val_loss: 0.4378 - val_accuracy: 0.7985 - 756ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "98/98 - 1s - loss: 0.4278 - accuracy: 0.8009 - val_loss: 0.4368 - val_accuracy: 0.7994 - 732ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "98/98 - 1s - loss: 0.4293 - accuracy: 0.7999 - val_loss: 0.4379 - val_accuracy: 0.7964 - 687ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "98/98 - 1s - loss: 0.4277 - accuracy: 0.7994 - val_loss: 0.4347 - val_accuracy: 0.7978 - 752ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "98/98 - 1s - loss: 0.4275 - accuracy: 0.8013 - val_loss: 0.4363 - val_accuracy: 0.7962 - 687ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "98/98 - 1s - loss: 0.4284 - accuracy: 0.7983 - val_loss: 0.4362 - val_accuracy: 0.7986 - 680ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "98/98 - 1s - loss: 0.4281 - accuracy: 0.7996 - val_loss: 0.4357 - val_accuracy: 0.8001 - 702ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "98/98 - 1s - loss: 0.4272 - accuracy: 0.8006 - val_loss: 0.4324 - val_accuracy: 0.8037 - 695ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "98/98 - 1s - loss: 0.4265 - accuracy: 0.8014 - val_loss: 0.4352 - val_accuracy: 0.7978 - 759ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "98/98 - 1s - loss: 0.4266 - accuracy: 0.8012 - val_loss: 0.4324 - val_accuracy: 0.7993 - 690ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "98/98 - 1s - loss: 0.4254 - accuracy: 0.8018 - val_loss: 0.4353 - val_accuracy: 0.7994 - 693ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "98/98 - 1s - loss: 0.4266 - accuracy: 0.8008 - val_loss: 0.4357 - val_accuracy: 0.7967 - 659ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "98/98 - 1s - loss: 0.4274 - accuracy: 0.8002 - val_loss: 0.4343 - val_accuracy: 0.8002 - 721ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.8019 - val_loss: 0.4356 - val_accuracy: 0.7967 - 751ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "98/98 - 1s - loss: 0.4261 - accuracy: 0.8008 - val_loss: 0.4390 - val_accuracy: 0.7938 - 689ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "98/98 - 1s - loss: 0.4273 - accuracy: 0.8000 - val_loss: 0.4331 - val_accuracy: 0.8005 - 715ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "98/98 - 1s - loss: 0.4274 - accuracy: 0.7994 - val_loss: 0.4336 - val_accuracy: 0.7994 - 730ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.8009 - val_loss: 0.4357 - val_accuracy: 0.7969 - 711ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "98/98 - 1s - loss: 0.4271 - accuracy: 0.8005 - val_loss: 0.4315 - val_accuracy: 0.8013 - 764ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "98/98 - 1s - loss: 0.4261 - accuracy: 0.7992 - val_loss: 0.4362 - val_accuracy: 0.7962 - 686ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.7976 - val_loss: 0.4383 - val_accuracy: 0.7965 - 738ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "98/98 - 1s - loss: 0.4272 - accuracy: 0.8000 - val_loss: 0.4354 - val_accuracy: 0.7943 - 703ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "98/98 - 1s - loss: 0.4260 - accuracy: 0.7998 - val_loss: 0.4336 - val_accuracy: 0.7986 - 720ms/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "98/98 - 1s - loss: 0.4258 - accuracy: 0.8005 - val_loss: 0.4369 - val_accuracy: 0.7991 - 746ms/epoch - 8ms/step\n",
      "Epoch 65/100\n",
      "98/98 - 1s - loss: 0.4270 - accuracy: 0.8008 - val_loss: 0.4330 - val_accuracy: 0.7981 - 747ms/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "98/98 - 1s - loss: 0.4266 - accuracy: 0.7998 - val_loss: 0.4344 - val_accuracy: 0.8015 - 736ms/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "98/98 - 1s - loss: 0.4260 - accuracy: 0.8002 - val_loss: 0.4348 - val_accuracy: 0.7986 - 704ms/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "98/98 - 1s - loss: 0.4266 - accuracy: 0.7993 - val_loss: 0.4352 - val_accuracy: 0.7989 - 661ms/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "98/98 - 1s - loss: 0.4264 - accuracy: 0.7983 - val_loss: 0.4319 - val_accuracy: 0.8004 - 740ms/epoch - 8ms/step\n",
      "Epoch 69: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "98/98 - 3s - loss: 0.5870 - accuracy: 0.7103 - val_loss: 0.5158 - val_accuracy: 0.7639 - 3s/epoch - 32ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.4943 - accuracy: 0.7648 - val_loss: 0.4839 - val_accuracy: 0.7710 - 760ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4702 - accuracy: 0.7755 - val_loss: 0.4649 - val_accuracy: 0.7806 - 700ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4587 - accuracy: 0.7807 - val_loss: 0.4614 - val_accuracy: 0.7847 - 710ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4502 - accuracy: 0.7848 - val_loss: 0.4591 - val_accuracy: 0.7861 - 791ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4451 - accuracy: 0.7897 - val_loss: 0.4557 - val_accuracy: 0.7855 - 706ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4430 - accuracy: 0.7916 - val_loss: 0.4513 - val_accuracy: 0.7876 - 750ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4406 - accuracy: 0.7900 - val_loss: 0.4451 - val_accuracy: 0.7914 - 702ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.4444 - val_accuracy: 0.7962 - 791ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4371 - accuracy: 0.7940 - val_loss: 0.4438 - val_accuracy: 0.7908 - 763ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4369 - accuracy: 0.7960 - val_loss: 0.4449 - val_accuracy: 0.7925 - 771ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4368 - accuracy: 0.7976 - val_loss: 0.4438 - val_accuracy: 0.7913 - 682ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4348 - accuracy: 0.7984 - val_loss: 0.4399 - val_accuracy: 0.7948 - 710ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4357 - accuracy: 0.7963 - val_loss: 0.4443 - val_accuracy: 0.7927 - 762ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4343 - accuracy: 0.7967 - val_loss: 0.4402 - val_accuracy: 0.7933 - 719ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4336 - accuracy: 0.7957 - val_loss: 0.4409 - val_accuracy: 0.7967 - 664ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4343 - accuracy: 0.7976 - val_loss: 0.4409 - val_accuracy: 0.7959 - 703ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4331 - accuracy: 0.7978 - val_loss: 0.4394 - val_accuracy: 0.7991 - 734ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4317 - accuracy: 0.7978 - val_loss: 0.4394 - val_accuracy: 0.7991 - 737ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4321 - accuracy: 0.7982 - val_loss: 0.4374 - val_accuracy: 0.7970 - 719ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4331 - accuracy: 0.7987 - val_loss: 0.4362 - val_accuracy: 0.7994 - 756ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4304 - accuracy: 0.8000 - val_loss: 0.4382 - val_accuracy: 0.7973 - 707ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4302 - accuracy: 0.7980 - val_loss: 0.4393 - val_accuracy: 0.7997 - 761ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4296 - accuracy: 0.7989 - val_loss: 0.4411 - val_accuracy: 0.7967 - 696ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4303 - accuracy: 0.8005 - val_loss: 0.4365 - val_accuracy: 0.7985 - 766ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4301 - accuracy: 0.7984 - val_loss: 0.4379 - val_accuracy: 0.7940 - 697ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4298 - accuracy: 0.7983 - val_loss: 0.4381 - val_accuracy: 0.7959 - 708ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4291 - accuracy: 0.7993 - val_loss: 0.4370 - val_accuracy: 0.7996 - 726ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4300 - accuracy: 0.7992 - val_loss: 0.4391 - val_accuracy: 0.7975 - 730ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4290 - accuracy: 0.8000 - val_loss: 0.4395 - val_accuracy: 0.7959 - 798ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4286 - accuracy: 0.7996 - val_loss: 0.4374 - val_accuracy: 0.8010 - 737ms/epoch - 8ms/step\n",
      "Epoch 31: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "98/98 - 3s - loss: 0.6196 - accuracy: 0.6710 - val_loss: 0.5316 - val_accuracy: 0.7636 - 3s/epoch - 30ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.4918 - accuracy: 0.7732 - val_loss: 0.4761 - val_accuracy: 0.7820 - 838ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4683 - accuracy: 0.7825 - val_loss: 0.4636 - val_accuracy: 0.7877 - 771ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4557 - accuracy: 0.7834 - val_loss: 0.4556 - val_accuracy: 0.7853 - 778ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4526 - accuracy: 0.7861 - val_loss: 0.4570 - val_accuracy: 0.7852 - 732ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4476 - accuracy: 0.7899 - val_loss: 0.4531 - val_accuracy: 0.7853 - 698ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4446 - accuracy: 0.7881 - val_loss: 0.4501 - val_accuracy: 0.7913 - 708ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4426 - accuracy: 0.7913 - val_loss: 0.4516 - val_accuracy: 0.7869 - 734ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4414 - accuracy: 0.7905 - val_loss: 0.4452 - val_accuracy: 0.7935 - 828ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4397 - accuracy: 0.7933 - val_loss: 0.4473 - val_accuracy: 0.7935 - 773ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4380 - accuracy: 0.7945 - val_loss: 0.4462 - val_accuracy: 0.7927 - 734ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4406 - accuracy: 0.7911 - val_loss: 0.4453 - val_accuracy: 0.7909 - 830ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4352 - accuracy: 0.7952 - val_loss: 0.4398 - val_accuracy: 0.7921 - 711ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4376 - accuracy: 0.7946 - val_loss: 0.4458 - val_accuracy: 0.7953 - 681ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4371 - accuracy: 0.7942 - val_loss: 0.4408 - val_accuracy: 0.7961 - 743ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4359 - accuracy: 0.7953 - val_loss: 0.4423 - val_accuracy: 0.7929 - 840ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4366 - accuracy: 0.7926 - val_loss: 0.4406 - val_accuracy: 0.7994 - 683ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.4437 - val_accuracy: 0.7948 - 790ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4342 - accuracy: 0.7961 - val_loss: 0.4425 - val_accuracy: 0.7957 - 716ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4350 - accuracy: 0.7972 - val_loss: 0.4402 - val_accuracy: 0.7989 - 799ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4331 - accuracy: 0.7959 - val_loss: 0.4424 - val_accuracy: 0.7965 - 729ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4371 - val_accuracy: 0.7975 - 711ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4319 - accuracy: 0.7950 - val_loss: 0.4386 - val_accuracy: 0.7924 - 754ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4324 - accuracy: 0.7981 - val_loss: 0.4422 - val_accuracy: 0.7953 - 791ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4326 - accuracy: 0.7958 - val_loss: 0.4403 - val_accuracy: 0.7900 - 759ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4324 - accuracy: 0.7963 - val_loss: 0.4390 - val_accuracy: 0.7962 - 697ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4322 - accuracy: 0.7952 - val_loss: 0.4427 - val_accuracy: 0.7957 - 719ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4329 - accuracy: 0.7984 - val_loss: 0.4363 - val_accuracy: 0.7940 - 702ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4320 - accuracy: 0.7973 - val_loss: 0.4376 - val_accuracy: 0.7954 - 723ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4306 - accuracy: 0.7971 - val_loss: 0.4412 - val_accuracy: 0.7946 - 714ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4296 - accuracy: 0.7962 - val_loss: 0.4379 - val_accuracy: 0.7962 - 718ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4296 - accuracy: 0.7970 - val_loss: 0.4357 - val_accuracy: 0.7988 - 729ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4321 - accuracy: 0.7972 - val_loss: 0.4423 - val_accuracy: 0.7930 - 709ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4300 - accuracy: 0.7989 - val_loss: 0.4364 - val_accuracy: 0.7943 - 753ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4293 - accuracy: 0.7978 - val_loss: 0.4390 - val_accuracy: 0.7973 - 751ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4290 - accuracy: 0.7987 - val_loss: 0.4387 - val_accuracy: 0.7988 - 751ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.4388 - val_accuracy: 0.7962 - 669ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4292 - accuracy: 0.7983 - val_loss: 0.4379 - val_accuracy: 0.7964 - 717ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4312 - accuracy: 0.7990 - val_loss: 0.4373 - val_accuracy: 0.7948 - 784ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.4311 - accuracy: 0.7958 - val_loss: 0.4377 - val_accuracy: 0.7975 - 790ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.4292 - accuracy: 0.7974 - val_loss: 0.4368 - val_accuracy: 0.7957 - 713ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "98/98 - 1s - loss: 0.4288 - accuracy: 0.7990 - val_loss: 0.4387 - val_accuracy: 0.8001 - 670ms/epoch - 7ms/step\n",
      "Epoch 42: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "98/98 - 4s - loss: 0.5697 - accuracy: 0.7268 - val_loss: 0.5167 - val_accuracy: 0.7612 - 4s/epoch - 45ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.4869 - accuracy: 0.7673 - val_loss: 0.4769 - val_accuracy: 0.7751 - 823ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4618 - accuracy: 0.7783 - val_loss: 0.4618 - val_accuracy: 0.7772 - 744ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4548 - accuracy: 0.7843 - val_loss: 0.4548 - val_accuracy: 0.7879 - 693ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4488 - accuracy: 0.7877 - val_loss: 0.4562 - val_accuracy: 0.7919 - 710ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4482 - accuracy: 0.7891 - val_loss: 0.4494 - val_accuracy: 0.7889 - 733ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4436 - accuracy: 0.7904 - val_loss: 0.4523 - val_accuracy: 0.7869 - 736ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4428 - accuracy: 0.7918 - val_loss: 0.4522 - val_accuracy: 0.7933 - 687ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4439 - accuracy: 0.7913 - val_loss: 0.4462 - val_accuracy: 0.7900 - 727ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4404 - accuracy: 0.7904 - val_loss: 0.4492 - val_accuracy: 0.7858 - 864ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4391 - accuracy: 0.7915 - val_loss: 0.4484 - val_accuracy: 0.7983 - 726ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4379 - accuracy: 0.7938 - val_loss: 0.4471 - val_accuracy: 0.7911 - 778ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4393 - accuracy: 0.7940 - val_loss: 0.4467 - val_accuracy: 0.7938 - 844ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4368 - accuracy: 0.7933 - val_loss: 0.4459 - val_accuracy: 0.7935 - 701ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4383 - accuracy: 0.7924 - val_loss: 0.4446 - val_accuracy: 0.7919 - 702ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4364 - accuracy: 0.7944 - val_loss: 0.4429 - val_accuracy: 0.7954 - 870ms/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4352 - accuracy: 0.7942 - val_loss: 0.4430 - val_accuracy: 0.7938 - 787ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4346 - accuracy: 0.7946 - val_loss: 0.4434 - val_accuracy: 0.7916 - 846ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4344 - accuracy: 0.7964 - val_loss: 0.4419 - val_accuracy: 0.7935 - 706ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4320 - accuracy: 0.7958 - val_loss: 0.4450 - val_accuracy: 0.7957 - 831ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4330 - accuracy: 0.7980 - val_loss: 0.4438 - val_accuracy: 0.7893 - 678ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4326 - accuracy: 0.7971 - val_loss: 0.4437 - val_accuracy: 0.7924 - 753ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4319 - accuracy: 0.7948 - val_loss: 0.4419 - val_accuracy: 0.7953 - 684ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.4412 - val_accuracy: 0.7961 - 724ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4298 - accuracy: 0.7968 - val_loss: 0.4399 - val_accuracy: 0.7914 - 905ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4306 - accuracy: 0.7977 - val_loss: 0.4378 - val_accuracy: 0.7973 - 701ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4317 - accuracy: 0.7965 - val_loss: 0.4426 - val_accuracy: 0.7945 - 696ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4308 - accuracy: 0.7973 - val_loss: 0.4368 - val_accuracy: 0.7962 - 701ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4294 - accuracy: 0.7984 - val_loss: 0.4353 - val_accuracy: 0.7978 - 716ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4321 - accuracy: 0.7978 - val_loss: 0.4419 - val_accuracy: 0.8001 - 810ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4304 - accuracy: 0.7964 - val_loss: 0.4398 - val_accuracy: 0.7922 - 744ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4309 - accuracy: 0.7988 - val_loss: 0.4382 - val_accuracy: 0.7965 - 723ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4305 - accuracy: 0.7976 - val_loss: 0.4372 - val_accuracy: 0.7919 - 725ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4296 - accuracy: 0.7980 - val_loss: 0.4401 - val_accuracy: 0.7943 - 739ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4363 - val_accuracy: 0.7967 - 704ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4314 - accuracy: 0.7938 - val_loss: 0.4368 - val_accuracy: 0.7962 - 722ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4314 - accuracy: 0.7970 - val_loss: 0.4368 - val_accuracy: 0.7975 - 716ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4305 - accuracy: 0.7971 - val_loss: 0.4402 - val_accuracy: 0.7970 - 742ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4287 - accuracy: 0.7974 - val_loss: 0.4376 - val_accuracy: 0.7954 - 699ms/epoch - 7ms/step\n",
      "Epoch 39: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "98/98 - 4s - loss: 0.5815 - accuracy: 0.7195 - val_loss: 0.5254 - val_accuracy: 0.7601 - 4s/epoch - 39ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.5026 - accuracy: 0.7615 - val_loss: 0.4845 - val_accuracy: 0.7625 - 807ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4747 - accuracy: 0.7632 - val_loss: 0.4667 - val_accuracy: 0.7692 - 736ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4617 - accuracy: 0.7693 - val_loss: 0.4679 - val_accuracy: 0.7780 - 707ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4559 - accuracy: 0.7820 - val_loss: 0.4550 - val_accuracy: 0.7849 - 710ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4513 - accuracy: 0.7874 - val_loss: 0.4503 - val_accuracy: 0.7885 - 741ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4466 - accuracy: 0.7913 - val_loss: 0.4468 - val_accuracy: 0.7887 - 737ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4440 - accuracy: 0.7920 - val_loss: 0.4452 - val_accuracy: 0.7906 - 727ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4393 - accuracy: 0.7940 - val_loss: 0.4441 - val_accuracy: 0.7925 - 849ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4380 - accuracy: 0.7949 - val_loss: 0.4502 - val_accuracy: 0.7895 - 724ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4372 - accuracy: 0.7955 - val_loss: 0.4467 - val_accuracy: 0.7932 - 690ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4355 - accuracy: 0.7970 - val_loss: 0.4431 - val_accuracy: 0.7932 - 667ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4366 - accuracy: 0.7978 - val_loss: 0.4414 - val_accuracy: 0.7946 - 697ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4347 - accuracy: 0.7998 - val_loss: 0.4397 - val_accuracy: 0.7988 - 831ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4340 - accuracy: 0.8006 - val_loss: 0.4440 - val_accuracy: 0.7959 - 780ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4350 - accuracy: 0.7994 - val_loss: 0.4384 - val_accuracy: 0.7967 - 683ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4337 - accuracy: 0.8010 - val_loss: 0.4409 - val_accuracy: 0.7949 - 680ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4328 - accuracy: 0.7994 - val_loss: 0.4376 - val_accuracy: 0.7954 - 672ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.4380 - val_accuracy: 0.7954 - 744ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4328 - accuracy: 0.7992 - val_loss: 0.4400 - val_accuracy: 0.7980 - 780ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4314 - accuracy: 0.8005 - val_loss: 0.4408 - val_accuracy: 0.7997 - 750ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4320 - accuracy: 0.8006 - val_loss: 0.4354 - val_accuracy: 0.7977 - 709ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4291 - accuracy: 0.8010 - val_loss: 0.4372 - val_accuracy: 0.7994 - 742ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4318 - accuracy: 0.8008 - val_loss: 0.4406 - val_accuracy: 0.7949 - 680ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4321 - accuracy: 0.7995 - val_loss: 0.4394 - val_accuracy: 0.7988 - 788ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4298 - accuracy: 0.8012 - val_loss: 0.4365 - val_accuracy: 0.7969 - 741ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4288 - accuracy: 0.8010 - val_loss: 0.4392 - val_accuracy: 0.7977 - 708ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4314 - accuracy: 0.7994 - val_loss: 0.4349 - val_accuracy: 0.8029 - 719ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4307 - accuracy: 0.8002 - val_loss: 0.4366 - val_accuracy: 0.7964 - 722ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4313 - accuracy: 0.8002 - val_loss: 0.4360 - val_accuracy: 0.7997 - 742ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4300 - accuracy: 0.7994 - val_loss: 0.4387 - val_accuracy: 0.7980 - 798ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4302 - accuracy: 0.8000 - val_loss: 0.4393 - val_accuracy: 0.7972 - 768ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4288 - accuracy: 0.8026 - val_loss: 0.4388 - val_accuracy: 0.7962 - 701ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4281 - accuracy: 0.8001 - val_loss: 0.4368 - val_accuracy: 0.7993 - 778ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4295 - accuracy: 0.8004 - val_loss: 0.4338 - val_accuracy: 0.7991 - 725ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4292 - accuracy: 0.8004 - val_loss: 0.4345 - val_accuracy: 0.7994 - 750ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4303 - accuracy: 0.8016 - val_loss: 0.4332 - val_accuracy: 0.8001 - 678ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4284 - accuracy: 0.8007 - val_loss: 0.4385 - val_accuracy: 0.7969 - 719ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4293 - accuracy: 0.7991 - val_loss: 0.4355 - val_accuracy: 0.8012 - 767ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.4295 - accuracy: 0.8024 - val_loss: 0.4362 - val_accuracy: 0.7969 - 755ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.4284 - accuracy: 0.8009 - val_loss: 0.4402 - val_accuracy: 0.7945 - 886ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "98/98 - 1s - loss: 0.4290 - accuracy: 0.7997 - val_loss: 0.4385 - val_accuracy: 0.7956 - 792ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "98/98 - 1s - loss: 0.4290 - accuracy: 0.8002 - val_loss: 0.4406 - val_accuracy: 0.7962 - 736ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "98/98 - 1s - loss: 0.4278 - accuracy: 0.8009 - val_loss: 0.4410 - val_accuracy: 0.7959 - 768ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "98/98 - 1s - loss: 0.4288 - accuracy: 0.8006 - val_loss: 0.4371 - val_accuracy: 0.7986 - 734ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "98/98 - 1s - loss: 0.4296 - accuracy: 0.7990 - val_loss: 0.4333 - val_accuracy: 0.7993 - 768ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "98/98 - 1s - loss: 0.4294 - accuracy: 0.8008 - val_loss: 0.4371 - val_accuracy: 0.8007 - 722ms/epoch - 7ms/step\n",
      "Epoch 47: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "98/98 - 3s - loss: 0.5838 - accuracy: 0.7238 - val_loss: 0.5103 - val_accuracy: 0.7626 - 3s/epoch - 32ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.4874 - accuracy: 0.7706 - val_loss: 0.4717 - val_accuracy: 0.7737 - 735ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4652 - accuracy: 0.7790 - val_loss: 0.4596 - val_accuracy: 0.7836 - 679ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4538 - accuracy: 0.7844 - val_loss: 0.4588 - val_accuracy: 0.7865 - 669ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4507 - accuracy: 0.7852 - val_loss: 0.4523 - val_accuracy: 0.7938 - 701ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.4581 - val_accuracy: 0.7853 - 737ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4461 - accuracy: 0.7889 - val_loss: 0.4492 - val_accuracy: 0.7916 - 721ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4414 - accuracy: 0.7919 - val_loss: 0.4438 - val_accuracy: 0.7938 - 717ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4401 - accuracy: 0.7932 - val_loss: 0.4466 - val_accuracy: 0.7924 - 727ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4388 - accuracy: 0.7924 - val_loss: 0.4406 - val_accuracy: 0.7917 - 740ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4367 - accuracy: 0.7927 - val_loss: 0.4432 - val_accuracy: 0.7961 - 685ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4367 - accuracy: 0.7941 - val_loss: 0.4443 - val_accuracy: 0.7903 - 654ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4346 - accuracy: 0.7935 - val_loss: 0.4394 - val_accuracy: 0.7997 - 687ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4354 - accuracy: 0.7950 - val_loss: 0.4415 - val_accuracy: 0.7959 - 684ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4344 - accuracy: 0.7964 - val_loss: 0.4384 - val_accuracy: 0.7957 - 734ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4355 - accuracy: 0.7951 - val_loss: 0.4419 - val_accuracy: 0.7957 - 640ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4323 - accuracy: 0.7963 - val_loss: 0.4413 - val_accuracy: 0.7885 - 660ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4321 - accuracy: 0.7953 - val_loss: 0.4418 - val_accuracy: 0.7965 - 658ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4319 - accuracy: 0.7984 - val_loss: 0.4413 - val_accuracy: 0.7940 - 704ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4314 - accuracy: 0.7958 - val_loss: 0.4379 - val_accuracy: 0.7941 - 697ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4308 - accuracy: 0.7945 - val_loss: 0.4380 - val_accuracy: 0.7993 - 725ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4325 - accuracy: 0.7968 - val_loss: 0.4416 - val_accuracy: 0.7919 - 697ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4309 - accuracy: 0.7978 - val_loss: 0.4362 - val_accuracy: 0.7969 - 865ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4300 - accuracy: 0.7976 - val_loss: 0.4393 - val_accuracy: 0.7959 - 701ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4311 - accuracy: 0.7959 - val_loss: 0.4420 - val_accuracy: 0.7951 - 694ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4303 - accuracy: 0.7982 - val_loss: 0.4391 - val_accuracy: 0.7967 - 648ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4296 - accuracy: 0.7974 - val_loss: 0.4384 - val_accuracy: 0.7959 - 728ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4294 - accuracy: 0.8000 - val_loss: 0.4418 - val_accuracy: 0.7938 - 651ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4290 - accuracy: 0.7980 - val_loss: 0.4366 - val_accuracy: 0.7943 - 724ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4305 - accuracy: 0.7982 - val_loss: 0.4362 - val_accuracy: 0.7975 - 731ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4307 - accuracy: 0.7968 - val_loss: 0.4402 - val_accuracy: 0.7922 - 708ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4296 - accuracy: 0.7985 - val_loss: 0.4392 - val_accuracy: 0.7943 - 710ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4287 - accuracy: 0.7978 - val_loss: 0.4369 - val_accuracy: 0.7956 - 764ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4298 - accuracy: 0.7970 - val_loss: 0.4347 - val_accuracy: 0.7970 - 832ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.4351 - val_accuracy: 0.7946 - 773ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4272 - accuracy: 0.7995 - val_loss: 0.4359 - val_accuracy: 0.7996 - 678ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4280 - accuracy: 0.7981 - val_loss: 0.4374 - val_accuracy: 0.7972 - 750ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.4301 - accuracy: 0.7979 - val_loss: 0.4355 - val_accuracy: 0.7977 - 708ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.4291 - accuracy: 0.7995 - val_loss: 0.4336 - val_accuracy: 0.7983 - 684ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.4280 - accuracy: 0.7990 - val_loss: 0.4392 - val_accuracy: 0.7993 - 699ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.4275 - accuracy: 0.7995 - val_loss: 0.4345 - val_accuracy: 0.7983 - 734ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "98/98 - 1s - loss: 0.4281 - accuracy: 0.7997 - val_loss: 0.4342 - val_accuracy: 0.8018 - 710ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "98/98 - 1s - loss: 0.4269 - accuracy: 0.8012 - val_loss: 0.4351 - val_accuracy: 0.7975 - 722ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "98/98 - 1s - loss: 0.4267 - accuracy: 0.7981 - val_loss: 0.4350 - val_accuracy: 0.7951 - 710ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "98/98 - 1s - loss: 0.4283 - accuracy: 0.7988 - val_loss: 0.4329 - val_accuracy: 0.7980 - 730ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "98/98 - 1s - loss: 0.4284 - accuracy: 0.7999 - val_loss: 0.4386 - val_accuracy: 0.7969 - 786ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "98/98 - 1s - loss: 0.4271 - accuracy: 0.8005 - val_loss: 0.4370 - val_accuracy: 0.7972 - 711ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "98/98 - 1s - loss: 0.4286 - accuracy: 0.7990 - val_loss: 0.4337 - val_accuracy: 0.7969 - 769ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "98/98 - 1s - loss: 0.4278 - accuracy: 0.7991 - val_loss: 0.4379 - val_accuracy: 0.7962 - 756ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "98/98 - 1s - loss: 0.4259 - accuracy: 0.7990 - val_loss: 0.4353 - val_accuracy: 0.7993 - 731ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "98/98 - 1s - loss: 0.4283 - accuracy: 0.7989 - val_loss: 0.4378 - val_accuracy: 0.7930 - 840ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "98/98 - 1s - loss: 0.4269 - accuracy: 0.7991 - val_loss: 0.4341 - val_accuracy: 0.8033 - 712ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "98/98 - 1s - loss: 0.4272 - accuracy: 0.7994 - val_loss: 0.4365 - val_accuracy: 0.7972 - 762ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "98/98 - 1s - loss: 0.4262 - accuracy: 0.8002 - val_loss: 0.4375 - val_accuracy: 0.7972 - 684ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "98/98 - 1s - loss: 0.4270 - accuracy: 0.8004 - val_loss: 0.4346 - val_accuracy: 0.7970 - 728ms/epoch - 7ms/step\n",
      "Epoch 55: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "98/98 - 4s - loss: 0.5557 - accuracy: 0.7417 - val_loss: 0.5033 - val_accuracy: 0.7726 - 4s/epoch - 41ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.4826 - accuracy: 0.7747 - val_loss: 0.4755 - val_accuracy: 0.7759 - 1s/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.4642 - accuracy: 0.7809 - val_loss: 0.4620 - val_accuracy: 0.7828 - 730ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.4543 - accuracy: 0.7867 - val_loss: 0.4550 - val_accuracy: 0.7861 - 774ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.4495 - accuracy: 0.7850 - val_loss: 0.4512 - val_accuracy: 0.7871 - 731ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.4445 - accuracy: 0.7864 - val_loss: 0.4485 - val_accuracy: 0.7948 - 748ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.4399 - accuracy: 0.7893 - val_loss: 0.4473 - val_accuracy: 0.7889 - 778ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.4405 - accuracy: 0.7903 - val_loss: 0.4424 - val_accuracy: 0.7922 - 729ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.4383 - accuracy: 0.7910 - val_loss: 0.4433 - val_accuracy: 0.7937 - 701ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.4383 - accuracy: 0.7938 - val_loss: 0.4436 - val_accuracy: 0.7897 - 887ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.4362 - accuracy: 0.7935 - val_loss: 0.4419 - val_accuracy: 0.7884 - 829ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.4366 - accuracy: 0.7945 - val_loss: 0.4429 - val_accuracy: 0.7946 - 772ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.4341 - accuracy: 0.7954 - val_loss: 0.4390 - val_accuracy: 0.7962 - 810ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.4341 - accuracy: 0.7938 - val_loss: 0.4448 - val_accuracy: 0.7909 - 714ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.4333 - accuracy: 0.7958 - val_loss: 0.4408 - val_accuracy: 0.7954 - 719ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.4348 - accuracy: 0.7946 - val_loss: 0.4408 - val_accuracy: 0.7937 - 775ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.4327 - accuracy: 0.7972 - val_loss: 0.4421 - val_accuracy: 0.7905 - 771ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.4334 - accuracy: 0.7954 - val_loss: 0.4384 - val_accuracy: 0.7929 - 652ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.4319 - accuracy: 0.7958 - val_loss: 0.4432 - val_accuracy: 0.7943 - 713ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.4320 - accuracy: 0.7955 - val_loss: 0.4370 - val_accuracy: 0.7991 - 729ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.4298 - accuracy: 0.7977 - val_loss: 0.4403 - val_accuracy: 0.7951 - 690ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.4414 - val_accuracy: 0.7957 - 763ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.4284 - accuracy: 0.7970 - val_loss: 0.4347 - val_accuracy: 0.7996 - 832ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.4313 - accuracy: 0.7987 - val_loss: 0.4374 - val_accuracy: 0.7961 - 762ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.4406 - val_accuracy: 0.7953 - 695ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.4295 - accuracy: 0.7993 - val_loss: 0.4379 - val_accuracy: 0.7951 - 706ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.4306 - accuracy: 0.7976 - val_loss: 0.4315 - val_accuracy: 0.7985 - 725ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.4312 - accuracy: 0.7997 - val_loss: 0.4338 - val_accuracy: 0.7983 - 763ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.4294 - accuracy: 0.7982 - val_loss: 0.4396 - val_accuracy: 0.7935 - 730ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.4287 - accuracy: 0.8001 - val_loss: 0.4374 - val_accuracy: 0.8001 - 711ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.4297 - accuracy: 0.7999 - val_loss: 0.4334 - val_accuracy: 0.7972 - 631ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.4290 - accuracy: 0.7976 - val_loss: 0.4387 - val_accuracy: 0.7972 - 619ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.4297 - accuracy: 0.8002 - val_loss: 0.4335 - val_accuracy: 0.7957 - 679ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.4285 - accuracy: 0.8000 - val_loss: 0.4352 - val_accuracy: 0.7961 - 724ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.4286 - accuracy: 0.7988 - val_loss: 0.4384 - val_accuracy: 0.7957 - 819ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.4295 - accuracy: 0.7993 - val_loss: 0.4375 - val_accuracy: 0.7975 - 740ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.4267 - accuracy: 0.8002 - val_loss: 0.4329 - val_accuracy: 0.7953 - 702ms/epoch - 7ms/step\n",
      "Epoch 37: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.38906637833434393\n",
      "epi entropy:  0.38091853387400054\n",
      "\n",
      "dataset size:  0.9\n",
      "Epoch 1/100\n",
      "110/110 - 4s - loss: 0.5524 - accuracy: 0.7411 - val_loss: 0.5070 - val_accuracy: 0.7594 - 4s/epoch - 38ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4783 - accuracy: 0.7738 - val_loss: 0.4763 - val_accuracy: 0.7698 - 931ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4596 - accuracy: 0.7819 - val_loss: 0.4689 - val_accuracy: 0.7695 - 869ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4492 - accuracy: 0.7879 - val_loss: 0.4601 - val_accuracy: 0.7817 - 850ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4453 - accuracy: 0.7916 - val_loss: 0.4585 - val_accuracy: 0.7782 - 782ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4430 - accuracy: 0.7923 - val_loss: 0.4566 - val_accuracy: 0.7771 - 774ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4395 - accuracy: 0.7943 - val_loss: 0.4533 - val_accuracy: 0.7844 - 754ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4383 - accuracy: 0.7935 - val_loss: 0.4526 - val_accuracy: 0.7864 - 754ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4356 - accuracy: 0.7950 - val_loss: 0.4492 - val_accuracy: 0.7840 - 777ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4339 - accuracy: 0.7968 - val_loss: 0.4465 - val_accuracy: 0.7836 - 764ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4346 - accuracy: 0.7944 - val_loss: 0.4492 - val_accuracy: 0.7862 - 737ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4324 - accuracy: 0.7975 - val_loss: 0.4470 - val_accuracy: 0.7886 - 740ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4342 - accuracy: 0.7973 - val_loss: 0.4446 - val_accuracy: 0.7833 - 722ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4332 - accuracy: 0.7979 - val_loss: 0.4453 - val_accuracy: 0.7880 - 754ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4325 - accuracy: 0.7971 - val_loss: 0.4461 - val_accuracy: 0.7871 - 750ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4316 - accuracy: 0.7980 - val_loss: 0.4441 - val_accuracy: 0.7881 - 757ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4303 - accuracy: 0.7974 - val_loss: 0.4424 - val_accuracy: 0.7877 - 739ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4318 - accuracy: 0.8000 - val_loss: 0.4434 - val_accuracy: 0.7846 - 758ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4308 - accuracy: 0.8009 - val_loss: 0.4435 - val_accuracy: 0.7904 - 725ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4289 - accuracy: 0.7996 - val_loss: 0.4433 - val_accuracy: 0.7867 - 776ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4301 - accuracy: 0.7996 - val_loss: 0.4436 - val_accuracy: 0.7890 - 722ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4304 - accuracy: 0.8003 - val_loss: 0.4394 - val_accuracy: 0.7893 - 739ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4303 - accuracy: 0.7988 - val_loss: 0.4431 - val_accuracy: 0.7876 - 740ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4295 - accuracy: 0.7994 - val_loss: 0.4425 - val_accuracy: 0.7898 - 736ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4301 - accuracy: 0.7994 - val_loss: 0.4401 - val_accuracy: 0.7913 - 853ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4287 - accuracy: 0.7999 - val_loss: 0.4393 - val_accuracy: 0.7893 - 757ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4288 - accuracy: 0.8015 - val_loss: 0.4436 - val_accuracy: 0.7876 - 728ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4278 - accuracy: 0.8025 - val_loss: 0.4396 - val_accuracy: 0.7876 - 928ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4297 - accuracy: 0.8007 - val_loss: 0.4381 - val_accuracy: 0.7891 - 866ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4286 - accuracy: 0.8014 - val_loss: 0.4436 - val_accuracy: 0.7914 - 689ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.8013 - val_loss: 0.4406 - val_accuracy: 0.7867 - 787ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4279 - accuracy: 0.8008 - val_loss: 0.4400 - val_accuracy: 0.7889 - 790ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8032 - val_loss: 0.4427 - val_accuracy: 0.7906 - 748ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4256 - accuracy: 0.8023 - val_loss: 0.4388 - val_accuracy: 0.7897 - 784ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.8013 - val_loss: 0.4414 - val_accuracy: 0.7881 - 789ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4276 - accuracy: 0.8019 - val_loss: 0.4406 - val_accuracy: 0.7938 - 787ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4265 - accuracy: 0.8031 - val_loss: 0.4456 - val_accuracy: 0.7869 - 728ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4268 - accuracy: 0.8035 - val_loss: 0.4400 - val_accuracy: 0.7886 - 775ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4271 - accuracy: 0.8018 - val_loss: 0.4407 - val_accuracy: 0.7880 - 752ms/epoch - 7ms/step\n",
      "Epoch 39: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "110/110 - 4s - loss: 0.5479 - accuracy: 0.7398 - val_loss: 0.5035 - val_accuracy: 0.7583 - 4s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4784 - accuracy: 0.7643 - val_loss: 0.4785 - val_accuracy: 0.7650 - 789ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4684 - val_accuracy: 0.7698 - 791ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4504 - accuracy: 0.7869 - val_loss: 0.4610 - val_accuracy: 0.7782 - 787ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4477 - accuracy: 0.7900 - val_loss: 0.4568 - val_accuracy: 0.7795 - 771ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4426 - accuracy: 0.7926 - val_loss: 0.4534 - val_accuracy: 0.7830 - 851ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4388 - accuracy: 0.7949 - val_loss: 0.4518 - val_accuracy: 0.7876 - 888ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4391 - accuracy: 0.7998 - val_loss: 0.4512 - val_accuracy: 0.7873 - 778ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4365 - accuracy: 0.7988 - val_loss: 0.4454 - val_accuracy: 0.7898 - 764ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4346 - accuracy: 0.8022 - val_loss: 0.4507 - val_accuracy: 0.7860 - 825ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4333 - accuracy: 0.8013 - val_loss: 0.4464 - val_accuracy: 0.7887 - 793ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4344 - accuracy: 0.7997 - val_loss: 0.4455 - val_accuracy: 0.7846 - 839ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4362 - accuracy: 0.7999 - val_loss: 0.4448 - val_accuracy: 0.7898 - 854ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4327 - accuracy: 0.8021 - val_loss: 0.4474 - val_accuracy: 0.7883 - 779ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4319 - accuracy: 0.8030 - val_loss: 0.4449 - val_accuracy: 0.7898 - 788ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4309 - accuracy: 0.8024 - val_loss: 0.4451 - val_accuracy: 0.7879 - 818ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4323 - accuracy: 0.8015 - val_loss: 0.4444 - val_accuracy: 0.7887 - 777ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4306 - accuracy: 0.8027 - val_loss: 0.4441 - val_accuracy: 0.7886 - 723ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4313 - accuracy: 0.8040 - val_loss: 0.4430 - val_accuracy: 0.7900 - 820ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4303 - accuracy: 0.8013 - val_loss: 0.4436 - val_accuracy: 0.7870 - 748ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4291 - accuracy: 0.8018 - val_loss: 0.4444 - val_accuracy: 0.7889 - 772ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4299 - accuracy: 0.8013 - val_loss: 0.4417 - val_accuracy: 0.7889 - 772ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4275 - accuracy: 0.8026 - val_loss: 0.4426 - val_accuracy: 0.7886 - 732ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4292 - accuracy: 0.8029 - val_loss: 0.4421 - val_accuracy: 0.7923 - 750ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4296 - accuracy: 0.8029 - val_loss: 0.4445 - val_accuracy: 0.7898 - 790ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4287 - accuracy: 0.8039 - val_loss: 0.4424 - val_accuracy: 0.7890 - 830ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4286 - accuracy: 0.8018 - val_loss: 0.4421 - val_accuracy: 0.7874 - 820ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8017 - val_loss: 0.4445 - val_accuracy: 0.7887 - 880ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4274 - accuracy: 0.8036 - val_loss: 0.4415 - val_accuracy: 0.7918 - 850ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4282 - accuracy: 0.8029 - val_loss: 0.4408 - val_accuracy: 0.7898 - 934ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4290 - accuracy: 0.8018 - val_loss: 0.4431 - val_accuracy: 0.7883 - 773ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8037 - val_loss: 0.4393 - val_accuracy: 0.7914 - 846ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4279 - accuracy: 0.8019 - val_loss: 0.4398 - val_accuracy: 0.7886 - 755ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.8036 - val_loss: 0.4421 - val_accuracy: 0.7889 - 832ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4252 - accuracy: 0.8031 - val_loss: 0.4399 - val_accuracy: 0.7917 - 960ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4284 - accuracy: 0.8038 - val_loss: 0.4419 - val_accuracy: 0.7908 - 930ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8040 - val_loss: 0.4419 - val_accuracy: 0.7921 - 810ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4274 - accuracy: 0.8047 - val_loss: 0.4398 - val_accuracy: 0.7901 - 800ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4270 - accuracy: 0.8032 - val_loss: 0.4416 - val_accuracy: 0.7910 - 834ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4279 - accuracy: 0.8039 - val_loss: 0.4405 - val_accuracy: 0.7871 - 851ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4284 - accuracy: 0.8017 - val_loss: 0.4420 - val_accuracy: 0.7910 - 791ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "110/110 - 1s - loss: 0.4274 - accuracy: 0.8042 - val_loss: 0.4406 - val_accuracy: 0.7903 - 828ms/epoch - 8ms/step\n",
      "Epoch 42: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "110/110 - 5s - loss: 0.5844 - accuracy: 0.7192 - val_loss: 0.5343 - val_accuracy: 0.7552 - 5s/epoch - 48ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4918 - accuracy: 0.7715 - val_loss: 0.4872 - val_accuracy: 0.7714 - 868ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4636 - accuracy: 0.7818 - val_loss: 0.4715 - val_accuracy: 0.7739 - 803ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4556 - accuracy: 0.7856 - val_loss: 0.4629 - val_accuracy: 0.7773 - 797ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4494 - accuracy: 0.7863 - val_loss: 0.4540 - val_accuracy: 0.7780 - 934ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4443 - accuracy: 0.7916 - val_loss: 0.4591 - val_accuracy: 0.7810 - 826ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.4491 - val_accuracy: 0.7809 - 900ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4398 - accuracy: 0.7936 - val_loss: 0.4491 - val_accuracy: 0.7862 - 835ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4353 - accuracy: 0.7972 - val_loss: 0.4517 - val_accuracy: 0.7854 - 835ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4361 - accuracy: 0.7952 - val_loss: 0.4472 - val_accuracy: 0.7883 - 839ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4345 - accuracy: 0.7975 - val_loss: 0.4492 - val_accuracy: 0.7887 - 755ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.4441 - val_accuracy: 0.7925 - 850ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4314 - accuracy: 0.7980 - val_loss: 0.4441 - val_accuracy: 0.7827 - 791ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4308 - accuracy: 0.7971 - val_loss: 0.4410 - val_accuracy: 0.7863 - 832ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4312 - accuracy: 0.7989 - val_loss: 0.4437 - val_accuracy: 0.7873 - 804ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.4440 - val_accuracy: 0.7819 - 857ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4295 - accuracy: 0.8004 - val_loss: 0.4429 - val_accuracy: 0.7870 - 817ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4299 - accuracy: 0.8007 - val_loss: 0.4409 - val_accuracy: 0.7873 - 835ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4300 - accuracy: 0.8016 - val_loss: 0.4422 - val_accuracy: 0.7893 - 869ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4295 - accuracy: 0.7996 - val_loss: 0.4449 - val_accuracy: 0.7883 - 816ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4290 - accuracy: 0.8025 - val_loss: 0.4402 - val_accuracy: 0.7896 - 896ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4280 - accuracy: 0.8017 - val_loss: 0.4426 - val_accuracy: 0.7871 - 778ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4295 - accuracy: 0.8016 - val_loss: 0.4418 - val_accuracy: 0.7870 - 837ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4270 - accuracy: 0.8033 - val_loss: 0.4446 - val_accuracy: 0.7884 - 844ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4273 - accuracy: 0.8017 - val_loss: 0.4435 - val_accuracy: 0.7920 - 821ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4282 - accuracy: 0.8015 - val_loss: 0.4424 - val_accuracy: 0.7933 - 781ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4271 - accuracy: 0.8032 - val_loss: 0.4423 - val_accuracy: 0.7927 - 746ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.8028 - val_loss: 0.4412 - val_accuracy: 0.7893 - 793ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4274 - accuracy: 0.8024 - val_loss: 0.4421 - val_accuracy: 0.7880 - 860ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4278 - accuracy: 0.8023 - val_loss: 0.4414 - val_accuracy: 0.7886 - 816ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4268 - accuracy: 0.8028 - val_loss: 0.4386 - val_accuracy: 0.7916 - 827ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4273 - accuracy: 0.8031 - val_loss: 0.4387 - val_accuracy: 0.7898 - 804ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4279 - accuracy: 0.8014 - val_loss: 0.4396 - val_accuracy: 0.7890 - 853ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4271 - accuracy: 0.8033 - val_loss: 0.4433 - val_accuracy: 0.7880 - 857ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4267 - accuracy: 0.8034 - val_loss: 0.4396 - val_accuracy: 0.7940 - 844ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4259 - accuracy: 0.8019 - val_loss: 0.4420 - val_accuracy: 0.7890 - 824ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4264 - accuracy: 0.8037 - val_loss: 0.4444 - val_accuracy: 0.7869 - 848ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4265 - accuracy: 0.8035 - val_loss: 0.4402 - val_accuracy: 0.7921 - 807ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4258 - accuracy: 0.8020 - val_loss: 0.4408 - val_accuracy: 0.7874 - 765ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4265 - accuracy: 0.8023 - val_loss: 0.4398 - val_accuracy: 0.7866 - 835ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8015 - val_loss: 0.4400 - val_accuracy: 0.7896 - 894ms/epoch - 8ms/step\n",
      "Epoch 41: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "110/110 - 2s - loss: 0.5600 - accuracy: 0.7435 - val_loss: 0.5214 - val_accuracy: 0.7610 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4888 - accuracy: 0.7731 - val_loss: 0.4787 - val_accuracy: 0.7701 - 883ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4629 - accuracy: 0.7859 - val_loss: 0.4713 - val_accuracy: 0.7771 - 848ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4536 - accuracy: 0.7918 - val_loss: 0.4587 - val_accuracy: 0.7846 - 828ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4476 - accuracy: 0.7925 - val_loss: 0.4588 - val_accuracy: 0.7847 - 804ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4418 - accuracy: 0.7928 - val_loss: 0.4517 - val_accuracy: 0.7863 - 884ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4415 - accuracy: 0.7943 - val_loss: 0.4518 - val_accuracy: 0.7842 - 857ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4398 - accuracy: 0.7953 - val_loss: 0.4488 - val_accuracy: 0.7785 - 931ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4374 - accuracy: 0.7950 - val_loss: 0.4498 - val_accuracy: 0.7827 - 835ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.4486 - val_accuracy: 0.7820 - 845ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4328 - accuracy: 0.7993 - val_loss: 0.4490 - val_accuracy: 0.7859 - 755ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4347 - accuracy: 0.7981 - val_loss: 0.4459 - val_accuracy: 0.7874 - 827ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4307 - accuracy: 0.7989 - val_loss: 0.4454 - val_accuracy: 0.7840 - 849ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4318 - accuracy: 0.8000 - val_loss: 0.4472 - val_accuracy: 0.7849 - 823ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4313 - accuracy: 0.8000 - val_loss: 0.4457 - val_accuracy: 0.7897 - 851ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4313 - accuracy: 0.7987 - val_loss: 0.4447 - val_accuracy: 0.7866 - 833ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4310 - accuracy: 0.7996 - val_loss: 0.4464 - val_accuracy: 0.7849 - 843ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4310 - accuracy: 0.8002 - val_loss: 0.4444 - val_accuracy: 0.7887 - 798ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4288 - accuracy: 0.8010 - val_loss: 0.4419 - val_accuracy: 0.7877 - 779ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4298 - accuracy: 0.8010 - val_loss: 0.4423 - val_accuracy: 0.7897 - 847ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4290 - accuracy: 0.8014 - val_loss: 0.4429 - val_accuracy: 0.7886 - 814ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4287 - accuracy: 0.8021 - val_loss: 0.4441 - val_accuracy: 0.7881 - 857ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4286 - accuracy: 0.8012 - val_loss: 0.4413 - val_accuracy: 0.7897 - 805ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4300 - accuracy: 0.8027 - val_loss: 0.4426 - val_accuracy: 0.7923 - 908ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.4449 - val_accuracy: 0.7893 - 827ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4291 - accuracy: 0.7996 - val_loss: 0.4386 - val_accuracy: 0.7881 - 885ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4289 - accuracy: 0.8013 - val_loss: 0.4409 - val_accuracy: 0.7891 - 876ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4254 - accuracy: 0.8030 - val_loss: 0.4437 - val_accuracy: 0.7849 - 863ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4289 - accuracy: 0.8014 - val_loss: 0.4402 - val_accuracy: 0.7903 - 832ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4285 - accuracy: 0.8021 - val_loss: 0.4395 - val_accuracy: 0.7893 - 897ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4275 - accuracy: 0.8013 - val_loss: 0.4427 - val_accuracy: 0.7897 - 859ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4270 - accuracy: 0.8012 - val_loss: 0.4397 - val_accuracy: 0.7901 - 824ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8030 - val_loss: 0.4411 - val_accuracy: 0.7914 - 799ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4263 - accuracy: 0.8044 - val_loss: 0.4436 - val_accuracy: 0.7903 - 861ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4269 - accuracy: 0.8024 - val_loss: 0.4385 - val_accuracy: 0.7924 - 924ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4280 - accuracy: 0.8026 - val_loss: 0.4410 - val_accuracy: 0.7881 - 839ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4271 - accuracy: 0.8018 - val_loss: 0.4392 - val_accuracy: 0.7907 - 873ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4261 - accuracy: 0.8019 - val_loss: 0.4415 - val_accuracy: 0.7871 - 916ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8050 - val_loss: 0.4392 - val_accuracy: 0.7904 - 938ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4246 - accuracy: 0.8048 - val_loss: 0.4401 - val_accuracy: 0.7913 - 827ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4261 - accuracy: 0.8043 - val_loss: 0.4430 - val_accuracy: 0.7900 - 844ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "110/110 - 1s - loss: 0.4272 - accuracy: 0.8015 - val_loss: 0.4393 - val_accuracy: 0.7916 - 828ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "110/110 - 1s - loss: 0.4257 - accuracy: 0.8028 - val_loss: 0.4386 - val_accuracy: 0.7891 - 788ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "110/110 - 1s - loss: 0.4264 - accuracy: 0.8030 - val_loss: 0.4412 - val_accuracy: 0.7898 - 886ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "110/110 - 1s - loss: 0.4271 - accuracy: 0.8022 - val_loss: 0.4380 - val_accuracy: 0.7898 - 867ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "110/110 - 1s - loss: 0.4259 - accuracy: 0.8032 - val_loss: 0.4391 - val_accuracy: 0.7906 - 877ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "110/110 - 1s - loss: 0.4272 - accuracy: 0.8019 - val_loss: 0.4408 - val_accuracy: 0.7891 - 815ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "110/110 - 1s - loss: 0.4244 - accuracy: 0.8032 - val_loss: 0.4384 - val_accuracy: 0.7867 - 848ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "110/110 - 1s - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.4381 - val_accuracy: 0.7890 - 828ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "110/110 - 1s - loss: 0.4256 - accuracy: 0.8036 - val_loss: 0.4389 - val_accuracy: 0.7887 - 888ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "110/110 - 1s - loss: 0.4258 - accuracy: 0.8029 - val_loss: 0.4410 - val_accuracy: 0.7901 - 877ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8028 - val_loss: 0.4407 - val_accuracy: 0.7900 - 829ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "110/110 - 1s - loss: 0.4252 - accuracy: 0.8016 - val_loss: 0.4391 - val_accuracy: 0.7916 - 790ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "110/110 - 1s - loss: 0.4265 - accuracy: 0.8025 - val_loss: 0.4402 - val_accuracy: 0.7918 - 855ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "110/110 - 1s - loss: 0.4258 - accuracy: 0.8028 - val_loss: 0.4411 - val_accuracy: 0.7891 - 857ms/epoch - 8ms/step\n",
      "Epoch 55: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "110/110 - 2s - loss: 0.5923 - accuracy: 0.6992 - val_loss: 0.5296 - val_accuracy: 0.7571 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4895 - accuracy: 0.7723 - val_loss: 0.4831 - val_accuracy: 0.7705 - 940ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4628 - accuracy: 0.7822 - val_loss: 0.4670 - val_accuracy: 0.7768 - 875ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4529 - accuracy: 0.7887 - val_loss: 0.4605 - val_accuracy: 0.7825 - 838ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4459 - accuracy: 0.7921 - val_loss: 0.4572 - val_accuracy: 0.7796 - 828ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4392 - accuracy: 0.7926 - val_loss: 0.4519 - val_accuracy: 0.7834 - 804ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4366 - accuracy: 0.7961 - val_loss: 0.4515 - val_accuracy: 0.7859 - 825ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4357 - accuracy: 0.7967 - val_loss: 0.4498 - val_accuracy: 0.7856 - 869ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4345 - accuracy: 0.7985 - val_loss: 0.4456 - val_accuracy: 0.7887 - 799ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4367 - accuracy: 0.7967 - val_loss: 0.4455 - val_accuracy: 0.7894 - 829ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4335 - accuracy: 0.7983 - val_loss: 0.4488 - val_accuracy: 0.7867 - 842ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4324 - accuracy: 0.7996 - val_loss: 0.4468 - val_accuracy: 0.7823 - 810ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4323 - accuracy: 0.7992 - val_loss: 0.4457 - val_accuracy: 0.7853 - 863ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4328 - accuracy: 0.7975 - val_loss: 0.4461 - val_accuracy: 0.7886 - 830ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4318 - accuracy: 0.7978 - val_loss: 0.4422 - val_accuracy: 0.7891 - 782ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4306 - accuracy: 0.8004 - val_loss: 0.4441 - val_accuracy: 0.7859 - 838ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4301 - accuracy: 0.7997 - val_loss: 0.4462 - val_accuracy: 0.7876 - 835ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4304 - accuracy: 0.8009 - val_loss: 0.4461 - val_accuracy: 0.7893 - 854ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.4422 - val_accuracy: 0.7867 - 840ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4312 - accuracy: 0.7995 - val_loss: 0.4421 - val_accuracy: 0.7850 - 841ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4283 - accuracy: 0.8002 - val_loss: 0.4435 - val_accuracy: 0.7864 - 832ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4293 - accuracy: 0.8007 - val_loss: 0.4420 - val_accuracy: 0.7887 - 820ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4295 - accuracy: 0.8013 - val_loss: 0.4399 - val_accuracy: 0.7925 - 839ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4287 - accuracy: 0.8026 - val_loss: 0.4405 - val_accuracy: 0.7879 - 839ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8020 - val_loss: 0.4406 - val_accuracy: 0.7891 - 844ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4287 - accuracy: 0.8015 - val_loss: 0.4428 - val_accuracy: 0.7886 - 781ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4293 - accuracy: 0.8005 - val_loss: 0.4428 - val_accuracy: 0.7876 - 804ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4274 - accuracy: 0.8024 - val_loss: 0.4398 - val_accuracy: 0.7876 - 883ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4296 - accuracy: 0.8018 - val_loss: 0.4404 - val_accuracy: 0.7889 - 809ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.4424 - val_accuracy: 0.7883 - 810ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.7996 - val_loss: 0.4393 - val_accuracy: 0.7891 - 827ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8015 - val_loss: 0.4415 - val_accuracy: 0.7889 - 781ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4275 - accuracy: 0.7997 - val_loss: 0.4422 - val_accuracy: 0.7857 - 805ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4270 - accuracy: 0.8021 - val_loss: 0.4401 - val_accuracy: 0.7873 - 800ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4264 - accuracy: 0.8002 - val_loss: 0.4397 - val_accuracy: 0.7911 - 845ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4250 - accuracy: 0.8012 - val_loss: 0.4416 - val_accuracy: 0.7879 - 805ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4269 - accuracy: 0.8020 - val_loss: 0.4406 - val_accuracy: 0.7908 - 819ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4270 - accuracy: 0.8008 - val_loss: 0.4391 - val_accuracy: 0.7930 - 917ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4267 - accuracy: 0.8031 - val_loss: 0.4409 - val_accuracy: 0.7884 - 807ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4254 - accuracy: 0.8014 - val_loss: 0.4425 - val_accuracy: 0.7918 - 785ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4260 - accuracy: 0.8012 - val_loss: 0.4395 - val_accuracy: 0.7916 - 843ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "110/110 - 1s - loss: 0.4271 - accuracy: 0.8024 - val_loss: 0.4417 - val_accuracy: 0.7859 - 949ms/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8008 - val_loss: 0.4379 - val_accuracy: 0.7894 - 844ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "110/110 - 1s - loss: 0.4264 - accuracy: 0.8020 - val_loss: 0.4398 - val_accuracy: 0.7863 - 824ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "110/110 - 1s - loss: 0.4249 - accuracy: 0.8029 - val_loss: 0.4410 - val_accuracy: 0.7897 - 832ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "110/110 - 1s - loss: 0.4237 - accuracy: 0.8040 - val_loss: 0.4377 - val_accuracy: 0.7907 - 899ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "110/110 - 1s - loss: 0.4242 - accuracy: 0.8020 - val_loss: 0.4389 - val_accuracy: 0.7881 - 876ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "110/110 - 1s - loss: 0.4255 - accuracy: 0.8022 - val_loss: 0.4402 - val_accuracy: 0.7877 - 844ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "110/110 - 1s - loss: 0.4272 - accuracy: 0.8019 - val_loss: 0.4409 - val_accuracy: 0.7866 - 807ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "110/110 - 1s - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.4402 - val_accuracy: 0.7910 - 879ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "110/110 - 1s - loss: 0.4241 - accuracy: 0.8035 - val_loss: 0.4374 - val_accuracy: 0.7911 - 821ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "110/110 - 1s - loss: 0.4263 - accuracy: 0.8033 - val_loss: 0.4397 - val_accuracy: 0.7917 - 849ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "110/110 - 1s - loss: 0.4255 - accuracy: 0.8034 - val_loss: 0.4386 - val_accuracy: 0.7880 - 821ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "110/110 - 1s - loss: 0.4259 - accuracy: 0.8012 - val_loss: 0.4394 - val_accuracy: 0.7918 - 836ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "110/110 - 1s - loss: 0.4245 - accuracy: 0.8011 - val_loss: 0.4400 - val_accuracy: 0.7898 - 862ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "110/110 - 1s - loss: 0.4241 - accuracy: 0.8045 - val_loss: 0.4428 - val_accuracy: 0.7859 - 845ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "110/110 - 1s - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.4410 - val_accuracy: 0.7901 - 887ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "110/110 - 1s - loss: 0.4248 - accuracy: 0.8016 - val_loss: 0.4390 - val_accuracy: 0.7897 - 861ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "110/110 - 1s - loss: 0.4251 - accuracy: 0.8018 - val_loss: 0.4380 - val_accuracy: 0.7898 - 842ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "110/110 - 1s - loss: 0.4257 - accuracy: 0.8028 - val_loss: 0.4402 - val_accuracy: 0.7880 - 828ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "110/110 - 1s - loss: 0.4244 - accuracy: 0.8020 - val_loss: 0.4402 - val_accuracy: 0.7906 - 845ms/epoch - 8ms/step\n",
      "Epoch 61: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "110/110 - 3s - loss: 0.5845 - accuracy: 0.7083 - val_loss: 0.5168 - val_accuracy: 0.7652 - 3s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4820 - accuracy: 0.7766 - val_loss: 0.4769 - val_accuracy: 0.7765 - 828ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4609 - accuracy: 0.7817 - val_loss: 0.4648 - val_accuracy: 0.7803 - 822ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4518 - accuracy: 0.7852 - val_loss: 0.4615 - val_accuracy: 0.7755 - 875ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4489 - accuracy: 0.7886 - val_loss: 0.4513 - val_accuracy: 0.7825 - 783ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4436 - accuracy: 0.7898 - val_loss: 0.4559 - val_accuracy: 0.7832 - 789ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4409 - accuracy: 0.7976 - val_loss: 0.4512 - val_accuracy: 0.7859 - 810ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4410 - accuracy: 0.7935 - val_loss: 0.4516 - val_accuracy: 0.7799 - 752ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4366 - accuracy: 0.7954 - val_loss: 0.4537 - val_accuracy: 0.7834 - 773ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4355 - accuracy: 0.7967 - val_loss: 0.4485 - val_accuracy: 0.7859 - 786ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4359 - accuracy: 0.7970 - val_loss: 0.4450 - val_accuracy: 0.7853 - 873ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4349 - accuracy: 0.7980 - val_loss: 0.4478 - val_accuracy: 0.7897 - 830ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4333 - accuracy: 0.7974 - val_loss: 0.4476 - val_accuracy: 0.7874 - 793ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4326 - accuracy: 0.7994 - val_loss: 0.4466 - val_accuracy: 0.7910 - 858ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4333 - accuracy: 0.7989 - val_loss: 0.4454 - val_accuracy: 0.7876 - 865ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4338 - accuracy: 0.7988 - val_loss: 0.4435 - val_accuracy: 0.7913 - 832ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4306 - accuracy: 0.7997 - val_loss: 0.4462 - val_accuracy: 0.7891 - 821ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4319 - accuracy: 0.7998 - val_loss: 0.4437 - val_accuracy: 0.7897 - 829ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4304 - accuracy: 0.8009 - val_loss: 0.4441 - val_accuracy: 0.7889 - 763ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4299 - accuracy: 0.7982 - val_loss: 0.4456 - val_accuracy: 0.7874 - 853ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4290 - accuracy: 0.8007 - val_loss: 0.4455 - val_accuracy: 0.7857 - 841ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4311 - accuracy: 0.7993 - val_loss: 0.4451 - val_accuracy: 0.7894 - 809ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.4417 - val_accuracy: 0.7908 - 840ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4292 - accuracy: 0.8010 - val_loss: 0.4432 - val_accuracy: 0.7901 - 828ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4304 - accuracy: 0.7978 - val_loss: 0.4403 - val_accuracy: 0.7897 - 838ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4295 - accuracy: 0.7989 - val_loss: 0.4412 - val_accuracy: 0.7894 - 770ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4290 - accuracy: 0.8020 - val_loss: 0.4411 - val_accuracy: 0.7921 - 774ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4279 - accuracy: 0.8009 - val_loss: 0.4394 - val_accuracy: 0.7898 - 832ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4296 - accuracy: 0.8014 - val_loss: 0.4386 - val_accuracy: 0.7877 - 830ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4296 - accuracy: 0.8009 - val_loss: 0.4441 - val_accuracy: 0.7900 - 786ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.8014 - val_loss: 0.4417 - val_accuracy: 0.7859 - 834ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4273 - accuracy: 0.8014 - val_loss: 0.4435 - val_accuracy: 0.7877 - 847ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4280 - accuracy: 0.8005 - val_loss: 0.4404 - val_accuracy: 0.7857 - 776ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4288 - accuracy: 0.7999 - val_loss: 0.4421 - val_accuracy: 0.7837 - 810ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4286 - accuracy: 0.7991 - val_loss: 0.4431 - val_accuracy: 0.7866 - 858ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4289 - accuracy: 0.8006 - val_loss: 0.4416 - val_accuracy: 0.7852 - 806ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4276 - accuracy: 0.8025 - val_loss: 0.4409 - val_accuracy: 0.7906 - 830ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4275 - accuracy: 0.8041 - val_loss: 0.4404 - val_accuracy: 0.7906 - 778ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4274 - accuracy: 0.8009 - val_loss: 0.4402 - val_accuracy: 0.7889 - 859ms/epoch - 8ms/step\n",
      "Epoch 39: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "110/110 - 3s - loss: 0.5552 - accuracy: 0.7275 - val_loss: 0.5069 - val_accuracy: 0.7556 - 3s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4788 - accuracy: 0.7668 - val_loss: 0.4781 - val_accuracy: 0.7637 - 789ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4641 - accuracy: 0.7739 - val_loss: 0.4683 - val_accuracy: 0.7671 - 841ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4497 - accuracy: 0.7860 - val_loss: 0.4631 - val_accuracy: 0.7736 - 783ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4478 - accuracy: 0.7876 - val_loss: 0.4594 - val_accuracy: 0.7775 - 807ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4419 - accuracy: 0.7895 - val_loss: 0.4576 - val_accuracy: 0.7779 - 855ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4423 - accuracy: 0.7927 - val_loss: 0.4531 - val_accuracy: 0.7862 - 846ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4381 - accuracy: 0.7945 - val_loss: 0.4507 - val_accuracy: 0.7864 - 861ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4367 - accuracy: 0.7966 - val_loss: 0.4475 - val_accuracy: 0.7837 - 798ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4380 - accuracy: 0.7988 - val_loss: 0.4463 - val_accuracy: 0.7800 - 799ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4352 - accuracy: 0.7972 - val_loss: 0.4482 - val_accuracy: 0.7850 - 785ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4325 - accuracy: 0.7997 - val_loss: 0.4456 - val_accuracy: 0.7859 - 800ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4318 - accuracy: 0.7997 - val_loss: 0.4453 - val_accuracy: 0.7870 - 780ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4318 - accuracy: 0.7990 - val_loss: 0.4464 - val_accuracy: 0.7850 - 872ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4330 - accuracy: 0.8023 - val_loss: 0.4453 - val_accuracy: 0.7869 - 862ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.4452 - val_accuracy: 0.7877 - 793ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4300 - accuracy: 0.8002 - val_loss: 0.4462 - val_accuracy: 0.7896 - 810ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4310 - accuracy: 0.8016 - val_loss: 0.4446 - val_accuracy: 0.7850 - 830ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4320 - accuracy: 0.8008 - val_loss: 0.4437 - val_accuracy: 0.7881 - 870ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4300 - accuracy: 0.8023 - val_loss: 0.4427 - val_accuracy: 0.7886 - 863ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4298 - accuracy: 0.8026 - val_loss: 0.4443 - val_accuracy: 0.7911 - 767ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4297 - accuracy: 0.8013 - val_loss: 0.4416 - val_accuracy: 0.7904 - 816ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4278 - accuracy: 0.8012 - val_loss: 0.4434 - val_accuracy: 0.7904 - 825ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4294 - accuracy: 0.8011 - val_loss: 0.4423 - val_accuracy: 0.7914 - 800ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4306 - accuracy: 0.8020 - val_loss: 0.4415 - val_accuracy: 0.7881 - 807ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8013 - val_loss: 0.4440 - val_accuracy: 0.7891 - 817ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4286 - accuracy: 0.8019 - val_loss: 0.4422 - val_accuracy: 0.7897 - 862ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4300 - accuracy: 0.8023 - val_loss: 0.4422 - val_accuracy: 0.7898 - 772ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4290 - accuracy: 0.8036 - val_loss: 0.4408 - val_accuracy: 0.7897 - 775ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4289 - accuracy: 0.8031 - val_loss: 0.4407 - val_accuracy: 0.7891 - 811ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4286 - accuracy: 0.8028 - val_loss: 0.4433 - val_accuracy: 0.7883 - 792ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4272 - accuracy: 0.8018 - val_loss: 0.4408 - val_accuracy: 0.7873 - 821ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4274 - accuracy: 0.8020 - val_loss: 0.4409 - val_accuracy: 0.7886 - 798ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4285 - accuracy: 0.8024 - val_loss: 0.4400 - val_accuracy: 0.7864 - 860ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4279 - accuracy: 0.8020 - val_loss: 0.4414 - val_accuracy: 0.7890 - 808ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4283 - accuracy: 0.8025 - val_loss: 0.4409 - val_accuracy: 0.7911 - 841ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4280 - accuracy: 0.8022 - val_loss: 0.4408 - val_accuracy: 0.7880 - 859ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4274 - accuracy: 0.8034 - val_loss: 0.4419 - val_accuracy: 0.7911 - 819ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4265 - accuracy: 0.8030 - val_loss: 0.4428 - val_accuracy: 0.7904 - 834ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4283 - accuracy: 0.8025 - val_loss: 0.4407 - val_accuracy: 0.7906 - 834ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4274 - accuracy: 0.8032 - val_loss: 0.4392 - val_accuracy: 0.7916 - 827ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "110/110 - 1s - loss: 0.4258 - accuracy: 0.8026 - val_loss: 0.4396 - val_accuracy: 0.7910 - 793ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "110/110 - 1s - loss: 0.4267 - accuracy: 0.8017 - val_loss: 0.4413 - val_accuracy: 0.7857 - 811ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.8031 - val_loss: 0.4415 - val_accuracy: 0.7913 - 1s/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "110/110 - 1s - loss: 0.4266 - accuracy: 0.8034 - val_loss: 0.4408 - val_accuracy: 0.7907 - 882ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "110/110 - 1s - loss: 0.4272 - accuracy: 0.8031 - val_loss: 0.4446 - val_accuracy: 0.7867 - 856ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "110/110 - 1s - loss: 0.4265 - accuracy: 0.8009 - val_loss: 0.4417 - val_accuracy: 0.7921 - 869ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "110/110 - 1s - loss: 0.4272 - accuracy: 0.8021 - val_loss: 0.4422 - val_accuracy: 0.7898 - 830ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "110/110 - 1s - loss: 0.4267 - accuracy: 0.8034 - val_loss: 0.4421 - val_accuracy: 0.7931 - 883ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "110/110 - 1s - loss: 0.4267 - accuracy: 0.8018 - val_loss: 0.4376 - val_accuracy: 0.7893 - 857ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "110/110 - 1s - loss: 0.4280 - accuracy: 0.8029 - val_loss: 0.4441 - val_accuracy: 0.7908 - 899ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "110/110 - 1s - loss: 0.4268 - accuracy: 0.8048 - val_loss: 0.4372 - val_accuracy: 0.7923 - 891ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "110/110 - 1s - loss: 0.4263 - accuracy: 0.8038 - val_loss: 0.4404 - val_accuracy: 0.7901 - 825ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "110/110 - 1s - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.4381 - val_accuracy: 0.7900 - 867ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "110/110 - 1s - loss: 0.4253 - accuracy: 0.8014 - val_loss: 0.4380 - val_accuracy: 0.7893 - 905ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "110/110 - 1s - loss: 0.4258 - accuracy: 0.8033 - val_loss: 0.4408 - val_accuracy: 0.7927 - 888ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "110/110 - 1s - loss: 0.4273 - accuracy: 0.8016 - val_loss: 0.4404 - val_accuracy: 0.7893 - 952ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.8026 - val_loss: 0.4392 - val_accuracy: 0.7910 - 952ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8027 - val_loss: 0.4409 - val_accuracy: 0.7910 - 942ms/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.4402 - val_accuracy: 0.7876 - 915ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "110/110 - 1s - loss: 0.4273 - accuracy: 0.8019 - val_loss: 0.4405 - val_accuracy: 0.7901 - 956ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "110/110 - 1s - loss: 0.4259 - accuracy: 0.8030 - val_loss: 0.4380 - val_accuracy: 0.7928 - 937ms/epoch - 9ms/step\n",
      "Epoch 62: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "110/110 - 6s - loss: 0.5479 - accuracy: 0.7354 - val_loss: 0.5061 - val_accuracy: 0.7596 - 6s/epoch - 54ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4817 - accuracy: 0.7724 - val_loss: 0.4831 - val_accuracy: 0.7662 - 1s/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4647 - accuracy: 0.7785 - val_loss: 0.4658 - val_accuracy: 0.7762 - 999ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4525 - accuracy: 0.7879 - val_loss: 0.4604 - val_accuracy: 0.7785 - 896ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4468 - accuracy: 0.7911 - val_loss: 0.4570 - val_accuracy: 0.7829 - 996ms/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4440 - accuracy: 0.7928 - val_loss: 0.4506 - val_accuracy: 0.7830 - 879ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4413 - accuracy: 0.7952 - val_loss: 0.4521 - val_accuracy: 0.7849 - 1s/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4374 - accuracy: 0.7958 - val_loss: 0.4493 - val_accuracy: 0.7829 - 1s/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4372 - accuracy: 0.7972 - val_loss: 0.4454 - val_accuracy: 0.7869 - 980ms/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4356 - accuracy: 0.7987 - val_loss: 0.4486 - val_accuracy: 0.7842 - 927ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4344 - accuracy: 0.7973 - val_loss: 0.4443 - val_accuracy: 0.7857 - 925ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4360 - accuracy: 0.7981 - val_loss: 0.4486 - val_accuracy: 0.7859 - 909ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4351 - accuracy: 0.7983 - val_loss: 0.4489 - val_accuracy: 0.7847 - 883ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4328 - accuracy: 0.7987 - val_loss: 0.4432 - val_accuracy: 0.7889 - 857ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4314 - accuracy: 0.8007 - val_loss: 0.4486 - val_accuracy: 0.7859 - 1s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4315 - accuracy: 0.8019 - val_loss: 0.4468 - val_accuracy: 0.7864 - 892ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.4460 - val_accuracy: 0.7852 - 890ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4308 - accuracy: 0.8000 - val_loss: 0.4423 - val_accuracy: 0.7873 - 858ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4307 - accuracy: 0.8008 - val_loss: 0.4384 - val_accuracy: 0.7904 - 938ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4451 - val_accuracy: 0.7890 - 855ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4318 - accuracy: 0.7998 - val_loss: 0.4442 - val_accuracy: 0.7874 - 893ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4303 - accuracy: 0.8000 - val_loss: 0.4441 - val_accuracy: 0.7904 - 869ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4290 - accuracy: 0.7995 - val_loss: 0.4428 - val_accuracy: 0.7871 - 815ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4320 - accuracy: 0.7985 - val_loss: 0.4421 - val_accuracy: 0.7923 - 850ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4302 - accuracy: 0.8007 - val_loss: 0.4441 - val_accuracy: 0.7879 - 881ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4296 - accuracy: 0.8011 - val_loss: 0.4434 - val_accuracy: 0.7896 - 791ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4296 - accuracy: 0.7991 - val_loss: 0.4458 - val_accuracy: 0.7847 - 852ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8018 - val_loss: 0.4416 - val_accuracy: 0.7887 - 794ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4291 - accuracy: 0.7996 - val_loss: 0.4424 - val_accuracy: 0.7871 - 871ms/epoch - 8ms/step\n",
      "Epoch 29: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "110/110 - 3s - loss: 0.5489 - accuracy: 0.7403 - val_loss: 0.5040 - val_accuracy: 0.7616 - 3s/epoch - 31ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4831 - accuracy: 0.7733 - val_loss: 0.4801 - val_accuracy: 0.7658 - 929ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4635 - accuracy: 0.7793 - val_loss: 0.4699 - val_accuracy: 0.7772 - 793ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4523 - accuracy: 0.7861 - val_loss: 0.4640 - val_accuracy: 0.7790 - 782ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4504 - accuracy: 0.7879 - val_loss: 0.4583 - val_accuracy: 0.7789 - 876ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4451 - accuracy: 0.7914 - val_loss: 0.4538 - val_accuracy: 0.7789 - 800ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4451 - accuracy: 0.7913 - val_loss: 0.4517 - val_accuracy: 0.7850 - 883ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4414 - accuracy: 0.7950 - val_loss: 0.4527 - val_accuracy: 0.7847 - 813ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4374 - accuracy: 0.7953 - val_loss: 0.4531 - val_accuracy: 0.7853 - 831ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4371 - accuracy: 0.7941 - val_loss: 0.4521 - val_accuracy: 0.7825 - 793ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4359 - accuracy: 0.7940 - val_loss: 0.4526 - val_accuracy: 0.7805 - 823ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4355 - accuracy: 0.7960 - val_loss: 0.4443 - val_accuracy: 0.7856 - 807ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4341 - accuracy: 0.7962 - val_loss: 0.4463 - val_accuracy: 0.7881 - 795ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4336 - accuracy: 0.7970 - val_loss: 0.4459 - val_accuracy: 0.7873 - 811ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4334 - accuracy: 0.7967 - val_loss: 0.4421 - val_accuracy: 0.7910 - 832ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4332 - accuracy: 0.7965 - val_loss: 0.4429 - val_accuracy: 0.7890 - 872ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4337 - accuracy: 0.7970 - val_loss: 0.4479 - val_accuracy: 0.7859 - 908ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4347 - accuracy: 0.7970 - val_loss: 0.4469 - val_accuracy: 0.7874 - 786ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4316 - accuracy: 0.8002 - val_loss: 0.4443 - val_accuracy: 0.7881 - 814ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4318 - accuracy: 0.7978 - val_loss: 0.4439 - val_accuracy: 0.7849 - 791ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4302 - accuracy: 0.8019 - val_loss: 0.4430 - val_accuracy: 0.7871 - 900ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4299 - accuracy: 0.8011 - val_loss: 0.4408 - val_accuracy: 0.7884 - 879ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4304 - accuracy: 0.8009 - val_loss: 0.4449 - val_accuracy: 0.7866 - 801ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4300 - accuracy: 0.8009 - val_loss: 0.4468 - val_accuracy: 0.7883 - 812ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4286 - accuracy: 0.8033 - val_loss: 0.4400 - val_accuracy: 0.7898 - 800ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4284 - accuracy: 0.8012 - val_loss: 0.4427 - val_accuracy: 0.7889 - 910ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4286 - accuracy: 0.8002 - val_loss: 0.4450 - val_accuracy: 0.7896 - 929ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4307 - accuracy: 0.8011 - val_loss: 0.4399 - val_accuracy: 0.7886 - 888ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4286 - accuracy: 0.8027 - val_loss: 0.4423 - val_accuracy: 0.7910 - 787ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8027 - val_loss: 0.4450 - val_accuracy: 0.7890 - 837ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4289 - accuracy: 0.8016 - val_loss: 0.4404 - val_accuracy: 0.7860 - 798ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4275 - accuracy: 0.8022 - val_loss: 0.4396 - val_accuracy: 0.7897 - 808ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4275 - accuracy: 0.8024 - val_loss: 0.4393 - val_accuracy: 0.7947 - 821ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4282 - accuracy: 0.8024 - val_loss: 0.4424 - val_accuracy: 0.7900 - 970ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4280 - accuracy: 0.8017 - val_loss: 0.4412 - val_accuracy: 0.7898 - 834ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4270 - accuracy: 0.8025 - val_loss: 0.4390 - val_accuracy: 0.7904 - 898ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4288 - accuracy: 0.8010 - val_loss: 0.4443 - val_accuracy: 0.7857 - 807ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4265 - accuracy: 0.8028 - val_loss: 0.4429 - val_accuracy: 0.7896 - 817ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4283 - accuracy: 0.8010 - val_loss: 0.4407 - val_accuracy: 0.7925 - 887ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4263 - accuracy: 0.8006 - val_loss: 0.4421 - val_accuracy: 0.7876 - 826ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8019 - val_loss: 0.4378 - val_accuracy: 0.7880 - 794ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "110/110 - 1s - loss: 0.4269 - accuracy: 0.8015 - val_loss: 0.4424 - val_accuracy: 0.7898 - 883ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "110/110 - 1s - loss: 0.4265 - accuracy: 0.8032 - val_loss: 0.4388 - val_accuracy: 0.7903 - 843ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "110/110 - 1s - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.4400 - val_accuracy: 0.7903 - 857ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "110/110 - 1s - loss: 0.4264 - accuracy: 0.8029 - val_loss: 0.4398 - val_accuracy: 0.7897 - 813ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "110/110 - 1s - loss: 0.4259 - accuracy: 0.8041 - val_loss: 0.4395 - val_accuracy: 0.7904 - 858ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "110/110 - 1s - loss: 0.4263 - accuracy: 0.8018 - val_loss: 0.4371 - val_accuracy: 0.7904 - 850ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "110/110 - 1s - loss: 0.4264 - accuracy: 0.8008 - val_loss: 0.4398 - val_accuracy: 0.7893 - 831ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "110/110 - 1s - loss: 0.4255 - accuracy: 0.8017 - val_loss: 0.4391 - val_accuracy: 0.7886 - 838ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "110/110 - 1s - loss: 0.4259 - accuracy: 0.8025 - val_loss: 0.4384 - val_accuracy: 0.7911 - 898ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "110/110 - 1s - loss: 0.4260 - accuracy: 0.8015 - val_loss: 0.4420 - val_accuracy: 0.7859 - 781ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "110/110 - 1s - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.4394 - val_accuracy: 0.7883 - 878ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "110/110 - 1s - loss: 0.4269 - accuracy: 0.8023 - val_loss: 0.4419 - val_accuracy: 0.7897 - 866ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "110/110 - 1s - loss: 0.4254 - accuracy: 0.8028 - val_loss: 0.4394 - val_accuracy: 0.7924 - 824ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "110/110 - 1s - loss: 0.4267 - accuracy: 0.8014 - val_loss: 0.4392 - val_accuracy: 0.7904 - 817ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8012 - val_loss: 0.4393 - val_accuracy: 0.7900 - 848ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "110/110 - 1s - loss: 0.4238 - accuracy: 0.8033 - val_loss: 0.4402 - val_accuracy: 0.7897 - 822ms/epoch - 7ms/step\n",
      "Epoch 57: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "110/110 - 5s - loss: 0.5895 - accuracy: 0.7057 - val_loss: 0.5271 - val_accuracy: 0.7557 - 5s/epoch - 43ms/step\n",
      "Epoch 2/100\n",
      "110/110 - 1s - loss: 0.4969 - accuracy: 0.7670 - val_loss: 0.4865 - val_accuracy: 0.7662 - 819ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "110/110 - 1s - loss: 0.4667 - accuracy: 0.7797 - val_loss: 0.4724 - val_accuracy: 0.7763 - 820ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "110/110 - 1s - loss: 0.4542 - accuracy: 0.7876 - val_loss: 0.4684 - val_accuracy: 0.7752 - 771ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "110/110 - 1s - loss: 0.4479 - accuracy: 0.7911 - val_loss: 0.4601 - val_accuracy: 0.7800 - 863ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "110/110 - 1s - loss: 0.4414 - accuracy: 0.7928 - val_loss: 0.4542 - val_accuracy: 0.7827 - 865ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "110/110 - 1s - loss: 0.4426 - accuracy: 0.7921 - val_loss: 0.4543 - val_accuracy: 0.7866 - 847ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "110/110 - 1s - loss: 0.4384 - accuracy: 0.7965 - val_loss: 0.4539 - val_accuracy: 0.7863 - 871ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "110/110 - 1s - loss: 0.4374 - accuracy: 0.7970 - val_loss: 0.4496 - val_accuracy: 0.7850 - 811ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "110/110 - 1s - loss: 0.4368 - accuracy: 0.7962 - val_loss: 0.4483 - val_accuracy: 0.7889 - 797ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "110/110 - 1s - loss: 0.4347 - accuracy: 0.7992 - val_loss: 0.4456 - val_accuracy: 0.7866 - 882ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "110/110 - 1s - loss: 0.4332 - accuracy: 0.8006 - val_loss: 0.4463 - val_accuracy: 0.7886 - 860ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "110/110 - 1s - loss: 0.4330 - accuracy: 0.8001 - val_loss: 0.4490 - val_accuracy: 0.7889 - 815ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "110/110 - 1s - loss: 0.4333 - accuracy: 0.7997 - val_loss: 0.4479 - val_accuracy: 0.7850 - 871ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "110/110 - 1s - loss: 0.4309 - accuracy: 0.8011 - val_loss: 0.4447 - val_accuracy: 0.7903 - 823ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "110/110 - 1s - loss: 0.4322 - accuracy: 0.7995 - val_loss: 0.4436 - val_accuracy: 0.7887 - 790ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "110/110 - 1s - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.4459 - val_accuracy: 0.7898 - 877ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "110/110 - 1s - loss: 0.4314 - accuracy: 0.8029 - val_loss: 0.4416 - val_accuracy: 0.7893 - 830ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "110/110 - 1s - loss: 0.4327 - accuracy: 0.8010 - val_loss: 0.4448 - val_accuracy: 0.7890 - 822ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "110/110 - 1s - loss: 0.4327 - accuracy: 0.8019 - val_loss: 0.4412 - val_accuracy: 0.7887 - 792ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "110/110 - 1s - loss: 0.4318 - accuracy: 0.8036 - val_loss: 0.4438 - val_accuracy: 0.7880 - 890ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "110/110 - 1s - loss: 0.4293 - accuracy: 0.8029 - val_loss: 0.4447 - val_accuracy: 0.7891 - 855ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "110/110 - 1s - loss: 0.4304 - accuracy: 0.8027 - val_loss: 0.4405 - val_accuracy: 0.7890 - 819ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "110/110 - 1s - loss: 0.4303 - accuracy: 0.8026 - val_loss: 0.4433 - val_accuracy: 0.7883 - 791ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "110/110 - 1s - loss: 0.4295 - accuracy: 0.8015 - val_loss: 0.4424 - val_accuracy: 0.7889 - 854ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "110/110 - 1s - loss: 0.4294 - accuracy: 0.8010 - val_loss: 0.4423 - val_accuracy: 0.7896 - 837ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "110/110 - 1s - loss: 0.4285 - accuracy: 0.8010 - val_loss: 0.4432 - val_accuracy: 0.7921 - 787ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "110/110 - 1s - loss: 0.4302 - accuracy: 0.8029 - val_loss: 0.4422 - val_accuracy: 0.7918 - 773ms/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "110/110 - 1s - loss: 0.4297 - accuracy: 0.8020 - val_loss: 0.4403 - val_accuracy: 0.7914 - 790ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "110/110 - 1s - loss: 0.4284 - accuracy: 0.8018 - val_loss: 0.4416 - val_accuracy: 0.7931 - 862ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "110/110 - 1s - loss: 0.4280 - accuracy: 0.8030 - val_loss: 0.4404 - val_accuracy: 0.7907 - 872ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "110/110 - 1s - loss: 0.4282 - accuracy: 0.8031 - val_loss: 0.4424 - val_accuracy: 0.7890 - 821ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "110/110 - 1s - loss: 0.4292 - accuracy: 0.8018 - val_loss: 0.4438 - val_accuracy: 0.7889 - 1s/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "110/110 - 1s - loss: 0.4279 - accuracy: 0.8025 - val_loss: 0.4415 - val_accuracy: 0.7914 - 943ms/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "110/110 - 1s - loss: 0.4275 - accuracy: 0.8031 - val_loss: 0.4418 - val_accuracy: 0.7900 - 820ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.8039 - val_loss: 0.4392 - val_accuracy: 0.7884 - 811ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "110/110 - 1s - loss: 0.4270 - accuracy: 0.8030 - val_loss: 0.4421 - val_accuracy: 0.7879 - 833ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "110/110 - 1s - loss: 0.4287 - accuracy: 0.8021 - val_loss: 0.4405 - val_accuracy: 0.7894 - 811ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "110/110 - 1s - loss: 0.4285 - accuracy: 0.8022 - val_loss: 0.4380 - val_accuracy: 0.7923 - 807ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "110/110 - 1s - loss: 0.4277 - accuracy: 0.8040 - val_loss: 0.4402 - val_accuracy: 0.7935 - 874ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "110/110 - 1s - loss: 0.4280 - accuracy: 0.8027 - val_loss: 0.4400 - val_accuracy: 0.7889 - 827ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "110/110 - 1s - loss: 0.4272 - accuracy: 0.8028 - val_loss: 0.4395 - val_accuracy: 0.7900 - 831ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "110/110 - 1s - loss: 0.4276 - accuracy: 0.8024 - val_loss: 0.4401 - val_accuracy: 0.7879 - 856ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "110/110 - 1s - loss: 0.4281 - accuracy: 0.8024 - val_loss: 0.4418 - val_accuracy: 0.7883 - 910ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "110/110 - 1s - loss: 0.4280 - accuracy: 0.8027 - val_loss: 0.4410 - val_accuracy: 0.7908 - 823ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "110/110 - 1s - loss: 0.4278 - accuracy: 0.8031 - val_loss: 0.4383 - val_accuracy: 0.7923 - 851ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "110/110 - 1s - loss: 0.4263 - accuracy: 0.8041 - val_loss: 0.4415 - val_accuracy: 0.7918 - 829ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "110/110 - 1s - loss: 0.4272 - accuracy: 0.8020 - val_loss: 0.4410 - val_accuracy: 0.7859 - 852ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "110/110 - 1s - loss: 0.4262 - accuracy: 0.8029 - val_loss: 0.4397 - val_accuracy: 0.7900 - 846ms/epoch - 8ms/step\n",
      "Epoch 49: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.3833037859121321\n",
      "epi entropy:  0.3581153583950656\n",
      "\n",
      "dataset size:  1.0\n",
      "Epoch 1/100\n",
      "123/123 - 4s - loss: 0.5460 - accuracy: 0.7438 - val_loss: 0.4909 - val_accuracy: 0.7722 - 4s/epoch - 36ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4820 - accuracy: 0.7690 - val_loss: 0.4586 - val_accuracy: 0.7816 - 866ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4623 - accuracy: 0.7792 - val_loss: 0.4517 - val_accuracy: 0.7855 - 944ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.4454 - val_accuracy: 0.7944 - 922ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4502 - accuracy: 0.7867 - val_loss: 0.4390 - val_accuracy: 0.7912 - 982ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4474 - accuracy: 0.7888 - val_loss: 0.4410 - val_accuracy: 0.7949 - 930ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4454 - accuracy: 0.7897 - val_loss: 0.4361 - val_accuracy: 0.7985 - 900ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4426 - accuracy: 0.7904 - val_loss: 0.4353 - val_accuracy: 0.7930 - 940ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4409 - accuracy: 0.7915 - val_loss: 0.4329 - val_accuracy: 0.7955 - 1s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.4287 - val_accuracy: 0.8001 - 1s/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4390 - accuracy: 0.7956 - val_loss: 0.4327 - val_accuracy: 0.7996 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4364 - accuracy: 0.7937 - val_loss: 0.4305 - val_accuracy: 0.7985 - 930ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4374 - accuracy: 0.7935 - val_loss: 0.4306 - val_accuracy: 0.7995 - 1s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4348 - accuracy: 0.7966 - val_loss: 0.4243 - val_accuracy: 0.7988 - 1s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4349 - accuracy: 0.7978 - val_loss: 0.4303 - val_accuracy: 0.7986 - 1s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4356 - accuracy: 0.7970 - val_loss: 0.4273 - val_accuracy: 0.8026 - 1s/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4326 - accuracy: 0.7981 - val_loss: 0.4275 - val_accuracy: 0.8003 - 993ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4340 - accuracy: 0.7962 - val_loss: 0.4265 - val_accuracy: 0.8022 - 957ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4330 - accuracy: 0.7943 - val_loss: 0.4260 - val_accuracy: 0.8015 - 914ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4340 - accuracy: 0.7952 - val_loss: 0.4261 - val_accuracy: 0.8006 - 1s/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4326 - accuracy: 0.7972 - val_loss: 0.4237 - val_accuracy: 0.8049 - 1s/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.4246 - val_accuracy: 0.8006 - 1s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4327 - accuracy: 0.7967 - val_loss: 0.4261 - val_accuracy: 0.8003 - 910ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4320 - accuracy: 0.7977 - val_loss: 0.4249 - val_accuracy: 0.8026 - 985ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4324 - accuracy: 0.7962 - val_loss: 0.4270 - val_accuracy: 0.8051 - 965ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7974 - val_loss: 0.4251 - val_accuracy: 0.8052 - 998ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.4263 - val_accuracy: 0.8012 - 982ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4312 - accuracy: 0.7970 - val_loss: 0.4266 - val_accuracy: 0.8026 - 951ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4319 - accuracy: 0.7959 - val_loss: 0.4261 - val_accuracy: 0.8040 - 991ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4307 - accuracy: 0.7978 - val_loss: 0.4243 - val_accuracy: 0.8009 - 1s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.7973 - val_loss: 0.4259 - val_accuracy: 0.8059 - 949ms/epoch - 8ms/step\n",
      "Epoch 31: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  1  trained\n",
      "Epoch 1/100\n",
      "123/123 - 4s - loss: 0.5565 - accuracy: 0.7415 - val_loss: 0.4938 - val_accuracy: 0.7740 - 4s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4820 - accuracy: 0.7734 - val_loss: 0.4611 - val_accuracy: 0.7829 - 922ms/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4496 - val_accuracy: 0.7893 - 904ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4547 - accuracy: 0.7851 - val_loss: 0.4476 - val_accuracy: 0.7918 - 923ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4490 - accuracy: 0.7850 - val_loss: 0.4363 - val_accuracy: 0.7950 - 925ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4457 - accuracy: 0.7900 - val_loss: 0.4380 - val_accuracy: 0.7954 - 1s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4441 - accuracy: 0.7885 - val_loss: 0.4351 - val_accuracy: 0.7960 - 983ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4428 - accuracy: 0.7897 - val_loss: 0.4344 - val_accuracy: 0.7955 - 894ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4398 - accuracy: 0.7924 - val_loss: 0.4309 - val_accuracy: 0.7949 - 1s/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4396 - accuracy: 0.7922 - val_loss: 0.4304 - val_accuracy: 0.7972 - 989ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4385 - accuracy: 0.7921 - val_loss: 0.4306 - val_accuracy: 0.8000 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4373 - accuracy: 0.7922 - val_loss: 0.4292 - val_accuracy: 0.7964 - 1s/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4353 - accuracy: 0.7945 - val_loss: 0.4267 - val_accuracy: 0.8001 - 996ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4360 - accuracy: 0.7953 - val_loss: 0.4298 - val_accuracy: 0.7990 - 1s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4351 - accuracy: 0.7943 - val_loss: 0.4281 - val_accuracy: 0.8008 - 1s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4361 - accuracy: 0.7933 - val_loss: 0.4260 - val_accuracy: 0.7971 - 1s/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4347 - accuracy: 0.7967 - val_loss: 0.4299 - val_accuracy: 0.7976 - 1s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4359 - accuracy: 0.7950 - val_loss: 0.4252 - val_accuracy: 0.8024 - 1s/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4334 - accuracy: 0.7975 - val_loss: 0.4249 - val_accuracy: 0.8010 - 1s/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4341 - accuracy: 0.7953 - val_loss: 0.4254 - val_accuracy: 0.8004 - 944ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4342 - accuracy: 0.7964 - val_loss: 0.4299 - val_accuracy: 0.7997 - 1s/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4339 - accuracy: 0.7941 - val_loss: 0.4278 - val_accuracy: 0.7983 - 923ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4334 - accuracy: 0.7958 - val_loss: 0.4254 - val_accuracy: 0.8023 - 1s/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4334 - accuracy: 0.7954 - val_loss: 0.4249 - val_accuracy: 0.8006 - 1s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4336 - accuracy: 0.7960 - val_loss: 0.4284 - val_accuracy: 0.7980 - 1s/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4331 - accuracy: 0.7965 - val_loss: 0.4265 - val_accuracy: 0.8015 - 1s/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4324 - accuracy: 0.7961 - val_loss: 0.4224 - val_accuracy: 0.8020 - 960ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4315 - accuracy: 0.7989 - val_loss: 0.4261 - val_accuracy: 0.8005 - 1s/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4322 - accuracy: 0.7981 - val_loss: 0.4260 - val_accuracy: 0.8033 - 1s/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4324 - accuracy: 0.7968 - val_loss: 0.4275 - val_accuracy: 0.8000 - 962ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4311 - accuracy: 0.7959 - val_loss: 0.4261 - val_accuracy: 0.7992 - 922ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.7981 - val_loss: 0.4253 - val_accuracy: 0.8026 - 1s/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4318 - accuracy: 0.7976 - val_loss: 0.4241 - val_accuracy: 0.8022 - 1s/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7980 - val_loss: 0.4265 - val_accuracy: 0.8010 - 1s/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.7975 - val_loss: 0.4247 - val_accuracy: 0.8032 - 996ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4314 - accuracy: 0.7981 - val_loss: 0.4274 - val_accuracy: 0.8022 - 978ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7972 - val_loss: 0.4213 - val_accuracy: 0.8037 - 957ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4320 - accuracy: 0.7995 - val_loss: 0.4246 - val_accuracy: 0.8036 - 998ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.4252 - val_accuracy: 0.8028 - 945ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4324 - accuracy: 0.7974 - val_loss: 0.4253 - val_accuracy: 0.8009 - 1s/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4315 - accuracy: 0.7973 - val_loss: 0.4239 - val_accuracy: 0.8041 - 975ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.7982 - val_loss: 0.4228 - val_accuracy: 0.8054 - 919ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4326 - accuracy: 0.7982 - val_loss: 0.4240 - val_accuracy: 0.8044 - 1s/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7977 - val_loss: 0.4220 - val_accuracy: 0.8036 - 1s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.7985 - val_loss: 0.4232 - val_accuracy: 0.8037 - 991ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.7974 - val_loss: 0.4243 - val_accuracy: 0.8038 - 986ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.7971 - val_loss: 0.4228 - val_accuracy: 0.8045 - 1s/epoch - 8ms/step\n",
      "Epoch 47: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  2  trained\n",
      "Epoch 1/100\n",
      "123/123 - 4s - loss: 0.5539 - accuracy: 0.7375 - val_loss: 0.4912 - val_accuracy: 0.7786 - 4s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4782 - accuracy: 0.7763 - val_loss: 0.4618 - val_accuracy: 0.7878 - 1s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4624 - accuracy: 0.7819 - val_loss: 0.4433 - val_accuracy: 0.7919 - 1s/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4531 - accuracy: 0.7865 - val_loss: 0.4394 - val_accuracy: 0.7991 - 1s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4484 - accuracy: 0.7881 - val_loss: 0.4367 - val_accuracy: 0.7953 - 1s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4437 - accuracy: 0.7915 - val_loss: 0.4382 - val_accuracy: 0.7972 - 981ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4420 - accuracy: 0.7898 - val_loss: 0.4333 - val_accuracy: 0.7933 - 967ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4398 - accuracy: 0.7922 - val_loss: 0.4324 - val_accuracy: 0.7990 - 1s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4382 - accuracy: 0.7928 - val_loss: 0.4333 - val_accuracy: 0.7958 - 951ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4364 - accuracy: 0.7942 - val_loss: 0.4315 - val_accuracy: 0.8019 - 923ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4366 - accuracy: 0.7950 - val_loss: 0.4309 - val_accuracy: 0.7991 - 940ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4363 - accuracy: 0.7961 - val_loss: 0.4271 - val_accuracy: 0.7999 - 889ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4348 - accuracy: 0.7965 - val_loss: 0.4270 - val_accuracy: 0.7985 - 1s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4349 - accuracy: 0.7949 - val_loss: 0.4272 - val_accuracy: 0.7994 - 966ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4332 - accuracy: 0.7972 - val_loss: 0.4268 - val_accuracy: 0.7971 - 985ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4338 - accuracy: 0.7958 - val_loss: 0.4277 - val_accuracy: 0.7994 - 1s/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4345 - accuracy: 0.7958 - val_loss: 0.4264 - val_accuracy: 0.8020 - 1s/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4242 - val_accuracy: 0.8046 - 1s/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4326 - accuracy: 0.7967 - val_loss: 0.4252 - val_accuracy: 0.8000 - 1s/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4336 - accuracy: 0.7946 - val_loss: 0.4256 - val_accuracy: 0.7995 - 1s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4336 - accuracy: 0.7962 - val_loss: 0.4232 - val_accuracy: 0.8055 - 984ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4320 - accuracy: 0.7978 - val_loss: 0.4260 - val_accuracy: 0.8010 - 947ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4322 - accuracy: 0.7967 - val_loss: 0.4256 - val_accuracy: 0.8022 - 947ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4314 - accuracy: 0.7981 - val_loss: 0.4276 - val_accuracy: 0.8020 - 952ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4315 - accuracy: 0.7973 - val_loss: 0.4257 - val_accuracy: 0.8001 - 936ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4312 - accuracy: 0.7962 - val_loss: 0.4254 - val_accuracy: 0.7959 - 1s/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4320 - accuracy: 0.7959 - val_loss: 0.4260 - val_accuracy: 0.8022 - 1s/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4319 - accuracy: 0.7973 - val_loss: 0.4240 - val_accuracy: 0.8012 - 965ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.7962 - val_loss: 0.4238 - val_accuracy: 0.8035 - 939ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.7994 - val_loss: 0.4234 - val_accuracy: 0.8028 - 961ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4314 - accuracy: 0.7974 - val_loss: 0.4247 - val_accuracy: 0.8033 - 986ms/epoch - 8ms/step\n",
      "Epoch 31: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  3  trained\n",
      "Epoch 1/100\n",
      "123/123 - 4s - loss: 0.5537 - accuracy: 0.7404 - val_loss: 0.4900 - val_accuracy: 0.7701 - 4s/epoch - 29ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4725 - accuracy: 0.7699 - val_loss: 0.4553 - val_accuracy: 0.7852 - 1s/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4543 - accuracy: 0.7823 - val_loss: 0.4508 - val_accuracy: 0.7931 - 1s/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4530 - accuracy: 0.7851 - val_loss: 0.4435 - val_accuracy: 0.7916 - 1s/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4463 - accuracy: 0.7893 - val_loss: 0.4382 - val_accuracy: 0.7945 - 1s/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4452 - accuracy: 0.7928 - val_loss: 0.4371 - val_accuracy: 0.7933 - 1s/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4421 - accuracy: 0.7914 - val_loss: 0.4333 - val_accuracy: 0.7965 - 1s/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4419 - accuracy: 0.7913 - val_loss: 0.4317 - val_accuracy: 0.7980 - 885ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4390 - accuracy: 0.7934 - val_loss: 0.4337 - val_accuracy: 0.7996 - 913ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4373 - accuracy: 0.7966 - val_loss: 0.4287 - val_accuracy: 0.7990 - 966ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4346 - accuracy: 0.7958 - val_loss: 0.4277 - val_accuracy: 0.7990 - 977ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.4301 - val_accuracy: 0.7960 - 912ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4346 - accuracy: 0.7977 - val_loss: 0.4296 - val_accuracy: 0.7962 - 1s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4350 - accuracy: 0.7966 - val_loss: 0.4267 - val_accuracy: 0.8044 - 1s/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4356 - accuracy: 0.7959 - val_loss: 0.4270 - val_accuracy: 0.8004 - 993ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4349 - accuracy: 0.7980 - val_loss: 0.4306 - val_accuracy: 0.7996 - 970ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4348 - accuracy: 0.7950 - val_loss: 0.4249 - val_accuracy: 0.8049 - 950ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4343 - accuracy: 0.7981 - val_loss: 0.4264 - val_accuracy: 0.7987 - 932ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4340 - accuracy: 0.7975 - val_loss: 0.4279 - val_accuracy: 0.8010 - 923ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4357 - accuracy: 0.7961 - val_loss: 0.4266 - val_accuracy: 0.8012 - 935ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4341 - accuracy: 0.7947 - val_loss: 0.4288 - val_accuracy: 0.7994 - 939ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4344 - accuracy: 0.7948 - val_loss: 0.4276 - val_accuracy: 0.8024 - 982ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4315 - accuracy: 0.7980 - val_loss: 0.4248 - val_accuracy: 0.8028 - 1s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4318 - accuracy: 0.7972 - val_loss: 0.4257 - val_accuracy: 0.8009 - 988ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4311 - accuracy: 0.7982 - val_loss: 0.4261 - val_accuracy: 0.7978 - 917ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4317 - accuracy: 0.7967 - val_loss: 0.4284 - val_accuracy: 0.8010 - 986ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4326 - accuracy: 0.7955 - val_loss: 0.4260 - val_accuracy: 0.8031 - 984ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.7984 - val_loss: 0.4242 - val_accuracy: 0.8022 - 979ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4329 - accuracy: 0.7981 - val_loss: 0.4268 - val_accuracy: 0.8010 - 902ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4304 - accuracy: 0.7983 - val_loss: 0.4264 - val_accuracy: 0.7991 - 1s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4315 - accuracy: 0.7977 - val_loss: 0.4228 - val_accuracy: 0.8008 - 956ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7970 - val_loss: 0.4275 - val_accuracy: 0.8037 - 942ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4324 - accuracy: 0.7987 - val_loss: 0.4245 - val_accuracy: 0.7999 - 912ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.7994 - val_loss: 0.4247 - val_accuracy: 0.8014 - 984ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.7985 - val_loss: 0.4257 - val_accuracy: 0.8029 - 1s/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4302 - accuracy: 0.7979 - val_loss: 0.4259 - val_accuracy: 0.8031 - 963ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4313 - accuracy: 0.7984 - val_loss: 0.4241 - val_accuracy: 0.8035 - 961ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4297 - accuracy: 0.7976 - val_loss: 0.4225 - val_accuracy: 0.8014 - 1s/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4300 - accuracy: 0.7980 - val_loss: 0.4227 - val_accuracy: 0.8005 - 1s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.8006 - val_loss: 0.4252 - val_accuracy: 0.8024 - 984ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4287 - accuracy: 0.7992 - val_loss: 0.4245 - val_accuracy: 0.8042 - 982ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 1s - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.4233 - val_accuracy: 0.8049 - 981ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4299 - accuracy: 0.7992 - val_loss: 0.4239 - val_accuracy: 0.8031 - 905ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.4244 - val_accuracy: 0.8027 - 1s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4291 - accuracy: 0.7972 - val_loss: 0.4239 - val_accuracy: 0.8047 - 1s/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "123/123 - 1s - loss: 0.4283 - accuracy: 0.8004 - val_loss: 0.4270 - val_accuracy: 0.8026 - 961ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.7976 - val_loss: 0.4223 - val_accuracy: 0.8023 - 964ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "123/123 - 1s - loss: 0.4304 - accuracy: 0.7988 - val_loss: 0.4219 - val_accuracy: 0.8004 - 885ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7975 - val_loss: 0.4241 - val_accuracy: 0.8026 - 961ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "123/123 - 1s - loss: 0.4287 - accuracy: 0.7997 - val_loss: 0.4200 - val_accuracy: 0.8051 - 966ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "123/123 - 1s - loss: 0.4290 - accuracy: 0.7975 - val_loss: 0.4251 - val_accuracy: 0.8006 - 930ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "123/123 - 1s - loss: 0.4306 - accuracy: 0.7981 - val_loss: 0.4229 - val_accuracy: 0.8044 - 1s/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "123/123 - 1s - loss: 0.4285 - accuracy: 0.7990 - val_loss: 0.4240 - val_accuracy: 0.8060 - 1s/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "123/123 - 1s - loss: 0.4297 - accuracy: 0.7976 - val_loss: 0.4234 - val_accuracy: 0.8024 - 997ms/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.7981 - val_loss: 0.4248 - val_accuracy: 0.8060 - 1s/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "123/123 - 1s - loss: 0.4288 - accuracy: 0.7988 - val_loss: 0.4212 - val_accuracy: 0.8026 - 978ms/epoch - 8ms/step\n",
      "Epoch 57/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.7982 - val_loss: 0.4225 - val_accuracy: 0.8050 - 1s/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "123/123 - 1s - loss: 0.4293 - accuracy: 0.7972 - val_loss: 0.4237 - val_accuracy: 0.8040 - 991ms/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "123/123 - 1s - loss: 0.4275 - accuracy: 0.7980 - val_loss: 0.4253 - val_accuracy: 0.7983 - 1s/epoch - 9ms/step\n",
      "Epoch 60/100\n",
      "123/123 - 1s - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.4224 - val_accuracy: 0.8035 - 1s/epoch - 8ms/step\n",
      "Epoch 60: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  4  trained\n",
      "Epoch 1/100\n",
      "123/123 - 5s - loss: 0.5571 - accuracy: 0.7301 - val_loss: 0.4919 - val_accuracy: 0.7675 - 5s/epoch - 44ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4814 - accuracy: 0.7662 - val_loss: 0.4613 - val_accuracy: 0.7840 - 1s/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4630 - accuracy: 0.7768 - val_loss: 0.4509 - val_accuracy: 0.7843 - 987ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4563 - accuracy: 0.7811 - val_loss: 0.4493 - val_accuracy: 0.7926 - 991ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4519 - accuracy: 0.7845 - val_loss: 0.4443 - val_accuracy: 0.7889 - 1s/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4468 - accuracy: 0.7878 - val_loss: 0.4418 - val_accuracy: 0.7935 - 927ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4451 - accuracy: 0.7892 - val_loss: 0.4427 - val_accuracy: 0.7930 - 1000ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4433 - accuracy: 0.7924 - val_loss: 0.4359 - val_accuracy: 0.7951 - 927ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4409 - accuracy: 0.7913 - val_loss: 0.4317 - val_accuracy: 0.8035 - 907ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4442 - accuracy: 0.7913 - val_loss: 0.4342 - val_accuracy: 0.7932 - 922ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4396 - accuracy: 0.7912 - val_loss: 0.4350 - val_accuracy: 0.7986 - 917ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4396 - accuracy: 0.7933 - val_loss: 0.4308 - val_accuracy: 0.7968 - 946ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4384 - accuracy: 0.7926 - val_loss: 0.4290 - val_accuracy: 0.8024 - 917ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4384 - accuracy: 0.7931 - val_loss: 0.4307 - val_accuracy: 0.7980 - 1s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4379 - accuracy: 0.7937 - val_loss: 0.4310 - val_accuracy: 0.8028 - 959ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4363 - accuracy: 0.7947 - val_loss: 0.4309 - val_accuracy: 0.7985 - 908ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4365 - accuracy: 0.7956 - val_loss: 0.4278 - val_accuracy: 0.8000 - 979ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4368 - accuracy: 0.7961 - val_loss: 0.4287 - val_accuracy: 0.7986 - 948ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4342 - accuracy: 0.7949 - val_loss: 0.4333 - val_accuracy: 0.8003 - 917ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4332 - accuracy: 0.7982 - val_loss: 0.4284 - val_accuracy: 0.7980 - 991ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4334 - accuracy: 0.7942 - val_loss: 0.4242 - val_accuracy: 0.8018 - 966ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4327 - accuracy: 0.7966 - val_loss: 0.4265 - val_accuracy: 0.7980 - 926ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4336 - accuracy: 0.7974 - val_loss: 0.4250 - val_accuracy: 0.8005 - 1s/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4322 - accuracy: 0.7978 - val_loss: 0.4282 - val_accuracy: 0.8018 - 954ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4324 - accuracy: 0.7974 - val_loss: 0.4248 - val_accuracy: 0.8037 - 1s/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4328 - accuracy: 0.7967 - val_loss: 0.4259 - val_accuracy: 0.8031 - 954ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4323 - accuracy: 0.7971 - val_loss: 0.4261 - val_accuracy: 0.8020 - 974ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4338 - accuracy: 0.7943 - val_loss: 0.4246 - val_accuracy: 0.8019 - 994ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4233 - val_accuracy: 0.8047 - 937ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4318 - accuracy: 0.7977 - val_loss: 0.4286 - val_accuracy: 0.8012 - 966ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4327 - accuracy: 0.7963 - val_loss: 0.4227 - val_accuracy: 0.8049 - 943ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4313 - accuracy: 0.7961 - val_loss: 0.4263 - val_accuracy: 0.8006 - 849ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4320 - accuracy: 0.7995 - val_loss: 0.4243 - val_accuracy: 0.8015 - 962ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7974 - val_loss: 0.4257 - val_accuracy: 0.8017 - 962ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.4210 - val_accuracy: 0.8040 - 916ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4300 - accuracy: 0.7975 - val_loss: 0.4229 - val_accuracy: 0.8033 - 1s/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7973 - val_loss: 0.4240 - val_accuracy: 0.8022 - 965ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4307 - accuracy: 0.7966 - val_loss: 0.4228 - val_accuracy: 0.8032 - 976ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7988 - val_loss: 0.4221 - val_accuracy: 0.8047 - 978ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4308 - accuracy: 0.7966 - val_loss: 0.4226 - val_accuracy: 0.8036 - 942ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7980 - val_loss: 0.4248 - val_accuracy: 0.8013 - 890ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 1s - loss: 0.4299 - accuracy: 0.7999 - val_loss: 0.4241 - val_accuracy: 0.8023 - 906ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4307 - accuracy: 0.7979 - val_loss: 0.4251 - val_accuracy: 0.8029 - 951ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.7976 - val_loss: 0.4221 - val_accuracy: 0.8069 - 1s/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4295 - accuracy: 0.7971 - val_loss: 0.4240 - val_accuracy: 0.8031 - 1000ms/epoch - 8ms/step\n",
      "Epoch 45: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  5  trained\n",
      "Epoch 1/100\n",
      "123/123 - 3s - loss: 0.5979 - accuracy: 0.6922 - val_loss: 0.5131 - val_accuracy: 0.7681 - 3s/epoch - 28ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4959 - accuracy: 0.7673 - val_loss: 0.4673 - val_accuracy: 0.7835 - 928ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4693 - accuracy: 0.7787 - val_loss: 0.4565 - val_accuracy: 0.7844 - 1s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4575 - accuracy: 0.7843 - val_loss: 0.4512 - val_accuracy: 0.7903 - 930ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.4440 - val_accuracy: 0.7928 - 1s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4470 - accuracy: 0.7865 - val_loss: 0.4415 - val_accuracy: 0.7876 - 1s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4457 - accuracy: 0.7891 - val_loss: 0.4363 - val_accuracy: 0.7991 - 918ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4430 - accuracy: 0.7912 - val_loss: 0.4345 - val_accuracy: 0.7918 - 1s/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4396 - accuracy: 0.7918 - val_loss: 0.4360 - val_accuracy: 0.7942 - 1s/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4415 - accuracy: 0.7910 - val_loss: 0.4339 - val_accuracy: 0.7946 - 925ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4374 - accuracy: 0.7924 - val_loss: 0.4331 - val_accuracy: 0.7991 - 932ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4372 - accuracy: 0.7949 - val_loss: 0.4280 - val_accuracy: 0.7995 - 979ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4368 - accuracy: 0.7951 - val_loss: 0.4292 - val_accuracy: 0.7986 - 889ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4361 - accuracy: 0.7944 - val_loss: 0.4258 - val_accuracy: 0.7995 - 892ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4356 - accuracy: 0.7941 - val_loss: 0.4294 - val_accuracy: 0.8005 - 887ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4345 - accuracy: 0.7970 - val_loss: 0.4274 - val_accuracy: 0.7981 - 937ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4279 - val_accuracy: 0.8004 - 911ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4360 - accuracy: 0.7967 - val_loss: 0.4251 - val_accuracy: 0.8040 - 925ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4275 - val_accuracy: 0.7988 - 908ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4341 - accuracy: 0.7967 - val_loss: 0.4280 - val_accuracy: 0.8032 - 973ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4334 - accuracy: 0.7968 - val_loss: 0.4278 - val_accuracy: 0.8005 - 1s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4338 - accuracy: 0.7970 - val_loss: 0.4261 - val_accuracy: 0.8000 - 950ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4331 - accuracy: 0.7961 - val_loss: 0.4271 - val_accuracy: 0.7986 - 1s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4329 - accuracy: 0.7968 - val_loss: 0.4231 - val_accuracy: 0.8024 - 1s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4323 - accuracy: 0.7974 - val_loss: 0.4240 - val_accuracy: 0.8012 - 954ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4321 - accuracy: 0.7973 - val_loss: 0.4259 - val_accuracy: 0.8005 - 979ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.7968 - val_loss: 0.4236 - val_accuracy: 0.8015 - 965ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4317 - accuracy: 0.7976 - val_loss: 0.4264 - val_accuracy: 0.8004 - 952ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4308 - accuracy: 0.7971 - val_loss: 0.4237 - val_accuracy: 0.8051 - 915ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4311 - accuracy: 0.7977 - val_loss: 0.4252 - val_accuracy: 0.8015 - 973ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4232 - val_accuracy: 0.8006 - 947ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4318 - accuracy: 0.7977 - val_loss: 0.4263 - val_accuracy: 0.8044 - 961ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.4227 - val_accuracy: 0.8049 - 979ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7980 - val_loss: 0.4245 - val_accuracy: 0.8047 - 978ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4300 - accuracy: 0.7985 - val_loss: 0.4239 - val_accuracy: 0.7995 - 1s/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4302 - accuracy: 0.7979 - val_loss: 0.4264 - val_accuracy: 0.8036 - 1s/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7982 - val_loss: 0.4273 - val_accuracy: 0.8051 - 1s/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4311 - accuracy: 0.7991 - val_loss: 0.4247 - val_accuracy: 0.8040 - 954ms/epoch - 8ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4296 - accuracy: 0.8000 - val_loss: 0.4255 - val_accuracy: 0.8042 - 962ms/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4297 - accuracy: 0.7982 - val_loss: 0.4218 - val_accuracy: 0.8044 - 918ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4308 - accuracy: 0.7997 - val_loss: 0.4232 - val_accuracy: 0.8045 - 1s/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7981 - val_loss: 0.4221 - val_accuracy: 0.8042 - 1s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4300 - accuracy: 0.7974 - val_loss: 0.4251 - val_accuracy: 0.8065 - 987ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4294 - accuracy: 0.7999 - val_loss: 0.4264 - val_accuracy: 0.7990 - 911ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7990 - val_loss: 0.4255 - val_accuracy: 0.8028 - 950ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "123/123 - 1s - loss: 0.4293 - accuracy: 0.7990 - val_loss: 0.4247 - val_accuracy: 0.8037 - 955ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7985 - val_loss: 0.4235 - val_accuracy: 0.8015 - 959ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "123/123 - 1s - loss: 0.4304 - accuracy: 0.7974 - val_loss: 0.4231 - val_accuracy: 0.8012 - 1s/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "123/123 - 1s - loss: 0.4286 - accuracy: 0.7994 - val_loss: 0.4248 - val_accuracy: 0.8036 - 1s/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "123/123 - 1s - loss: 0.4301 - accuracy: 0.7988 - val_loss: 0.4240 - val_accuracy: 0.8050 - 1s/epoch - 8ms/step\n",
      "Epoch 50: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  6  trained\n",
      "Epoch 1/100\n",
      "123/123 - 3s - loss: 0.5387 - accuracy: 0.7480 - val_loss: 0.4836 - val_accuracy: 0.7707 - 3s/epoch - 28ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4755 - accuracy: 0.7673 - val_loss: 0.4615 - val_accuracy: 0.7844 - 924ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4609 - accuracy: 0.7815 - val_loss: 0.4503 - val_accuracy: 0.7928 - 909ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4550 - accuracy: 0.7861 - val_loss: 0.4450 - val_accuracy: 0.7930 - 907ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4495 - accuracy: 0.7903 - val_loss: 0.4377 - val_accuracy: 0.7971 - 1s/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4471 - accuracy: 0.7899 - val_loss: 0.4344 - val_accuracy: 0.7949 - 1s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4432 - accuracy: 0.7928 - val_loss: 0.4329 - val_accuracy: 0.7991 - 962ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4409 - accuracy: 0.7937 - val_loss: 0.4332 - val_accuracy: 0.7983 - 973ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4401 - accuracy: 0.7940 - val_loss: 0.4361 - val_accuracy: 0.7971 - 945ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4391 - accuracy: 0.7959 - val_loss: 0.4302 - val_accuracy: 0.8015 - 923ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4372 - accuracy: 0.7961 - val_loss: 0.4300 - val_accuracy: 0.8037 - 874ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4388 - accuracy: 0.7948 - val_loss: 0.4332 - val_accuracy: 0.7972 - 956ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4359 - accuracy: 0.7956 - val_loss: 0.4266 - val_accuracy: 0.8006 - 993ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4355 - accuracy: 0.7957 - val_loss: 0.4258 - val_accuracy: 0.8003 - 956ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4332 - accuracy: 0.7984 - val_loss: 0.4287 - val_accuracy: 0.8022 - 948ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4359 - accuracy: 0.7980 - val_loss: 0.4273 - val_accuracy: 0.8008 - 1s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4342 - accuracy: 0.7977 - val_loss: 0.4253 - val_accuracy: 0.8033 - 1s/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4350 - accuracy: 0.7988 - val_loss: 0.4286 - val_accuracy: 0.8037 - 925ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4328 - accuracy: 0.7983 - val_loss: 0.4278 - val_accuracy: 0.8026 - 958ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4327 - accuracy: 0.7984 - val_loss: 0.4294 - val_accuracy: 0.8022 - 885ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4337 - accuracy: 0.7978 - val_loss: 0.4237 - val_accuracy: 0.8049 - 1s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4330 - accuracy: 0.7989 - val_loss: 0.4256 - val_accuracy: 0.8015 - 916ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4323 - accuracy: 0.7979 - val_loss: 0.4274 - val_accuracy: 0.8006 - 971ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4338 - accuracy: 0.7970 - val_loss: 0.4260 - val_accuracy: 0.8023 - 994ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4326 - accuracy: 0.7987 - val_loss: 0.4247 - val_accuracy: 0.8006 - 996ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4317 - accuracy: 0.7995 - val_loss: 0.4243 - val_accuracy: 0.8023 - 997ms/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4321 - accuracy: 0.7974 - val_loss: 0.4250 - val_accuracy: 0.8037 - 1s/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4329 - accuracy: 0.7979 - val_loss: 0.4275 - val_accuracy: 0.8001 - 995ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4314 - accuracy: 0.7981 - val_loss: 0.4239 - val_accuracy: 0.8035 - 1s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.7973 - val_loss: 0.4257 - val_accuracy: 0.8009 - 1s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4318 - accuracy: 0.7994 - val_loss: 0.4263 - val_accuracy: 0.8056 - 923ms/epoch - 8ms/step\n",
      "Epoch 31: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  7  trained\n",
      "Epoch 1/100\n",
      "123/123 - 3s - loss: 0.5640 - accuracy: 0.7229 - val_loss: 0.4971 - val_accuracy: 0.7754 - 3s/epoch - 27ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4783 - accuracy: 0.7763 - val_loss: 0.4605 - val_accuracy: 0.7832 - 1s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4631 - accuracy: 0.7800 - val_loss: 0.4499 - val_accuracy: 0.7946 - 994ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4524 - accuracy: 0.7853 - val_loss: 0.4472 - val_accuracy: 0.7903 - 968ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4502 - accuracy: 0.7881 - val_loss: 0.4392 - val_accuracy: 0.7964 - 916ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4437 - accuracy: 0.7908 - val_loss: 0.4404 - val_accuracy: 0.7987 - 1000ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4438 - accuracy: 0.7903 - val_loss: 0.4343 - val_accuracy: 0.7990 - 917ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4406 - accuracy: 0.7928 - val_loss: 0.4357 - val_accuracy: 0.7969 - 967ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4393 - accuracy: 0.7941 - val_loss: 0.4320 - val_accuracy: 0.7953 - 975ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4402 - accuracy: 0.7926 - val_loss: 0.4292 - val_accuracy: 0.7988 - 948ms/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4396 - accuracy: 0.7947 - val_loss: 0.4320 - val_accuracy: 0.7996 - 953ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4378 - accuracy: 0.7947 - val_loss: 0.4314 - val_accuracy: 0.8003 - 952ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4380 - accuracy: 0.7958 - val_loss: 0.4295 - val_accuracy: 0.8022 - 1s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4362 - accuracy: 0.7957 - val_loss: 0.4296 - val_accuracy: 0.7982 - 999ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4387 - accuracy: 0.7942 - val_loss: 0.4318 - val_accuracy: 0.7990 - 986ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4351 - accuracy: 0.7967 - val_loss: 0.4276 - val_accuracy: 0.7994 - 933ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4354 - accuracy: 0.7963 - val_loss: 0.4305 - val_accuracy: 0.7997 - 942ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4338 - accuracy: 0.7961 - val_loss: 0.4261 - val_accuracy: 0.8005 - 941ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4332 - accuracy: 0.7980 - val_loss: 0.4261 - val_accuracy: 0.8033 - 950ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.4277 - val_accuracy: 0.8004 - 970ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4345 - accuracy: 0.7970 - val_loss: 0.4278 - val_accuracy: 0.8023 - 954ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4339 - accuracy: 0.7971 - val_loss: 0.4291 - val_accuracy: 0.8018 - 1s/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4314 - accuracy: 0.7983 - val_loss: 0.4254 - val_accuracy: 0.8045 - 966ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4333 - accuracy: 0.7971 - val_loss: 0.4263 - val_accuracy: 0.8017 - 911ms/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4322 - accuracy: 0.7990 - val_loss: 0.4277 - val_accuracy: 0.8032 - 932ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4333 - accuracy: 0.7983 - val_loss: 0.4263 - val_accuracy: 0.8015 - 1s/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4324 - accuracy: 0.7977 - val_loss: 0.4277 - val_accuracy: 0.8010 - 1s/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4323 - accuracy: 0.7977 - val_loss: 0.4234 - val_accuracy: 0.8058 - 1s/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4324 - accuracy: 0.7977 - val_loss: 0.4270 - val_accuracy: 0.7995 - 938ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4311 - accuracy: 0.8009 - val_loss: 0.4243 - val_accuracy: 0.8003 - 938ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7982 - val_loss: 0.4234 - val_accuracy: 0.8044 - 975ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4320 - accuracy: 0.7975 - val_loss: 0.4252 - val_accuracy: 0.8024 - 934ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4326 - accuracy: 0.7962 - val_loss: 0.4250 - val_accuracy: 0.8018 - 924ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4301 - accuracy: 0.7990 - val_loss: 0.4275 - val_accuracy: 0.8008 - 933ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7982 - val_loss: 0.4279 - val_accuracy: 0.8031 - 922ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4313 - accuracy: 0.7966 - val_loss: 0.4231 - val_accuracy: 0.8058 - 941ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7990 - val_loss: 0.4265 - val_accuracy: 0.7988 - 932ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "123/123 - 1s - loss: 0.4301 - accuracy: 0.7974 - val_loss: 0.4245 - val_accuracy: 0.7997 - 887ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7985 - val_loss: 0.4260 - val_accuracy: 0.8024 - 1s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.7963 - val_loss: 0.4235 - val_accuracy: 0.8042 - 999ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "123/123 - 1s - loss: 0.4304 - accuracy: 0.7994 - val_loss: 0.4237 - val_accuracy: 0.8040 - 897ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "123/123 - 1s - loss: 0.4310 - accuracy: 0.7960 - val_loss: 0.4252 - val_accuracy: 0.8004 - 944ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "123/123 - 1s - loss: 0.4303 - accuracy: 0.7989 - val_loss: 0.4245 - val_accuracy: 0.8041 - 930ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "123/123 - 1s - loss: 0.4302 - accuracy: 0.7985 - val_loss: 0.4262 - val_accuracy: 0.8038 - 934ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "123/123 - 1s - loss: 0.4306 - accuracy: 0.7995 - val_loss: 0.4244 - val_accuracy: 0.8023 - 929ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "123/123 - 1s - loss: 0.4311 - accuracy: 0.7987 - val_loss: 0.4262 - val_accuracy: 0.7982 - 866ms/epoch - 7ms/step\n",
      "Epoch 46: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  8  trained\n",
      "Epoch 1/100\n",
      "123/123 - 4s - loss: 0.5379 - accuracy: 0.7496 - val_loss: 0.4904 - val_accuracy: 0.7706 - 4s/epoch - 31ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4791 - accuracy: 0.7731 - val_loss: 0.4606 - val_accuracy: 0.7873 - 932ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4588 - accuracy: 0.7853 - val_loss: 0.4499 - val_accuracy: 0.7916 - 1s/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4501 - accuracy: 0.7885 - val_loss: 0.4373 - val_accuracy: 0.7928 - 1s/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4440 - accuracy: 0.7914 - val_loss: 0.4363 - val_accuracy: 0.7982 - 927ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4431 - accuracy: 0.7918 - val_loss: 0.4324 - val_accuracy: 0.7932 - 956ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4410 - accuracy: 0.7925 - val_loss: 0.4343 - val_accuracy: 0.8001 - 924ms/epoch - 8ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4396 - accuracy: 0.7953 - val_loss: 0.4312 - val_accuracy: 0.8022 - 920ms/epoch - 7ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4378 - accuracy: 0.7953 - val_loss: 0.4301 - val_accuracy: 0.8028 - 932ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4371 - accuracy: 0.7947 - val_loss: 0.4290 - val_accuracy: 0.8013 - 1s/epoch - 8ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4359 - accuracy: 0.7966 - val_loss: 0.4278 - val_accuracy: 0.8006 - 1s/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4344 - accuracy: 0.7973 - val_loss: 0.4300 - val_accuracy: 0.8008 - 956ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 1s - loss: 0.4367 - accuracy: 0.7953 - val_loss: 0.4296 - val_accuracy: 0.8018 - 941ms/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 1s - loss: 0.4367 - accuracy: 0.7974 - val_loss: 0.4292 - val_accuracy: 0.8020 - 923ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 1s - loss: 0.4341 - accuracy: 0.7980 - val_loss: 0.4279 - val_accuracy: 0.7978 - 921ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 1s - loss: 0.4347 - accuracy: 0.7954 - val_loss: 0.4286 - val_accuracy: 0.8022 - 940ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 1s - loss: 0.4343 - accuracy: 0.7964 - val_loss: 0.4293 - val_accuracy: 0.7980 - 964ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 1s - loss: 0.4340 - accuracy: 0.7977 - val_loss: 0.4297 - val_accuracy: 0.8040 - 964ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 1s - loss: 0.4329 - accuracy: 0.7979 - val_loss: 0.4252 - val_accuracy: 0.8035 - 910ms/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.4277 - val_accuracy: 0.8015 - 1s/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 1s - loss: 0.4323 - accuracy: 0.7981 - val_loss: 0.4238 - val_accuracy: 0.8059 - 946ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4337 - accuracy: 0.7978 - val_loss: 0.4269 - val_accuracy: 0.8014 - 1s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4337 - accuracy: 0.7968 - val_loss: 0.4240 - val_accuracy: 0.8042 - 1s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "123/123 - 1s - loss: 0.4319 - accuracy: 0.7996 - val_loss: 0.4251 - val_accuracy: 0.8041 - 955ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "123/123 - 1s - loss: 0.4338 - accuracy: 0.7972 - val_loss: 0.4265 - val_accuracy: 0.8041 - 886ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "123/123 - 1s - loss: 0.4314 - accuracy: 0.7991 - val_loss: 0.4239 - val_accuracy: 0.8040 - 1s/epoch - 8ms/step\n",
      "Epoch 27/100\n",
      "123/123 - 1s - loss: 0.4305 - accuracy: 0.7993 - val_loss: 0.4235 - val_accuracy: 0.8070 - 1s/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.7984 - val_loss: 0.4255 - val_accuracy: 0.8032 - 1s/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "123/123 - 1s - loss: 0.4316 - accuracy: 0.7984 - val_loss: 0.4254 - val_accuracy: 0.8022 - 1s/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "123/123 - 1s - loss: 0.4309 - accuracy: 0.7990 - val_loss: 0.4258 - val_accuracy: 0.8019 - 1s/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "123/123 - 1s - loss: 0.4329 - accuracy: 0.7970 - val_loss: 0.4254 - val_accuracy: 0.8047 - 1s/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "123/123 - 1s - loss: 0.4308 - accuracy: 0.7985 - val_loss: 0.4239 - val_accuracy: 0.8044 - 1s/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "123/123 - 1s - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4275 - val_accuracy: 0.8063 - 965ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "123/123 - 1s - loss: 0.4302 - accuracy: 0.8001 - val_loss: 0.4261 - val_accuracy: 0.7997 - 1s/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "123/123 - 1s - loss: 0.4312 - accuracy: 0.7989 - val_loss: 0.4256 - val_accuracy: 0.8028 - 949ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "123/123 - 1s - loss: 0.4306 - accuracy: 0.7987 - val_loss: 0.4255 - val_accuracy: 0.8014 - 920ms/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "123/123 - 1s - loss: 0.4300 - accuracy: 0.7991 - val_loss: 0.4252 - val_accuracy: 0.7992 - 949ms/epoch - 8ms/step\n",
      "Epoch 37: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  9  trained\n",
      "Epoch 1/100\n",
      "123/123 - 28s - loss: 0.5438 - accuracy: 0.7459 - val_loss: 0.4861 - val_accuracy: 0.7738 - 28s/epoch - 230ms/step\n",
      "Epoch 2/100\n",
      "123/123 - 1s - loss: 0.4778 - accuracy: 0.7735 - val_loss: 0.4588 - val_accuracy: 0.7837 - 1s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "123/123 - 1s - loss: 0.4649 - accuracy: 0.7776 - val_loss: 0.4485 - val_accuracy: 0.7899 - 1s/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "123/123 - 1s - loss: 0.4545 - accuracy: 0.7817 - val_loss: 0.4431 - val_accuracy: 0.7948 - 1s/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "123/123 - 1s - loss: 0.4486 - accuracy: 0.7875 - val_loss: 0.4403 - val_accuracy: 0.7965 - 1s/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "123/123 - 1s - loss: 0.4449 - accuracy: 0.7883 - val_loss: 0.4361 - val_accuracy: 0.7958 - 1s/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "123/123 - 1s - loss: 0.4431 - accuracy: 0.7913 - val_loss: 0.4373 - val_accuracy: 0.7995 - 1s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "123/123 - 1s - loss: 0.4426 - accuracy: 0.7905 - val_loss: 0.4304 - val_accuracy: 0.7959 - 1s/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "123/123 - 1s - loss: 0.4400 - accuracy: 0.7927 - val_loss: 0.4339 - val_accuracy: 0.7959 - 1s/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "123/123 - 1s - loss: 0.4384 - accuracy: 0.7927 - val_loss: 0.4309 - val_accuracy: 0.8017 - 1s/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "123/123 - 1s - loss: 0.4374 - accuracy: 0.7925 - val_loss: 0.4305 - val_accuracy: 0.7987 - 1s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "123/123 - 1s - loss: 0.4368 - accuracy: 0.7937 - val_loss: 0.4302 - val_accuracy: 0.7992 - 1s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "123/123 - 2s - loss: 0.4364 - accuracy: 0.7956 - val_loss: 0.4233 - val_accuracy: 0.8032 - 2s/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "123/123 - 2s - loss: 0.4365 - accuracy: 0.7961 - val_loss: 0.4297 - val_accuracy: 0.8020 - 2s/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "123/123 - 2s - loss: 0.4349 - accuracy: 0.7944 - val_loss: 0.4291 - val_accuracy: 0.7981 - 2s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "123/123 - 2s - loss: 0.4366 - accuracy: 0.7949 - val_loss: 0.4269 - val_accuracy: 0.8026 - 2s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "123/123 - 2s - loss: 0.4354 - accuracy: 0.7956 - val_loss: 0.4263 - val_accuracy: 0.8026 - 2s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "123/123 - 2s - loss: 0.4336 - accuracy: 0.7967 - val_loss: 0.4273 - val_accuracy: 0.8024 - 2s/epoch - 15ms/step\n",
      "Epoch 19/100\n",
      "123/123 - 2s - loss: 0.4342 - accuracy: 0.7984 - val_loss: 0.4264 - val_accuracy: 0.8000 - 2s/epoch - 15ms/step\n",
      "Epoch 20/100\n",
      "123/123 - 1s - loss: 0.4344 - accuracy: 0.7985 - val_loss: 0.4256 - val_accuracy: 0.8009 - 1s/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "123/123 - 2s - loss: 0.4345 - accuracy: 0.7954 - val_loss: 0.4261 - val_accuracy: 0.8022 - 2s/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "123/123 - 1s - loss: 0.4306 - accuracy: 0.7976 - val_loss: 0.4260 - val_accuracy: 0.8015 - 1s/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "123/123 - 1s - loss: 0.4332 - accuracy: 0.7979 - val_loss: 0.4258 - val_accuracy: 0.8024 - 1s/epoch - 11ms/step\n",
      "Epoch 23: early stopping\n",
      "predicting...\n",
      "prediction completed\n",
      "ensemble model  10  trained\n",
      "ale entropy:  0.38920761635213935\n",
      "epi entropy:  0.36781284496582334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train ensemble dropout model for dataset size 0.1 to 1.0\n",
    "ale_entropy_ensemble_dropout = []\n",
    "epi_entropy_ensemble_dropout = []\n",
    "pred_prob_ensemble_dropout = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print('dataset size: ', np.round((i * 0.1 + 0.1),1))\n",
    "    pred, ale_entropy, epi_entropy = train_dropout_ensemble_model(train_sets[dataset_frac[i]].features, train_sets[dataset_frac[i]].labels.ravel(), dataset_orig_test.features, ensemble_size=10, prob=0.5)\n",
    "    print('ale entropy: ', np.mean(ale_entropy))\n",
    "    print('epi entropy: ', np.mean(epi_entropy))\n",
    "\n",
    "    # save ale and epi entropy\n",
    "    ale_entropy_ensemble_dropout.append(ale_entropy)\n",
    "    epi_entropy_ensemble_dropout.append(epi_entropy)\n",
    "    pred_prob_ensemble_dropout.append(pred)\n",
    "\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal opportunity difference for dataset of size 0.10 = 0.436810\n",
      "Equal opportunity difference for dataset of size 0.20 = 0.471916\n",
      "Equal opportunity difference for dataset of size 0.30 = 0.499498\n",
      "Equal opportunity difference for dataset of size 0.40 = 0.490973\n",
      "Equal opportunity difference for dataset of size 0.50 = 0.498495\n",
      "Equal opportunity difference for dataset of size 0.60 = 0.504012\n",
      "Equal opportunity difference for dataset of size 0.70 = 0.473420\n",
      "Equal opportunity difference for dataset of size 0.80 = 0.483952\n",
      "Equal opportunity difference for dataset of size 0.90 = 0.483952\n",
      "Equal opportunity difference for dataset of size 1.00 = 0.474423\n"
     ]
    }
   ],
   "source": [
    "Equal_opp_diffs_ensemble_dropout = equal_opportunity_difference(dataset_orig_test, pred_prob_ensemble_dropout, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  0.1\n",
      "ale entropy:  0.4372722935317099\n",
      "epi entropy:  0.4299152274922801\n",
      "\n",
      "dataset size:  0.2\n",
      "ale entropy:  0.4087815525819864\n",
      "epi entropy:  0.3970674522992296\n",
      "\n",
      "dataset size:  0.3\n",
      "ale entropy:  0.38071962967802947\n",
      "epi entropy:  0.3708748322640115\n",
      "\n",
      "dataset size:  0.4\n",
      "ale entropy:  0.387198803150255\n",
      "epi entropy:  0.366570313793259\n",
      "\n",
      "dataset size:  0.5\n",
      "ale entropy:  0.3861303614192076\n",
      "epi entropy:  0.3720618487291568\n",
      "\n",
      "dataset size:  0.6\n",
      "ale entropy:  0.38957228566957974\n",
      "epi entropy:  0.3716298815172853\n",
      "\n",
      "dataset size:  0.7\n",
      "ale entropy:  0.37922286468089633\n",
      "epi entropy:  0.36004314366085577\n",
      "\n",
      "dataset size:  0.8\n",
      "ale entropy:  0.38906637833434393\n",
      "epi entropy:  0.38091853387400054\n",
      "\n",
      "dataset size:  0.9\n",
      "ale entropy:  0.3833037859121321\n",
      "epi entropy:  0.3581153583950656\n",
      "\n",
      "dataset size:  1.0\n",
      "ale entropy:  0.38920761635213935\n",
      "epi entropy:  0.36781284496582334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mean of each entropy in ale and epi_entropy_ensemble_dropout\n",
    "for i in range(0, 10):\n",
    "    print('dataset size: ', np.round((i * 0.1 + 0.1),1))\n",
    "    print('ale entropy: ', np.mean(ale_entropy_ensemble_dropout[i]))\n",
    "    print('epi entropy: ', np.mean(epi_entropy_ensemble_dropout[i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sketch graph for mean epistemic entropy of ensemble dropout model\n",
    "plt.plot(dataset_frac, np.mean(epi_entropy_ensemble_dropout, axis=1), label='ensemble dropout model')\n",
    "plt.xlabel('dataset size')\n",
    "plt.ylabel('Mean Epistemic Entropy')\n",
    "plt.title('Mean Epistemic Uncertainty of Ensemble Dropout Model')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sketch graph of mean equal opportunity difference for ensemble dropout model\n",
    "plt.plot(dataset_frac, Equal_opp_diffs_ensemble_dropout, label='ensemble dropout model')\n",
    "plt.xlabel('Dataset Size')\n",
    "plt.ylabel('Mean Equal Opportunity Difference')\n",
    "plt.title('Mean Equal Opportunity Difference of Ensemble Dropout Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAAHHCAYAAAAf0a9iAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACEmUlEQVR4nO3dd1gUV9sG8HupS0elKwJixYaiIDYsKBiDLYktCiiW2CPRqEms8ZUYNWLsMSq22I3RmNiwxG4sJFZUBDVKsYRmQ9nz/eHHhnEXXWBhAe/fde2lnDkz+5zZ2Zl5ds6ckQkhBIiIiIiIiHLR03UARERERERU8jBRICIiIiIiFUwUiIiIiIhIBRMFIiIiIiJSwUSBiIiIiIhUMFEgIiIiIiIVTBSIiIiIiEgFEwUiIiIiIlLBRIGIiIiIiFQwUSjBoqKiIJPJkJCQoOtQyiyZTIYpU6boOgy1XF1dERoaKim7fv062rdvDysrK8hkMmzfvh0A8Oeff6Jp06YwMzODTCZDTExMscdLlJCQAJlMhqioKF2Hkm+tWrVCq1atdB0GAcjMzMSAAQPg4OAAmUyGTz/9VNch6Yyrqyvef//9t9Y7dOgQZDIZDh06VPRBkU4V5txwypQpkMlk+ZonX4lCTnAymQxHjx5VmS6EgLOzM2QymUYbti65uroq2/L6KzAwUNfhFcixY8fQtWtX2Nvbw9jYGK6urhg8eDBu376t69A09ttvv+n0xP348eOYMmUKUlNTtbrcVq1aKbcvPT09WFpaokaNGujbty/27dun8XJCQkJw4cIF/O9//8OaNWvQqFEjvHjxAh999BEePXqEuXPnYs2aNXBxcdFq/PSfnB2tnp4e7ty5ozI9PT0dJiYmkMlkGD58uA4i1Fxe+0CZTIZPPvmk2OJYtGhRqUwu8pL7+/76q2bNmgVa5owZM5Q/DJR1M2bMQFRUFIYMGYI1a9agb9++edYti8fykiAn6c95GRoawsbGBk2bNsUXX3xRqs4rNJXf84+c73m1atXUTt+3b59y/W3ZskVLURY/g4LMJJfL8dNPP6F58+aS8sOHD+Off/6BsbGxVoIrap6envjss89Uyp2cnHQQTeHMnz8fo0aNQpUqVTBixAg4OjriypUr+PHHH7Fx40b89ttvaNq0qa7DfKvffvsNCxcuLLZk4enTpzAw+O9rcPz4cUydOhWhoaGwtrbW6ntVqlQJERERAIDHjx/jxo0b2LZtG9auXYvu3btj7dq1MDQ0VNaPjY2Fnt5/ufzTp09x4sQJfPnll5IT0KtXr+LWrVtYtmwZBgwYoNWYKW/GxsZYv349Pv/8c0n5tm3bdBRRwbRr1w7BwcEq5dWrV8/3slxcXPD06VPJdqyJRYsWwcbGRuUKWnHau3evVpeX+/uem5WVVYGWN2PGDHz44Yfo0qVLISMr+Q4cOIAmTZpg8uTJGtUvS8fykqZXr1547733oFAo8O+//+LPP/9EZGQk5s2bh+XLl6Nnz566DlFrCnL+IZfLcePGDZw+fRre3t6SaevWrYNcLsezZ8+0HGnxKlCi8N5772Hz5s34/vvvJSdZP/30E7y8vPDgwQOtBViUKlasiD59+ug6jEI7duwYPv30UzRv3hy7d++GqampctqQIUPQrFkzfPjhh7h06RLKlSunw0jz9vjxY5iZmRX7+8rl8mJ7LysrK5Xt7ZtvvsHIkSOxaNEiuLq6YubMmcppryfc9+/fBwCVBCYlJUVteWHo6vMoTd577z21icJPP/2Ejh07YuvWrTqKLH+qV6+utf2gTCYr1u+UNhkZGWl1eeq+78WltH9/U1JS4OHhoXH9snIsL4kaNmyosm5v3bqF9u3bIyQkBLVq1UL9+vXznL+0b4tv4+7ujpcvX2L9+vWSROHZs2f4+eefS9WxIC8FukehV69eePjwoaTLRFZWFrZs2YLevXurnUehUCAyMhK1a9eGXC6Hvb09Bg8ejH///VdS75dffkHHjh3h5OQEY2NjuLu74+uvv0Z2drakXqtWrVCnTh1cvnwZrVu3hqmpKSpWrIhvv/22IE16o+3bt6NOnTqQy+WoU6cOfv75Z4SGhsLV1VVZJ6/+ger67P79998IDQ1FlSpVIJfL4eDggP79++Phw4cFiu/rr7+GTCbDqlWrJEkC8Goj/vbbb5GYmIilS5cqy0NDQ2Fubo6bN28iICAAZmZmcHJywrRp0yCEUIl/9uzZmDt3LlxcXGBiYgI/Pz9cvHhRJZYDBw6gRYsWMDMzg7W1NTp37owrV65I6uR03bh8+TJ69+6NcuXKoXnz5ggNDcXChQsBSLtE5Hf95rTt7t276NKlC8zNzWFra4sxY8aobEe571GYMmUKxo4dCwBwc3NTvn9CQgL8/Pzy3BnWqFEDAQEBaqe9jb6+Pr7//nt4eHhgwYIFSEtLU07LfY/ClClTlN2Jxo4dC5lMppzu5+cHAPjoo48gk8kk/ayvXr2KDz/8EOXLl4dcLkejRo2wY8cOSQw5XQoPHz6MoUOHws7ODpUqVVJO//3335WfqYWFBTp27IhLly5JlpGfda5QKDBv3jzUrVsXcrkctra2CAwMxJkzZyT11q5dCy8vL5iYmKB8+fLo2bOn2q4+uW3ZskXZltctXboUMplMud0mJSWhX79+qFSpEoyNjeHo6IjOnTtr3O+zd+/eiImJwdWrV5VlSUlJOHDgQJ77wefPn2Py5MmoWrUqjI2N4ezsjM8//xzPnz+X1Fu5ciXatGkDOzs7GBsbw8PDA4sXL1ZZXk7/5aNHj8Lb2xtyuRxVqlTB6tWrNWqDpnL2t2fPnkXTpk1hYmICNzc3LFmyRFJP3ffxbevZ1dUVly5dwuHDh5XfudzbcGpqKj799FM4OzvD2NgYVatWxcyZM6FQKFTed/bs2Vi4cCGqVKkCU1NTtG/fHnfu3IEQAl9//TUqVaoEExMTdO7cGY8ePVJp4+v3KDx79gxTpkxB9erVIZfL4ejoiG7duiEuLk4r6zVnX3jjxg3lVUwrKyv069cPT548UdaTyWR4/PgxVq1apVxHufcN6vanAPDy5Ut8/fXXcHd3V3ZH/eKLL1S2t5ztaO/evfD09IRcLoeHh4fk6tjNmzchk8kwd+5clXYcP34cMpkM69evf2N7U1JSEBYWBnt7e8jlctSvXx+rVq1STs/Zz8fHx2PXrl2SfXBh5WcftWHDBnh5ecHCwgKWlpaoW7cu5s2bJ6lTXNtljjd9Nm9y6tQpBAYGwsrKCqampvDz88OxY8fyufakXFxcEBUVhaysLMk519uOJYsWLULt2rVhbGwMJycnDBs2TKWbr6b7GuDt2xOg+bnDm84/3qZXr17YuHGj5LPfuXMnnjx5gu7du6ud5/z58+jQoQMsLS1hbm6Otm3b4uTJkyr1Ll26hDZt2sDExASVKlXC9OnTJe+TmybH6oIo0BUFV1dX+Pr6Yv369ejQoYMywLS0NPTs2RPff/+9yjyDBw9GVFQU+vXrh5EjRyI+Ph4LFizA+fPncezYMeWl6qioKJibmyM8PBzm5uY4cOAAJk2ahPT0dMyaNUuyzH///ReBgYHo1q0bunfvji1btmDcuHGoW7euMq43efHihdqrH2ZmZjAxMQHw6sv5wQcfwMPDAxEREXj48KHyoFdQ+/btw82bN9GvXz84ODjg0qVL+OGHH3Dp0iWcPHkyXzeaPHnyBNHR0WjRogXc3NzU1unRowcGDRqEX3/9FePHj1eWZ2dnIzAwEE2aNMG3336L3bt3Y/LkyXj58iWmTZsmWcbq1auRkZGBYcOG4dmzZ5g3bx7atGmDCxcuwN7eHgCwf/9+dOjQAVWqVMGUKVPw9OlTzJ8/H82aNcO5c+ckiRXw6sS2WrVqmDFjBoQQaNCgAe7du4d9+/ZhzZo1Gq8DdbKzsxEQEAAfHx/Mnj0b+/fvx5w5c+Du7o4hQ4aonadbt264du0a1q9fj7lz58LGxgYAYGtri759+2LgwIG4ePEi6tSpo5znzz//xLVr1/DVV18VOFZ9fX306tULEydOxNGjR9GxY0e1sVlbW2P06NHKS8Hm5uawt7dHxYoVMWPGDIwcORKNGzdWfh6XLl1Cs2bNULFiRYwfPx5mZmbYtGkTunTpgq1bt6Jr166S9xg6dChsbW0xadIkPH78GACwZs0ahISEICAgADNnzsSTJ0+wePFiNG/eHOfPn5d8ppqu87CwMERFRaFDhw4YMGAAXr58iSNHjuDkyZNo1KgRAOB///sfJk6ciO7du2PAgAG4f/8+5s+fj5YtW+L8+fN5Xj3p2LEjzM3NsWnTJmUClWPjxo2oXbu28vP74IMPcOnSJYwYMQKurq5ISUnBvn37cPv2bZVtVZ2WLVuiUqVK+Omnn5Tfl40bN8Lc3FztZ6hQKNCpUyccPXoUgwYNQq1atXDhwgXMnTsX165dk/Q/X7x4MWrXro1OnTrBwMAAO3fuxNChQ6FQKDBs2DDJcm/cuIEPP/wQYWFhCAkJwYoVKxAaGgovLy/Url37re149uyZ2v2gpaWl5Ff2f//9F++99x66d++OXr16YdOmTRgyZAiMjIzQv3//PJf/tvUcGRmJESNGwNzcHF9++SUAKLfhJ0+ewM/PD3fv3sXgwYNRuXJlHD9+HBMmTEBiYiIiIyMl77Vu3TpkZWVhxIgRePToEb799lt0794dbdq0waFDhzBu3DjcuHED8+fPx5gxY7BixYo8487Ozsb777+P6Oho9OzZE6NGjUJGRgb27duHixcvwt3d/Y3rNTs7W+16NTExUfmFtXv37nBzc0NERATOnTuHH3/8EXZ2dsorjGvWrMGAAQPg7e2NQYMGAYDK+7++PwWAAQMGYNWqVfjwww/x2Wef4dSpU4iIiMCVK1fw888/S+a/fv06evTogU8++QQhISFYuXIlPvroI+zevRvt2rVDlSpV0KxZM6xbtw6jR49WWe8WFhbo3Llznuvj6dOnaNWqFW7cuIHhw4fDzc0NmzdvRmhoKFJTUzFq1CjUqlULa9aswejRo1GpUiVldyJbW9s3rmtNjuWAZvuoffv2oVevXmjbtq1y/V+5cgXHjh3DqFGjABT/dvm2zyYvBw4cQIcOHeDl5YXJkydDT09P+SPEkSNHVLrK5Ievry/c3d3V3mOn7lgyZcoUTJ06Ff7+/hgyZAhiY2OxePFi/Pnnn5JzQECzfY0m21N+DB48uMDnH71798aUKVNw6NAhtGnTBsCrK8tt27aFnZ2dSv1Lly6hRYsWsLS0xOeffw5DQ0MsXboUrVq1wuHDh+Hj4wPg1Y8srVu3xsuXL5XH8B9++EGyTefIz7E630Q+rFy5UgAQf/75p1iwYIGwsLAQT548EUII8dFHH4nWrVsLIYRwcXERHTt2VM535MgRAUCsW7dOsrzdu3erlOcsL7fBgwcLU1NT8ezZM2WZn5+fACBWr16tLHv+/LlwcHAQH3zwwVvb4uLiIgCofUVERCjreXp6CkdHR5Gamqos27t3rwAgXFxclGUHDx4UAMTBgwcl7xMfHy8AiJUrV76xjevXrxcAxB9//KEsy1nf8fHxebYjJiZGABCjRo16Y3vr1asnypcvr/w7JCREABAjRoxQlikUCtGxY0dhZGQk7t+/L4nfxMRE/PPPP8q6p06dEgDE6NGjlWWenp7Czs5OPHz4UFn2119/CT09PREcHKwsmzx5sgAgevXqpRLnsGHDhLrNMj/rN6dt06ZNk9Rt0KCB8PLykpQBEJMnT1b+PWvWLLXrPDU1VcjlcjFu3DhJ+ciRI4WZmZnIzMxUiTk3Pz8/Ubt27Tyn//zzzwKAmDdvnrLMxcVFhISEqLR11qxZknlz1s3mzZsl5W3bthV169aVfG8UCoVo2rSpqFatmrIsZztr3ry5ePnypbI8IyNDWFtbi4EDB0qWm5SUJKysrCTlmq7zAwcOCABi5MiRKutAoVAIIYRISEgQ+vr64n//+59k+oULF4SBgYFK+et69eol7OzsJG1JTEwUenp6yvj+/fdftetSEznb7/3798WYMWNE1apVldMaN24s+vXrJ4R4tW0NGzZMOW3NmjVCT09PHDlyRLK8JUuWCADi2LFjyjJ1+4iAgABRpUoVSVnOfiz3fiMlJUUYGxuLzz777K1tyWsfCECsX79eWS9nfztnzhxl2fPnz5Xf+aysLCGE6vdR0/Vcu3Zt4efnp1L+9ddfCzMzM3Ht2jVJ+fjx44W+vr64ffu25H1tbW0l++oJEyYIAKJ+/frixYsXyvJevXoJIyMjlWNK7hhWrFghAIjvvvtOJa6cbTUvOetL3Wvw4MHKejnbUv/+/SXzd+3aVVSoUEFSZmZmJtkfvL6M1/enOceGAQMGSMrHjBkjAIgDBw4oy3K2o61btyrL0tLShKOjo2jQoIGybOnSpQKAuHLlirIsKytL2NjYqI0tt8jISAFArF27VjKvr6+vMDc3F+np6ZJ4cp9DvImmx3JN91GjRo0SlpaWkv3H64pzu9T0s3n9GKlQKES1atVEQECAZHt98uSJcHNzE+3atcuzfbljf9N3t3PnzgKASEtLE0LkfSxJSUkRRkZGon379iI7O1tZvmDBAgFArFixQlmm6b5G0+0pP+cOeZ1/5CX3cb1Ro0YiLCxMCPFqv2dkZCRWrVql9vjcpUsXYWRkJOLi4pRl9+7dExYWFqJly5bKsk8//VQAEKdOnZKsSysrK8l5Sn6O1Tn7i/wo8PCo3bt3x9OnT/Hrr78iIyMDv/76a56X2zdv3gwrKyu0a9cODx48UL68vLxgbm6OgwcPKuvmzpQyMjLw4MEDtGjRAk+ePJFc4gcAc3NzSd85IyMjeHt74+bNmxq1wcfHB/v27VN59erVCwCQmJiImJgYhISESG5Aa9euXb76T74udxtzfs1r0qQJAODcuXP5WlZGRgYAwMLC4o31LCwskJ6erlKe+6bYnFFasrKysH//fkm9Ll26oGLFisq/vb294ePjg99++w3Af+sqNDQU5cuXV9arV68e2rVrp6yXW1GPqvL68lu0aKHxtvE6KysrdO7cGevXr1f+WpednY2NGzeiS5cuhe6DaW5uDuC/z7OwHj16hAMHDqB79+7K79GDBw/w8OFDBAQE4Pr167h7965knoEDB0JfX1/59759+5CamopevXpJvrf6+vrw8fGRfG9zvG2db926FTKZTO1NijlX0rZt2waFQoHu3btL3tfBwQHVqlVT+7659ejRAykpKZJLzVu2bIFCoUCPHj0AvPoOGhkZ4dChQyrdH/Ojd+/euHHjBv7880/lv2/aD9aqVQs1a9aUtCvnF6i89oNpaWl48OAB/Pz8cPPmTUn3NADw8PBAixYtlH/b2tqiRo0aGm/rnTt3VrsfbN26taSegYEBBg8erPzbyMgIgwcPRkpKCs6ePat22YVdz5s3b0aLFi1Qrlw5yTrz9/dHdnY2/vjjD0n9jz76SLKvzvllrk+fPpL76Xx8fJCVlaXyHcht69atsLGxwYgRI1SmaXLV19XVVe16VTfUp7rvzcOHD9Xus/Py+jJy9rnh4eGS8pxf6Xft2iUpd3JyklxltLS0RHBwMM6fP4+kpCQAr477crkc69atU9bbs2cPHjx48NZ7BH777Tc4ODgoj68AYGhoiJEjRyIzM1Ntd0FNve1Yntvb9lHW1tZ4/PjxG0ejK+7tUpPP5nUxMTG4fv06evfujYcPHypjfPz4Mdq2bYs//vgjzy4smsrruPX6sWT//v3IysrCp59+KhmgY+DAgbC0tFTZFjXZ1xTl9lQQvXv3xrZt25Td8PX19VWu2gOvzhv27t2LLl26oEqVKspyR0dH9O7dG0ePHlV+73/77Tc0adJEcuXH1tYWH3/8sWSZBTlW50eBuh7lBOvv74+ffvoJT548QXZ2Nj788EO1da9fv460tDS1l2CA/27GBF5dkvnqq69w4MABlZ3k6wfISpUqqeywy5Urh7///lujNtjY2MDf3z/P6bdu3QIAtUNf1ahRI98n9TkePXqEqVOnYsOGDZK2A6ptfJucBOFtJ5gZGRkqyYSenp5kQwX+G+nk9T6h6tZB9erVsWnTJgD/rasaNWqo1KtVqxb27NmjclNTXl2ltCGn73tu5cqVK9RJYXBwMDZu3IgjR46gZcuW2L9/P5KTk984dJ+mMjMzAbw94dPUjRs3IITAxIkTMXHiRLV1UlJSJMnf65/H9evXAUB5Ivs6S0tLyd+arPO4uDg4OTlJksnXXb9+HUKIPIece9uIOjn9cTdu3Ii2bdsCeNUlyNPTU7l9GxsbY+bMmfjss89gb2+PJk2a4P3330dwcDAcHBzeuPzcGjRogJo1a+Knn36CtbU1HBwc8lxf169fx5UrV/LsRpF7X3Ds2DFMnjwZJ06ckPRVB17tI3KfdFSuXFllWfnZ1itVqvTG/WAOJycnlYQ49/4i58eO3Aq7nq9fv46///5bo3UGqK6LnPXk7OystvxN6yguLg41atSQnMjlh5mZmUbrFVCNO2fQiX///Vfle5aX17+/t27dgp6eHqpWrSopd3BwgLW1tXKfnaNq1aoqx9Pcn2/OfEFBQfjpp5/w9ddfA3jVraZixYp5bve546lWrZrkRBF4dXzImV5QbzuW59BkHzV06FBs2rQJHTp0QMWKFdG+fXt0795dMtRqcW+Xmnw2r8vZf4eEhKiNEXi1LynMACd5HbfUbYuA6vmBkZERqlSpovLZa7KvKcrtqSB69uyJMWPG4Pfff8e6devw/vvvqz2e379/H0+ePMnzXEmhUODOnTuoXbs2bt26pUwqc3t93vweq/OrwIkC8CqDGjhwIJKSktChQ4c8+w0rFArY2dlJfoXILefLlpqaCj8/P1haWmLatGlwd3eHXC7HuXPnMG7cOJXsN3fGmlvOL77FKa9fmF6/SQp49avM8ePHMXbsWHh6esLc3BwKhQKBgYH5zvCrVq0KAwODNyZHz58/R2xsrLL/d0mhrp9dXvKzfoG8t43CCAgIgL29PdauXYuWLVti7dq1cHBw0Phk4E1ybrB9/aBeUDnb0ZgxY/K80fr193r988hZxpo1a9QeiF4/gdLWOlcoFJDJZPj999/VLjPnV6y8GBsbo0uXLvj555+xaNEiJCcn49ixY5gxY4ak3qeffoqgoCBs374de/bswcSJExEREYEDBw6gQYMGGsfbu3dvLF68GBYWFujRo4fKgSt3u+rWrYvvvvtO7fSck4a4uDi0bdsWNWvWxHfffQdnZ2cYGRnht99+w9y5c0v0flCdwqxnhUKBdu3aqYwsleP1IVzzWhclfR1pI7689qf5fbjS2wQHB2Pz5s04fvw46tatix07dmDo0KF5bvcliSb7KDs7O8TExGDPnj34/fff8fvvv2PlypUIDg5W3ihbGrbLnP3ErFmz4OnpqbbO2/alb3Px4kXY2dmpnIjm59he1PJ77lBQjo6OaNWqFebMmYNjx44V60hH+T1W51eh5u7atSsGDx6MkydPYuPGjXnWc3d3x/79+9GsWbM3bkCHDh3Cw4cPsW3bNrRs2VJZHh8fX5gwCyxnlJmcbC232NhYyd85Wfnrd/C/ntX++++/iI6OxtSpUzFp0iRlubr30ISZmRlat26NAwcO4NatW2oftLVp0yY8f/5c5SF4CoUCN2/elOzUrl27BgAqN76oi+/atWvKejnv+/p6AV6NvGNjY6NR95y8vtSart/CetNBVV9fH71790ZUVBRmzpyJ7du3q1xiLYjs7Gz89NNPMDU1VXk2SUHlXCkyNDQscCKTc7OknZ2dVpKhnGXu2bMHjx49yvOqgru7O4QQcHNzK9BY/sCr7kerVq1CdHQ0rly5AiGEstvR6+/12Wef4bPPPsP169fh6emJOXPmYO3atRq/V+/evTFp0iQkJia+8SY4d3d3/PXXX2jbtu0bt7OdO3fi+fPn2LFjh+SXyMJePi6se/fuqVwVzGt/8bq3ree81oe7uzsyMzO1tv3lh7u7O06dOoUXL17k+7kQRSG/J/wuLi5QKBS4fv268ldWAEhOTkZqaqrKsSLnKmTu91H3+QYGBsLW1hbr1q2Dj48Pnjx5otFVVRcXF/z9999QKBSSpCKnS3FJekikkZERgoKCEBQUBIVCgaFDh2Lp0qWYOHEiqlatWuzbpaafTW45+29LS8siifPEiROIi4vTaFja3OcHuXsxZGVlIT4+XiU+TfY1mm5P+Tl3KGxS3bt3bwwYMADW1tZ477331NaxtbWFqalpnudKenp6yh+NXFxcNDr/LIpjdW6F+gnA3NwcixcvxpQpUxAUFJRnve7duyM7O1t5qTK3ly9fKj/AnBOu3Nl0VlYWFi1aVJgwC8zR0RGenp5YtWqVpEvQvn37cPnyZUldFxcX6Ovrq/RNfD12dW0EoDJKQn589dVXEEIgNDQUT58+lUyLj4/H559/DkdHR0mfvxwLFixQ/l8IgQULFsDQ0FDZZSPH9u3bJf0mT58+jVOnTilHl8q9rnJ/IS9evIi9e/fm+aV5Xc6O4fUvtabrt7Dyev8cffv2xb///ovBgwcjMzOz0GN3Z2dnY+TIkbhy5QpGjhxZ6EuEOezs7NCqVSssXboUiYmJKtNznsnwJgEBAbC0tMSMGTPw4sWLAi3jdR988AGEEJg6darKtJzvRLdu3aCvr4+pU6eqfE+EEBoNI+zv74/y5ctj48aN2LhxI7y9vSWXw588eaLyEBx3d3dYWFioDB35Nu7u7oiMjERERMQbRxHp3r077t69i2XLlqlMe/r0qXJ0EHX7iLS0NKxcuTJfcWnby5cvJUMsZ2VlYenSpbC1tYWXl5faeTRdz2ZmZmq/c927d8eJEyewZ88elWmpqal4+fJlAVvzdh988AEePHgg2Ufm0MWViLzWUV5y9rmvH1tyrmi9PjLXvXv3JCMhpaenY/Xq1fD09JT8SmlgYKAciSYqKgp169ZFvXr1NIonKSlJ8qPiy5cvMX/+fJibm6uMUqYrr+9f9PT0lO3L2WaLe7vU9LPJzcvLC+7u7pg9e7ayi1BuBdl/57h16xZCQ0NhZGSkHFL8Tfz9/WFkZITvv/9e8t1Zvnw50tLSVLZFTfY1mm5P+Tl3eNvx/20+/PBDTJ48GYsWLcrzuSz6+vpo3749fvnlF0kX7+TkZOWDjHPOA9577z2cPHkSp0+fVta7f/++Su+cojhW51a46xF4c/+3HH5+fhg8eDAiIiIQExOD9u3bw9DQENevX8fmzZsxb948fPjhh2jatCnKlSuHkJAQjBw5EjKZDGvWrCmynfLdu3fV/nJobm6ufPplREQEOnbsiObNm6N///549OgR5s+fj9q1a0u+fFZWVvjoo48wf/58yGQyuLu749dff1Xpq2hpaYmWLVvi22+/xYsXL1CxYkXs3bu3UFdNWrZsidmzZyM8PBz16tVDaGgoHB0dcfXqVSxbtgwKhQK//fabSl9EuVyO3bt3IyQkBD4+Pvj999+xa9cufPHFFyp9L6tWrYrmzZtjyJAheP78OSIjI1GhQgXJpddZs2ahQ4cO8PX1RVhYmHJ4VCsrK42fdJizExg5ciQCAgKgr6+Pnj17arx+Cyvn/b/88kv07NkThoaGCAoKUu5AGjRogDp16ihvTG3YsKHGy05LS1Nub0+ePFE+mTkuLg49e/ZUm0gXxsKFC9G8eXPUrVsXAwcORJUqVZCcnIwTJ07gn3/+wV9//fXG+S0tLbF48WL07dsXDRs2RM+ePWFra4vbt29j165daNasmdqTqDdp3bo1+vbti++//x7Xr19Xdrc7cuQIWrdujeHDh8Pd3R3Tp0/HhAkTkJCQgC5dusDCwgLx8fH4+eefMWjQIIwZM+aN72NoaIhu3bphw4YNePz4MWbPni2Zfu3aNbRt2xbdu3eHh4cHDAwM8PPPPyM5OblATxrVZCi+vn37YtOmTfjkk09w8OBBNGvWDNnZ2bh69So2bdqEPXv2oFGjRmjfvr3yF82chHTZsmWws7NTm/QV1rVr19TuB+3t7SVDLzo5OWHmzJlISEhA9erVsXHjRsTExOCHH37I8xd3Tdezl5cXFi9ejOnTp6Nq1aqws7NDmzZtMHbsWOzYsQPvv/++csjXx48f48KFC9iyZQsSEhKUwxhrW3BwMFavXo3w8HCcPn0aLVq0wOPHj7F//34MHTr0jUOBAtLv++sK8gODl5cX9u/fj++++w5OTk5wc3NT2385R/369RESEoIffvhB2a339OnTWLVqFbp06aJys3r16tURFhaGP//8E/b29lixYgWSk5PVJqjBwcH4/vvvcfDgQclDIt9k0KBBWLp0KUJDQ3H27Fm4urpiy5YtOHbsGCIjIwt1f5Ymx3JNDRgwAI8ePUKbNm1QqVIl3Lp1C/Pnz4enp6fyykxxb5f5+Wxy6Onp4ccff0SHDh1Qu3Zt9OvXDxUrVsTdu3dx8OBBWFpaYufOnW9973PnzmHt2rVQKBRITU3Fn3/+qRyUYs2aNRoliba2tpgwYQKmTp2KwMBAdOrUCbGxsVi0aBEaN26s8n3QZF+j6faUn3OHvM4/NKXpuc706dOxb98+NG/eHEOHDoWBgQGWLl2K58+fS55L8fnnn2PNmjUIDAzEqFGjlMOj5lxNyVEUx2qJ/AyRlHt41DfJa2izH374QXh5eQkTExNhYWEh6tatKz7//HNx7949ZZ1jx46JJk2aCBMTE+Hk5CQ+//xzsWfPHpXhrfIabjIkJEQybOmbYkQeQ6q9Pv/WrVtFrVq1hLGxsfDw8BDbtm1T+z73798XH3zwgTA1NRXlypUTgwcPFhcvXlQZguuff/4RXbt2FdbW1sLKykp89NFH4t69ewKvDdWpyfCouf3xxx+ic+fOwsbGRhgaGorKlSuLgQMHioSEBLXryczMTMTFxYn27dsLU1NTYW9vLyZPniwZviz3EGlz5swRzs7OwtjYWLRo0UL89ddfKsvdv3+/aNasmTAxMRGWlpYiKChIXL58WVIn9/CSr3v58qUYMWKEsLW1FTKZTDKMl6brN6dtr1M3LNjr61yIV0PfVaxYUejp6ald/99++60AIGbMmKHyHnl5fbhEc3NzUa1aNdGnTx+xd+9etfMUdnhUIYSIi4sTwcHBwsHBQRgaGoqKFSuK999/X2zZskVZ523f64MHD4qAgABhZWUl5HK5cHd3F6GhoeLMmTPKOvlZ5y9fvhSzZs0SNWvWFEZGRsLW1lZ06NBBnD17VlJv69atonnz5sLMzEyYmZmJmjVrimHDhonY2Fi1cb5u3759AoCQyWTizp07kmkPHjwQw4YNEzVr1hRmZmbCyspK+Pj4iE2bNr11uW/afnPDa8OjCvFq+L6ZM2eK2rVrC2NjY1GuXDnh5eUlpk6dqhxiUAghduzYIerVqyfkcrlwdXUVM2fOVA7XmXt7zGtf+/pQn2+KMa9X7vlz9rdnzpwRvr6+Qi6XCxcXF7FgwQLJ8l4fclDT9ZyUlCQ6duwoLCwsVN47IyNDTJgwQVStWlUYGRkJGxsb0bRpUzF79myVYVk1/W6o2+bVrbMnT56IL7/8Uri5uQlDQ0Ph4OAgPvzwQ8mwhuq8aXjU3N+HvLYldfv+q1evipYtWwoTExMBQLlveNP2+OLFCzF16lRl/M7OzmLChAmS4TeF+G872rNnj6hXr54wNjYWNWvWVLtPyVG7dm2hp6cnGTb7bZKTk0W/fv2EjY2NMDIyEnXr1pXsu1+PRxOaHss13Udt2bJFtG/fXtjZ2QkjIyNRuXJlMXjwYJGYmCiZr7i2S00/m7yGAT1//rzo1q2bqFChgjA2NhYuLi6ie/fuIjo6+o3rNSf2nJeBgYEoX7688PHxERMmTBC3bt1Smedtx5IFCxaImjVrCkNDQ2Fvby+GDBki/v33X0kdTfc1Qmi+PWl67vCm8w913jbsuRB5f9bnzp0TAQEBwtzcXJiamorWrVuL48ePq8z/999/Cz8/PyGXy0XFihXF119/LZYvX6723ESTY3VBhkeVCVFC7uYqZUJDQ3Ho0CGtPDFSF0JDQ7Flyxa1lyRzS0hIgJubG2bNmvXWX3HfFfPmzcPo0aORkJCgdsQZorKmVatWePDggdqnsVPp5+rqijp16uDXX3/VeJ4GDRqgfPnyiI6OLsLI6F3DfU3JU/KHKSAqQYQQWL58Ofz8/JgkENE76cyZM4iJiUFwcLCuQyGiIlboexSI3gWPHz/Gjh07cPDgQVy4cAG//PKLrkMiIipWFy9exNmzZzFnzhw4OjqqHUmMiMoWJgpEGrh//z569+4Na2trfPHFF+jUqZOuQyIiKlZbtmzBtGnTUKNGDaxfvx5yuVzXIRFREeM9CkREREREpIL3KBARERERkQomCkREREREpIL3KFC+KBQK3Lt3DxYWFoV+3DkREREVDyEEMjIy4OTkBD09/k5MmmGiQPly7949ODs76zoMIiIiKoA7d+6gUqVKug6DSgkmCpQvOY9Fv3PnDiwtLXUcDREREWkiPT0dzs7OyuM4kSaYKFC+5HQ3srS0ZKJARERUyrDbMOUHO6kREREREZEKJgpERERERKSCiQIREREREangPQpERFQksrOz8eLFC12HQfTOMDIy4tCnpFVMFIiISKuEEEhKSkJqaqquQyF6p+jp6cHNzQ1GRka6DoXKCCYKRESkVTlJgp2dHUxNTTnKClExyHkgamJiIipXrszvHWkFEwUiItKa7OxsZZJQoUIFXYdD9E6xtbXFvXv38PLlSxgaGuo6HCoD2JGNiIi0JueeBFNTUx1HQvTuyelylJ2dreNIqKxgokBERFrHbg9ExY/fO9I2dj0iKqOyFQKn4x8hJeMZ7Czk8HYrD309HkSIiIhIM7yiQFQG7b6YiOYzD6DXspMYtSEGvZadRPOZB7D7YqKuQyMiLYuKioK1tfUb60yZMgWenp5af+9WrVrh008/1fpy3yWurq6IjIzUuH5RfZZE6jBRICpjdl9MxJC155CY9kxSnpT2DEPWnmOyQETvLCY2RPnDRIGoDMlWCEzdeRlCzbScsqk7LyNboa4GUcmSrRA4EfcQv8TcxYm4h9xuS6GsrCxdh0BEhcBEgagMOR3/SOVKQm4CQGLaM5yOf1R8QREVgC66zykUCkRERMDNzQ0mJiaoX78+tmzZopx+6NAhyGQyREdHo1GjRjA1NUXTpk0RGxurrPPXX3+hdevWsLCwgKWlJby8vHDmzBnl9KNHj6JFixYwMTGBs7MzRo4cicePHyunu7q6Yvr06QgODoa5uTlcXFywY8cO3L9/H507d4a5uTnq1asnWWaO7du3o1q1apDL5QgICMCdO3fe2N4ff/wRtWrVglwuR82aNbFo0aI31n/8+LEyLkdHR8yZM0eljqurK77++msEBwfD0tISgwYNAgBs3boVtWvXhrGxMVxdXVXmzZmvV69eMDMzQ8WKFbFw4UJJndu3byvXgaWlJbp3747k5GTl9NDQUHTp0kUyz6effopWrVoppx8+fBjz5s2DTCaDTCZDQkKC2rYW9HN4WztTUlIQFBQEExMTuLm5Yd26dSrvnZqaigEDBsDW1haWlpZo06YN/vrrL7VxEhU1JgpEZUhKRt5JQkHqEemCrrrPRUREYPXq1ViyZAkuXbqE0aNHo0+fPjh8+LCk3pdffok5c+bgzJkzMDAwQP/+/ZXTPv74Y1SqVAl//vknzp49i/HjxyvHs4+Li0NgYCA++OAD/P3339i4cSOOHj2K4cOHS5Y/d+5cNGvWDOfPn0fHjh3Rt29fBAcHo0+fPjh37hzc3d0RHBwMIf67wvLkyRP873//w+rVq3Hs2DGkpqaiZ8+eebZ13bp1mDRpEv73v//hypUrmDFjBiZOnIhVq1blOc/YsWNx+PBh/PLLL9i7dy8OHTqEc+fOqdSbPXs26tevj/Pnz2PixIk4e/Ysunfvjp49e+LChQuYMmUKJk6ciKioKMl8s2bNUs43fvx4jBo1Cvv27QPwKonr3LkzHj16hMOHD2Pfvn24efMmevTokWe8r5s3bx58fX0xcOBAJCYmIjExEc7OznnWz+/noEk7Q0NDcefOHRw8eBBbtmzBokWLkJKSInnfjz76CCkpKfj9999x9uxZNGzYEG3btsWjR/yBh3RAEOVDWlqaACDS0tJ0HQqpcfzGA+Ey7te3vo7feKDrUKmMevr0qbh8+bJ4+vRpgeZ/ma0QTWbsz3PbdR33q2gyY794ma3QatzPnj0Tpqam4vjx45LysLAw0atXLyGEEAcPHhQAxP79+5XTd+3aJQAo22thYSGioqLUvkdYWJgYNGiQpOzIkSNCT09POb+Li4vo06ePcnpiYqIAICZOnKgsO3HihAAgEhMThRBCrFy5UgAQJ0+eVNa5cuWKACBOnTolhBBi8uTJon79+srp7u7u4qeffpLE8vXXXwtfX1+1sWdkZAgjIyOxadMmZdnDhw+FiYmJGDVqlLLMxcVFdOnSRTJv7969Rbt27SRlY8eOFR4eHpL5AgMDJXV69OghOnToIIQQYu/evUJfX1/cvn1bOf3SpUsCgDh9+rQQQoiQkBDRuXNnyTJGjRol/Pz8lH/7+flJ4s1LQT6Ht7UzNjZWEq8Q/31Oc+fOFUK82h4sLS3Fs2fPJMtxd3cXS5cuFUKofpa5ven7x+M3FQSvKBCVId5u5eFoJUdeg6DKADhavRoqlagk0lX3uRs3buDJkydo164dzM3Nla/Vq1cjLi5OUrdevXrK/zs6OgKA8lfh8PBwDBgwAP7+/vjmm28k8/7111+IioqSLD8gIAAKhQLx8fFql29vbw8AqFu3rkpZ7l+iDQwM0LhxY+XfNWvWhLW1Na5cuaLS1sePHyMuLg5hYWGSWKZPn67S1hxxcXHIysqCj4+Psqx8+fKoUaOGSt1GjRpJ/r5y5QqaNWsmKWvWrBmuX78ueTCYr6+vpI6vr68y/itXrsDZ2VlyBcDDwyPPNmpDfj+Ht7XzypUrMDAwgJeXl3J6zueU46+//kJmZiYqVKgg+Wzi4+Pz/GyIihKfo0BUhujryTA5yAND1p6DDJDc1JyTPEwO8uDzFKjE0lX3uczMTADArl27ULFiRck0Y2Njyd85XYmA/x5wpVAoALwaurJ3797YtWsXfv/9d0yePBkbNmxA165dkZmZicGDB2PkyJEq71+5cuU3Lv9N75lfOW1dtmyZ5MQfAPT19Qu0zNzMzMwKvYyC0NPTk3THAv57UnhBFPXnoE5mZiYcHR1x6NAhlWlvGwKXqCgwUSAqYwLrOGJxn4aYuvOy5JdZBys5Jgd5ILCOow6jI3ozOwu5VutpysPDA8bGxrh9+zb8/PwKtazq1aujevXqGD16NHr16oWVK1eia9euaNiwIS5fvoyqVatqKer/vHz5EmfOnIG3tzcAIDY2FqmpqahVq5ZKXXt7ezg5OeHmzZv4+OOPNVq+u7s7DA0NcerUKWVS8++//+LatWtvXV+1atXCsWPHJGXHjh1D9erVJYnJyZMnJXVOnjypjL9WrVq4c+cO7ty5o7yqcPnyZaSmpsLDwwMAYGtri4sXL0qWERMTIzm5NzIyklzF0Ka3tbNmzZp4+fIlzp49q7z6k/M55WjYsCGSkpJgYGAAV1fXIomTKD+YKBCVQYF1HNHOw4FPZqZSJ6f7XFLaM7XD/MrwKunVdvc5CwsLjBkzBqNHj4ZCoUDz5s2RlpaGY8eOwdLSEiEhIW9dxtOnTzF27Fh8+OGHcHNzwz///IM///wTH3zwAQBg3LhxaNKkCYYPH44BAwbAzMwMly9fxr59+7BgwYJCxW9oaIgRI0bg+++/h4GBAYYPH44mTZooE4fXTZ06FSNHjoSVlRUCAwPx/PlznDlzBv/++y/Cw8NV6pubmyMsLAxjx45FhQoVYGdnhy+//BJ6em/vwfzZZ5+hcePG+Prrr9GjRw+cOHECCxYsUBll6dixY/j222/RpUsX7Nu3D5s3b8auXbsAAP7+/qhbty4+/vhjREZG4uXLlxg6dCj8/PyUXZ3atGmDWbNmYfXq1fD19cXatWtx8eJFNGjQQPkerq6uOHXqFBISEmBubo7y5ctr1AZNvK2dNWrUQGBgIAYPHozFixfDwMAAn376KUxMTJTL8Pf3h6+vL7p06YJvv/0W1atXx71797Br1y507dpVpVsXUVHjPQpEZZS+ngy+7hXQ2bMifN0rMEmgUiGn+xwAlXttirr73Ndff42JEyciIiICtWrVQmBgIHbt2gU3NzeN5tfX18fDhw8RHByM6tWro3v37ujQoQOmTp0K4FWf98OHD+PatWto0aIFGjRogEmTJsHJyanQsZuammLcuHHo3bs3mjVrBnNzc2zcuDHP+gMGDMCPP/6IlStXom7duvDz80NUVNQb2zpr1iy0aNECQUFB8Pf3R/PmzSX97fPSsGFDbNq0CRs2bECdOnUwadIkTJs2DaGhoZJ6n332Gc6cOYMGDRpg+vTp+O677xAQEADgVTefX375BeXKlUPLli3h7++PKlWqSNoYEBCAiRMn4vPPP0fjxo2RkZGB4OBgyXuMGTMG+vr68PDwgK2tLW7fvv3W+DWlSTtXrlwJJycn+Pn5oVu3bhg0aBDs7OyU02UyGX777Te0bNkS/fr1Q/Xq1dGzZ0/cunVLeU8EUXGSidc79BG9QXp6OqysrJCWlgZLS0tdh0NEJcyzZ88QHx8PNzc3yOUF7x60+2KiSvc5R3afK7NcXV3x6aef8qnJhfSm7x+P31QQ7HpEREQlDrvPERHpHhMFIiIqkXK6zxERkW4wUSAiIiKdSkhI0HUIRKQGb2YmIiIiIiIVTBSIiEjrOE4GUfHj9460jYkCERFpTc7DrZ48eaLjSIjePVlZWQC084RtIoD3KBARkRbp6+vD2toaKSkpAF6N7y+TcaQioqKmUChw//59mJqawsCAp3ekHdySiIhIqxwcHABAmSwQUfHQ09ND5cqVmZyT1jBRKOEWLlyIWbNmISkpCfXr18f8+fPh7e2ttm5UVBT69esnKTM2NsazZ/89sEgIgcmTJ2PZsmVITU1Fs2bNsHjxYlSrVq1I20FE7w6ZTAZHR0fY2dnhxYsXug6H6J1hZGQEPT32KiftYaJQgm3cuBHh4eFYsmQJfHx8EBkZiYCAAMTGxkoe+Z6bpaUlYmNjlX+//qvCt99+i++//x6rVq2Cm5sbJk6ciICAAFy+fLlQT1El3cpWCD6YikocfX199pUmIirFZIK3yJdYPj4+aNy4MRYsWADgVf9DZ2dnjBgxAuPHj1epHxUVhU8//RSpqalqlyeEgJOTEz777DOMGTMGAJCWlgZ7e3tERUWhZ8+eb42Jj4AveXZfTMTUnZeRmPbflSNHKzkmB3kgsI6jDiMjIqKSgsdvKghenyqhsrKycPbsWfj7+yvL9PT04O/vjxMnTuQ5X2ZmJlxcXODs7IzOnTvj0qVLymnx8fFISkqSLNPKygo+Pj55LvP58+dIT0+XvKjk2H0xEUPWnpMkCQCQlPYMQ9aew+6LiTqKjIiIiEo7Jgol1IMHD5CdnQ17e3tJub29PZKSktTOU6NGDaxYsQK//PIL1q5dC4VCgaZNm+Kff/4BAOV8+VlmREQErKyslC9nZ+fCNo20JFshMHXnZai7JJhTNnXnZWQreNGQiIiI8o+JQhni6+uL4OBgeHp6ws/PD9u2bYOtrS2WLl1a4GVOmDABaWlpytedO3e0GDEVxun4RypXEnITABLTnuF0/KPiC4qIiIjKDCYKJZSNjQ309fWRnJwsKU9OTlYOPfg2hoaGaNCgAW7cuAHgvyEL87NMY2NjWFpaSl5UMqRk5J0kFKQeERERUW5MFEooIyMjeHl5ITo6WlmmUCgQHR0NX19fjZaRnZ2NCxcuwNHx1Q2tbm5ucHBwkCwzPT0dp06d0niZVHLYWWg2SpWNmTFOxD3ELzF3cSLuIbsiERERkUY4PGoJFh4ejpCQEDRq1Aje3t6IjIzE48ePlc9KCA4ORsWKFREREQEAmDZtGpo0aYKqVasiNTUVs2bNwq1btzBgwAAAr4ZK/fTTTzF9+nRUq1ZNOTyqk5MTunTpoqtmUgF5u5WHo5UcSWnP1N6nIANgZWqIzzb/haR0johERERE+cNEoQTr0aMH7t+/j0mTJiEpKQmenp7YvXu38mbk27dvSx6s8u+//2LgwIFISkpCuXLl4OXlhePHj8PDw0NZ5/PPP8fjx48xaNAgpKamonnz5ti9ezefoVAK6evJMDnIA0PWnoMMkCQLOX+nPnkBQPrAq5wRkRb3achkgYiIiPLE5yhQvnAc5pJH3XMUHCyN8eyl4v8TBVUyAA5Wchwd14YPZiMiegfw+E0FwSsKRKVcYB1HtPNwkDyZWSEEPv7xVJ7z5B4Ryde9QvEFS0RERKUGEwWiMkBfTyY54f8l5q5G83FEJCIiIsoLRz0iKoM0HRFJ03pERET07mGiQFQG5YyIlNfdBzK8Gv3I2618cYZFREREpQgTBaIyKGdEJAAqyULO35ODPHgjMxEREeWJiQJRGRVYxxGL+zSEg5W0e5GDlZxDoxIREdFb8WZmojJM3YhI3m7leSWBiIiI3oqJAlEZ9/qISERERESaYNcjIiIiIiJSwUSBiIiIiIhUMFEgIiIiIiIVTBSIiIiIiEgFEwUiIiIiIlLBRIGIiIiIiFQwUSAiIiIiIhVMFIiIiIiISAUTBSIiIiIiUsFEgYiIiIiIVDBRICIiIiIiFUwUiIiIiIhIBRMFLYuLi8NXX32FXr16ISUlBQDw+++/49KlSzqOjIiIiIhIc0wUtOjw4cOoW7cuTp06hW3btiEzMxMA8Ndff2Hy5Mk6jo6IiIiISHNMFLRo/PjxmD59Ovbt2wcjIyNleZs2bXDy5EkdRkZERERElD9MFLTowoUL6Nq1q0q5nZ0dHjx4oIOIiIiIiIgKhomCFllbWyMxMVGl/Pz586hYsaIOIiIiIiIiKhgmClrUs2dPjBs3DklJSZDJZFAoFDh27BjGjBmD4OBgXYdHRERERKQxJgpaNGPGDNSsWRPOzs7IzMyEh4cHWrZsiaZNm+Krr77SdXhERERERBqTCSGEroMoa+7cuYMLFy4gMzMTDRo0QLVq1XQdktakp6fDysoKaWlpsLS01HU4REREpAEev6kgDHQdQFnk7OwMZ2dnXYdBRERERFRg7HqkRR988AFmzpypUv7tt9/io48+0kFEREREREQFw0RBi/744w+89957KuUdOnTAH3/8oYOIiIiIiIgKhomCFmVmZkoetJbD0NAQ6enpOoiIiIiIiKhgmChoUd26dbFx40aV8g0bNsDDw0MHERERERERFQxvZtaiiRMnolu3boiLi0ObNm0AANHR0Vi/fj02b96s4+iouGUrBE7HP0JKxjPYWcjh7VYe+noyXYdFREREpBEmCloUFBSE7du3Y8aMGdiyZQtMTExQr1497N+/H35+froOj4rR7ouJmLrzMhLTninLHK3kmBzkgcA6jjqMjIiIiEgzfI4C5QvHYX673RcTMWTtObz+xcq5lrC4T0MmC0REVKx4/KaC4BWFIpCVlYWUlBQoFApJeeXKlXUUERWXbIXA1J2XVZIEABB4lSxM3XkZ7Twc2A2JiIiISjQmClp0/fp19O/fH8ePH5eUCyEgk8mQnZ2to8iouJyOfyTpbvQ6ASAx7RlOxz+Cr3uF4guMiIiIKJ+YKGhRaGgoDAwM8Ouvv8LR0REyGX8xftekZOSdJBSkHhEREZGucHhULYqJicHSpUvRoUMHeHp6on79+pJXQSxcuBCurq6Qy+Xw8fHB6dOnNZpvw4YNkMlk6NKli6Q8OTkZoaGhcHJygqmpKQIDA3H9+vUCxUaq7CzkWq1HREREpCtMFLTIw8MDDx480NryNm7ciPDwcEyePBnnzp1D/fr1ERAQgJSUlDfOl5CQgDFjxqBFixaSciEEunTpgps3b+KXX37B+fPn4eLiAn9/fzx+/Fhrcb/LvN3Kw9FKjryuJcnwavQjb7fyxRkWERERUb4xUdCimTNn4vPPP8ehQ4fw8OFDpKenS1759d1332HgwIHo168fPDw8sGTJEpiammLFihV5zpOdnY2PP/4YU6dORZUqVSTTrl+/jpMnT2Lx4sVo3LgxatSogcWLF+Pp06dYv359vuMjVfp6MkwOevVwvdeThZy/Jwd58EZmIiIiKvGYKGiRv78/Tp48ibZt28LOzg7lypVDuXLlYG1tjXLlyuVrWVlZWTh79iz8/f2VZXp6evD398eJEyfynG/atGmws7NDWFiYyrTnz58DAOTy/7q96OnpwdjYGEePHlW7vOfPnxc64XnXBNZxxOI+DeFgJe1e5GAl59CoREREVGrwZmYtOnjwoNaW9eDBA2RnZ8Pe3l5Sbm9vj6tXr6qd5+jRo1i+fDliYmLUTq9ZsyYqV66MCRMmYOnSpTAzM8PcuXPxzz//IDExUe08ERERmDp1aqHa8i4KrOOIdh4OfDIzERERlVpMFLRIl09fzsjIQN++fbFs2TLY2NiorWNoaIht27YhLCwM5cuXh76+Pvz9/dGhQwfk9dy9CRMmIDw8XPl3eno6nJ2di6QNZY2+noxDoBIREVGpxURBy44cOYKlS5fi5s2b2Lx5MypWrIg1a9bAzc0NzZs313g5NjY20NfXR3JysqQ8OTkZDg4OKvXj4uKQkJCAoKAgZVnOA98MDAwQGxsLd3d3eHl5ISYmBmlpacjKyoKtrS18fHzQqFEjtXEYGxvD2NhY47iJiIiIqGzgPQpatHXrVgQEBMDExATnzp1T3hOQlpaGGTNm5GtZRkZG8PLyQnR0tLJMoVAgOjoavr6+KvVr1qyJCxcuICYmRvnq1KkTWrdujZiYGJWrAFZWVrC1tcX169dx5swZdO7cuQAtJiIiIqKyilcUtGj69OlYsmQJgoODsWHDBmV5s2bNMH369HwvLzw8HCEhIWjUqBG8vb0RGRmJx48fo1+/fgCA4OBgVKxYEREREZDL5ahTp45kfmtrawCQlG/evBm2traoXLkyLly4gFGjRqFLly5o3759AVpMRERERGUVEwUtio2NRcuWLVXKrayskJqamu/l9ejRA/fv38ekSZOQlJQET09P7N69W3mD8+3bt6Gnl7+LQomJiQgPD0dycjIcHR0RHByMiRMn5js2IiIiIirbZCKvu1gp36pUqYIffvgB/v7+sLCwwF9//YUqVapg9erV+Oabb3D58mVdh1ho6enpsLKyQlpaGiwtLXUdDhEREWmAx28qCN6joEUDBw7EqFGjcOrUKchkMty7dw/r1q3DmDFjMGTIEF2HR0RERESkMXY90qLx48dDoVCgbdu2ePLkCVq2bAljY2OMGTMGI0aM0HV4REREREQaY9cjLcnOzsaxY8dQr149mJqa4saNG8jMzISHhwfMzc11HZ7W8NIlERFR6cPjNxUEryhoib6+Ptq3b48rV67A2toaHh4eug6JiIiIiKjAeI+CFtWpUwc3b97UdRhERERERIXGREGLpk+fjjFjxuDXX39FYmIi0tPTJS8iIiIiotKC9yhoUe5nGshkMuX/hRCQyWTIzs7WRVhaxT6OREREpQ+P31QQvEdBiw4ePKjrEIiIiIiItIKJghb5+fnpOgQiIiIiIq3gPQpaduTIEfTp0wdNmzbF3bt3AQBr1qzB0aNHdRwZEREREZHmmCho0datWxEQEAATExOcO3cOz58/BwCkpaVhxowZOo6OiIiIiEhzTBS0aPr06ViyZAmWLVsGQ0NDZXmzZs1w7tw5HUZGRERERJQ/TBS0KDY2Fi1btlQpt7KyQmpqavEHRERERERUQEwUtMjBwQE3btxQKT969CiqVKmig4iIiIiIiAqGiYIWDRw4EKNGjcKpU6cgk8lw7949rFu3DmPGjMGQIUN0HR4RERERkcY4PKoWjR8/HgqFAm3btsWTJ0/QsmVLGBsbY8yYMRgxYoSuwyMiIiIi0hifzFxIf//9N+rUqSN5KnNWVhZu3LiBzMxMeHh4wNzcXIcRahef7EhERFT68PhNBcGuR4XUoEEDPHjwAABQpUoVPHz4EEZGRvDw8IC3t3eZShKIiIiI6N3BrkeFZG1tjfj4eNjZ2SEhIQEKhULXIZVK2QqB0/GPkJLxDHYWcni7lYe+nkzXYVEpwG2HiIioaDBRKKQPPvgAfn5+cHR0hEwmQ6NGjaCvr6+27s2bN4s5utJh98VETN15GYlpz5RljlZyTA7yQGAdRx1GRiUdtx0iIqKiw3sUtGD37t24ceMGRo4ciWnTpsHCwkJtvVGjRhVzZNqn7T6Ouy8mYsjac3h9I8z5PXhxn4Y84SO1uO0QEWmO9yhQQfCKQiH9/fffaN++PQIDA3H27FmMGjUqz0SBpLIVAlN3XlY50QMAgVcnfFN3XkY7Dwd2JSEJbjtERERFjzczF1Lum5kPHz6MrKwsHUdUepyOfyTpMvI6ASAx7RlOxz8qvqCoVOC2Q0REVPSYKBRSzs3MAHgzcz6lZOR9oleQevTu4LZDRERU9Nj1qJB4M3PB2VnItVqP3h3cdoiIiIoeE4VC+uGHH9CtWzflzcwDBw7kPQoa8nYrD0crOZLSnqntay4D4GD1arhLoty47RARERU9JgpaEBgYCAC8mTmf9PVkmBzkgSFrz0EGSE74cm4/nRzkwZtRSQW3HSIioqLHexS0aOXKlUwS8imwjiMW92kIBytpFxEHKzmHt6Q34rZDRERUtPgchULq1q0boqKiYGlpiW7dur2x7rZt24opqqJTVOMw8+m6VFDcdoiI3o7PUaCCYNejQrKysoJMJlP+nwpGX08GX/cKug6DSiFuO0REREWDVxQoX/iLBBERUenD4zcVBK8oaNmDBw+QkJAAmUwGV1dXVKjAXzqJiIiIqPThzcxacunSJbRs2RL29vbw8fGBt7c37Ozs0KZNG1y9elXX4RERERER5QuvKGhBUlIS/Pz8YGtri++++w41a9aEEAKXL1/GsmXL0LJlS1y8eBF2dna6DpWIiIiISCO8R0ELxo0bh/379+PYsWOQy6VDNT59+hTNmzdH+/btERERoaMItYd9HImIiEofHr+pINj1SAv27duHcePGqSQJAGBiYoKxY8diz549OoiMiIiIiKhgmChowc2bN9GwYcM8pzdq1Ag3b94sxoiIiIiIiAqHiYIWZGRkvPEynoWFBTIzM4sxIiIiIiKiwuHNzFqSkZGhtusR8KpfIG8FISIiIqLShFcUtEAIgerVq6NcuXJqXzVq1CjwshcuXAhXV1fI5XL4+Pjg9OnTGs23YcMGyGQydOnSRVKemZmJ4cOHo1KlSjAxMYGHhweWLFlS4PiIiIiIqGziFQUtOHjwYJEsd+PGjQgPD8eSJUvg4+ODyMhIBAQEIDY29o1DrSYkJGDMmDFo0aKFyrTw8HAcOHAAa9euhaurK/bu3YuhQ4fCyckJnTp1KpJ2EBEREVHpw+FRSzAfHx80btwYCxYsAAAoFAo4OztjxIgRGD9+vNp5srOz0bJlS/Tv3x9HjhxBamoqtm/frpxep04d9OjRAxMnTlSWeXl5oUOHDpg+ffpbY+LwakRERKUPj99UEOx6VEJlZWXh7Nmz8Pf3V5bp6enB398fJ06cyHO+adOmwc7ODmFhYWqnN23aFDt27MDdu3chhMDBgwdx7do1tG/fXm3958+fIz09XfIiIiIiorKPXY9KqAcPHiA7Oxv29vaScnt7e1y9elXtPEePHsXy5csRExOT53Lnz5+PQYMGoVKlSjAwMICenp7y6dHqREREYOrUqQVuBxERERGVTryiUEZkZGSgb9++WLZsGWxsbPKsN3/+fJw8eRI7duzA2bNnMWfOHAwbNgz79+9XW3/ChAlIS0tTvu7cuVNUTSAiIiKiEoRXFEooGxsb6OvrIzk5WVKenJwMBwcHlfpxcXFISEhAUFCQskyhUAAADAwMEBsbCycnJ3zxxRf4+eef0bFjRwBAvXr1EBMTg9mzZ0u6OeUwNjaGsbGxNptGRERERKUAryho0cqVK/HkyROtLMvIyAheXl6Ijo5WlikUCkRHR8PX11elfs2aNXHhwgXExMQoX506dULr1q0RExMDZ2dnvHjxAi9evICenvRj19fXVyYVREREREQAryho1fjx4zFq1Ch89NFHCAsLQ9OmTQu1vPDwcISEhKBRo0bw9vZGZGQkHj9+jH79+gEAgoODUbFiRUREREAul6NOnTqS+a2trQFAWW5kZAQ/Pz+MHTsWJiYmcHFxweHDh7F69Wp89913hYqViIiIiMoWJgpadPfuXezcuRNRUVFo1aoVqlSpgn79+iEkJERtd6G36dGjB+7fv49JkyYhKSkJnp6e2L17t/IG59u3b6tcHXibDRs2YMKECfj444/x6NEjuLi44H//+x8++eSTfMdHRERERGUXn6NQRJKTk7F27VqsWrUKV69eRWBgIMLCwhAUFJTvk/uShOMwExERlT48flNBlN4z1hLO3t4ezZs3h6+vL/T09HDhwgWEhITA3d0dhw4d0nV4RERERERvxERBy5KTkzF79mzUrl0brVq1Qnp6On799VfEx8fj7t276N69O0JCQnQdJhERERHRG7HrkRYFBQVhz549qF69OgYMGIDg4GCUL19eUiclJQUODg6ldpQhXrokIiIqfXj8poLgzcxaZGdnh8OHD6sdvjSHra0t4uPjizEqIiIiIqL8Y9cjLfLz80PDhg1VyrOysrB69WoAgEwmg4uLS3GHRkRERESUL+x6pEX6+vpITEyEnZ2dpPzhw4ews7NDdna2jiLTHl66JCIiKn14/KaC4BUFLRJCQCaTqZT/888/sLKy0kFEREREREQFw3sUtKBBgwaQyWSQyWRo27YtDAz+W63Z2dmIj49HYGCgDiMkIiIiIsofJgpa0KVLFwBATEwMAgICYG5urpxmZGQEV1dXfPDBBzqKjoiIiIgo/5goaMHkyZMBAK6urujRowfkcrmOIyIiIiIiKhwmClrEB6kRERERUVnBRKGQypcvj2vXrsHGxgblypVTezNzjkePHhVjZEREREREBcdEoZDmzp0LCwsLAEBkZKRugyEiIiIi0hI+R4HyheMwExERlT48flNB8IqClikUCty4cQMpKSlQKBSSaS1bttRRVERERERE+cNEQYtOnjyJ3r1749atW3j9Qo1MJisTT2YmIiIioncDEwUt+uSTT9CoUSPs2rULjo6Ob7yxmShbIXA6/hFSMp7BzkIOb7fy0NfjNkNEREQlAxMFLbp+/Tq2bNmCqlWr6joUKuF2X0zE1J2XkZj2TFnmaCXH5CAPBNZx1GFkRERERK/o6TqAssTHxwc3btzQdRhUwu2+mIgha89JkgQASEp7hiFrz2H3xUQdRUZERET0H15R0KIRI0bgs88+Q1JSEurWrQtDQ0PJ9Hr16ukoMiopshUCU3dehrqhxgQAGYCpOy+jnYcDuyERERGRTjFR0KIPPvgAANC/f39lmUwmgxCCNzMTAOB0/COVKwm5CQCJac9wOv4RfN0rFF9gRERERK9hoqBF8fHxug7hnVFabwROycg7SShIPSIiIqKiwkRBi1xcXHQdwjuhNN8IbGch12o9IiIioqLCREGLVq9e/cbpwcHBxRRJ2ZVzI/DrffxzbgRe3KdhiU4WvN3Kw9FKjqS0Z2rvU5ABcLB6dYWEiIiISJdk4vUng1GBlStXTvL3ixcv8OTJExgZGcHU1BSPHj3SUWTao8tHwGcrBJrPPJBnH/+ck+yj49qU6G5IOckOAEmykBNxSU92iIio9NHl8ZtKLw6PqkX//vuv5JWZmYnY2Fg0b94c69ev13V4pV5+bgQuyQLrOGJxn4ZwsJJ2L3KwkjNJICIiohKDXY+KWLVq1fDNN9+gT58+uHr1qq7DKdXK0o3AgXUc0c7DoVTekE1ERETvBiYKxcDAwAD37t3TdRilXlm7EVhfT8YhUImIiKjEYqKgRTt27JD8LYRAYmIiFixYgGbNmukoqrKDNwITlQ6ldfhiIiKSYqKgRV26dJH8LZPJYGtrizZt2mDOnDm6CaoM0deTYXKQB4asPQcZ1N8IPDnIgyckRDpUmocvJiIiKY56RPlSEkZN4IkIUcmU1/DFHNGLSPdKwvGbSh9eUdCiadOmYcyYMTA1NZWUP336FLNmzcKkSZN0FFnZwhuBiUqebIXA1J2X1XYLFHiVLEzdeRntPBz4XSUiKiV4RUGL9PX1kZiYCDs7O0n5w4cPYWdnh+zsbB1Fpj38RYKI1DkR9xC9lp18a731A5vwJn4iHeDxmwqCz1HQIiEEZDLVX8r++usvlC/PG2yJqOwqS8MXExHRK+x6pAXlypWDTCaDTCZD9erVJclCdnY2MjMz8cknn+gwQiKiolXWhi8mIiImCloRGRkJIQT69++PqVOnwsrKSjnNyMgIrq6u8PX11WGERERFi8MXExGVPUwUtCAkJAQvX76ETCZDmzZt4OzsrOuQiIiKFYcvJiIqe3iPgpYYGBhgyJAhUCgUug6FiEgnAus4YnGfhnCwknYvcrCSc2hUIqJSiFcUtMjb2xvnz5+Hi4uLrkMhItIJDl9MRFR28IqCFg0dOhSfffYZFixYgBMnTuDvv/+WvApi4cKFcHV1hVwuh4+PD06fPq3RfBs2bIBMJlP7tGh1r1mzZhUoPiKi1+nryeDrXgGdPSvC170CkwQiolKKz1HQIj091bxLJpMph03N73MUNm7ciODgYCxZsgQ+Pj6IjIzE5s2bERsbq/KshtwSEhLQvHlzVKlSBeXLl8f27duV05KSkiR1f//9d4SFheHGjRuoUqXKW2PiOMxERESlD4/fVBBMFLTo1q1bb5ye3y5JPj4+aNy4MRYsWAAAUCgUcHZ2xogRIzB+/Hi182RnZ6Nly5bo378/jhw5gtTUVEmi8LouXbogIyMD0dHRGsXEHQ0REVHpw+M3FQTvUdAibd6bkJWVhbNnz2LChAnKMj09Pfj7++PEiRN5zjdt2jTY2dkhLCwMR44ceeN7JCcnY9euXVi1alWedZ4/f47nz58r/05PT89HK4iIiIiotGKioGVxcXGIjIzElStXAAAeHh4YNWoU3N3d87WcBw8eIDs7G/b29pJye3t7XL16Ve08R48exfLlyxETE6PRe6xatQoWFhbo1q1bnnUiIiIwdepUjeMmIiIiorKBNzNr0Z49e+Dh4YHTp0+jXr16qFevHk6dOoXatWtj3759RfreGRkZ6Nu3L5YtWwYbGxuN5lmxYgU+/vhjyOV5Pyl1woQJSEtLU77u3LmjrZCJiIiIqATjFQUtGj9+PEaPHo1vvvlGpXzcuHFo166dxsuysbGBvr4+kpOTJeXJyclwcHBQqR8XF4eEhAQEBQUpy3Ke6WBgYIDY2FjJVY0jR44gNjYWGzdufGMcxsbGMDY21jhuIiIiIiobeEVBi65cuYKwsDCV8v79++Py5cv5WpaRkRG8vLwkNxkrFApER0fD19dXpX7NmjVx4cIFxMTEKF+dOnVC69atERMTo/K06OXLl8PLywv169fPV1xERERE9G7gFQUtsrW1RUxMDKpVqyYpj4mJeeNwpnkJDw9HSEgIGjVqBG9vb0RGRuLx48fo168fACA4OBgVK1ZEREQE5HI56tSpI5nf2toaAFTK09PTsXnzZsyZMyffMRERERHRu4GJghYNHDgQgwYNws2bN9G0aVMAwLFjxzBz5kyEh4fne3k9evTA/fv3MWnSJCQlJcHT0xO7d+9W3uB8+/Zttc9ueJsNGzZACIFevXrle14iIiIiejfwOQpaJIRAZGQk5syZg3v37gEAnJycMHbsWIwcORIyWel/OinHYSYiIip9ePymgmCiUEQyMjIAABYWFjqORLu4oyEiIip9ePymgmDXoyKQkpKC2NhYAK9uMra1tdVxRERERERE+cNRj7Qo51kGTk5O8PPzg5+fH5ycnNCnTx+kpaXpOjwiIiIiIo0xUdCiAQMG4NSpU9i1axdSU1ORmpqKX3/9FWfOnMHgwYN1HR4RERERkcZ4j4IWmZmZYc+ePWjevLmk/MiRIwgMDMTjx491FJn2sI8jERFR6cPjNxUEryhoUYUKFWBlZaVSbmVlhXLlyukgIiIiIiKigmGioEVfffUVwsPDkZSUpCxLSkrC2LFjMXHiRB1GRkRERESUP+x6pEUNGjTAjRs38Pz5c1SuXBnAq4eiGRsbqzyt+dy5c7oIsdB46ZKIiKj04fGbCoLDo2pRly5ddB0CEREREZFW8IoC5Qt/kSAiIip9ePymguAVhSJw5swZXLlyBQDg4eEBLy8vHUdERERERJQ/TBS06J9//kGvXr1w7NgxWFtbAwBSU1PRtGlTbNiwAZUqVdJtgEREREREGuKoR1o0YMAAvHjxAleuXMGjR4/w6NEjXLlyBQqFAgMGDNB1eEREREREGuM9ClpkYmKC48ePo0GDBpLys2fPokWLFnjy5ImOItMe9nEkIiIqfXj8poLgFQUtcnZ2xosXL1TKs7Oz4eTkpIOIiIiIiIgKhomCFs2aNQsjRozAmTNnlGVnzpzBqFGjMHv2bB1GRkRERESUP+x6pEXlypXDkydP8PLlSxgYvLpPPOf/ZmZmkrqPHj3SRYiFxkuXREREpQ+P31QQHPVIiyIjI3UdAhERERGRVjBR0KKQkBBdh0BEREREpBVMFLTo7t272Lp1K65duwYAqFGjBrp164aKFSvqODIiIiIiovxhoqAlixYtQnh4OLKyspR9/9LT0zF27Fh89913GDp0qI4jJCIiIiLSHEc90oJdu3Zh5MiRGD58OO7evYvU1FSkpqbi7t27GDp0KEaNGoXffvtN12ESEREREWmMox5pQatWrdC8eXNMnz5d7fSvvvoKR48exaFDh4o3sCLAUROIiIhKHx6/qSB4RUELzp07h759++Y5vW/fvjh37lwxRkREREREVDhMFLQgOzsbhoaGeU43NDREdnZ2MUZERERERFQ4TBS0oHbt2vjll1/ynL59+3bUrl27GCMiIiIiIiocjnqkBcOGDcOQIUNgbGyMQYMGSZ7KvHTpUnz11VdYtGiRjqMkIiIiItIcEwUtCAkJwYULFzB8+HBMmDAB7u7uEELg5s2byMzMxMiRIxEaGqrrMImIiIiINMZRj7To5MmTWL9+Pa5fvw4AqF69Onr27IkmTZroODLt4agJREREpQ+P31QQvKKgRU2aNClTSQERERERvbt4MzMREREREalgokBERERERCqYKBARERERkQomCkREREREpIKJAhERERERqeCoR4XUoEEDyGQyjeqeO3euiKMhIiIiItIOJgqF1KVLF12HQERERESkdXzgGuULH9hCRERU+vD4TQXBexSIiIiIiEgFEwUtys7OxuzZs+Ht7Q0HBweUL19e8iqIhQsXwtXVFXK5HD4+Pjh9+rRG823YsAEymUxt16grV66gU6dOsLKygpmZGRo3bozbt28XKD4iIiIiKpuYKGjR1KlT8d1336FHjx5IS0tDeHg4unXrBj09PUyZMiXfy9u4cSPCw8MxefJknDt3DvXr10dAQABSUlLeOF9CQgLGjBmDFi1aqEyLi4tD8+bNUbNmTRw6dAh///03Jk6cCLlcnu/4iIiIiKjs4j0KWuTu7o7vv/8eHTt2hIWFBWJiYpRlJ0+exE8//ZSv5fn4+KBx48ZYsGABAEChUMDZ2RkjRozA+PHj1c6TnZ2Nli1bon///jhy5AhSU1Oxfft25fSePXvC0NAQa9asKVAb2ceRiIio9OHxmwqCVxS0KCkpCXXr1gUAmJubIy0tDQDw/vvvY9euXflaVlZWFs6ePQt/f39lmZ6eHvz9/XHixIk855s2bRrs7OwQFhamMk2hUGDXrl2oXr06AgICYGdnBx8fH0ki8brnz58jPT1d8iIiIiKiso+JghZVqlQJiYmJAF5dXdi7dy8A4M8//4SxsXG+lvXgwQNkZ2fD3t5eUm5vb4+kpCS18xw9ehTLly/HsmXL1E5PSUlBZmYmvvnmGwQGBmLv3r3o2rUrunXrhsOHD6udJyIiAlZWVsqXs7NzvtpBRERERKUTEwUt6tq1K6KjowEAI0aMwMSJE1GtWjUEBwejf//+RfreGRkZ6Nu3L5YtWwYbGxu1dRQKBQCgc+fOGD16NDw9PTF+/Hi8//77WLJkidp5JkyYgLS0NOXrzp07RdYGIiIiIio5+MA1Lfrmm2+U/+/RowcqV66MEydOoFq1aggKCsrXsmxsbKCvr4/k5GRJeXJyMhwcHFTqx8XFISEhQfI+OYmBgYEBYmNj4ezsDAMDA3h4eEjmrVWrFo4ePao2DmNj43xfDSEiIiKi0o+JQhHy9fWFr69vgeY1MjKCl5cXoqOjlUOcKhQKREdHY/jw4Sr1a9asiQsXLkjKvvrqK2RkZGDevHlwdnaGkZERGjdujNjYWEm9a9euwcXFpUBxEhEREVHZxERBi1avXv3G6cHBwflaXnh4OEJCQtCoUSN4e3sjMjISjx8/Rr9+/ZTLq1ixIiIiIiCXy1GnTh3J/NbW1gAgKR87dix69OiBli1bonXr1ti9ezd27tyJQ4cO5Ss2IiIiIirbmCho0ahRoyR/v3jxAk+ePIGRkRFMTU3znSj06NED9+/fx6RJk5CUlARPT0/s3r1beYPz7du3oaeXv9tMunbtiiVLliAiIgIjR45EjRo1sHXrVjRv3jxfyyEiIiKiso3PUShi169fx5AhQzB27FgEBAToOpxC4zjMREREpQ+P31QQHPWoiFWrVg3ffPONytUGIiIiIqKSjIlCMTAwMMC9e/d0HQYRERERkcZ4j4IW7dixQ/K3EAKJiYlYsGABmjVrpqOoiIiIiIjyj4mCFuUMY5pDJpPB1tYWbdq0wZw5c3QTFBERERFRATBR0KKcB5wREREREZV2vEeBiIiIiIhU8IqCFoWHh2tc97vvvivCSIiIiIiICoeJghadP38e58+fx4sXL1CjRg0AwLVr16Cvr4+GDRsq68lkMl2FSERERESkESYKWhQUFAQLCwusWrUK5cqVAwD8+++/6NevH1q0aIHPPvtMxxESEREREWmGT2bWoooVK2Lv3r2oXbu2pPzixYto3759mXiWAp/sSEREVPrw+E0FwZuZtSg9PR33799XKb9//z4yMjJ0EBERERERUcEwUdCirl27ol+/fti2bRv++ecf/PPPP9i6dSvCwsLQrVs3XYdHRERERKQx3qOgRUuWLMGYMWPQu3dvvHjxAgBgYGCAsLAwzJo1S8fRERERERFpjvcoFIHHjx8jLi4OAODu7g4zMzMdR6Q97ONIRERU+vD4TQXBKwpFwMzMDPXq1ZOUpaSkwM7OTkcRERERERHlD+9R0AJTU1PJTcwdO3ZEYmKi8u/k5GQ4OjrqIjQiIiIiogJhoqAFz549Q+4eXH/88QeePn0qqcMeXkRERERUmjBRKCZ8GjMRERERlSZMFIiIiIiISAUTBS2QyWSSKwav/01EREREVNpw1CMtEEKgevXqyuQgMzMTDRo0gJ6ennI6EREREVFpwkRBC1auXKnrEIiIiIiItIqJghaEhIToOgQiIiIiIq3iPQpERERERKSCiQIREREREalgokBERERERCqYKBARERERkQomCkREREREpIKjHmlRdnY2oqKiEB0djZSUFCgUCsn0AwcO6CgyIiIiIqL8YaKgRaNGjUJUVBQ6duyIOnXq8OnMRERERFRqMVHQog0bNmDTpk147733dB0KEREREVGh8B4FLTIyMkLVqlV1HQYRERERUaExUdCizz77DPPmzYMQQtehEBEREREVCrseadHRo0dx8OBB/P7776hduzYMDQ0l07dt26ajyIiIiIiI8oeJghZZW1uja9euug6DiIiIiKjQmCho0cqVK3UdAhERERGRVvAeBSIiIiIiUsErClq2ZcsWbNq0Cbdv30ZWVpZk2rlz53QUFRERERFR/vCKghZ9//336NevH+zt7XH+/Hl4e3ujQoUKuHnzJjp06KDr8IiIiIiINMZEQYsWLVqEH374AfPnz4eRkRE+//xz7Nu3DyNHjkRaWlqBlrlw4UK4urpCLpfDx8cHp0+f1mi+DRs2QCaToUuXLpLy0NBQyGQyySswMLBAsRERERFR2cVEQYtu376Npk2bAgBMTEyQkZEBAOjbty/Wr1+f7+Vt3LgR4eHhmDx5Ms6dO4f69esjICAAKSkpb5wvISEBY8aMQYsWLdRODwwMRGJiovJVkNiIiIiIqGxjoqBFDg4OePToEQCgcuXKOHnyJAAgPj6+QA9h++677zBw4ED069cPHh4eWLJkCUxNTbFixYo858nOzsbHH3+MqVOnokqVKmrrGBsbw8HBQfkqV65cvmMjIiIiorKNiYIWtWnTBjt27AAA9OvXD6NHj0a7du3Qo0ePfD9fISsrC2fPnoW/v7+yTE9PD/7+/jhx4kSe802bNg12dnYICwvLs86hQ4dgZ2eHGjVqYMiQIXj48GGedZ8/f4709HTJi4iIiIjKPo56pEU//PADFAoFAGDYsGGoUKECjh8/jk6dOmHw4MH5WtaDBw+QnZ0Ne3t7Sbm9vT2uXr2qdp6jR49i+fLliImJyXO5gYGB6NatG9zc3BAXF4cvvvgCHTp0wIkTJ6Cvr69SPyIiAlOnTs1X7ERERERU+jFR0CI9PT3o6f13kaZnz57o2bNnsbx3RkYG+vbti2XLlsHGxibPernjqVu3LurVqwd3d3ccOnQIbdu2Vak/YcIEhIeHK/9OT0+Hs7OzdoMnIiIiohKHiYKWHTlyBEuXLkVcXBy2bNmCihUrYs2aNXBzc0Pz5s01Xo6NjQ309fWRnJwsKU9OToaDg4NK/bi4OCQkJCAoKEhZlnN1w8DAALGxsXB3d1eZr0qVKrCxscGNGzfUJgrGxsYwNjbWOG4iIiIiKht4j4IWbd26FQEBATAxMcH58+fx/PlzAEBaWhpmzJiRr2UZGRnBy8sL0dHRyjKFQoHo6Gj4+vqq1K9ZsyYuXLiAmJgY5atTp05o3bo1YmJi8rwK8M8//+Dhw4dwdHTMV3xEREREVLYxUdCi6dOnY8mSJVi2bBkMDQ2V5c2aNSvQU5nDw8OxbNkyrFq1CleuXMGQIUPw+PFj9OvXDwAQHByMCRMmAADkcjnq1KkjeVlbW8PCwgJ16tSBkZERMjMzMXbsWJw8eRIJCQmIjo5G586dUbVqVQQEBGhnJRARERFRmcCuR1oUGxuLli1bqpRbWVkhNTU138vr0aMH7t+/j0mTJiEpKQmenp7YvXu38gbn27dvS+6JeBt9fX38/fffWLVqFVJTU+Hk5IT27dvj66+/ZvciIiIiIpJgoqBFDg4OuHHjBlxdXSXlR48ezfOZBm8zfPhwDB8+XO20Q4cOvXHeqKgoyd8mJibYs2dPgeIgIiIioncLux5p0cCBAzFq1CicOnUKMpkM9+7dw7p16zBmzBgMGTJE1+EREREREWmMVxS0aPz48VAoFGjbti2ePHmCli1bwtjYGGPGjMGIESN0HR4RERERkcZkQgih6yDKmqysLNy4cQOZmZnw8PCAubm5rkPSmvT0dFhZWSEtLQ2Wlpa6DoeIiIg0wOM3FQSvKBQBIyMjeHh46DoMIiIiIqICY6KgBf3799eo3ooVK4o4EiIiIiIi7WCioAVRUVFwcXFBgwYNwJ5cRERERFQWMFHQgiFDhmD9+vWIj49Hv3790KdPH5QvX17XYRERERERFRiHR9WChQsXIjExEZ9//jl27twJZ2dndO/eHXv27OEVBiIiIiIqlTjqURG4desWoqKisHr1arx8+RKXLl0qMyMfcdQEIiKi0ofHbyoIXlEoAnp6epDJZBBCIDs7W9fhEBERERHlGxMFLXn+/DnWr1+Pdu3aoXr16rhw4QIWLFiA27dvl5mrCURERET07uDNzFowdOhQbNiwAc7Ozujfvz/Wr18PGxsbXYdFRERERFRgvEdBC/T09FC5cmU0aNAAMpksz3rbtm0rxqiKBvs4EhERlT48flNB8IqCFgQHB78xQSAiIiIiKm2YKGhBVFSUrkMgIiIiItIq3sxMREREREQqmCgQEREREZEKJgpERERERKSCiQIREREREalgokBERERERCqYKBARERERkQomCkREREREpIKJAhERERERqWCiQEREREREKpgoEBERERGRCiYKRERERESkgokCERERERGpYKJAREREREQqmCgQEREREZEKJgpERERERKSCiQIREREREalgokBERERERCqYKBARERERkQomCkREREREpIKJAhERERERqWCiQEREREREKpgoEBERERGRCiYKRERERESkgokCERERERGpYKJQwi1cuBCurq6Qy+Xw8fHB6dOnNZpvw4YNkMlk6NKlS551PvnkE8hkMkRGRmonWCIiIiIqM5golGAbN25EeHg4Jk+ejHPnzqF+/foICAhASkrKG+dLSEjAmDFj0KJFizzr/Pzzzzh58iScnJy0HTYRERERlQFMFEqw7777DgMHDkS/fv3g4eGBJUuWwNTUFCtWrMhznuzsbHz88ceYOnUqqlSporbO3bt3MWLECKxbtw6GhoZFFT4RERERlWJMFEqorKwsnD17Fv7+/soyPT09+Pv748SJE3nON23aNNjZ2SEsLEztdIVCgb59+2Ls2LGoXbv2W+N4/vw50tPTJS8iIiIiKvuYKJRQDx48QHZ2Nuzt7SXl9vb2SEpKUjvP0aNHsXz5cixbtizP5c6cORMGBgYYOXKkRnFERETAyspK+XJ2dta8EURERERUajFRKCMyMjLQt29fLFu2DDY2NmrrnD17FvPmzUNUVBRkMplGy50wYQLS0tKUrzt37mgzbCIiIiIqoQx0HQCpZ2NjA319fSQnJ0vKk5OT4eDgoFI/Li4OCQkJCAoKUpYpFAoAgIGBAWJjY3HkyBGkpKSgcuXKyjrZ2dn47LPPEBkZiYSEBJXlGhsbw9jYWEutIiIiIqLSgolCCWVkZAQvLy9ER0crhzhVKBSIjo7G8OHDVerXrFkTFy5ckJR99dVXyMjIwLx58+Ds7Iy+fftK7nkAgICAAPTt2xf9+vUrsrYQERERUenDRKEECw8PR0hICBo1agRvb29ERkbi8ePHypP64OBgVKxYEREREZDL5ahTp45kfmtrawBQlleoUAEVKlSQ1DE0NISDgwNq1KhR9A0iIiIiolKDiUIJ1qNHD9y/fx+TJk1CUlISPD09sXv3buUNzrdv34aeHm8zISIiIiLtkwkhhK6DoNIjPT0dVlZWSEtLg6Wlpa7DISIiIg3w+E0FwZ+jiYiIiIhIBRMFIiIiIiJSwUSBiIiIiIhUMFEgIiIiIiIVHPWIiIiIqATIVgicjn+ElIxnsLOQw9utPPT1ZLoOi95hTBSIiIiIdGz3xURM3XkZiWnPlGWOVnJMDvJAYB1HHUZG7zJ2PSIiIiLSod0XEzFk7TlJkgAASWnPMGTtOey+mKijyOhdx0SBiIiISEeyFQJTd16Guoda5ZRN3XkZ2Qo+9oqKHxMFIiIiIh05Hf9I5UpCbgJAYtoznI5/VHxBEf0/JgpEREREOpKSkXeSUJB6RNrERIGIiIhIR+ws5FqtR6RNTBSIiIiIdMTbrTwcreTIaxBUGV6NfuTtVr44wyICwESBiIiISGf09WSYHOQBACrJQs7fk4M8+DwF0gkmCkREREQ6FFjHEYv7NISDlbR7kYOVHIv7NORzFEhn+MA1IiIiIh0LrOOIdh4OfDIzlShMFIiIiIhKAH09GXzdK+g6DCIldj0iIiIiIiIVTBSIiIiIiEgFEwUiIiIiIlLBRIGIiIiIiFQwUSAiIiIiIhVMFIiIiIiISAUTBSIiIiIiUsFEgYiIiIiIVDBRICIiIiIiFXwyM+WLEAIAkJ6eruNIiIiISFM5x+2c4ziRJpgoUL5kZGQAAJydnXUcCREREeVXRkYGrKysdB0GlRIywdSS8kGhUODevXuwsLCATCbTaSzp6elwdnbGnTt3YGlpqdNYitO72m6AbWfb2fZ3xbvabqDo2i6EQEZGBpycnKCnx57npBleUaB80dPTQ6VKlXQdhoSlpeU7dyAB3t12A2w72/7ueVfb/q62GyiatvNKAuUXU0oiIiIiIlLBRIGIiIiIiFQwUaBSy9jYGJMnT4axsbGuQylW72q7AbadbWfb3xXvaruBd7vtVPLwZmYiIiIiIlLBKwpERERERKSCiQIREREREalgokBERERERCqYKBARERERkQomClRiLFy4EK6urpDL5fDx8cHp06fzrLtt2zY0atQI1tbWMDMzg6enJ9asWaNS78qVK+jUqROsrKxgZmaGxo0b4/bt20XZjALRdttlMpna16xZs4q6Kfmm7bZnZmZi+PDhqFSpEkxMTODh4YElS5YUdTMKRNttT05ORmhoKJycnGBqaorAwEBcv369qJuRb/lpd24bNmyATCZDly5dJOVCCEyaNAmOjo4wMTGBv79/iWw3oP22b9u2De3bt0eFChUgk8kQExOj/aC1RJttf/HiBcaNG4e6devCzMwMTk5OCA4Oxr1794oo+sLR9uc+ZcoU1KxZE2ZmZihXrhz8/f1x6tSpIoic3nmCqATYsGGDMDIyEitWrBCXLl0SAwcOFNbW1iI5OVlt/YMHD4pt27aJy5cvixs3bojIyEihr68vdu/eraxz48YNUb58eTF27Fhx7tw5cePGDfHLL7/kuUxdKYq2JyYmSl4rVqwQMplMxMXFFVezNFIUbR84cKBwd3cXBw8eFPHx8WLp0qVCX19f/PLLL8XVLI1ou+0KhUI0adJEtGjRQpw+fVpcvXpVDBo0SFSuXFlkZmYWZ9PeKL/tzhEfHy8qVqwoWrRoITp37iyZ9s033wgrKyuxfft28ddff4lOnToJNzc38fTp0yJsSf4VRdtXr14tpk6dKpYtWyYAiPPnzxddAwpB221PTU0V/v7+YuPGjeLq1avixIkTwtvbW3h5eRVxS/KvKD73devWiX379om4uDhx8eJFERYWJiwtLUVKSkoRtoTeRUwUqETw9vYWw4YNU/6dnZ0tnJycREREhMbLaNCggfjqq6+Uf/fo0UP06dNHq3EWhaJo++s6d+4s2rRpU6g4i0JRtL127dpi2rRpkjoNGzYUX375ZeED1iJttz02NlYAEBcvXpQs09bWVixbtkx7gRdSQdr98uVL0bRpU/Hjjz+KkJAQyUmTQqEQDg4OYtasWcqy1NRUYWxsLNavX18kbSgobbc9t/j4+BKdKBRl23OcPn1aABC3bt3SVthaURxtT0tLEwDE/v37tRU2kRBCCHY9Ip3LysrC2bNn4e/vryzT09ODv78/Tpw48db5hRCIjo5GbGwsWrZsCQBQKBTYtWsXqlevjoCAANjZ2cHHxwfbt28vqmYUSFG0/XXJycnYtWsXwsLCtBa3NhRV25s2bYodO3bg7t27EELg4MGDuHbtGtq3b18k7SiIomj78+fPAQByuVyyTGNjYxw9elTLLSiYgrZ72rRpsLOzU7sNx8fHIykpSbJMKysr+Pj4aLQui0tRtL20KK62p6WlQSaTwdraurAha01xtD0rKws//PADrKysUL9+fa3ETZTDQNcBED148ADZ2dmwt7eXlNvb2+Pq1at5zpeWloaKFSvi+fPn0NfXx6JFi9CuXTsAQEpKCjIzM/HNN99g+vTpmDlzJnbv3o1u3brh4MGD8PPzK9I2aaoo2v66VatWwcLCAt26ddNq7IVVVG2fP38+Bg0ahEqVKsHAwAB6enpYtmxZnomULhRF22vWrInKlStjwoQJWLp0KczMzDB37lz8888/SExMLNL2aKog7T569CiWL1+eZ9/7pKQk5TJeX2bOtJKgKNpeWhRH2589e4Zx48ahV69esLS0LGzIWlOUbf/111/Rs2dPPHnyBI6Ojti3bx9sbGy0FToRACYKVIpZWFggJiYGmZmZiI6ORnh4OKpUqYJWrVpBoVAAADp37ozRo0cDADw9PXH8+HEsWbKkxCQKBfWmtr9uxYoV+PjjjyW/NJdmb2v7/PnzcfLkSezYsQMuLi74448/MGzYMDg5OUl+1SuN3tR2Q0NDbNu2DWFhYShfvjz09fXh7++PDh06QAih69ALJCMjA3379sWyZcveuRMgtl3ztr948QLdu3eHEAKLFy8uhgiLTn7a3rp1a8TExODBgwdYtmwZunfvjlOnTsHOzq6YoqV3ARMF0jkbGxvo6+sjOTlZUp6cnAwHB4c859PT00PVqlUBvEoCrly5goiICLRq1Qo2NjYwMDCAh4eHZJ5atWqVmG4YQNG0PbcjR44gNjYWGzdu1HrshVUUbX/69Cm++OIL/Pzzz+jYsSMAoF69eoiJicHs2bNLTKJQVJ+7l5cXYmJikJaWhqysLNja2sLHxweNGjUqsrbkR37bHRcXh4SEBAQFBSnLcn4EMDAwQGxsrHK+5ORkODo6Spbp6elZBK0omKJou7u7e9EGrSVF2facJOHWrVs4cOBAibqaABRt283MzFC1alVUrVoVTZo0QbVq1bB8+XJMmDChCFtE7xreo0A6Z2RkBC8vL0RHRyvLFAoFoqOj4evrq/FyFAqFsp+2kZERGjdujNjYWEmda9euwcXFRTuBa0FRtD235cuXw8vLq0T2Wy2Ktr948QIvXryAnp5016avr6882JYERf25W1lZwdbWFtevX8eZM2fQuXNnrcRdWPltd82aNXHhwgXExMQoX506dVL+kurs7Aw3Nzc4ODhIlpmeno5Tp07la10WtaJoe2lRVG3PSRKuX7+O/fv3o0KFCsXWJk0V5+ee1/6AqFB0eCM1kdKGDRuEsbGxiIqKEpcvXxaDBg0S1tbWIikpSQghRN++fcX48eOV9WfMmCH27t0r4uLixOXLl8Xs2bOFgYGBZHSXbdu2CUNDQ/HDDz+I69evi/nz5wt9fX1x5MiRYm/fmxRF24V4NQqGqampWLx4cbG2Jz+Kou1+fn6idu3a4uDBg+LmzZti5cqVQi6Xi0WLFhV7+96kKNq+adMmcfDgQREXFye2b98uXFxcRLdu3Yq9bW+S33a/Tt0IMN98842wtrYWv/zyi/j7779F586dS+zwqNpu+8OHD8X58+fFrl27BACxYcMGcf78eZGYmFiUTck3bbc9KytLdOrUSVSqVEnExMRIhoN+/vx5UTcnX7Td9szMTDFhwgRx4sQJkZCQIM6cOSP69esnjI2NJaOeEWkDEwUqMebPny8qV64sjIyMhLe3tzh58qRymp+fnwgJCVH+/eWXX4qqVasKuVwuypUrJ3x9fcWGDRtUlrl8+XJlvfr164vt27cXR1PyrSjavnTpUmFiYiJSU1OLowkFpu22JyYmitDQUOHk5CTkcrmoUaOGmDNnjlAoFMXVJI1pu+3z5s0TlSpVEoaGhqJy5criq6++KnEnTULkr92vU3eyrFAoxMSJE4W9vb0wNjYWbdu2FbGxsUUUfeFou+0rV64UAFRekydPLpoGFII2254zHKy618GDB4uuEQWkzbY/ffpUdO3aVTg5OQkjIyPh6OgoOnXqJE6fPl2ELaB3lUyIUnqXGxERERERFRneo0BERERERCqYKBARERERkQomCkREREREpIKJAhERERERqWCiQEREREREKpgoEBERERGRCiYKRERERESkgokCEVEp4+rqisjISF2HoSIqKgrW1ta6DoOIiLSEiQIRlXqhoaGQyWT45JNPVKYNGzYMMpkMoaGhxR/Ya6KioiCTyVRecrk8X8v5888/MWjQII3qFmdS0aNHD1y7dq3A82tr/chkMmzfvr3AcRAR0SsGug6AiEgbnJ2dsWHDBsydOxcmJiYAgGfPnuGnn35C5cqVdRzdfywtLREbGyspk8lk+VqGra2tNkPSGhMTE+W6LyhtrB9NZGVlwcjISOvLJSIqS3hFgYjKhIYNG8LZ2Rnbtm1Tlm3btg2VK1dGgwYNJHUVCgUiIiLg5uYGExMT1K9fH1u2bFFOz87ORlhYmHJ6jRo1MG/ePMkyQkND0aVLF8yePRuOjo6oUKEChg0bhhcvXrwxTplMBgcHB8nL3t5eOb1Vq1YYPnw4hg8fDisrK9jY2GDixIkQQijr5L5KIITAlClTULlyZRgbG8PJyQkjR45ULuvWrVsYPXq08tf5HEePHkWLFi1gYmICZ2dnjBw5Eo8fP5a8x/Tp0xEcHAxzc3O4uLhgx44duH//Pjp37gxzc3PUq1cPZ86cUc6jruvRzp070bhxY8jlctjY2KBr166FXj8jR47E559/jvLly8PBwQFTpkyRxA0AXbt2hUwmU/49ZcoUeHp64scff4Sbm5vyKsXt27eV7bG0tET37t2RnJysXF7OfEuXLoWzszNMTU3RvXt3pKWlAQD++OMPGBoaIikpSdKOTz/9FC1atHhjW4mISjomCkRUZvTv3x8rV65U/r1ixQr069dPpV5ERARWr16NJUuW4NKlSxg9ejT69OmDw4cPA3iVSFSqVAmbN2/G5cuXMWnSJHzxxRfYtGmTZDkHDx5EXFwcDh48iFWrViEqKgpRUVGFbseqVatgYGCA06dPY968efjuu+/w448/qq27detWzJ07F0uXLsX169exfft21K1bF8CrRKlSpUqYNm0aEhMTkZiYCACIi4tDYGAgPvjgA/z999/YuHEjjh49iuHDh0uWPXfuXDRr1gznz59Hx44d0bdvXwQHB6NPnz44d+4c3N3dERwcLElictu1axe6du2K9957D+fPn0d0dDS8vb21sn7MzMxw6tQpfPvtt5g2bRr27dsH4FW3LABYuXIlEhMTlX8DwI0bN7B161Zs27YNMTExUCgU6Ny5Mx49eoTDhw9j3759uHnzJnr06CF5vxs3bmDTpk3YuXMndu/ejfPnz2Po0KEAgJYtW6JKlSpYs2aNsv6LFy+wbt069O/fv9BtJSLSKUFEVMqFhISIzp07i5SUFGFsbCwSEhJEQkKCkMvl4v79+6Jz584iJCRECCHEs2fPhKmpqTh+/LhkGWFhYaJXr155vsewYcPEBx98IHlPFxcX8fLlS2XZRx99JHr06JHnMlauXCkACDMzM8krMDBQWcfPz0/UqlVLKBQKZdm4ceNErVq1lH+7uLiIuXPnCiGEmDNnjqhevbrIyspS+5656+Zu66BBgyRlR44cEXp6euLp06fK+fr06aOcnpiYKACIiRMnKstOnDghAIjExERl+6ysrJTTfX19xccff5zn+nidpuunefPmkvkaN24sxo0bp/wbgPj5558ldSZPniwMDQ1FSkqKsmzv3r1CX19f3L59W1l26dIlAUCcPn1aOZ++vr74559/lHV+//13oaenp2z3zJkzJZ/P1q1bhbm5ucjMzNS47UREJRHvUSCiMsPW1hYdO3ZEVFQUhBDo2LEjbGxsJHVu3LiBJ0+eoF27dpLyrKwsSRelhQsXYsWKFbh9+zaePn2KrKwseHp6SuapXbs29PX1lX87OjriwoULb4zRwsIC586dk5S93q+/SZMmkm5Cvr6+mDNnDrKzsyXvBwAfffQRIiMjUaVKFQQGBuK9995DUFAQDAzy3r3/9ddf+Pvvv7Fu3TplmRACCoUC8fHxqFWrFgCgXr16yuk53X9yrlbkLktJSYGDg4PK+8TExGDgwIF5xqGOJusnd1zAq/WekpLy1mW7uLhI7u+4cuUKnJ2d4ezsrCzz8PCAtbU1rly5gsaNGwMAKleujIoVKyrr+Pr6QqFQIDY2Fg4ODggNDcVXX32FkydPokmTJoiKikL37t1hZmamecOJiEogJgpEVKb0799f2YVm4cKFKtMzMzMBvOoWk/vkDwCMjY0BABs2bMCYMWMwZ84c+Pr6wsLCArNmzcKpU6ck9Q0NDSV/y2QyKBSKN8anp6eHqlWr5q9Rb+Ds7IzY2Fjs378f+/btw9ChQzFr1iwcPnxYJb4cmZmZGDx4sPJehtxy3/ide/6cxEVdWV5tLsiNzZqsn4KsdwBFduJuZ2eHoKAgrFy5Em5ubvj9999x6NChInkvIqLixESBiMqUwMBAZGVlQSaTISAgQGW6h4cHjI2Ncfv2bfj5+aldxrFjx9C0aVNlP3TgVb/+4vJ6QnLy5ElUq1ZN5WpCDhMTEwQFBSEoKAjDhg1DzZo1ceHCBTRs2BBGRkbIzs6W1G/YsCEuX76s1YRFnXr16iE6OlrtfSJFydDQUKXN6tSqVQt37tzBnTt3lFcVLl++jNTUVHh4eCjr3b59G/fu3YOTkxOAV5+Hnp4eatSooawzYMAA9OrVC5UqVYK7uzuaNWum5VYRERU/JgpEVKbo6+vjypUryv+/zsLCAmPGjMHo0aOhUCjQvHlzpKWl4dixY7C0tERISAiqVauG1atXY8+ePXBzc8OaNWvw559/ws3NrdDxCSFURsgBXv0qraf3anyJ27dvIzw8HIMHD8a5c+cwf/58zJkzR+3yoqKikJ2dDR8fH5iammLt2rUwMTGBi4sLgFejAP3xxx/o2bMnjI2NYWNjg3HjxqFJkyYYPnw4BgwYADMzM1y+fBn79u3DggULCt3GHJMnT0bbtm3h7u6Onj174uXLl/jtt98wbty4POfRZP28jaurK6Kjo9GsWTMYGxujXLlyauv5+/ujbt26+PjjjxEZGYmXL19i6NCh8PPzQ6NGjZT15HI5QkJCMHv2bKSnp2PkyJHo3r27pLtVQEAALC0tMX36dEybNk2jOImISjqOekREZY6lpSUsLS3znP71119j4sSJiIiIQK1atRAYGIhdu3YpE4HBgwejW7du6NGjB3x8fPDw4UPJ1YXCSE9Ph6Ojo8ordx/74OBgPH36FN7e3hg2bBhGjRqV5wPWrK2tsWzZMjRr1gz16tXD/v37sXPnTlSoUAEAMG3aNCQkJMDd3V3ZP79evXo4fPgwrl27hhYtWqBBgwaYNGmS8hdzbWnVqhU2b96MHTt2wNPTE23atMHp06ffOI8m6+dt5syZg3379sHZ2VllaNzcZDIZfvnlF5QrVw4tW7aEv78/qlSpgo0bN0rqVa1aFd26dcN7772H9u3bo169eli0aJGkjp6eHkJDQ5GdnY3g4GCNYyUiKslkQuQxrh0RERW7Vq1awdPTs9iepkxvNmXKFGzfvh0xMTFvrRsWFob79+9jx44dRR8YEVExYNcjIiKiQkhLS8OFCxfw008/MUkgojKFiQIREVEhdO7cGadPn8Ynn3yiMuwuEVFpxq5HRERERESkgjczExERERGRCiYKRERERESkgokCERERERGpYKJAREREREQqmCgQEREREZEKJgpERERERKSCiQIREREREalgokBERERERCqYKBARERERkYr/A3tLVh6JMZ4EAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot epistemic entropy as x-axis and equal opportunity difference as y-axis for ensemble dropout model\n",
    "plt.scatter(np.mean(epi_entropy_ensemble_dropout, axis=1), Equal_opp_diffs_ensemble_dropout, label='ensemble dropout model')\n",
    "plt.xlabel('Mean Epistemic Entropy')\n",
    "plt.ylabel('Mean Equal Opportunity Difference')\n",
    "plt.title('Mean Equal Opportunity Difference vs Mean Epistemic Entropy of Ensemble Dropout Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to pickle file\n",
    "import pickle\n",
    "\n",
    "with open('adult_results/ale_entropy_ensemble_dropout_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(ale_entropy_ensemble_dropout, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('adult_results/epi_entropy_ensemble_dropout_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(epi_entropy_ensemble_dropout, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# #load pickle file\n",
    "# import pickle\n",
    "\n",
    "# with open('adult_results/ale_entropy_ensemble_dropout_dict.pickle', 'rb') as handle:\n",
    "#     ale_entropy_ensemble_dropout = pickle.load(handle)\n",
    "\n",
    "# with open('adult_results/epi_entropy_ensemble_dropout_dict.pickle', 'rb') as handle:\n",
    "#     epi_entropy_ensemble_dropout = pickle.load(handle)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
